[
  {
    "title": "Mission Impossible: A Statistical Perspective on Jailbreaking LLMs",
    "authors": "Jingtong Su, Julia Kempe, Karen Ullrich",
    "abstract": "Large language models (LLMs) are trained on a deluge of text data with\nlimited quality control. As a result, LLMs can exhibit unintended or even\nharmful behaviours, such as leaking information, fake news or hate speech.\nCountermeasures, commonly referred to as preference alignment, include\nfine-tuning the pretrained LLMs with carefully crafted text examples of desired\nbehaviour. Even then, empirical evidence shows preference aligned LLMs can be\nenticed to harmful behaviour. This so called jailbreaking of LLMs is typically\nachieved by adversarially modifying the input prompt to the LLM. Our paper\nprovides theoretical insights into the phenomenon of preference alignment and\njailbreaking from a statistical perspective. Under our framework, we first show\nthat pretrained LLMs will mimic harmful behaviour if present in the training\ncorpus. Under that same framework, we then introduce a statistical notion of\nalignment, and lower-bound the jailbreaking probability, showing that it is\nunpreventable under reasonable assumptions. Based on our insights, we propose\nan alteration to the currently prevalent alignment strategy RLHF. Specifically,\nwe introduce a simple modification to the RLHF objective, we call E-RLHF, that\naims to increase the likelihood of safe responses. E-RLHF brings no additional\ntraining cost, and is compatible with other methods. Empirically, we\ndemonstrate that E-RLHF outperforms RLHF on all alignment problems put forward\nby the AdvBench and HarmBench project without sacrificing model performance as\nmeasured by the MT-Bench project.",
    "arxiv_id": "http://arxiv.org/abs/2408.01420v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01420v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Talk Less, Interact Better: Evaluating In-context Conversational Adaptation in Multimodal LLMs",
    "authors": "Yilun Hua, Yoav Artzi",
    "abstract": "Humans spontaneously use increasingly efficient language as interactions\nprogress, by adapting and forming ad-hoc conventions. This phenomenon has been\nstudied extensively using reference games, showing properties of human language\nthat go beyond relaying intents. It remains unexplored whether multimodal large\nlanguage models (MLLMs) similarly increase communication efficiency during\ninteractions, and what mechanisms they may adopt for this purpose. We introduce\nICCA, an automated framework to evaluate such conversational adaptation as an\nin-context behavior in MLLMs. We evaluate several state-of-the-art MLLMs, and\nobserve that while they may understand the increasingly efficient language of\ntheir interlocutor, they do not spontaneously make their own language more\nefficient over time. This latter ability can only be elicited in some models\n(e.g., GPT-4) with heavy-handed prompting. This shows that this property of\nlinguistic interaction does not arise from current training regimes, even\nthough it is a common hallmark of human language. ICCA is available at\nhttps://github.com/lil-lab/ICCA.",
    "arxiv_id": "http://arxiv.org/abs/2408.01417v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01417v1",
    "primary_category": "cs.CL",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Conditional LoRA Parameter Generation",
    "authors": "Xiaolong Jin, Kai Wang, Dongwen Tang, Wangbo Zhao, Yukun Zhou, Junshu Tang, Yang You",
    "abstract": "Generative models have achieved remarkable success in image, video, and text\ndomains. Inspired by this, researchers have explored utilizing generative\nmodels to generate neural network parameters. However, these efforts have been\nlimited by the parameter size and the practicality of generating\nhigh-performance parameters. In this paper, we propose COND P-DIFF, a novel\napproach that demonstrates the feasibility of controllable high-performance\nparameter generation, particularly for LoRA (Low-Rank Adaptation) weights,\nduring the fine-tuning process. Specifically, we employ an autoencoder to\nextract efficient latent representations for parameters. We then train a\nconditional latent diffusion model to synthesize high-performing model\nparameters from random noise based on specific task conditions. Experimental\nresults in both computer vision and natural language processing domains\nconsistently demonstrate that COND P-DIFF can generate high-performance\nparameters conditioned on the given task. Moreover, we observe that the\nparameter distribution generated by COND P-DIFF exhibits differences compared\nto the distribution obtained through normal optimization methods, indicating a\ncertain level of generalization capability. Our work paves the way for further\nexploration of condition-driven parameter generation, offering a promising\ndirection for task-specific adaptation of neural networks.",
    "arxiv_id": "http://arxiv.org/abs/2408.01415v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01415v1",
    "primary_category": "cs.AI",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Pre-trained Language Models Improve the Few-shot Prompt Ability of Decision Transformer",
    "authors": "Yu Yang, Pan Xu",
    "abstract": "Decision Transformer (DT) has emerged as a promising class of algorithms in\noffline reinforcement learning (RL) tasks, leveraging pre-collected datasets\nand Transformer's capability to model long sequences. Recent works have\ndemonstrated that using parts of trajectories from training tasks as prompts in\nDT enhances its performance on unseen tasks, giving rise to Prompt-DT methods.\nHowever, collecting data from specific environments can be both costly and\nunsafe in many scenarios, leading to suboptimal performance and limited\nfew-shot prompt abilities due to the data-hungry nature of Transformer-based\nmodels. Additionally, the limited datasets used in pre-training make it\nchallenging for Prompt-DT type of methods to distinguish between various RL\ntasks through prompts alone. To address these challenges, we introduce the\nLanguage model-initialized Prompt Decision Transformer (LPDT), which leverages\npre-trained language models for meta-RL tasks and fine-tunes the model using\nLow-rank Adaptation (LoRA). We further incorporate prompt regularization to\neffectively differentiate between tasks based on prompt feature\nrepresentations. Our approach integrates pre-trained language model and RL\ntasks seamlessly. Extensive empirical studies demonstrate that initializing\nwith a pre-trained language model significantly enhances the performance of\nPrompt-DT on unseen tasks compared to baseline methods.",
    "arxiv_id": "http://arxiv.org/abs/2408.01402v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01402v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "The Impact of Hyperparameters on Large Language Model Inference Performance: An Evaluation of vLLM and HuggingFace Pipelines",
    "authors": "Matias Martinez",
    "abstract": "The recent surge of open-source large language models (LLMs) enables\ndevelopers to create AI-based solutions while maintaining control over aspects\nsuch as privacy and compliance, thereby providing governance and ownership of\nthe model deployment process. To utilize these LLMs, inference engines are\nneeded. These engines load the model's weights onto available resources, such\nas GPUs, and process queries to generate responses. The speed of inference, or\nperformance, of the LLM, is critical for real-time applications, as it computes\nmillions or billions of floating point operations per inference. Recently,\nadvanced inference engines such as vLLM have emerged, incorporating novel\nmechanisms such as efficient memory management to achieve state-of-the-art\nperformance. In this paper, we analyze the performance, particularly the\nthroughput (tokens generated per unit of time), of 20 LLMs using two inference\nlibraries: vLLM and HuggingFace's pipelines. We investigate how various\nhyperparameters, which developers must configure, influence inference\nperformance. Our results reveal that throughput landscapes are irregular, with\ndistinct peaks, highlighting the importance of hyperparameter optimization to\nachieve maximum performance. We also show that applying hyperparameter\noptimization when upgrading or downgrading the GPU model used for inference can\nimprove throughput from HuggingFace pipelines by an average of 9.16% and 13.7%,\nrespectively.",
    "arxiv_id": "http://arxiv.org/abs/2408.01050v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01050v1",
    "primary_category": "cs.SE",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Tensor Train Low-rank Approximation (TT-LoRA): Democratizing AI with Accelerated LLMs",
    "authors": "Afia Anjum, Maksim E. Eren, Ismael Boureima, Boian Alexandrov, Manish Bhattarai",
    "abstract": "In recent years, Large Language Models (LLMs) have demonstrated remarkable\ncapabilities across a wide range of natural language processing (NLP) tasks,\nsuch as question-answering, sentiment analysis, text summarization, and machine\ntranslation. However, the ever-growing complexity of LLMs demands immense\ncomputational resources, hindering the broader research and application of\nthese models. To address this, various parameter-efficient fine-tuning\nstrategies, such as Low-Rank Approximation (LoRA) and Adapters, have been\ndeveloped. Despite their potential, these methods often face limitations in\ncompressibility. Specifically, LoRA struggles to scale effectively with the\nincreasing number of trainable parameters in modern large scale LLMs.\nAdditionally, Low-Rank Economic Tensor-Train Adaptation (LoRETTA), which\nutilizes tensor train decomposition, has not yet achieved the level of\ncompression necessary for fine-tuning very large scale models with limited\nresources. This paper introduces Tensor Train Low-Rank Approximation (TT-LoRA),\na novel parameter-efficient fine-tuning (PEFT) approach that extends LoRETTA\nwith optimized tensor train (TT) decomposition integration. By eliminating\nAdapters and traditional LoRA-based structures, TT-LoRA achieves greater model\ncompression without compromising downstream task performance, along with\nreduced inference latency and computational overhead. We conduct an exhaustive\nparameter search to establish benchmarks that highlight the trade-off between\nmodel compression and performance. Our results demonstrate significant\ncompression of LLMs while maintaining comparable performance to larger models,\nfacilitating their deployment on resource-constraint platforms.",
    "arxiv_id": "http://arxiv.org/abs/2408.01008v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01008v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "AgentGen: Enhancing Planning Abilities for Large Language Model based Agent via Environment and Task Generation",
    "authors": "Mengkang Hu, Pu Zhao, Can Xu, Qingfeng Sun, Jianguang Lou, Qingwei Lin, Ping Luo, Saravan Rajmohan, Dongmei Zhang",
    "abstract": "Large Language Model (LLM) based agents have garnered significant attention\nand are becoming increasingly popular. Furthermore, planning ability is a\ncrucial component of an LLM-based agent, involving interaction with the\nenvironment and executing actions to complete a planning task, which generally\nentails achieving a desired goal from an initial state. This paper investigates\nenhancing the planning abilities of LLMs through instruction tuning, referred\nto as agent training. Recent studies have demonstrated that utilizing\nexpert-level trajectory for instruction-tuning LLMs effectively enhances their\nplanning capabilities. However, existing work primarily focuses on synthesizing\ntrajectories from manually designed planning tasks and environments. The\nlabor-intensive nature of creating these environments and tasks impedes the\ngeneration of sufficiently varied and extensive trajectories. To address this\nlimitation, this paper explores the automated synthesis of diverse environments\nand a gradual range of planning tasks, from easy to difficult. We introduce a\nframework, AgentGen, that leverages LLMs first to generate environments and\nsubsequently generate planning tasks conditioned on these environments.\nSpecifically, to improve environmental diversity, we propose using an\ninspiration corpus composed of various domain-specific text segments as the\ncontext for synthesizing environments. Moreover, to increase the difficulty\ndiversity of generated planning tasks, we propose a bidirectional evolution\nmethod, Bi-Evol, that evolves planning tasks from easier and harder directions\nto synthesize a task set with a smoother difficulty curve. The evaluation\nresults derived from AgentBoard show that AgentGen greatly improves LLMs'\nplanning ability, e.g., the AgentGen instruction-tuned Llama-3 8B surpasses\nGPT-3.5 in overall performance. Moreover, in certain tasks, it even outperforms\nGPT-4.",
    "arxiv_id": "http://arxiv.org/abs/2408.00764v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00764v1",
    "primary_category": "cs.CL",
    "votes": 1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "AutoM3L: An Automated Multimodal Machine Learning Framework with Large Language Models",
    "authors": "Daqin Luo, Chengjian Feng, Yuxuan Nong, Yiqing Shen",
    "abstract": "Automated Machine Learning (AutoML) offers a promising approach to streamline\nthe training of machine learning models. However, existing AutoML frameworks\nare often limited to unimodal scenarios and require extensive manual\nconfiguration. Recent advancements in Large Language Models (LLMs) have\nshowcased their exceptional abilities in reasoning, interaction, and code\ngeneration, presenting an opportunity to develop a more automated and\nuser-friendly framework. To this end, we introduce AutoM3L, an innovative\nAutomated Multimodal Machine Learning framework that leverages LLMs as\ncontrollers to automatically construct multimodal training pipelines. AutoM3L\ncomprehends data modalities and selects appropriate models based on user\nrequirements, providing automation and interactivity. By eliminating the need\nfor manual feature engineering and hyperparameter optimization, our framework\nsimplifies user engagement and enables customization through directives,\naddressing the limitations of previous rule-based AutoML approaches. We\nevaluate the performance of AutoM3L on six diverse multimodal datasets spanning\nclassification, regression, and retrieval tasks, as well as a comprehensive set\nof unimodal datasets. The results demonstrate that AutoM3L achieves competitive\nor superior performance compared to traditional rule-based AutoML methods.\nFurthermore, a user study highlights the user-friendliness and usability of our\nframework, compared to the rule-based AutoML methods.",
    "arxiv_id": "http://arxiv.org/abs/2408.00665v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00665v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Disentangling Dense Embeddings with Sparse Autoencoders",
    "authors": "Charles O'Neill, Christine Ye, Kartheik Iyer, John F. Wu",
    "abstract": "Sparse autoencoders (SAEs) have shown promise in extracting interpretable\nfeatures from complex neural networks. We present one of the first applications\nof SAEs to dense text embeddings from large language models, demonstrating\ntheir effectiveness in disentangling semantic concepts. By training SAEs on\nembeddings of over 420,000 scientific paper abstracts from computer science and\nastronomy, we show that the resulting sparse representations maintain semantic\nfidelity while offering interpretability. We analyse these learned features,\nexploring their behaviour across different model capacities and introducing a\nnovel method for identifying ``feature families'' that represent related\nconcepts at varying levels of abstraction. To demonstrate the practical utility\nof our approach, we show how these interpretable features can be used to\nprecisely steer semantic search, allowing for fine-grained control over query\nsemantics. This work bridges the gap between the semantic richness of dense\nembeddings and the interpretability of sparse representations. We open source\nour embeddings, trained sparse autoencoders, and interpreted features, as well\nas a web app for exploring them.",
    "arxiv_id": "http://arxiv.org/abs/2408.00657v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00657v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Mission Impossible: A Statistical Perspective on Jailbreaking LLMs",
    "authors": "Jingtong Su, Julia Kempe, Karen Ullrich",
    "abstract": "Large language models (LLMs) are trained on a deluge of text data with\nlimited quality control. As a result, LLMs can exhibit unintended or even\nharmful behaviours, such as leaking information, fake news or hate speech.\nCountermeasures, commonly referred to as preference alignment, include\nfine-tuning the pretrained LLMs with carefully crafted text examples of desired\nbehaviour. Even then, empirical evidence shows preference aligned LLMs can be\nenticed to harmful behaviour. This so called jailbreaking of LLMs is typically\nachieved by adversarially modifying the input prompt to the LLM. Our paper\nprovides theoretical insights into the phenomenon of preference alignment and\njailbreaking from a statistical perspective. Under our framework, we first show\nthat pretrained LLMs will mimic harmful behaviour if present in the training\ncorpus. Under that same framework, we then introduce a statistical notion of\nalignment, and lower-bound the jailbreaking probability, showing that it is\nunpreventable under reasonable assumptions. Based on our insights, we propose\nan alteration to the currently prevalent alignment strategy RLHF. Specifically,\nwe introduce a simple modification to the RLHF objective, we call E-RLHF, that\naims to increase the likelihood of safe responses. E-RLHF brings no additional\ntraining cost, and is compatible with other methods. Empirically, we\ndemonstrate that E-RLHF outperforms RLHF on all alignment problems put forward\nby the AdvBench and HarmBench project without sacrificing model performance as\nmeasured by the MT-Bench project.",
    "arxiv_id": "http://arxiv.org/abs/2408.01420v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01420v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Talk Less, Interact Better: Evaluating In-context Conversational Adaptation in Multimodal LLMs",
    "authors": "Yilun Hua, Yoav Artzi",
    "abstract": "Humans spontaneously use increasingly efficient language as interactions\nprogress, by adapting and forming ad-hoc conventions. This phenomenon has been\nstudied extensively using reference games, showing properties of human language\nthat go beyond relaying intents. It remains unexplored whether multimodal large\nlanguage models (MLLMs) similarly increase communication efficiency during\ninteractions, and what mechanisms they may adopt for this purpose. We introduce\nICCA, an automated framework to evaluate such conversational adaptation as an\nin-context behavior in MLLMs. We evaluate several state-of-the-art MLLMs, and\nobserve that while they may understand the increasingly efficient language of\ntheir interlocutor, they do not spontaneously make their own language more\nefficient over time. This latter ability can only be elicited in some models\n(e.g., GPT-4) with heavy-handed prompting. This shows that this property of\nlinguistic interaction does not arise from current training regimes, even\nthough it is a common hallmark of human language. ICCA is available at\nhttps://github.com/lil-lab/ICCA.",
    "arxiv_id": "http://arxiv.org/abs/2408.01417v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01417v1",
    "primary_category": "cs.CL",
    "votes": 0,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "The Quest for the Right Mediator: A History, Survey, and Theoretical Grounding of Causal Interpretability",
    "authors": "Aaron Mueller, Jannik Brinkmann, Millicent Li, Samuel Marks, Koyena Pal, Nikhil Prakash, Can Rager, Aruna Sankaranarayanan, Arnab Sen Sharma, Jiuding Sun, Eric Todd, David Bau, Yonatan Belinkov",
    "abstract": "Interpretability provides a toolset for understanding how and why neural\nnetworks behave in certain ways. However, there is little unity in the field:\nmost studies employ ad-hoc evaluations and do not share theoretical\nfoundations, making it difficult to measure progress and compare the pros and\ncons of different techniques. Furthermore, while mechanistic understanding is\nfrequently discussed, the basic causal units underlying these mechanisms are\noften not explicitly defined. In this paper, we propose a perspective on\ninterpretability research grounded in causal mediation analysis. Specifically,\nwe describe the history and current state of interpretability taxonomized\naccording to the types of causal units (mediators) employed, as well as methods\nused to search over mediators. We discuss the pros and cons of each mediator,\nproviding insights as to when particular kinds of mediators and search methods\nare most appropriate depending on the goals of a given study. We argue that\nthis framing yields a more cohesive narrative of the field, as well as\nactionable insights for future work. Specifically, we recommend a focus on\ndiscovering new mediators with better trade-offs between human-interpretability\nand compute-efficiency, and which can uncover more sophisticated abstractions\nfrom neural networks than the primarily linear mediators employed in current\nwork. We also argue for more standardized evaluations that enable principled\ncomparisons across mediator types, such that we can better understand when\nparticular causal units are better suited to particular use cases.",
    "arxiv_id": "http://arxiv.org/abs/2408.01416v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01416v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Conditional LoRA Parameter Generation",
    "authors": "Xiaolong Jin, Kai Wang, Dongwen Tang, Wangbo Zhao, Yukun Zhou, Junshu Tang, Yang You",
    "abstract": "Generative models have achieved remarkable success in image, video, and text\ndomains. Inspired by this, researchers have explored utilizing generative\nmodels to generate neural network parameters. However, these efforts have been\nlimited by the parameter size and the practicality of generating\nhigh-performance parameters. In this paper, we propose COND P-DIFF, a novel\napproach that demonstrates the feasibility of controllable high-performance\nparameter generation, particularly for LoRA (Low-Rank Adaptation) weights,\nduring the fine-tuning process. Specifically, we employ an autoencoder to\nextract efficient latent representations for parameters. We then train a\nconditional latent diffusion model to synthesize high-performing model\nparameters from random noise based on specific task conditions. Experimental\nresults in both computer vision and natural language processing domains\nconsistently demonstrate that COND P-DIFF can generate high-performance\nparameters conditioned on the given task. Moreover, we observe that the\nparameter distribution generated by COND P-DIFF exhibits differences compared\nto the distribution obtained through normal optimization methods, indicating a\ncertain level of generalization capability. Our work paves the way for further\nexploration of condition-driven parameter generation, offering a promising\ndirection for task-specific adaptation of neural networks.",
    "arxiv_id": "http://arxiv.org/abs/2408.01415v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01415v1",
    "primary_category": "cs.AI",
    "votes": 0,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Derivation of Back-propagation for Graph Convolutional Networks using Matrix Calculus and its Application to Explainable Artificial Intelligence",
    "authors": "Yen-Che Hsiao, Rongting Yue, Abhishek Dutta",
    "abstract": "This paper provides a comprehensive and detailed derivation of the\nbackpropagation algorithm for graph convolutional neural networks using matrix\ncalculus. The derivation is extended to include arbitrary element-wise\nactivation functions and an arbitrary number of layers. The study addresses two\nfundamental problems, namely node classification and link prediction. To\nvalidate our method, we compare it with reverse-mode automatic differentiation.\nThe experimental results demonstrate that the median sum of squared errors of\nthe updated weight matrices, when comparing our method to the approach using\nreverse-mode automatic differentiation, falls within the range of $10^{-18}$ to\n$10^{-14}$. These outcomes are obtained from conducting experiments on a\nfive-layer graph convolutional network, applied to a node classification\nproblem on Zachary's karate club social network and a link prediction problem\non a drug-drug interaction network. Finally, we show how the derived\nclosed-form solution can facilitate the development of explainable AI and\nsensitivity analysis.",
    "arxiv_id": "http://arxiv.org/abs/2408.01408v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01408v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Pre-trained Language Models Improve the Few-shot Prompt Ability of Decision Transformer",
    "authors": "Yu Yang, Pan Xu",
    "abstract": "Decision Transformer (DT) has emerged as a promising class of algorithms in\noffline reinforcement learning (RL) tasks, leveraging pre-collected datasets\nand Transformer's capability to model long sequences. Recent works have\ndemonstrated that using parts of trajectories from training tasks as prompts in\nDT enhances its performance on unseen tasks, giving rise to Prompt-DT methods.\nHowever, collecting data from specific environments can be both costly and\nunsafe in many scenarios, leading to suboptimal performance and limited\nfew-shot prompt abilities due to the data-hungry nature of Transformer-based\nmodels. Additionally, the limited datasets used in pre-training make it\nchallenging for Prompt-DT type of methods to distinguish between various RL\ntasks through prompts alone. To address these challenges, we introduce the\nLanguage model-initialized Prompt Decision Transformer (LPDT), which leverages\npre-trained language models for meta-RL tasks and fine-tunes the model using\nLow-rank Adaptation (LoRA). We further incorporate prompt regularization to\neffectively differentiate between tasks based on prompt feature\nrepresentations. Our approach integrates pre-trained language model and RL\ntasks seamlessly. Extensive empirical studies demonstrate that initializing\nwith a pre-trained language model significantly enhances the performance of\nPrompt-DT on unseen tasks compared to baseline methods.",
    "arxiv_id": "http://arxiv.org/abs/2408.01402v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01402v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "FT K-Means: A High-Performance K-Means on GPU with Fault Tolerance",
    "authors": "Shixun Wu, Yitong Ding, Yujia Zhai, Jinyang Liu, Jiajun Huang, Zizhe Jian, Huangliang Dai, Sheng Di, Bryan M. Wong, Zizhong Chen, Franck Cappello",
    "abstract": "K-Means is a widely used algorithm in clustering, however, its efficiency is\nprimarily constrained by the computational cost of distance computing. Existing\nimplementations suffer from suboptimal utilization of computational units and\nlack resilience against soft errors. To address these challenges, we introduce\nFT K-Means, a high-performance GPU-accelerated implementation of K-Means with\nonline fault tolerance. We first present a stepwise optimization strategy that\nachieves competitive performance compared to NVIDIA's cuML library. We further\nimprove FT K-Means with a template-based code generation framework that\nsupports different data types and adapts to different input shapes. A novel\nwarp-level tensor-core error correction scheme is proposed to address the\nfailure of existing fault tolerance methods due to memory asynchronization\nduring copy operations. Our experimental evaluations on NVIDIA T4 GPU and A100\nGPU demonstrate that FT K-Means without fault tolerance outperforms cuML's\nK-Means implementation, showing a performance increase of 10\\%-300\\% in\nscenarios involving irregular data shapes. Moreover, the fault tolerance\nfeature of FT K-Means introduces only an overhead of 11\\%, maintaining robust\nperformance even with tens of errors injected per second.",
    "arxiv_id": "http://arxiv.org/abs/2408.01391v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01391v1",
    "primary_category": "cs.DC",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "NeuralBeta: Estimating Beta Using Deep Learning",
    "authors": "Yuxin Liu, Jimin Lin, Achintya Gopal",
    "abstract": "Traditional approaches to estimating beta in finance often involve rigid\nassumptions and fail to adequately capture beta dynamics, limiting their\neffectiveness in use cases like hedging. To address these limitations, we have\ndeveloped a novel method using neural networks called NeuralBeta, which is\ncapable of handling both univariate and multivariate scenarios and tracking the\ndynamic behavior of beta. To address the issue of interpretability, we\nintroduce a new output layer inspired by regularized weighted linear\nregression, which provides transparency into the model's decision-making\nprocess. We conducted extensive experiments on both synthetic and market data,\ndemonstrating NeuralBeta's superior performance compared to benchmark methods\nacross various scenarios, especially instances where beta is highly\ntime-varying, e.g., during regime shifts in the market. This model not only\nrepresents an advancement in the field of beta estimation, but also shows\npotential for applications in other financial contexts that assume linear\nrelationships.",
    "arxiv_id": "http://arxiv.org/abs/2408.01387v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01387v1",
    "primary_category": "q-fin.ST",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Explaining a probabilistic prediction on the simplex with Shapley compositions",
    "authors": "Paul-Gauthier No\u00e9, Miquel Perell\u00f3-Nieto, Jean-Fran\u00e7ois Bonastre, Peter Flach",
    "abstract": "Originating in game theory, Shapley values are widely used for explaining a\nmachine learning model's prediction by quantifying the contribution of each\nfeature's value to the prediction. This requires a scalar prediction as in\nbinary classification, whereas a multiclass probabilistic prediction is a\ndiscrete probability distribution, living on a multidimensional simplex. In\nsuch a multiclass setting the Shapley values are typically computed separately\non each class in a one-vs-rest manner, ignoring the compositional nature of the\noutput distribution. In this paper, we introduce Shapley compositions as a\nwell-founded way to properly explain a multiclass probabilistic prediction,\nusing the Aitchison geometry from compositional data analysis. We prove that\nthe Shapley composition is the unique quantity satisfying linearity, symmetry\nand efficiency on the Aitchison simplex, extending the corresponding axiomatic\nproperties of the standard Shapley value. We demonstrate this proper multiclass\ntreatment in a range of scenarios.",
    "arxiv_id": "http://arxiv.org/abs/2408.01382v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01382v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Resampling and averaging coordinates on data",
    "authors": "Andrew J. Blumberg, Mathieu Carriere, Jun Hou Fung, Michael A. Mandell",
    "abstract": "We introduce algorithms for robustly computing intrinsic coordinates on point\nclouds. Our approach relies on generating many candidate coordinates by\nsubsampling the data and varying hyperparameters of the embedding algorithm\n(e.g., manifold learning). We then identify a subset of representative\nembeddings by clustering the collection of candidate coordinates and using\nshape descriptors from topological data analysis. The final output is the\nembedding obtained as an average of the representative embeddings using\ngeneralized Procrustes analysis. We validate our algorithm on both synthetic\ndata and experimental measurements from genomics, demonstrating robustness to\nnoise and outliers.",
    "arxiv_id": "http://arxiv.org/abs/2408.01379v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01379v1",
    "primary_category": "stat.ML",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Adaptive Recruitment Resource Allocation to Improve Cohort Representativeness in Participatory Biomedical Datasets",
    "authors": "Victor Borza, Andrew Estornell, Ellen Wright Clayton, Chien-Ju Ho, Russell Rothman, Yevgeniy Vorobeychik, Bradley Malin",
    "abstract": "Large participatory biomedical studies, studies that recruit individuals to\njoin a dataset, are gaining popularity and investment, especially for analysis\nby modern AI methods. Because they purposively recruit participants, these\nstudies are uniquely able to address a lack of historical representation, an\nissue that has affected many biomedical datasets. In this work, we define\nrepresentativeness as the similarity to a target population distribution of a\nset of attributes and our goal is to mirror the U.S. population across\ndistributions of age, gender, race, and ethnicity. Many participatory studies\nrecruit at several institutions, so we introduce a computational approach to\nadaptively allocate recruitment resources among sites to improve\nrepresentativeness. In simulated recruitment of 10,000-participant cohorts from\nmedical centers in the STAR Clinical Research Network, we show that our\napproach yields a more representative cohort than existing baselines. Thus, we\nhighlight the value of computational modeling in guiding recruitment efforts.",
    "arxiv_id": "http://arxiv.org/abs/2408.01375v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01375v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Hybrid Coordinate Descent for Efficient Neural Network Learning Using Line Search and Gradient Descent",
    "authors": "Yen-Che Hsiao, Abhishek Dutta",
    "abstract": "This paper presents a novel coordinate descent algorithm leveraging a\ncombination of one-directional line search and gradient information for\nparameter updates for a squared error loss function. Each parameter undergoes\nupdates determined by either the line search or gradient method, contingent\nupon whether the modulus of the gradient of the loss with respect to that\nparameter surpasses a predefined threshold. Notably, a larger threshold value\nenhances algorithmic efficiency. Despite the potentially slower nature of the\nline search method relative to gradient descent, its parallelizability\nfacilitates computational time reduction. Experimental validation conducted on\na 2-layer Rectified Linear Unit network with synthetic data elucidates the\nimpact of hyperparameters on convergence rates and computational efficiency.",
    "arxiv_id": "http://arxiv.org/abs/2408.01374v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01374v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Data Debugging is NP-hard for Classifiers Trained with SGD",
    "authors": "Zizheng Guo, Pengyu Chen, Yanzhang Fu, Dongjing Miao",
    "abstract": "Data debugging is to find a subset of the training data such that the model\nobtained by retraining on the subset has a better accuracy. A bunch of\nheuristic approaches are proposed, however, none of them are guaranteed to\nsolve this problem effectively. This leaves an open issue whether there exists\nan efficient algorithm to find the subset such that the model obtained by\nretraining on it has a better accuracy. To answer this open question and\nprovide theoretical basis for further study on developing better algorithms for\ndata debugging, we investigate the computational complexity of the problem\nnamed Debuggable. Given a machine learning model $\\mathcal{M}$ obtained by\ntraining on dataset $D$ and a test instance\n$(\\mathbf{x}_\\text{test},y_\\text{test})$ where\n$\\mathcal{M}(\\mathbf{x}_\\text{test})\\neq y_\\text{test}$, Debuggable is to\ndetermine whether there exists a subset $D^\\prime$ of $D$ such that the model\n$\\mathcal{M}^\\prime$ obtained by retraining on $D^\\prime$ satisfies\n$\\mathcal{M}^\\prime(\\mathbf{x}_\\text{test})=y_\\text{test}$. To cover a wide\nrange of commonly used models, we take SGD-trained linear classifier as the\nmodel and derive the following main results. (1) If the loss function and the\ndimension of the model are not fixed, Debuggable is NP-complete regardless of\nthe training order in which all the training samples are processed during SGD.\n(2) For hinge-like loss functions, a comprehensive analysis on the\ncomputational complexity of Debuggable is provided; (3) If the loss function is\na linear function, Debuggable can be solved in linear time, that is, data\ndebugging can be solved easily in this case. These results not only highlight\nthe limitations of current approaches but also offer new insights into data\ndebugging.",
    "arxiv_id": "http://arxiv.org/abs/2408.01365v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01365v1",
    "primary_category": "cs.CC",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Autoencoders in Function Space",
    "authors": "Justin Bunker, Mark Girolami, Hefin Lambley, Andrew M. Stuart, T. J. Sullivan",
    "abstract": "Autoencoders have found widespread application, in both their original\ndeterministic form and in their variational formulation (VAEs). In scientific\napplications it is often of interest to consider data that are comprised of\nfunctions; the same perspective is useful in image processing. In practice,\ndiscretisation (of differential equations arising in the sciences) or\npixellation (of images) renders problems finite dimensional, but conceiving\nfirst of algorithms that operate on functions, and only then discretising or\npixellating, leads to better algorithms that smoothly operate between different\nlevels of discretisation or pixellation. In this paper function-space versions\nof the autoencoder (FAE) and variational autoencoder (FVAE) are introduced,\nanalysed, and deployed. Well-definedness of the objective function governing\nVAEs is a subtle issue, even in finite dimension, and more so on function\nspace. The FVAE objective is well defined whenever the data distribution is\ncompatible with the chosen generative model; this happens, for example, when\nthe data arise from a stochastic differential equation. The FAE objective is\nvalid much more broadly, and can be straightforwardly applied to data governed\nby differential equations. Pairing these objectives with neural operator\narchitectures, which can thus be evaluated on any mesh, enables new\napplications of autoencoders to inpainting, superresolution, and generative\nmodelling of scientific data.",
    "arxiv_id": "http://arxiv.org/abs/2408.01362v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01362v1",
    "primary_category": "stat.ML",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "PC$^2$: Pseudo-Classification Based Pseudo-Captioning for Noisy Correspondence Learning in Cross-Modal Retrieval",
    "authors": "Yue Duan, Zhangxuan Gu, Zhenzhe Ying, Lei Qi, Changhua Meng, Yinghuan Shi",
    "abstract": "In the realm of cross-modal retrieval, seamlessly integrating diverse\nmodalities within multimedia remains a formidable challenge, especially given\nthe complexities introduced by noisy correspondence learning (NCL). Such noise\noften stems from mismatched data pairs, which is a significant obstacle\ndistinct from traditional noisy labels. This paper introduces\nPseudo-Classification based Pseudo-Captioning (PC$^2$) framework to address\nthis challenge. PC$^2$ offers a threefold strategy: firstly, it establishes an\nauxiliary \"pseudo-classification\" task that interprets captions as categorical\nlabels, steering the model to learn image-text semantic similarity through a\nnon-contrastive mechanism. Secondly, unlike prevailing margin-based techniques,\ncapitalizing on PC$^2$'s pseudo-classification capability, we generate\npseudo-captions to provide more informative and tangible supervision for each\nmismatched pair. Thirdly, the oscillation of pseudo-classification is borrowed\nto assistant the correction of correspondence. In addition to technical\ncontributions, we develop a realistic NCL dataset called Noise of Web (NoW),\nwhich could be a new powerful NCL benchmark where noise exists naturally.\nEmpirical evaluations of PC$^2$ showcase marked improvements over existing\nstate-of-the-art robust cross-modal retrieval techniques on both simulated and\nrealistic datasets with various NCL settings. The contributed dataset and\nsource code are released at https://github.com/alipay/PC2-NoiseofWeb.",
    "arxiv_id": "http://arxiv.org/abs/2408.01349v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01349v1",
    "primary_category": "cs.MM",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "StitchFusion: Weaving Any Visual Modalities to Enhance Multimodal Semantic Segmentation",
    "authors": "Bingyu Li, Da Zhang, Zhiyuan Zhao, Junyu Gao, Xuelong Li",
    "abstract": "Multimodal semantic segmentation shows significant potential for enhancing\nsegmentation accuracy in complex scenes. However, current methods often\nincorporate specialized feature fusion modules tailored to specific modalities,\nthereby restricting input flexibility and increasing the number of training\nparameters. To address these challenges, we propose StitchFusion, a\nstraightforward yet effective modal fusion framework that integrates\nlarge-scale pre-trained models directly as encoders and feature fusers. This\napproach facilitates comprehensive multi-modal and multi-scale feature fusion,\naccommodating any visual modal inputs. Specifically, Our framework achieves\nmodal integration during encoding by sharing multi-modal visual information. To\nenhance information exchange across modalities, we introduce a\nmulti-directional adapter module (MultiAdapter) to enable cross-modal\ninformation transfer during encoding. By leveraging MultiAdapter to propagate\nmulti-scale information across pre-trained encoders during the encoding\nprocess, StitchFusion achieves multi-modal visual information integration\nduring encoding. Extensive comparative experiments demonstrate that our model\nachieves state-of-the-art performance on four multi-modal segmentation datasets\nwith minimal additional parameters. Furthermore, the experimental integration\nof MultiAdapter with existing Feature Fusion Modules (FFMs) highlights their\ncomplementary nature. Our code is available at StitchFusion_repo.",
    "arxiv_id": "http://arxiv.org/abs/2408.01343v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01343v1",
    "primary_category": "cs.CV",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "MuChoMusic: Evaluating Music Understanding in Multimodal Audio-Language Models",
    "authors": "Benno Weck, Ilaria Manco, Emmanouil Benetos, Elio Quinton, George Fazekas, Dmitry Bogdanov",
    "abstract": "Multimodal models that jointly process audio and language hold great promise\nin audio understanding and are increasingly being adopted in the music domain.\nBy allowing users to query via text and obtain information about a given audio\ninput, these models have the potential to enable a variety of music\nunderstanding tasks via language-based interfaces. However, their evaluation\nposes considerable challenges, and it remains unclear how to effectively assess\ntheir ability to correctly interpret music-related inputs with current methods.\nMotivated by this, we introduce MuChoMusic, a benchmark for evaluating music\nunderstanding in multimodal language models focused on audio. MuChoMusic\ncomprises 1,187 multiple-choice questions, all validated by human annotators,\non 644 music tracks sourced from two publicly available music datasets, and\ncovering a wide variety of genres. Questions in the benchmark are crafted to\nassess knowledge and reasoning abilities across several dimensions that cover\nfundamental musical concepts and their relation to cultural and functional\ncontexts. Through the holistic analysis afforded by the benchmark, we evaluate\nfive open-source models and identify several pitfalls, including an\nover-reliance on the language modality, pointing to a need for better\nmultimodal integration. Data and code are open-sourced.",
    "arxiv_id": "http://arxiv.org/abs/2408.01337v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01337v1",
    "primary_category": "cs.SD",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Sparse Linear Regression when Noises and Covariates are Heavy-Tailed and Contaminated by Outliers",
    "authors": "Takeyuki Sasai, Hironori Fujisawa",
    "abstract": "We investigate a problem estimating coefficients of linear regression under\nsparsity assumption when covariates and noises are sampled from heavy tailed\ndistributions. Additionally, we consider the situation where not only\ncovariates and noises are sampled from heavy tailed distributions but also\ncontaminated by outliers. Our estimators can be computed efficiently, and\nexhibit sharp error bounds.",
    "arxiv_id": "http://arxiv.org/abs/2408.01336v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01336v1",
    "primary_category": "stat.ML",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "HMDN: Hierarchical Multi-Distribution Network for Click-Through Rate Prediction",
    "authors": "Xingyu Lou, Yu Yang, Kuiyao Dong, Heyuan Huang, Wenyi Yu, Ping Wang, Xiu Li, Jun Wang",
    "abstract": "As the recommendation service needs to address increasingly diverse\ndistributions, such as multi-population, multi-scenario, multitarget, and\nmulti-interest, more and more recent works have focused on multi-distribution\nmodeling and achieved great progress. However, most of them only consider\nmodeling in a single multi-distribution manner, ignoring that mixed\nmulti-distributions often coexist and form hierarchical relationships. To\naddress these challenges, we propose a flexible modeling paradigm, named\nHierarchical Multi-Distribution Network (HMDN), which efficiently models these\nhierarchical relationships and can seamlessly integrate with existing\nmulti-distribution methods, such as Mixture of-Experts (MoE) and Dynamic-Weight\n(DW) models. Specifically, we first design a hierarchical multi-distribution\nrepresentation refinement module, employing a multi-level residual quantization\nto obtain fine-grained hierarchical representation. Then, the refined\nhierarchical representation is integrated into the existing single\nmulti-distribution models, seamlessly expanding them into mixed\nmulti-distribution models. Experimental results on both public and industrial\ndatasets validate the effectiveness and flexibility of HMDN.",
    "arxiv_id": "http://arxiv.org/abs/2408.01332v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01332v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "UnifiedNN: Efficient Neural Network Training on the Cloud",
    "authors": "Sifat Ut Taki, Spyridon Mastorakis, Arthi Padmanabhan",
    "abstract": "Nowadays, cloud-based services are widely favored over the traditional\napproach of locally training a Neural Network (NN) model. Oftentimes, a cloud\nservice processes multiple requests from users--thus training multiple NN\nmodels concurrently. However, training NN models concurrently is a challenging\nprocess, which typically requires significant amounts of available computing\nresources and takes a long time to complete. In this paper, we present\nUnifiedNN to effectively train multiple NN models concurrently on the cloud.\nUnifiedNN effectively \"combines\" multiple NN models and features several memory\nand time conservation mechanisms to train multiple NN models simultaneously\nwithout impacting the accuracy of the training process. Specifically, UnifiedNN\nmerges multiple NN models and creates a large singular unified model in order\nto efficiently train all models at once. We have implemented a prototype of\nUnifiedNN in PyTorch and we have compared its performance with relevant\nstate-of-the-art frameworks. Our experimental results demonstrate that\nUnifiedNN can reduce memory consumption by up to 53% and training time by up to\n81% when compared with vanilla PyTorch without impacting the model training and\ntesting accuracy. Finally, our results indicate that UnifiedNN can reduce\nmemory consumption by up to 52% and training time by up to 41% when compared to\nstate-of-the-art frameworks when training multiple models concurrently.",
    "arxiv_id": "http://arxiv.org/abs/2408.01331v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01331v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Point Prediction for Streaming Data",
    "authors": "Aleena Chanda, N. V. Vinodchandran, Bertrand Clarke",
    "abstract": "We present two new approaches for point prediction with streaming data. One\nis based on the Count-Min sketch (CMS) and the other is based on Gaussian\nprocess priors with a random bias. These methods are intended for the most\ngeneral predictive problems where no true model can be usefully formulated for\nthe data stream. In statistical contexts, this is often called the\n$\\mathcal{M}$-open problem class. Under the assumption that the data consists\nof i.i.d samples from a fixed distribution function $F$, we show that the\nCMS-based estimates of the distribution function are consistent.\n  We compare our new methods with two established predictors in terms of\ncumulative $L^1$ error. One is based on the Shtarkov solution (often called the\nnormalized maximum likelihood) in the normal experts setting and the other is\nbased on Dirichlet process priors. These comparisons are for two cases. The\nfirst is one-pass meaning that the updating of the predictors is done using the\nfact that the CMS is a sketch. For predictors that are not one-pass, we use\nstreaming $K$-means to give a representative subset of fixed size that can be\nupdated as data accumulate.\n  Preliminary computational work suggests that the one-pass median version of\nthe CMS method is rarely outperformed by the other methods for sufficiently\ncomplex data. We also find that predictors based on Gaussian process priors\nwith random biases perform well. The Shtarkov predictors we use here did not\nperform as well probably because we were only using the simplest example. The\nother predictors seemed to perform well mainly when the data did not look like\nthey came from an M-open data generator.",
    "arxiv_id": "http://arxiv.org/abs/2408.01318v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01318v1",
    "primary_category": "stat.ML",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Decentralized Smoothing ADMM for Quantile Regression with Non-Convex Sparse Penalties",
    "authors": "Reza Mirzaeifard, Diyako Ghaderyan, Stefan Werner",
    "abstract": "In the rapidly evolving internet-of-things (IoT) ecosystem, effective data\nanalysis techniques are crucial for handling distributed data generated by\nsensors. Addressing the limitations of existing methods, such as the\nsub-gradient approach, which fails to distinguish between active and non-active\ncoefficients effectively, this paper introduces the decentralized smoothing\nalternating direction method of multipliers (DSAD) for penalized quantile\nregression. Our method leverages non-convex sparse penalties like the minimax\nconcave penalty (MCP) and smoothly clipped absolute deviation (SCAD), improving\nthe identification and retention of significant predictors. DSAD incorporates a\ntotal variation norm within a smoothing ADMM framework, achieving consensus\namong distributed nodes and ensuring uniform model performance across disparate\ndata sources. This approach overcomes traditional convergence challenges\nassociated with non-convex penalties in decentralized settings. We present\ntheoretical proofs and extensive simulation results to validate the\neffectiveness of the DSAD, demonstrating its superiority in achieving reliable\nconvergence and enhancing estimation accuracy compared with prior methods.",
    "arxiv_id": "http://arxiv.org/abs/2408.01307v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01307v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "A Decision-driven Methodology for Designing Uncertainty-aware AI Self-Assessment",
    "authors": "Gregory Canal, Vladimir Leung, Philip Sage, Eric Heim, I-Jeng Wang",
    "abstract": "Artificial intelligence (AI) has revolutionized decision-making processes and\nsystems throughout society and, in particular, has emerged as a significant\ntechnology in high-impact scenarios of national interest. Yet, despite AI's\nimpressive predictive capabilities in controlled settings, it still suffers\nfrom a range of practical setbacks preventing its widespread use in various\ncritical scenarios. In particular, it is generally unclear if a given AI\nsystem's predictions can be trusted by decision-makers in downstream\napplications. To address the need for more transparent, robust, and trustworthy\nAI systems, a suite of tools has been developed to quantify the uncertainty of\nAI predictions and, more generally, enable AI to \"self-assess\" the reliability\nof its predictions. In this manuscript, we categorize methods for AI\nself-assessment along several key dimensions and provide guidelines for\nselecting and designing the appropriate method for a practitioner's needs. In\nparticular, we focus on uncertainty estimation techniques that consider the\nimpact of self-assessment on the choices made by downstream decision-makers and\non the resulting costs and benefits of decision outcomes. To demonstrate the\nutility of our methodology for self-assessment design, we illustrate its use\nfor two realistic national-interest scenarios. This manuscript is a practical\nguide for machine learning engineers and AI system users to select the ideal\nself-assessment techniques for each problem.",
    "arxiv_id": "http://arxiv.org/abs/2408.01301v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01301v1",
    "primary_category": "stat.ML",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Assessing Robustness of Machine Learning Models using Covariate Perturbations",
    "authors": "Arun Prakash R, Anwesha Bhattacharyya, Joel Vaughan, Vijayan N. Nair",
    "abstract": "As machine learning models become increasingly prevalent in critical\ndecision-making models and systems in fields like finance, healthcare, etc.,\nensuring their robustness against adversarial attacks and changes in the input\ndata is paramount, especially in cases where models potentially overfit. This\npaper proposes a comprehensive framework for assessing the robustness of\nmachine learning models through covariate perturbation techniques. We explore\nvarious perturbation strategies to assess robustness and examine their impact\non model predictions, including separate strategies for numeric and non-numeric\nvariables, summaries of perturbations to assess and compare model robustness\nacross different scenarios, and local robustness diagnosis to identify any\nregions in the data where a model is particularly unstable. Through empirical\nstudies on real world dataset, we demonstrate the effectiveness of our approach\nin comparing robustness across models, identifying the instabilities in the\nmodel, and enhancing model robustness.",
    "arxiv_id": "http://arxiv.org/abs/2408.01300v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01300v1",
    "primary_category": "stat.ML",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Optimal Mixed Integer Linear Optimization Trained Multivariate Classification Trees",
    "authors": "Brandon Alston, Illya V. Hicks",
    "abstract": "Multivariate decision trees are powerful machine learning tools for\nclassification and regression that attract many researchers and industry\nprofessionals. An optimal binary tree has two types of vertices, (i) branching\nvertices which have exactly two children and where datapoints are assessed on a\nset of discrete features and (ii) leaf vertices at which datapoints are given a\nprediction, and can be obtained by solving a biobjective optimization problem\nthat seeks to (i) maximize the number of correctly classified datapoints and\n(ii) minimize the number of branching vertices. Branching vertices are linear\ncombinations of training features and therefore can be thought of as\nhyperplanes. In this paper, we propose two cut-based mixed integer linear\noptimization (MILO) formulations for designing optimal binary classification\ntrees (leaf vertices assign discrete classes). Our models leverage on-the-fly\nidentification of minimal infeasible subsystems (MISs) from which we derive\ncutting planes that hold the form of packing constraints. We show theoretical\nimprovements on the strongest flow-based MILO formulation currently in the\nliterature and conduct experiments on publicly available datasets to show our\nmodels' ability to scale, strength against traditional branch and bound\napproaches, and robustness in out-of-sample test performance. Our code and data\nare available on GitHub.",
    "arxiv_id": "http://arxiv.org/abs/2408.01297v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01297v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Feature Clock: High-Dimensional Effects in Two-Dimensional Plots",
    "authors": "Olga Ovcharenko, Rita Sevastjanova, Valentina Boeva",
    "abstract": "Humans struggle to perceive and interpret high-dimensional data. Therefore,\nhigh-dimensional data are often projected into two dimensions for\nvisualization. Many applications benefit from complex nonlinear dimensionality\nreduction techniques, but the effects of individual high-dimensional features\nare hard to explain in the two-dimensional space. Most visualization solutions\nuse multiple two-dimensional plots, each showing the effect of one\nhigh-dimensional feature in two dimensions; this approach creates a need for a\nvisual inspection of k plots for a k-dimensional input space. Our solution,\nFeature Clock, provides a novel approach that eliminates the need to inspect\nthese k plots to grasp the influence of original features on the data structure\ndepicted in two dimensions. Feature Clock enhances the explainability and\ncompactness of visualizations of embedded data and is available in an\nopen-source Python library.",
    "arxiv_id": "http://arxiv.org/abs/2408.01294v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01294v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "A Tiny Supervised ODL Core with Auto Data Pruning for Human Activity Recognition",
    "authors": "Hiroki Matsutani, Radu Marculescu",
    "abstract": "In this paper, we introduce a low-cost and low-power tiny supervised\non-device learning (ODL) core that can address the distributional shift of\ninput data for human activity recognition. Although ODL for resource-limited\nedge devices has been studied recently, how exactly to provide the training\nlabels to these devices at runtime remains an open-issue. To address this\nproblem, we propose to combine an automatic data pruning with supervised ODL to\nreduce the number queries needed to acquire predicted labels from a nearby\nteacher device and thus save power consumption during model retraining. The\ndata pruning threshold is automatically tuned, eliminating a manual threshold\ntuning. As a tinyML solution at a few mW for the human activity recognition, we\ndesign a supervised ODL core that supports our automatic data pruning using a\n45nm CMOS process technology. We show that the required memory size for the\ncore is smaller than the same-shaped multilayer perceptron (MLP) and the power\nconsumption is only 3.39mW. Experiments using a human activity recognition\ndataset show that the proposed automatic data pruning reduces the communication\nvolume by 55.7% and power consumption accordingly with only 0.9% accuracy loss.",
    "arxiv_id": "http://arxiv.org/abs/2408.01283v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01283v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Certified Robust Invariant Polytope Training in Neural Controlled ODEs",
    "authors": "Akash Harapanahalli, Samuel Coogan",
    "abstract": "We consider a nonlinear control system modeled as an ordinary differential\nequation subject to disturbance, with a state feedback controller parameterized\nas a feedforward neural network. We propose a framework for training\ncontrollers with certified robust forward invariant polytopes, where any\ntrajectory initialized inside the polytope remains within the polytope,\nregardless of the disturbance. First, we parameterize a family of lifted\ncontrol systems in a higher dimensional space, where the original neural\ncontrolled system evolves on an invariant subspace of each lifted system. We\nuse interval analysis and neural network verifiers to further construct a\nfamily of lifted embedding systems, carefully capturing the knowledge of this\ninvariant subspace. If the vector field of any lifted embedding system\nsatisfies a sign constraint at a single point, then a certain convex polytope\nof the original system is robustly forward invariant. Treating the neural\nnetwork controller and the lifted system parameters as variables, we propose an\nalgorithm to train controllers with certified forward invariant polytopes in\nthe closed-loop control system. Through two examples, we demonstrate how the\nsimplicity of the sign constraint allows our approach to scale with system\ndimension to over $50$ states, and outperform state-of-the-art Lyapunov-based\nsampling approaches in runtime.",
    "arxiv_id": "http://arxiv.org/abs/2408.01273v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01273v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Detection and Characterization of Coordinated Online Behavior: A Survey",
    "authors": "Lorenzo Mannocci, Michele Mazza, Anna Monreale, Maurizio Tesconi, Stefano Cresci",
    "abstract": "Coordination is a fundamental aspect of life. The advent of social media has\nmade it integral also to online human interactions, such as those that\ncharacterize thriving online communities and social movements. At the same\ntime, coordination is also core to effective disinformation, manipulation, and\nhate campaigns. This survey collects, categorizes, and critically discusses the\nbody of work produced as a result of the growing interest on coordinated online\nbehavior. We reconcile industry and academic definitions, propose a\ncomprehensive framework to study coordinated online behavior, and review and\ncritically discuss the existing detection and characterization methods. Our\nanalysis identifies open challenges and promising directions of research,\nserving as a guide for scholars, practitioners, and policymakers in\nunderstanding and addressing the complexities inherent to online coordination.",
    "arxiv_id": "http://arxiv.org/abs/2408.01257v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01257v1",
    "primary_category": "cs.SI",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Deep progressive reinforcement learning-based flexible resource scheduling framework for IRS and UAV-assisted MEC system",
    "authors": "Li Dong, Feibo Jiang, Minjie Wang, Yubo Peng, Xiaolong Li",
    "abstract": "The intelligent reflection surface (IRS) and unmanned aerial vehicle\n(UAV)-assisted mobile edge computing (MEC) system is widely used in temporary\nand emergency scenarios. Our goal is to minimize the energy consumption of the\nMEC system by jointly optimizing UAV locations, IRS phase shift, task\noffloading, and resource allocation with a variable number of UAVs. To this\nend, we propose a Flexible REsource Scheduling (FRES) framework by employing a\nnovel deep progressive reinforcement learning which includes the following\ninnovations: Firstly, a novel multi-task agent is presented to deal with the\nmixed integer nonlinear programming (MINLP) problem. The multi-task agent has\ntwo output heads designed for different tasks, in which a classified head is\nemployed to make offloading decisions with integer variables while a fitting\nhead is applied to solve resource allocation with continuous variables.\nSecondly, a progressive scheduler is introduced to adapt the agent to the\nvarying number of UAVs by progressively adjusting a part of neurons in the\nagent. This structure can naturally accumulate experiences and be immune to\ncatastrophic forgetting. Finally, a light taboo search (LTS) is introduced to\nenhance the global search of the FRES. The numerical results demonstrate the\nsuperiority of the FRES framework which can make real-time and optimal resource\nscheduling even in dynamic MEC systems.",
    "arxiv_id": "http://arxiv.org/abs/2408.01248v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01248v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Automated Classification of Dry Bean Varieties Using XGBoost and SVM Models",
    "authors": "Ramtin Ardeshirifar",
    "abstract": "This paper presents a comparative study on the automated classification of\nseven different varieties of dry beans using machine learning models.\nLeveraging a dataset of 12,909 dry bean samples, reduced from an initial 13,611\nthrough outlier removal and feature extraction, we applied Principal Component\nAnalysis (PCA) for dimensionality reduction and trained two multiclass\nclassifiers: XGBoost and Support Vector Machine (SVM). The models were\nevaluated using nested cross-validation to ensure robust performance assessment\nand hyperparameter tuning. The XGBoost and SVM models achieved overall correct\nclassification rates of 94.00% and 94.39%, respectively. The results underscore\nthe efficacy of these machine learning approaches in agricultural applications,\nparticularly in enhancing the uniformity and efficiency of seed classification.\nThis study contributes to the growing body of work on precision agriculture,\ndemonstrating that automated systems can significantly support seed quality\ncontrol and crop yield optimization. Future work will explore incorporating\nmore diverse datasets and advanced algorithms to further improve classification\naccuracy.",
    "arxiv_id": "http://arxiv.org/abs/2408.01244v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01244v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Tailoring Graph Neural Network-based Flow-guided Localization to Individual Bloodstreams and Activities",
    "authors": "Pablo Galv\u00e1n, Filip Lemic, Gerard Calvo Bartra, Sergi Abadal, Xavier Costa P\u00e9rez",
    "abstract": "Flow-guided localization using in-body nanodevices in the bloodstream is\nexpected to be beneficial for early disease detection, continuous monitoring of\nbiological conditions, and targeted treatment. The nanodevices face size and\npower constraints that produce erroneous raw data for localization purposes.\nOn-body anchors receive this data, and use it to derive the locations of\ndiagnostic events of interest. Different Machine Learning (ML) approaches have\nbeen recently proposed for this task, yet they are currently restricted to a\nreference bloodstream of a resting patient. As such, they are unable to deal\nwith the physical diversity of patients' bloodstreams and cannot provide\ncontinuous monitoring due to changes in individual patient's activities. Toward\naddressing these issues for the current State-of-the-Art (SotA) flow-guided\nlocalization approach based on Graph Neural Networks (GNNs), we propose a\npipeline for GNN adaptation based on individual physiological indicators\nincluding height, weight, and heart rate. Our results indicate that the\nproposed adaptions are beneficial in reconciling the individual differences\nbetween bloodstreams and activities.",
    "arxiv_id": "http://arxiv.org/abs/2408.01239v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01239v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "HeteroMorpheus: Universal Control Based on Morphological Heterogeneity Modeling",
    "authors": "YiFan Hao, Yang Yang, Junru Song, Wei Peng, Weien Zhou, Tingsong Jiang, Wen Yao",
    "abstract": "In the field of robotic control, designing individual controllers for each\nrobot leads to high computational costs. Universal control policies, applicable\nacross diverse robot morphologies, promise to mitigate this challenge.\nPredominantly, models based on Graph Neural Networks (GNN) and Transformers are\nemployed, owing to their effectiveness in capturing relational dynamics across\na robot's limbs. However, these models typically employ homogeneous graph\nstructures that overlook the functional diversity of different limbs. To bridge\nthis gap, we introduce HeteroMorpheus, a novel method based on heterogeneous\ngraph Transformer. This method uniquely addresses limb heterogeneity, fostering\nbetter representation of robot dynamics of various morphologies. Through\nextensive experiments we demonstrate the superiority of HeteroMorpheus against\nstate-of-the-art methods in the capability of policy generalization, including\nzero-shot generalization and sample-efficient transfer to unfamiliar robot\nmorphologies.",
    "arxiv_id": "http://arxiv.org/abs/2408.01230v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01230v1",
    "primary_category": "cs.RO",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "ZNorm: Z-Score Gradient Normalization for Accelerating Neural Network Training",
    "authors": "Juyoung Yun, Hoyoung Kim, Suin Cho, Hangil Kang",
    "abstract": "The rapid advancements in deep learning necessitate efficient training\nmethods for deep neural networks (DNNs). As models grow in complexity,\nvanishing and exploding gradients impede convergence and performance. We\npropose Z-Score Normalization for Gradient Descent (ZNorm), an innovative\ntechnique that adjusts only the gradients to enhance training efficiency and\nimprove model performance. ZNorm normalizes the overall gradients, providing\nconsistent gradient scaling across layers, thereby reducing the risks of\nvanishing and exploding gradients. Our extensive experiments on CIFAR-10 and\nmedical datasets demonstrate that ZNorm not only accelerates convergence but\nalso enhances performance metrics. ZNorm consistently outperforms existing\nmethods, achieving superior results using the same computational settings. In\nmedical imaging applications, ZNorm improves tumor prediction and segmentation\nperformances, underscoring its practical utility. These findings highlight\nZNorm's potential as a robust and versatile tool for improving the efficiency\nand effectiveness of deep neural network training across a wide range of\narchitectures and applications.",
    "arxiv_id": "http://arxiv.org/abs/2408.01215v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01215v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Certifiably Robust Encoding Schemes",
    "authors": "Aman Saxena, Tom Wollschl\u00e4ger, Nicola Franco, Jeanette Miriam Lorenz, Stephan G\u00fcnnemann",
    "abstract": "Quantum machine learning uses principles from quantum mechanics to process\ndata, offering potential advances in speed and performance. However, previous\nwork has shown that these models are susceptible to attacks that manipulate\ninput data or exploit noise in quantum circuits. Following this, various\nstudies have explored the robustness of these models. These works focus on the\nrobustness certification of manipulations of the quantum states. We extend this\nline of research by investigating the robustness against perturbations in the\nclassical data for a general class of data encoding schemes. We show that for\nsuch schemes, the addition of suitable noise channels is equivalent to\nevaluating the mean value of the noiseless classifier at the smoothed data,\nakin to Randomized Smoothing from classical machine learning. Using our general\nframework, we show that suitable additions of phase-damping noise channels\nimprove empirical and provable robustness for the considered class of encoding\nschemes.",
    "arxiv_id": "http://arxiv.org/abs/2408.01200v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01200v1",
    "primary_category": "quant-ph",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Optimizing Variational Quantum Circuits Using Metaheuristic Strategies in Reinforcement Learning",
    "authors": "Michael K\u00f6lle, Daniel Seidl, Maximilian Zorn, Philipp Altmann, Jonas Stein, Thomas Gabor",
    "abstract": "Quantum Reinforcement Learning (QRL) offers potential advantages over\nclassical Reinforcement Learning, such as compact state space representation\nand faster convergence in certain scenarios. However, practical benefits\nrequire further validation. QRL faces challenges like flat solution landscapes,\nwhere traditional gradient-based methods are inefficient, necessitating the use\nof gradient-free algorithms. This work explores the integration of\nmetaheuristic algorithms -- Particle Swarm Optimization, Ant Colony\nOptimization, Tabu Search, Genetic Algorithm, Simulated Annealing, and Harmony\nSearch -- into QRL. These algorithms provide flexibility and efficiency in\nparameter optimization. Evaluations in $5\\times5$ MiniGrid Reinforcement\nLearning environments show that, all algorithms yield near-optimal results,\nwith Simulated Annealing and Particle Swarm Optimization performing best. In\nthe Cart Pole environment, Simulated Annealing, Genetic Algorithms, and\nParticle Swarm Optimization achieve optimal results, while the others perform\nslightly better than random action selection. These findings demonstrate the\npotential of Particle Swarm Optimization and Simulated Annealing for efficient\nQRL learning, emphasizing the need for careful algorithm selection and\nadaptation.",
    "arxiv_id": "http://arxiv.org/abs/2408.01187v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01187v1",
    "primary_category": "quant-ph",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Nested Music Transformer: Sequentially Decoding Compound Tokens in Symbolic Music and Audio Generation",
    "authors": "Jiwoo Ryu, Hao-Wen Dong, Jongmin Jung, Dasaem Jeong",
    "abstract": "Representing symbolic music with compound tokens, where each token consists\nof several different sub-tokens representing a distinct musical feature or\nattribute, offers the advantage of reducing sequence length. While previous\nresearch has validated the efficacy of compound tokens in music sequence\nmodeling, predicting all sub-tokens simultaneously can lead to suboptimal\nresults as it may not fully capture the interdependencies between them. We\nintroduce the Nested Music Transformer (NMT), an architecture tailored for\ndecoding compound tokens autoregressively, similar to processing flattened\ntokens, but with low memory usage. The NMT consists of two transformers: the\nmain decoder that models a sequence of compound tokens and the sub-decoder for\nmodeling sub-tokens of each compound token. The experiment results showed that\napplying the NMT to compound tokens can enhance the performance in terms of\nbetter perplexity in processing various symbolic music datasets and discrete\naudio tokens from the MAESTRO dataset.",
    "arxiv_id": "http://arxiv.org/abs/2408.01180v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01180v1",
    "primary_category": "cs.SD",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Sustainable Diffusion-based Incentive Mechanism for Generative AI-driven Digital Twins in Industrial Cyber-Physical Systems",
    "authors": "Jinbo Wen, Jiawen Kang, Dusit Niyato, Yang Zhang, Shiwen Mao",
    "abstract": "Industrial Cyber-Physical Systems (ICPSs) are an integral component of modern\nmanufacturing and industries. By digitizing data throughout the product life\ncycle, Digital Twins (DTs) in ICPSs enable a shift from current industrial\ninfrastructures to intelligent and adaptive infrastructures. Thanks to data\nprocess capability, Generative Artificial Intelligence (GAI) can drive the\nconstruction and update of DTs to improve predictive accuracy and prepare for\ndiverse smart manufacturing. However, mechanisms that leverage sensing\nIndustrial Internet of Things (IIoT) devices to share data for the construction\nof DTs are susceptible to adverse selection problems. In this paper, we first\ndevelop a GAI-driven DT architecture for ICPSs. To address the adverse\nselection problem caused by information asymmetry, we propose a contract theory\nmodel and develop the sustainable diffusion-based soft actor-critic algorithm\nto identify the optimal feasible contract. Specifically, we leverage the\ndynamic structured pruning technique to reduce parameter numbers of actor\nnetworks, allowing sustainability and efficient implementation of the proposed\nalgorithm. Finally, numerical results demonstrate the effectiveness of the\nproposed scheme.",
    "arxiv_id": "http://arxiv.org/abs/2408.01173v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01173v1",
    "primary_category": "cs.NI",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Domain Adaptation-Enhanced Searchlight: Enabling brain decoding from visual perception to mental imagery",
    "authors": "Alexander Olza, David Soto, Roberto Santana",
    "abstract": "In cognitive neuroscience and brain-computer interface research, accurately\npredicting imagined stimuli is crucial. This study investigates the\neffectiveness of Domain Adaptation (DA) in enhancing imagery prediction using\nprimarily visual data from fMRI scans of 18 subjects. Initially, we train a\nbaseline model on visual stimuli to predict imagined stimuli, utilizing data\nfrom 14 brain regions. We then develop several models to improve imagery\nprediction, comparing different DA methods. Our results demonstrate that DA\nsignificantly enhances imagery prediction, especially with the Regular Transfer\napproach. We then conduct a DA-enhanced searchlight analysis using Regular\nTransfer, followed by permutation-based statistical tests to identify brain\nregions where imagery decoding is consistently above chance across subjects.\nOur DA-enhanced searchlight predicts imagery contents in a highly distributed\nset of brain regions, including the visual cortex and the frontoparietal\ncortex, thereby outperforming standard cross-domain classification methods. The\ncomplete code and data for this paper have been made openly available for the\nuse of the scientific community.",
    "arxiv_id": "http://arxiv.org/abs/2408.01163v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01163v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "TCR-GPT: Integrating Autoregressive Model and Reinforcement Learning for T-Cell Receptor Repertoires Generation",
    "authors": "Yicheng Lin, Dandan Zhang, Yun Liu",
    "abstract": "T-cell receptors (TCRs) play a crucial role in the immune system by\nrecognizing and binding to specific antigens presented by infected or cancerous\ncells. Understanding the sequence patterns of TCRs is essential for developing\ntargeted immune therapies and designing effective vaccines. Language models,\nsuch as auto-regressive transformers, offer a powerful solution to this problem\nby learning the probability distributions of TCR repertoires, enabling the\ngeneration of new TCR sequences that inherit the underlying patterns of the\nrepertoire. We introduce TCR-GPT, a probabilistic model built on a decoder-only\ntransformer architecture, designed to uncover and replicate sequence patterns\nin TCR repertoires. TCR-GPT demonstrates an accuracy of 0.953 in inferring\nsequence probability distributions measured by Pearson correlation coefficient.\nFurthermore, by leveraging Reinforcement Learning(RL), we adapted the\ndistribution of TCR sequences to generate TCRs capable of recognizing specific\npeptides, offering significant potential for advancing targeted immune\ntherapies and vaccine development. With the efficacy of RL, fine-tuned\npretrained TCR-GPT models demonstrated the ability to produce TCR repertoires\nlikely to bind specific peptides, illustrating RL's efficiency in enhancing the\nmodel's adaptability to the probability distributions of biologically relevant\nTCR sequences.",
    "arxiv_id": "http://arxiv.org/abs/2408.01156v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01156v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Enhanced Prediction of Ventilator-Associated Pneumonia in Patients with Traumatic Brain Injury Using Advanced Machine Learning Techniques",
    "authors": "Negin Ashrafi, Armin Abdollahi, Maryam Pishgar",
    "abstract": "Background: Ventilator-associated pneumonia (VAP) in traumatic brain injury\n(TBI) patients poses a significant mortality risk and imposes a considerable\nfinancial burden on patients and healthcare systems. Timely detection and\nprognostication of VAP in TBI patients are crucial to improve patient outcomes\nand alleviate the strain on healthcare resources.\n  Methods: We implemented six machine learning models using the MIMIC-III\ndatabase. Our methodology included preprocessing steps, such as feature\nselection with CatBoost and expert opinion, addressing class imbalance with the\nSynthetic Minority Oversampling Technique (SMOTE), and rigorous model tuning\nthrough 5-fold cross-validation to optimize hyperparameters. Key models\nevaluated included SVM, Logistic Regression, Random Forest, XGBoost, ANN, and\nAdaBoost. Additionally, we conducted SHAP analysis to determine feature\nimportance and performed an ablation study to assess feature impacts on model\nperformance.\n  Results: XGBoost outperformed the baseline models and the best existing\nliterature. We used metrics, including AUC, Accuracy, Specificity, Sensitivity,\nF1 Score, PPV, and NPV. XGBoost demonstrated the highest performance with an\nAUC of 0.940 and an Accuracy of 0.875, which are 23.4% and 23.5% higher than\nthe best results in the existing literature, with an AUC of 0.706 and an\nAccuracy of 0.640, respectively. This enhanced performance underscores the\nmodels' effectiveness in clinical settings.\n  Conclusions: This study enhances the predictive modeling of VAP in TBI\npatients, improving early detection and intervention potential. Refined feature\nselection and advanced ensemble techniques significantly boosted model accuracy\nand reliability, offering promising directions for future clinical applications\nand medical diagnostics research.",
    "arxiv_id": "http://arxiv.org/abs/2408.01144v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01144v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Machine learning topological energy braiding of non-Bloch bands",
    "authors": "Shuwei Shi, Shibing Chu, Yuee Xie, Yuanping Chen",
    "abstract": "Machine learning has been used to identify phase transitions in a variety of\nphysical systems. However, there is still a lack of relevant research on\nnon-Bloch energy braiding in non-Hermitian systems. In this work, we study\nnon-Bloch energy braiding in one-dimensional non-Hermitian systems using\nunsupervised and supervised methods. In unsupervised learning, we use diffusion\nmaps to successfully identify non-Bloch energy braiding without any prior\nknowledge and combine it with k-means to cluster different topological elements\ninto clusters, such as Unlink and Hopf link. In supervised learning, we train a\nConvolutional Neural Network (CNN) based on Bloch energy data to predict not\nonly Bloch energy braiding but also non-Bloch energy braiding with an accuracy\napproaching 100%. By analysing the CNN, we can ascertain that the network has\nsuccessfully acquired the ability to recognise the braiding topology of the\nenergy bands. The present study demonstrates the considerable potential of\nmachine learning in the identification of non-Hermitian topological phases and\nenergy braiding.",
    "arxiv_id": "http://arxiv.org/abs/2408.01141v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01141v1",
    "primary_category": "cond-mat.mes-hall",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "A Survey of Mamba",
    "authors": "Haohao Qu, Liangbo Ning, Rui An, Wenqi Fan, Tyler Derr, Xin Xu, Qing Li",
    "abstract": "Deep learning, as a vital technique, has sparked a notable revolution in\nartificial intelligence. As the most representative architecture, Transformers\nhave empowered numerous advanced models, especially the large language models\nthat comprise billions of parameters, becoming a cornerstone in deep learning.\nDespite the impressive achievements, Transformers still face inherent\nlimitations, particularly the time-consuming inference resulting from the\nquadratic computation complexity of attention calculation. Recently, a novel\narchitecture named Mamba, drawing inspiration from classical state space\nmodels, has emerged as a promising alternative for building foundation models,\ndelivering comparable modeling abilities to Transformers while preserving\nnear-linear scalability concerning sequence length. This has sparked an\nincreasing number of studies actively exploring Mamba's potential to achieve\nimpressive performance across diverse domains. Given such rapid evolution,\nthere is a critical need for a systematic review that consolidates existing\nMamba-empowered models, offering a comprehensive understanding of this emerging\nmodel architecture. In this survey, we therefore conduct an in-depth\ninvestigation of recent Mamba-associated studies, covering from three main\naspects: the advancements of Mamba-based models, the techniques of adapting\nMamba to diverse data, and the applications where Mamba can excel.\nSpecifically, we first recall the foundational knowledge of various\nrepresentative deep learning models and the details of Mamba as preliminaries.\nThen, to showcase the significance of Mamba, we comprehensively review the\nrelated studies focusing on Mamba models' architecture design, data\nadaptability, and applications. Finally, we present an discussion of current\nlimitations and explore various promising research directions to provide deeper\ninsights for future investigations.",
    "arxiv_id": "http://arxiv.org/abs/2408.01129v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01129v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "An Encoding--Searching Separation Perspective on Bi-Encoder Neural Search",
    "authors": "Hung-Nghiep Tran, Akiko Aizawa, Atsuhiro Takasu",
    "abstract": "This paper reviews, analyzes, and proposes a new perspective on the\nbi-encoder architecture for neural search. While the bi-encoder architecture is\nwidely used due to its simplicity and scalability at test time, it has some\nnotable issues such as low performance on seen datasets and weak zero-shot\nperformance on new datasets. In this paper, we analyze these issues and\nsummarize two main critiques: the encoding information bottleneck problem and\nlimitations of the basic assumption of embedding search. We then construct a\nthought experiment to logically analyze the encoding and searching operations\nand challenge the basic assumption of embedding search. Building on these\nobservations, we propose a new perspective on the bi-encoder architecture\ncalled the \\textit{encoding--searching separation} perspective, which\nconceptually and practically separates the encoding and searching operations.\nThis new perspective is applied to explain the root cause of the identified\nissues and discuss ways to mitigate the problems. Finally, we discuss the\nimplications of the ideas underlying the new perspective, the design surface\nthat it exposes and the potential research directions arising from it.",
    "arxiv_id": "http://arxiv.org/abs/2408.01094v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01094v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Universality of kernel random matrices and kernel regression in the quadratic regime",
    "authors": "Parthe Pandit, Zhichao Wang, Yizhe Zhu",
    "abstract": "Kernel ridge regression (KRR) is a popular class of machine learning models\nthat has become an important tool for understanding deep learning. Much of the\nfocus has been on studying the proportional asymptotic regime, $n \\asymp d$,\nwhere $n$ is the number of training samples and $d$ is the dimension of the\ndataset. In this regime, under certain conditions on the data distribution, the\nkernel random matrix involved in KRR exhibits behavior akin to that of a linear\nkernel. In this work, we extend the study of kernel regression to the quadratic\nasymptotic regime, where $n \\asymp d^2$. In this regime, we demonstrate that a\nbroad class of inner-product kernels exhibit behavior similar to a quadratic\nkernel. Specifically, we establish an operator norm approximation bound for the\ndifference between the original kernel random matrix and a quadratic kernel\nrandom matrix with additional correction terms compared to the Taylor expansion\nof the kernel functions. The approximation works for general data distributions\nunder a Gaussian-moment-matching assumption with a covariance structure. This\nnew approximation is utilized to obtain a limiting spectral distribution of the\noriginal kernel matrix and characterize the precise asymptotic training and\ngeneralization errors for KRR in the quadratic regime when $n/d^2$ converges to\na non-zero constant. The generalization errors are obtained for both\ndeterministic and random teacher models. Our proof techniques combine moment\nmethods, Wick's formula, orthogonal polynomials, and resolvent analysis of\nrandom matrices with correlated entries.",
    "arxiv_id": "http://arxiv.org/abs/2408.01062v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01062v1",
    "primary_category": "stat.ML",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "The Impact of Hyperparameters on Large Language Model Inference Performance: An Evaluation of vLLM and HuggingFace Pipelines",
    "authors": "Matias Martinez",
    "abstract": "The recent surge of open-source large language models (LLMs) enables\ndevelopers to create AI-based solutions while maintaining control over aspects\nsuch as privacy and compliance, thereby providing governance and ownership of\nthe model deployment process. To utilize these LLMs, inference engines are\nneeded. These engines load the model's weights onto available resources, such\nas GPUs, and process queries to generate responses. The speed of inference, or\nperformance, of the LLM, is critical for real-time applications, as it computes\nmillions or billions of floating point operations per inference. Recently,\nadvanced inference engines such as vLLM have emerged, incorporating novel\nmechanisms such as efficient memory management to achieve state-of-the-art\nperformance. In this paper, we analyze the performance, particularly the\nthroughput (tokens generated per unit of time), of 20 LLMs using two inference\nlibraries: vLLM and HuggingFace's pipelines. We investigate how various\nhyperparameters, which developers must configure, influence inference\nperformance. Our results reveal that throughput landscapes are irregular, with\ndistinct peaks, highlighting the importance of hyperparameter optimization to\nachieve maximum performance. We also show that applying hyperparameter\noptimization when upgrading or downgrading the GPU model used for inference can\nimprove throughput from HuggingFace pipelines by an average of 9.16% and 13.7%,\nrespectively.",
    "arxiv_id": "http://arxiv.org/abs/2408.01050v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01050v1",
    "primary_category": "cs.SE",
    "votes": 0,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Privacy-Preserving Split Learning with Vision Transformers using Patch-Wise Random and Noisy CutMix",
    "authors": "Seungeun Oh, Sihun Baek, Jihong Park, Hyelin Nam, Praneeth Vepakomma, Ramesh Raskar, Mehdi Bennis, Seong-Lyun Kim",
    "abstract": "In computer vision, the vision transformer (ViT) has increasingly superseded\nthe convolutional neural network (CNN) for improved accuracy and robustness.\nHowever, ViT's large model sizes and high sample complexity make it difficult\nto train on resource-constrained edge devices. Split learning (SL) emerges as a\nviable solution, leveraging server-side resources to train ViTs while utilizing\nprivate data from distributed devices. However, SL requires additional\ninformation exchange for weight updates between the device and the server,\nwhich can be exposed to various attacks on private training data. To mitigate\nthe risk of data breaches in classification tasks, inspired from the CutMix\nregularization, we propose a novel privacy-preserving SL framework that injects\nGaussian noise into smashed data and mixes randomly chosen patches of smashed\ndata across clients, coined DP-CutMixSL. Our analysis demonstrates that\nDP-CutMixSL is a differentially private (DP) mechanism that strengthens privacy\nprotection against membership inference attacks during forward propagation.\nThrough simulations, we show that DP-CutMixSL improves privacy protection\nagainst membership inference attacks, reconstruction attacks, and label\ninference attacks, while also improving accuracy compared to DP-SL and\nDP-MixSL.",
    "arxiv_id": "http://arxiv.org/abs/2408.01040v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01040v1",
    "primary_category": "cs.DC",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Distilling interpretable causal trees from causal forests",
    "authors": "Patrick Rehill",
    "abstract": "Machine learning methods for estimating treatment effect heterogeneity\npromise greater flexibility than existing methods that test a few pre-specified\nhypotheses. However, one problem these methods can have is that it can be\nchallenging to extract insights from complicated machine learning models. A\nhigh-dimensional distribution of conditional average treatment effects may give\naccurate, individual-level estimates, but it can be hard to understand the\nunderlying patterns; hard to know what the implications of the analysis are.\nThis paper proposes the Distilled Causal Tree, a method for distilling a\nsingle, interpretable causal tree from a causal forest. This compares well to\nexisting methods of extracting a single tree, particularly in noisy data or\nhigh-dimensional data where there are many correlated features. Here it even\noutperforms the base causal forest in most simulations. Its estimates are\ndoubly robust and asymptotically normal just as those of the causal forest are.",
    "arxiv_id": "http://arxiv.org/abs/2408.01023v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01023v1",
    "primary_category": "econ.EM",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "A Family of Distributions of Random Subsets for Controlling Positive and Negative Dependence",
    "authors": "Takahiro Kawashima, Hideitsu Hino",
    "abstract": "Positive and negative dependence are fundamental concepts that characterize\nthe attractive and repulsive behavior of random subsets. Although some\nprobabilistic models are known to exhibit positive or negative dependence, it\nis challenging to seamlessly bridge them with a practicable probabilistic\nmodel. In this study, we introduce a new family of distributions, named the\ndiscrete kernel point process (DKPP), which includes determinantal point\nprocesses and parts of Boltzmann machines. We also develop some computational\nmethods for probabilistic operations and inference with DKPPs, such as\ncalculating marginal and conditional probabilities and learning the parameters.\nOur numerical experiments demonstrate the controllability of positive and\nnegative dependence and the effectiveness of the computational methods for\nDKPPs.",
    "arxiv_id": "http://arxiv.org/abs/2408.01022v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01022v1",
    "primary_category": "stat.ML",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "GNN-MolKAN: Harnessing the Power of KAN to Advance Molecular Representation Learning with GNNs",
    "authors": "Ruifeng Li",
    "abstract": "Effective molecular representation learning is crucial for molecular property\nprediction and drug design. However, existing approaches struggle with\nlimitations in insufficient annotations and suboptimal architecture design. For\ninstance, Graph Neural Networks (GNNs) suffer from over-squashing, causing the\nloss of important structural details in molecules, thus impairing molecular\nrepresentations. In this work, we propose a new class of GNNs, GNN-MolKAN and\nits augmented variant, GNN-MolKAN+, that integrate the Kolmogorov-Arnold\nNetworks (KAN) architecture from AI + Science into GNNs to address these\nchallenges. Additionally, we introduce Adaptive FastKAN (AdFastKAN), an\nadvanced KAN that offers increased stability and speed, further enhancing the\nperformance of standard GNNs. Notably, our approach holds three key benefits:\n1) Superior Performance: GNN-MolKAN and GNN-MolKAN+ demonstrate superior\nprediction ability, robust generalization to unseen scaffolds, and versatile\ntransferability across different GNN architectures. 2) Efficiency: These models\nrequire less computational time and fewer parameters while matching or\nsurpassing the state-of-the-art (SOTA) self-supervised methods. 3) Few-shot\nLearning Ability: GNN-MolKAN demonstrates great potential in few-shot learning\nscenarios, achieving an average improvement of 6.97% across few-shot\nbenchmarks. Overall, we validate our architecture on 6 classification datasets,\n6 regression datasets, and 4 few-shot learning datasets, consistently achieving\nhighly competitive results across all of them.",
    "arxiv_id": "http://arxiv.org/abs/2408.01018v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01018v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "IBB Traffic Graph Data: Benchmarking and Road Traffic Prediction Model",
    "authors": "Eren Olug, Kiymet Kaya, Resul Tugay, Sule Gunduz Oguducu",
    "abstract": "Road traffic congestion prediction is a crucial component of intelligent\ntransportation systems, since it enables proactive traffic management, enhances\nsuburban experience, reduces environmental impact, and improves overall safety\nand efficiency. Although there are several public datasets, especially for\nmetropolitan areas, these datasets may not be applicable to practical scenarios\ndue to insufficiency in the scale of data (i.e. number of sensors and road\nlinks) and several external factors like different characteristics of the\ntarget area such as urban, highways and the data collection location. To\naddress this, this paper introduces a novel IBB Traffic graph dataset as an\nalternative benchmark dataset to mitigate these limitations and enrich the\nliterature with new geographical characteristics. IBB Traffic graph dataset\ncovers the sensor data collected at 2451 distinct locations. Moreover, we\npropose a novel Road Traffic Prediction Model that strengthens temporal links\nthrough feature engineering, node embedding with GLEE to represent\ninter-related relationships within the traffic network, and traffic prediction\nwith ExtraTrees. The results indicate that the proposed model consistently\noutperforms the baseline models, demonstrating an average accuracy improvement\nof 4%.",
    "arxiv_id": "http://arxiv.org/abs/2408.01016v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01016v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Tensor Train Low-rank Approximation (TT-LoRA): Democratizing AI with Accelerated LLMs",
    "authors": "Afia Anjum, Maksim E. Eren, Ismael Boureima, Boian Alexandrov, Manish Bhattarai",
    "abstract": "In recent years, Large Language Models (LLMs) have demonstrated remarkable\ncapabilities across a wide range of natural language processing (NLP) tasks,\nsuch as question-answering, sentiment analysis, text summarization, and machine\ntranslation. However, the ever-growing complexity of LLMs demands immense\ncomputational resources, hindering the broader research and application of\nthese models. To address this, various parameter-efficient fine-tuning\nstrategies, such as Low-Rank Approximation (LoRA) and Adapters, have been\ndeveloped. Despite their potential, these methods often face limitations in\ncompressibility. Specifically, LoRA struggles to scale effectively with the\nincreasing number of trainable parameters in modern large scale LLMs.\nAdditionally, Low-Rank Economic Tensor-Train Adaptation (LoRETTA), which\nutilizes tensor train decomposition, has not yet achieved the level of\ncompression necessary for fine-tuning very large scale models with limited\nresources. This paper introduces Tensor Train Low-Rank Approximation (TT-LoRA),\na novel parameter-efficient fine-tuning (PEFT) approach that extends LoRETTA\nwith optimized tensor train (TT) decomposition integration. By eliminating\nAdapters and traditional LoRA-based structures, TT-LoRA achieves greater model\ncompression without compromising downstream task performance, along with\nreduced inference latency and computational overhead. We conduct an exhaustive\nparameter search to establish benchmarks that highlight the trade-off between\nmodel compression and performance. Our results demonstrate significant\ncompression of LLMs while maintaining comparable performance to larger models,\nfacilitating their deployment on resource-constraint platforms.",
    "arxiv_id": "http://arxiv.org/abs/2408.01008v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01008v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Enhancing Financial Market Predictions: Causality-Driven Feature Selection",
    "authors": "Wenhao Liang, Zhengyang Li, Weitong Chen",
    "abstract": "This paper introduces the FinSen dataset that revolutionizes financial market\nanalysis by integrating economic and financial news articles from 197 countries\nwith stock market data. The dataset's extensive coverage spans 15 years from\n2007 to 2023 with temporal information, offering a rich, global perspective\nwith 160,000 records on financial market news. Our study leverages causally\nvalidated sentiment scores and LSTM models to enhance market forecast accuracy\nand reliability. Utilizing the FinSen dataset, we introduce an innovative Focal\nCalibration Loss, reducing Expected Calibration Error (ECE) to 3.34 percent\nwith the DAN 3 model. This not only improves prediction accuracy but also\naligns probabilistic forecasts closely with real outcomes, crucial for the\nfinancial sector where predicted probability is paramount. Our approach\ndemonstrates the effectiveness of combining sentiment analysis with precise\ncalibration techniques for trustworthy financial forecasting where the cost of\nmisinterpretation can be high. Finsen Data can be found at [this github\nURL](https://github.com/EagleAdelaide/FinSen_Dataset.git).",
    "arxiv_id": "http://arxiv.org/abs/2408.01005v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01005v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Adaptive Two-Stage Cloud Resource Scaling via Hierarchical Multi-Indicator Forecasting and Bayesian Decision-Making",
    "authors": "Yang Luo, Shiyu Wang, Zhemeng Yu, Wei Lu, Xiaofeng Gao, Lintao Ma, Guihai Chen",
    "abstract": "The surging demand for cloud computing resources, driven by the rapid growth\nof sophisticated large-scale models and data centers, underscores the critical\nimportance of efficient and adaptive resource allocation. As major tech\nenterprises deploy massive infrastructures with thousands of GPUs, existing\ncloud platforms still struggle with low resource utilization due to key\nchallenges: capturing hierarchical indicator structures, modeling non-Gaussian\ndistributions, and decision-making under uncertainty. To address these\nchallenges, we propose HRAMONY, an adaptive Hierarchical Attention-based\nResource Modeling and Decision-Making System. HARMONY combines hierarchical\nmulti-indicator distribution forecasting and uncertainty-aware Bayesian\ndecision-making. It introduces a novel hierarchical attention mechanism that\ncomprehensively models complex inter-indicator dependencies, enabling accurate\npredictions that can adapt to evolving environment states. By transforming\nGaussian projections into adaptive non-Gaussian distributions via Normalizing\nFlows. Crucially, HARMONY leverages the full predictive distributions in an\nadaptive Bayesian process, proactively incorporating uncertainties to optimize\nresource allocation while robustly meeting SLA constraints under varying\nconditions. Extensive evaluations across four large-scale cloud datasets\ndemonstrate HARMONY's state-of-the-art performance, significantly outperforming\nnine established methods. A month-long real-world deployment validated\nHARMONY's substantial practical impact, realizing over 35,000 GPU hours in\nsavings and translating to $100K+ in cost reduction, showcasing its remarkable\neconomic value through adaptive, uncertainty-aware scaling. Our code is\navailable at https://github.com/Floating-LY/HARMONY1.",
    "arxiv_id": "http://arxiv.org/abs/2408.01000v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01000v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "IncidentNet: Traffic Incident Detection, Localization and Severity Estimation with Sparse Sensing",
    "authors": "Sai Shashank Peddiraju, Kaustubh Harapanahalli, Edward Andert, Aviral Shrivastava",
    "abstract": "Prior art in traffic incident detection relies on high sensor coverage and is\nprimarily based on decision-tree and random forest models that have limited\nrepresentation capacity and, as a result, cannot detect incidents with high\naccuracy. This paper presents IncidentNet - a novel approach for classifying,\nlocalizing, and estimating the severity of traffic incidents using deep\nlearning models trained on data captured from sparsely placed sensors in urban\nenvironments. Our model works on microscopic traffic data that can be collected\nusing cameras installed at traffic intersections. Due to the unavailability of\ndatasets that provide microscopic traffic details and traffic incident details\nsimultaneously, we also present a methodology to generate a synthetic\nmicroscopic traffic dataset that matches given macroscopic traffic data.\nIncidentNet achieves a traffic incident detection rate of 98%, with false alarm\nrates of less than 7% in 197 seconds on average in urban environments with\ncameras on less than 20% of the traffic intersections.",
    "arxiv_id": "http://arxiv.org/abs/2408.00996v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00996v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Fairness in Large Language Models in Three Hour",
    "authors": "Thang Doan Viet, Zichong Wang, Minh Nhat Nguyen, Wenbin Zhang",
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable success across\nvarious domains but often lack fairness considerations, potentially leading to\ndiscriminatory outcomes against marginalized populations. Unlike fairness in\ntraditional machine learning, fairness in LLMs involves unique backgrounds,\ntaxonomies, and fulfillment techniques. This tutorial provides a systematic\noverview of recent advances in the literature concerning fair LLMs, beginning\nwith real-world case studies to introduce LLMs, followed by an analysis of bias\ncauses therein. The concept of fairness in LLMs is then explored, summarizing\nthe strategies for evaluating bias and the algorithms designed to promote\nfairness. Additionally, resources for assessing bias in LLMs, including\ntoolkits and datasets, are compiled, and current research challenges and open\nquestions in the field are discussed. The repository is available at\n\\url{https://github.com/LavinWong/Fairness-in-Large-Language-Models}.",
    "arxiv_id": "http://arxiv.org/abs/2408.00992v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00992v1",
    "primary_category": "cs.CL",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Reconstructing Richtmyer-Meshkov instabilities from noisy radiographs using low dimensional features and attention-based neural networks",
    "authors": "Daniel A. Serino, Marc L. Klasky, Balasubramanya T. Nadiga, Xiaojian Xu, Trevor Wilcox",
    "abstract": "A trained attention-based transformer network can robustly recover the\ncomplex topologies given by the Richtmyer-Meshkoff instability from a sequence\nof hydrodynamic features derived from radiographic images corrupted with blur,\nscatter, and noise. This approach is demonstrated on ICF-like double shell\nhydrodynamic simulations. The key component of this network is a transformer\nencoder that acts on a sequence of features extracted from noisy radiographs.\nThis encoder includes numerous self-attention layers that act to learn temporal\ndependencies in the input sequences and increase the expressiveness of the\nmodel. This approach is demonstrated to exhibit an excellent ability to\naccurately recover the Richtmyer-Meshkov instability growth rates, even despite\nthe gas-metal interface being greatly obscured by radiographic noise.",
    "arxiv_id": "http://arxiv.org/abs/2408.00985v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00985v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "META-ANOVA: Screening interactions for interpretable machine learning",
    "authors": "Yongchan Choi, Seokhun Park, Chanmoo Park, Dongha Kim, Yongdai Kim",
    "abstract": "There are two things to be considered when we evaluate predictive models. One\nis prediction accuracy,and the other is interpretability. Over the recent\ndecades, many prediction models of high performance, such as ensemble-based\nmodels and deep neural networks, have been developed. However, these models are\noften too complex, making it difficult to intuitively interpret their\npredictions. This complexity in interpretation limits their use in many\nreal-world fields that require accountability, such as medicine, finance, and\ncollege admissions. In this study, we develop a novel method called Meta-ANOVA\nto provide an interpretable model for any given prediction model. The basic\nidea of Meta-ANOVA is to transform a given black-box prediction model to the\nfunctional ANOVA model. A novel technical contribution of Meta-ANOVA is a\nprocedure of screening out unnecessary interaction before transforming a given\nblack-box model to the functional ANOVA model. This screening procedure allows\nthe inclusion of higher order interactions in the transformed functional ANOVA\nmodel without computational difficulties. We prove that the screening procedure\nis asymptotically consistent. Through various experiments with synthetic and\nreal-world datasets, we empirically demonstrate the superiority of Meta-ANOVA",
    "arxiv_id": "http://arxiv.org/abs/2408.00973v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00973v1",
    "primary_category": "stat.ML",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "MIS-ME: A Multi-modal Framework for Soil Moisture Estimation",
    "authors": "Mohammed Rakib, Adil Aman Mohammed, Cole Diggins, Sumit Sharma, Jeff Michael Sadler, Tyson Ochsner, Arun Bagavathi",
    "abstract": "Soil moisture estimation is an important task to enable precision agriculture\nin creating optimal plans for irrigation, fertilization, and harvest. It is\ncommon to utilize statistical and machine learning models to estimate soil\nmoisture from traditional data sources such as weather forecasts, soil\nproperties, and crop properties. However, there is a growing interest in\nutilizing aerial and geospatial imagery to estimate soil moisture. Although\nthese images capture high-resolution crop details, they are expensive to curate\nand challenging to interpret. Imagine, an AI-enhanced software tool that\npredicts soil moisture using visual cues captured by smartphones and\nstatistical data given by weather forecasts. This work is a first step towards\nthat goal of developing a multi-modal approach for soil moisture estimation. In\nparticular, we curate a dataset consisting of real-world images taken from\nground stations and their corresponding weather data. We also propose MIS-ME -\nMeteorological & Image based Soil Moisture Estimator, a multi-modal framework\nfor soil moisture estimation. Our extensive analysis shows that MIS-ME achieves\na MAPE of 10.79%, outperforming traditional unimodal approaches with a\nreduction of 2.6% in MAPE for meteorological data and 1.5% in MAPE for image\ndata, highlighting the effectiveness of tailored multi-modal approaches.",
    "arxiv_id": "http://arxiv.org/abs/2408.00963v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00963v1",
    "primary_category": "cs.CV",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Aggregation Models with Optimal Weights for Distributed Gaussian Processes",
    "authors": "Haoyuan Chen, Rui Tuo",
    "abstract": "Gaussian process (GP) models have received increasingly attentions in recent\nyears due to their superb prediction accuracy and modeling flexibility. To\naddress the computational burdens of GP models for large-scale datasets,\ndistributed learning for GPs are often adopted. Current aggregation models for\ndistributed GPs are not time-efficient when incorporating correlations between\nGP experts. In this work, we propose a novel approach for aggregated prediction\nin distributed GPs. The technique is suitable for both the exact and sparse\nvariational GPs. The proposed method incorporates correlations among experts,\nleading to better prediction accuracy with manageable computational\nrequirements. As demonstrated by empirical studies, the proposed approach\nresults in more stable predictions in less time than state-of-the-art\nconsistent aggregation models.",
    "arxiv_id": "http://arxiv.org/abs/2408.00955v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00955v1",
    "primary_category": "stat.ML",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Equivariant neural networks and piecewise linear representation theory",
    "authors": "Joel Gibson, Daniel Tubbenhauer, Geordie Williamson",
    "abstract": "Equivariant neural networks are neural networks with symmetry. Motivated by\nthe theory of group representations, we decompose the layers of an equivariant\nneural network into simple representations. The nonlinear activation functions\nlead to interesting nonlinear equivariant maps between simple representations.\nFor example, the rectified linear unit (ReLU) gives rise to piecewise linear\nmaps. We show that these considerations lead to a filtration of equivariant\nneural networks, generalizing Fourier series. This observation might provide a\nuseful tool for interpreting equivariant neural networks.",
    "arxiv_id": "http://arxiv.org/abs/2408.00949v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00949v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Generalisation of Total Uncertainty in AI: A Theoretical Study",
    "authors": "Keivan Shariatmadar",
    "abstract": "AI has been dealing with uncertainty to have highly accurate results. This\nbecomes even worse with reasonably small data sets or a variation in the data\nsets. This has far-reaching effects on decision-making, forecasting and\nlearning mechanisms. This study seeks to unpack the nature of uncertainty that\nexists within AI by drawing ideas from established works, the latest\ndevelopments and practical applications and provide a novel total uncertainty\ndefinition in AI.\n  From inception theories up to current methodologies, this paper provides an\nintegrated view of dealing with better total uncertainty as well as\ncomplexities of uncertainty in AI that help us understand its meaning and value\nacross different domains.",
    "arxiv_id": "http://arxiv.org/abs/2408.00946v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00946v1",
    "primary_category": "cs.AI",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Enabling High Data Throughput Reinforcement Learning on GPUs: A Domain Agnostic Framework for Data-Driven Scientific Research",
    "authors": "Tian Lan, Huan Wang, Caiming Xiong, Silvio Savarese",
    "abstract": "We introduce WarpSci, a domain agnostic framework designed to overcome\ncrucial system bottlenecks encountered in the application of reinforcement\nlearning to intricate environments with vast datasets featuring\nhigh-dimensional observation or action spaces. Notably, our framework\neliminates the need for data transfer between the CPU and GPU, enabling the\nconcurrent execution of thousands of simulations on a single or multiple GPUs.\nThis high data throughput architecture proves particularly advantageous for\ndata-driven scientific research, where intricate environment models are\ncommonly essential.",
    "arxiv_id": "http://arxiv.org/abs/2408.00930v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00930v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Verification of Machine Unlearning is Fragile",
    "authors": "Binchi Zhang, Zihan Chen, Cong Shen, Jundong Li",
    "abstract": "As privacy concerns escalate in the realm of machine learning, data owners\nnow have the option to utilize machine unlearning to remove their data from\nmachine learning models, following recent legislation. To enhance transparency\nin machine unlearning and avoid potential dishonesty by model providers,\nvarious verification strategies have been proposed. These strategies enable\ndata owners to ascertain whether their target data has been effectively\nunlearned from the model. However, our understanding of the safety issues of\nmachine unlearning verification remains nascent. In this paper, we explore the\nnovel research question of whether model providers can circumvent verification\nstrategies while retaining the information of data supposedly unlearned. Our\ninvestigation leads to a pessimistic answer: \\textit{the verification of\nmachine unlearning is fragile}. Specifically, we categorize the current\nverification strategies regarding potential dishonesty among model providers\ninto two types. Subsequently, we introduce two novel adversarial unlearning\nprocesses capable of circumventing both types. We validate the efficacy of our\nmethods through theoretical analysis and empirical experiments using real-world\ndatasets. This study highlights the vulnerabilities and limitations in machine\nunlearning verification, paving the way for further research into the safety of\nmachine unlearning.",
    "arxiv_id": "http://arxiv.org/abs/2408.00929v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00929v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Automatic Pull Request Description Generation Using LLMs: A T5 Model Approach",
    "authors": "Md Nazmus Sakib, Md Athikul Islam, Md Mashrur Arifin",
    "abstract": "Developers create pull request (PR) descriptions to provide an overview of\ntheir changes and explain the motivations behind them. These descriptions help\nreviewers and fellow developers quickly understand the updates. Despite their\nimportance, some developers omit these descriptions. To tackle this problem, we\npropose an automated method for generating PR descriptions based on commit\nmessages and source code comments. This method frames the task as a text\nsummarization problem, for which we utilized the T5 text-to-text transfer\nmodel. We fine-tuned a pre-trained T5 model using a dataset containing 33,466\nPRs. The model's effectiveness was assessed using ROUGE metrics, which are\nrecognized for their strong alignment with human evaluations. Our findings\nreveal that the T5 model significantly outperforms LexRank, which served as our\nbaseline for comparison.",
    "arxiv_id": "http://arxiv.org/abs/2408.00921v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00921v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Towards Certified Unlearning for Deep Neural Networks",
    "authors": "Binchi Zhang, Yushun Dong, Tianhao Wang, Jundong Li",
    "abstract": "In the field of machine unlearning, certified unlearning has been extensively\nstudied in convex machine learning models due to its high efficiency and strong\ntheoretical guarantees. However, its application to deep neural networks\n(DNNs), known for their highly nonconvex nature, still poses challenges. To\nbridge the gap between certified unlearning and DNNs, we propose several simple\ntechniques to extend certified unlearning methods to nonconvex objectives. To\nreduce the time complexity, we develop an efficient computation method by\ninverse Hessian approximation without compromising certification guarantees. In\naddition, we extend our discussion of certification to nonconvergence training\nand sequential unlearning, considering that real-world users can send\nunlearning requests at different time points. Extensive experiments on three\nreal-world datasets demonstrate the efficacy of our method and the advantages\nof certified unlearning in DNNs.",
    "arxiv_id": "http://arxiv.org/abs/2408.00920v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00920v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Distance-Preserving Generative Modeling of Spatial Transcriptomics",
    "authors": "Wenbin Zhou, Jin-Hong Du",
    "abstract": "Spatial transcriptomics data is invaluable for understanding the spatial\norganization of gene expression in tissues. There have been consistent efforts\nin studying how to effectively utilize the associated spatial information for\nrefining gene expression modeling. We introduce a class of distance-preserving\ngenerative models for spatial transcriptomics, which utilizes the provided\nspatial information to regularize the learned representation space of gene\nexpressions to have a similar pair-wise distance structure. This helps the\nlatent space to capture meaningful encodings of genes in spatial proximity. We\ncarry out theoretical analysis over a tractable loss function for this purpose\nand formalize the overall learning objective as a regularized evidence lower\nbound. Our framework grants compatibility with any variational-inference-based\ngenerative models for gene expression modeling. Empirically, we validate our\nproposed method on the mouse brain tissues Visium dataset and observe improved\nperformance with variational autoencoders and scVI used as backbone models.",
    "arxiv_id": "http://arxiv.org/abs/2408.00911v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00911v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Early Stopping Based on Repeated Significance",
    "authors": "Eric Bax, Arundhyoti Sarkar, Alex Shtoff",
    "abstract": "For a bucket test with a single criterion for success and a fixed number of\nsamples or testing period, requiring a $p$-value less than a specified value of\n$\\alpha$ for the success criterion produces statistical confidence at level $1\n- \\alpha$. For multiple criteria, a Bonferroni correction that partitions\n$\\alpha$ among the criteria produces statistical confidence, at the cost of\nrequiring lower $p$-values for each criterion. The same concept can be applied\nto decisions about early stopping, but that can lead to strict requirements for\n$p$-values. We show how to address that challenge by requiring criteria to be\nsuccessful at multiple decision points.",
    "arxiv_id": "http://arxiv.org/abs/2408.00908v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00908v1",
    "primary_category": "stat.ME",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Parkinson's Disease Detection from Resting State EEG using Multi-Head Graph Structure Learning with Gradient Weighted Graph Attention Explanations",
    "authors": "Christopher Neves, Yong Zeng, Yiming Xiao",
    "abstract": "Parkinson's disease (PD) is a debilitating neurodegenerative disease that has\nsevere impacts on an individual's quality of life. Compared with structural and\nfunctional MRI-based biomarkers for the disease, electroencephalography (EEG)\ncan provide more accessible alternatives for clinical insights. While deep\nlearning (DL) techniques have provided excellent outcomes, many techniques fail\nto model spatial information and dynamic brain connectivity, and face\nchallenges in robust feature learning, limited data sizes, and poor\nexplainability. To address these issues, we proposed a novel graph neural\nnetwork (GNN) technique for explainable PD detection using resting state EEG.\nSpecifically, we employ structured global convolutions with contrastive\nlearning to better model complex features with limited data, a novel multi-head\ngraph structure learner to capture the non-Euclidean structure of EEG data, and\na head-wise gradient-weighted graph attention explainer to offer neural\nconnectivity insights. We developed and evaluated our method using the UC San\nDiego Parkinson's disease EEG dataset, and achieved 69.40% detection accuracy\nin subject-wise leave-one-out cross-validation while generating intuitive\nexplanations for the learnt graph topology.",
    "arxiv_id": "http://arxiv.org/abs/2408.00906v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00906v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Discrete Randomized Smoothing Meets Quantum Computing",
    "authors": "Tom Wollschl\u00e4ger, Aman Saxena, Nicola Franco, Jeanette Miriam Lorenz, Stephan G\u00fcnnemann",
    "abstract": "Breakthroughs in machine learning (ML) and advances in quantum computing (QC)\ndrive the interdisciplinary field of quantum machine learning to new levels.\nHowever, due to the susceptibility of ML models to adversarial attacks,\npractical use raises safety-critical concerns. Existing Randomized Smoothing\n(RS) certification methods for classical machine learning models are\ncomputationally intensive. In this paper, we propose the combination of QC and\nthe concept of discrete randomized smoothing to speed up the stochastic\ncertification of ML models for discrete data. We show how to encode all the\nperturbations of the input binary data in superposition and use Quantum\nAmplitude Estimation (QAE) to obtain a quadratic reduction in the number of\ncalls to the model that are required compared to traditional randomized\nsmoothing techniques. In addition, we propose a new binary threat model to\nallow for an extensive evaluation of our approach on images, graphs, and text.",
    "arxiv_id": "http://arxiv.org/abs/2408.00895v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00895v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Peptide Sequencing Via Protein Language Models",
    "authors": "Thuong Le Hoai Pham, Jillur Rahman Saurav, Aisosa A. Omere, Calvin J. Heyl, Mohammad Sadegh Nasr, Cody Tyler Reynolds, Jai Prakash Yadav Veerla, Helen H Shang, Justyn Jaworski, Alison Ravenscraft, Joseph Anthony Buonomo, Jacob M. Luber",
    "abstract": "We introduce a protein language model for determining the complete sequence\nof a peptide based on measurement of a limited set of amino acids. To date,\nprotein sequencing relies on mass spectrometry, with some novel edman\ndegregation based platforms able to sequence non-native peptides. Current\nprotein sequencing techniques face limitations in accurately identifying all\namino acids, hindering comprehensive proteome analysis. Our method simulates\npartial sequencing data by selectively masking amino acids that are\nexperimentally difficult to identify in protein sequences from the UniRef\ndatabase. This targeted masking mimics real-world sequencing limitations. We\nthen modify and finetune a ProtBert derived transformer-based model, for a new\ndownstream task predicting these masked residues, providing an approximation of\nthe complete sequence. Evaluating on three bacterial Escherichia species, we\nachieve per-amino-acid accuracy up to 90.5% when only four amino acids ([KCYM])\nare known. Structural assessment using AlphaFold and TM-score validates the\nbiological relevance of our predictions. The model also demonstrates potential\nfor evolutionary analysis through cross-species performance. This integration\nof simulated experimental constraints with computational predictions offers a\npromising avenue for enhancing protein sequence analysis, potentially\naccelerating advancements in proteomics and structural biology by providing a\nprobabilistic reconstruction of the complete protein sequence from limited\nexperimental data.",
    "arxiv_id": "http://arxiv.org/abs/2408.00892v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00892v1",
    "primary_category": "q-bio.BM",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "On the Relationship Between Monotone and Squared Probabilistic Circuits",
    "authors": "Benjie Wang, Guy Van den Broeck",
    "abstract": "Probabilistic circuits are a unifying representation of functions as\ncomputation graphs of weighted sums and products. Their primary application is\nin probabilistic modeling, where circuits with non-negative weights (monotone\ncircuits) can be used to represent and learn density/mass functions, with\ntractable marginal inference. Recently, it was proposed to instead represent\ndensities as the square of the circuit function (squared circuits); this allows\nthe use of negative weights while retaining tractability, and can be\nexponentially more compact than monotone circuits. Unfortunately, we show the\nreverse also holds, meaning that monotone circuits and squared circuits are\nincomparable in general. This raises the question of whether we can reconcile,\nand indeed improve upon the two modeling approaches. We answer in the positive\nby proposing InceptionPCs, a novel type of circuit that naturally encompasses\nboth monotone circuits and squared circuits as special cases, and employs\ncomplex parameters. Empirically, we validate that InceptionPCs can outperform\nboth monotone and squared circuits on image datasets.",
    "arxiv_id": "http://arxiv.org/abs/2408.00876v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00876v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Online Detection of Anomalies in Temporal Knowledge Graphs with Interpretability",
    "authors": "Jiasheng Zhang, Jie Shao, Rex Ying",
    "abstract": "Temporal knowledge graphs (TKGs) are valuable resources for capturing\nevolving relationships among entities, yet they are often plagued by noise,\nnecessitating robust anomaly detection mechanisms. Existing dynamic graph\nanomaly detection approaches struggle to capture the rich semantics introduced\nby node and edge categories within TKGs, while TKG embedding methods lack\ninterpretability, undermining the credibility of anomaly detection. Moreover,\nthese methods falter in adapting to pattern changes and semantic drifts\nresulting from knowledge updates. To tackle these challenges, we introduce\nAnoT, an efficient TKG summarization method tailored for interpretable online\nanomaly detection in TKGs. AnoT begins by summarizing a TKG into a novel rule\ngraph, enabling flexible inference of complex patterns in TKGs. When new\nknowledge emerges, AnoT maps it onto a node in the rule graph and traverses the\nrule graph recursively to derive the anomaly score of the knowledge. The\ntraversal yields reachable nodes that furnish interpretable evidence for the\nvalidity or the anomalous of the new knowledge. Overall, AnoT embodies a\ndetector-updater-monitor architecture, encompassing a detector for offline TKG\nsummarization and online scoring, an updater for real-time rule graph updates\nbased on emerging knowledge, and a monitor for estimating the approximation\nerror of the rule graph. Experimental results on four real-world datasets\ndemonstrate that AnoT surpasses existing methods significantly in terms of\naccuracy and interoperability. All of the raw datasets and the implementation\nof AnoT are provided in https://github.com/zjs123/ANoT.",
    "arxiv_id": "http://arxiv.org/abs/2408.00872v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00872v1",
    "primary_category": "cs.AI",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "UniMoT: Unified Molecule-Text Language Model with Discrete Token Representation",
    "authors": "Juzheng Zhang, Yatao Bian, Yongqiang Chen, Quanming Yao",
    "abstract": "The remarkable success of Large Language Models (LLMs) across diverse tasks\nhas driven the research community to extend their capabilities to molecular\napplications. However, most molecular LLMs employ adapter-based architectures\nthat do not treat molecule and text modalities equally and lack a supervision\nsignal for the molecule modality. To address these issues, we introduce UniMoT,\na Unified Molecule-Text LLM adopting a tokenizer-based architecture that\nexpands the vocabulary of LLM with molecule tokens. Specifically, we introduce\na Vector Quantization-driven tokenizer that incorporates a Q-Former to bridge\nthe modality gap between molecule and text. This tokenizer transforms molecules\ninto sequences of molecule tokens with causal dependency, encapsulating\nhigh-level molecular and textual information. Equipped with this tokenizer,\nUniMoT can unify molecule and text modalities under a shared token\nrepresentation and an autoregressive training paradigm, enabling it to\ninterpret molecules as a foreign language and generate them as text. Following\na four-stage training scheme, UniMoT emerges as a multi-modal generalist\ncapable of performing both molecule-to-text and text-to-molecule tasks.\nExtensive experiments demonstrate that UniMoT achieves state-of-the-art\nperformance across a wide range of molecule comprehension and generation tasks.",
    "arxiv_id": "http://arxiv.org/abs/2408.00863v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00863v1",
    "primary_category": "cs.CL",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Deep Learning Approach for Changepoint Detection: Penalty Parameter Optimization",
    "authors": "Tung L Nguyen, Toby Dylan Hocking",
    "abstract": "Changepoint detection, a technique for identifying significant shifts within\ndata sequences, is crucial in various fields such as finance, genomics,\nmedicine, etc. Dynamic programming changepoint detection algorithms are\nemployed to identify the locations of changepoints within a sequence, which\nrely on a penalty parameter to regulate the number of changepoints. To estimate\nthis penalty parameter, previous work uses simple models such as linear models\nor decision trees. This study introduces a novel deep learning method for\npredicting penalty parameters, leading to demonstrably improved changepoint\ndetection accuracy on large benchmark supervised labeled datasets compared to\nprevious methods.",
    "arxiv_id": "http://arxiv.org/abs/2408.00856v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00856v1",
    "primary_category": "stat.ML",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "A Novel Use of Pseudospectra in Mathematical Biology: Understanding HPA Axis Sensitivity",
    "authors": "Catherine Drysdale, Matthew J. Colbrook",
    "abstract": "The Hypothalamic-Pituitary-Adrenal (HPA) axis is a major neuroendocrine\nsystem, and its dysregulation is implicated in various diseases. This system\nalso presents interesting mathematical challenges for modeling. We consider a\nnonlinear delay differential equation model and calculate pseudospectra of\nthree different linearizations: a time-dependent Jacobian, linearization around\nthe limit cycle, and dynamic mode decomposition (DMD) analysis of Koopman\noperators (global linearization). The time-dependent Jacobian provided insight\ninto experimental phenomena, explaining why rats respond differently to\nperturbations during corticosterone secretion's upward versus downward slopes.\nWe developed new mathematical techniques for the other two linearizations to\ncalculate pseudospectra on Banach spaces and apply DMD to delay differential\nequations, respectively. These methods helped establish local and global limit\ncycle stability and study transients. Additionally, we discuss using\npseudospectra to substantiate the model in experimental contexts and establish\nbio-variability via data-driven methods. This work is the first to utilize\npseudospectra to explore the HPA axis.",
    "arxiv_id": "http://arxiv.org/abs/2408.00845v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00845v1",
    "primary_category": "math.SP",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Calibrating Bayesian Generative Machine Learning for Bayesiamplification",
    "authors": "Sebastian Bieringer, Sascha Diefenbacher, Gregor Kasieczka, Mathias Trabs",
    "abstract": "Recently, combinations of generative and Bayesian machine learning have been\nintroduced in particle physics for both fast detector simulation and inference\ntasks. These neural networks aim to quantify the uncertainty on the generated\ndistribution originating from limited training statistics. The interpretation\nof a distribution-wide uncertainty however remains ill-defined. We show a clear\nscheme for quantifying the calibration of Bayesian generative machine learning\nmodels. For a Continuous Normalizing Flow applied to a low-dimensional toy\nexample, we evaluate the calibration of Bayesian uncertainties from either a\nmean-field Gaussian weight posterior, or Monte Carlo sampling network weights,\nto gauge their behaviour on unsteady distribution edges. Well calibrated\nuncertainties can then be used to roughly estimate the number of uncorrelated\ntruth samples that are equivalent to the generated sample and clearly indicate\ndata amplification for smooth features of the distribution.",
    "arxiv_id": "http://arxiv.org/abs/2408.00838v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00838v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "AgentGen: Enhancing Planning Abilities for Large Language Model based Agent via Environment and Task Generation",
    "authors": "Mengkang Hu, Pu Zhao, Can Xu, Qingfeng Sun, Jianguang Lou, Qingwei Lin, Ping Luo, Saravan Rajmohan, Dongmei Zhang",
    "abstract": "Large Language Model (LLM) based agents have garnered significant attention\nand are becoming increasingly popular. Furthermore, planning ability is a\ncrucial component of an LLM-based agent, involving interaction with the\nenvironment and executing actions to complete a planning task, which generally\nentails achieving a desired goal from an initial state. This paper investigates\nenhancing the planning abilities of LLMs through instruction tuning, referred\nto as agent training. Recent studies have demonstrated that utilizing\nexpert-level trajectory for instruction-tuning LLMs effectively enhances their\nplanning capabilities. However, existing work primarily focuses on synthesizing\ntrajectories from manually designed planning tasks and environments. The\nlabor-intensive nature of creating these environments and tasks impedes the\ngeneration of sufficiently varied and extensive trajectories. To address this\nlimitation, this paper explores the automated synthesis of diverse environments\nand a gradual range of planning tasks, from easy to difficult. We introduce a\nframework, AgentGen, that leverages LLMs first to generate environments and\nsubsequently generate planning tasks conditioned on these environments.\nSpecifically, to improve environmental diversity, we propose using an\ninspiration corpus composed of various domain-specific text segments as the\ncontext for synthesizing environments. Moreover, to increase the difficulty\ndiversity of generated planning tasks, we propose a bidirectional evolution\nmethod, Bi-Evol, that evolves planning tasks from easier and harder directions\nto synthesize a task set with a smoother difficulty curve. The evaluation\nresults derived from AgentBoard show that AgentGen greatly improves LLMs'\nplanning ability, e.g., the AgentGen instruction-tuned Llama-3 8B surpasses\nGPT-3.5 in overall performance. Moreover, in certain tasks, it even outperforms\nGPT-4.",
    "arxiv_id": "http://arxiv.org/abs/2408.00764v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00764v1",
    "primary_category": "cs.CL",
    "votes": 0,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Tamper-Resistant Safeguards for Open-Weight LLMs",
    "authors": "Rishub Tamirisa, Bhrugu Bharathi, Long Phan, Andy Zhou, Alice Gatti, Tarun Suresh, Maxwell Lin, Justin Wang, Rowan Wang, Ron Arel, Andy Zou, Dawn Song, Bo Li, Dan Hendrycks, Mantas Mazeika",
    "abstract": "Rapid advances in the capabilities of large language models (LLMs) have\nraised widespread concerns regarding their potential for malicious use.\nOpen-weight LLMs present unique challenges, as existing safeguards lack\nrobustness to tampering attacks that modify model weights. For example, recent\nworks have demonstrated that refusal and unlearning safeguards can be trivially\nremoved with a few steps of fine-tuning. These vulnerabilities necessitate new\napproaches for enabling the safe release of open-weight LLMs. We develop a\nmethod, called TAR, for building tamper-resistant safeguards into open-weight\nLLMs such that adversaries cannot remove the safeguards even after thousands of\nsteps of fine-tuning. In extensive evaluations and red teaming analyses, we\nfind that our method greatly improves tamper-resistance while preserving benign\ncapabilities. Our results demonstrate that tamper-resistance is a tractable\nproblem, opening up a promising new avenue to improve the safety and security\nof open-weight LLMs.",
    "arxiv_id": "http://arxiv.org/abs/2408.00761v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00761v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Smoothed Energy Guidance: Guiding Diffusion Models with Reduced Energy Curvature of Attention",
    "authors": "Susung Hong",
    "abstract": "Conditional diffusion models have shown remarkable success in visual content\ngeneration, producing high-quality samples across various domains, largely due\nto classifier-free guidance (CFG). Recent attempts to extend guidance to\nunconditional models have relied on heuristic techniques, resulting in\nsuboptimal generation quality and unintended effects. In this work, we propose\nSmoothed Energy Guidance (SEG), a novel training- and condition-free approach\nthat leverages the energy-based perspective of the self-attention mechanism to\nenhance image generation. By defining the energy of self-attention, we\nintroduce a method to reduce the curvature of the energy landscape of attention\nand use the output as the unconditional prediction. Practically, we control the\ncurvature of the energy landscape by adjusting the Gaussian kernel parameter\nwhile keeping the guidance scale parameter fixed. Additionally, we present a\nquery blurring method that is equivalent to blurring the entire attention\nweights without incurring quadratic complexity in the number of tokens. In our\nexperiments, SEG achieves a Pareto improvement in both quality and the\nreduction of side effects. The code is available at\n\\url{https://github.com/SusungHong/SEG-SDXL}.",
    "arxiv_id": "http://arxiv.org/abs/2408.00760v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00760v1",
    "primary_category": "cs.CV",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Coarse Correspondence Elicit 3D Spacetime Understanding in Multimodal Language Model",
    "authors": "Benlin Liu, Yuhao Dong, Yiqin Wang, Yongming Rao, Yansong Tang, Wei-Chiu Ma, Ranjay Krishna",
    "abstract": "Multimodal language models (MLLMs) are increasingly being implemented in\nreal-world environments, necessitating their ability to interpret 3D spaces and\ncomprehend temporal dynamics. Despite their potential, current top models\nwithin our community still fall short in adequately understanding spatial and\ntemporal dimensions. We introduce Coarse Correspondence, a simple,\ntraining-free, effective, and general-purpose visual prompting method to elicit\n3D and temporal understanding in multimodal LLMs. Our method uses a lightweight\ntracking model to find object correspondences between frames in a video or\nbetween sets of image viewpoints. It selects the most frequent object instances\nand visualizes them with markers with unique IDs in the image. With this simple\napproach, we achieve state-of-the-art results on 3D understanding benchmarks\nincluding ScanQA (+20.5\\%) and a subset of OpenEQA (+9.7\\%), and on long-form\nvideo benchmarks such as EgoSchema (+6.0\\%). We also curate a small diagnostic\ndataset to evaluate whether MLLMs can reason about space from a described\nviewpoint other than the camera viewpoint. Again, Coarse Correspondence\nimproves spatial perspective-taking abilities but we highlight that MLLMs\nstruggle with this task. Together, we demonstrate that our simple prompting\nmethod can significantly aid downstream tasks that require 3D or temporal\nreasoning.",
    "arxiv_id": "http://arxiv.org/abs/2408.00754v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00754v1",
    "primary_category": "cs.CV",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "A Policy-Gradient Approach to Solving Imperfect-Information Games with Iterate Convergence",
    "authors": "Mingyang Liu, Gabriele Farina, Asuman Ozdaglar",
    "abstract": "Policy gradient methods have become a staple of any single-agent\nreinforcement learning toolbox, due to their combination of desirable\nproperties: iterate convergence, efficient use of stochastic trajectory\nfeedback, and theoretically-sound avoidance of importance sampling corrections.\nIn multi-agent imperfect-information settings (extensive-form games), however,\nit is still unknown whether the same desiderata can be guaranteed while\nretaining theoretical guarantees. Instead, sound methods for extensive-form\ngames rely on approximating counterfactual values (as opposed to Q values),\nwhich are incompatible with policy gradient methodologies. In this paper, we\ninvestigate whether policy gradient can be safely used in two-player zero-sum\nimperfect-information extensive-form games (EFGs). We establish positive\nresults, showing for the first time that a policy gradient method leads to\nprovable best-iterate convergence to a regularized Nash equilibrium in\nself-play.",
    "arxiv_id": "http://arxiv.org/abs/2408.00751v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00751v1",
    "primary_category": "cs.GT",
    "votes": 1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Leaf Angle Estimation using Mask R-CNN and LETR Vision Transformer",
    "authors": "Venkat Margapuri, Prapti Thapaliya, Trevor Rife",
    "abstract": "Modern day studies show a high degree of correlation between high yielding\ncrop varieties and plants with upright leaf angles. It is observed that plants\nwith upright leaf angles intercept more light than those without upright leaf\nangles, leading to a higher rate of photosynthesis. Plant scientists and\nbreeders benefit from tools that can directly measure plant parameters in the\nfield i.e. on-site phenotyping. The estimation of leaf angles by manual means\nin a field setting is tedious and cumbersome. We mitigate the tedium using a\ncombination of the Mask R-CNN instance segmentation neural network, and Line\nSegment Transformer (LETR), a vision transformer. The proposed Computer Vision\n(CV) pipeline is applied on two image datasets, Summer 2015-Ames ULA and Summer\n2015- Ames MLA, with a combined total of 1,827 plant images collected in the\nfield using FieldBook, an Android application aimed at on-site phenotyping. The\nleaf angles estimated by the proposed pipeline on the image datasets are\ncompared to two independent manual measurements using ImageJ, a Java-based\nimage processing program developed at the National Institutes of Health and the\nLaboratory for Optical and Computational Instrumentation. The results, when\ncompared for similarity using the Cosine Similarity measure, exhibit 0.98\nsimilarity scores on both independent measurements of Summer 2015-Ames ULA and\nSummer 2015-Ames MLA image datasets, demonstrating the feasibility of the\nproposed pipeline for on-site measurement of leaf angles.",
    "arxiv_id": "http://arxiv.org/abs/2408.00749v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00749v1",
    "primary_category": "cs.CV",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "CERT-ED: Certifiably Robust Text Classification for Edit Distance",
    "authors": "Zhuoqun Huang, Neil G Marchant, Olga Ohrimenko, Benjamin I. P. Rubinstein",
    "abstract": "With the growing integration of AI in daily life, ensuring the robustness of\nsystems to inference-time attacks is crucial. Among the approaches for\ncertifying robustness to such adversarial examples, randomized smoothing has\nemerged as highly promising due to its nature as a wrapper around arbitrary\nblack-box models. Previous work on randomized smoothing in natural language\nprocessing has primarily focused on specific subsets of edit distance\noperations, such as synonym substitution or word insertion, without exploring\nthe certification of all edit operations. In this paper, we adapt Randomized\nDeletion (Huang et al., 2023) and propose, CERTified Edit Distance defense\n(CERT-ED) for natural language classification. Through comprehensive\nexperiments, we demonstrate that CERT-ED outperforms the existing Hamming\ndistance method RanMASK (Zeng et al., 2023) in 4 out of 5 datasets in terms of\nboth accuracy and the cardinality of the certificate. By covering various\nthreat models, including 5 direct and 5 transfer attacks, our method improves\nempirical robustness in 38 out of 50 settings.",
    "arxiv_id": "http://arxiv.org/abs/2408.00728v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00728v1",
    "primary_category": "cs.CL",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "A Natural Language Processing Framework for Hotel Recommendation Based on Users' Text Reviews",
    "authors": "Lavrentia Aravani, Emmanuel Pintelas, Christos Pierrakeas, Panagiotis Pintelas",
    "abstract": "Recently, the application of Artificial Intelligence algorithms in hotel\nrecommendation systems has become an increasingly popular topic. One such\nmethod that has proven to be effective in this field is Deep Learning,\nespecially Natural Language processing models, which are able to extract\nsemantic knowledge from user's text reviews to create more efficient\nrecommendation systems. This can lead to the development of intelligent models\nthat can classify a user's preferences and emotions based on their feedback in\nthe form of text reviews about their hotel stay experience. In this study, we\npropose a Natural Language Processing framework that utilizes customer text\nreviews to provide personalized recommendations for the most appropriate hotel\nbased on their preferences. The framework is based on Bidirectional Encoder\nRepresentations from Transformers (BERT) and a fine-tuning/validation pipeline\nthat categorizes customer hotel review texts into \"Bad,\" \"Good,\" or \"Excellent\"\nrecommended hotels. Our findings indicate that the hotel recommendation system\nwe propose can significantly enhance the user experience of booking\naccommodations by providing personalized recommendations based on user\npreferences and previous booking history.",
    "arxiv_id": "http://arxiv.org/abs/2408.00716v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00716v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "SAM 2: Segment Anything in Images and Videos",
    "authors": "Nikhila Ravi, Valentin Gabeur, Yuan-Ting Hu, Ronghang Hu, Chaitanya Ryali, Tengyu Ma, Haitham Khedr, Roman R\u00e4dle, Chloe Rolland, Laura Gustafson, Eric Mintun, Junting Pan, Kalyan Vasudev Alwala, Nicolas Carion, Chao-Yuan Wu, Ross Girshick, Piotr Doll\u00e1r, Christoph Feichtenhofer",
    "abstract": "We present Segment Anything Model 2 (SAM 2), a foundation model towards\nsolving promptable visual segmentation in images and videos. We build a data\nengine, which improves model and data via user interaction, to collect the\nlargest video segmentation dataset to date. Our model is a simple transformer\narchitecture with streaming memory for real-time video processing. SAM 2\ntrained on our data provides strong performance across a wide range of tasks.\nIn video segmentation, we observe better accuracy, using 3x fewer interactions\nthan prior approaches. In image segmentation, our model is more accurate and 6x\nfaster than the Segment Anything Model (SAM). We believe that our data, model,\nand insights will serve as a significant milestone for video segmentation and\nrelated perception tasks. We are releasing a version of our model, the dataset\nand an interactive demo.",
    "arxiv_id": "http://arxiv.org/abs/2408.00714v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00714v1",
    "primary_category": "cs.CV",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Reinforcement Learning applied to Insurance Portfolio Pursuit",
    "authors": "Edward James Young, Alistair Rogers, Elliott Tong, James Jordon",
    "abstract": "When faced with a new customer, many factors contribute to an insurance\nfirm's decision of what offer to make to that customer. In addition to the\nexpected cost of providing the insurance, the firm must consider the other\noffers likely to be made to the customer, and how sensitive the customer is to\ndifferences in price. Moreover, firms often target a specific portfolio of\ncustomers that could depend on, e.g., age, location, and occupation. Given such\na target portfolio, firms may choose to modulate an individual customer's offer\nbased on whether the firm desires the customer within their portfolio. We term\nthe problem of modulating offers to achieve a desired target portfolio the\nportfolio pursuit problem. Having formulated the portfolio pursuit problem as a\nsequential decision making problem, we devise a novel reinforcement learning\nalgorithm for its solution. We test our method on a complex synthetic market\nenvironment, and demonstrate that it outperforms a baseline method which mimics\ncurrent industry approaches to portfolio pursuit.",
    "arxiv_id": "http://arxiv.org/abs/2408.00713v2",
    "pdf_url": "http://arxiv.org/pdf/2408.00713v2",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Synthetic dual image generation for reduction of labeling efforts in semantic segmentation of micrographs with a customized metric function",
    "authors": "Matias Oscar Volman Stern, Dominic Hohs, Andreas Jansche, Timo Bernthaler, Gerhard Schneider",
    "abstract": "Training of semantic segmentation models for material analysis requires\nmicrographs and their corresponding masks. It is quite unlikely that perfect\nmasks will be drawn, especially at the edges of objects, and sometimes the\namount of data that can be obtained is small, since only a few samples are\navailable. These aspects make it very problematic to train a robust model. We\ndemonstrate a workflow for the improvement of semantic segmentation models of\nmicrographs through the generation of synthetic microstructural images in\nconjunction with masks. The workflow only requires joining a few micrographs\nwith their respective masks to create the input for a Vector\nQuantised-Variational AutoEncoder model that includes an embedding space, which\nis trained such that a generative model (PixelCNN) learns the distribution of\neach input, transformed into discrete codes, and can be used to sample new\ncodes. The latter will eventually be decoded by VQ-VAE to generate images\nalongside corresponding masks for semantic segmentation. To evaluate the\nsynthetic data, we have trained U-Net models with different amounts of these\nsynthetic data in conjunction with real data. These models were then evaluated\nusing non-synthetic images only. Additionally, we introduce a customized metric\nderived from the mean Intersection over Union (mIoU). The proposed metric\nprevents a few falsely predicted pixels from greatly reducing the value of the\nmIoU. We have achieved a reduction in sample preparation and acquisition times,\nas well as the efforts, needed for image processing and labeling tasks, are\nless when it comes to training semantic segmentation model. The approach could\nbe generalized to various types of image data such that it serves as a\nuser-friendly solution for training models with a small number of real images.",
    "arxiv_id": "http://arxiv.org/abs/2408.00707v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00707v1",
    "primary_category": "cs.CV",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Point-supervised Brain Tumor Segmentation with Box-prompted MedSAM",
    "authors": "Xiaofeng Liu, Jonghye Woo, Chao Ma, Jinsong Ouyang, Georges El Fakhri",
    "abstract": "Delineating lesions and anatomical structure is important for image-guided\ninterventions. Point-supervised medical image segmentation (PSS) has great\npotential to alleviate costly expert delineation labeling. However, due to the\nlack of precise size and boundary guidance, the effectiveness of PSS often\nfalls short of expectations. Although recent vision foundational models, such\nas the medical segment anything model (MedSAM), have made significant\nadvancements in bounding-box-prompted segmentation, it is not straightforward\nto utilize point annotation, and is prone to semantic ambiguity. In this\npreliminary study, we introduce an iterative framework to facilitate\nsemantic-aware point-supervised MedSAM. Specifically, the semantic box-prompt\ngenerator (SBPG) module has the capacity to convert the point input into\npotential pseudo bounding box suggestions, which are explicitly refined by the\nprototype-based semantic similarity. This is then succeeded by a prompt-guided\nspatial refinement (PGSR) module that harnesses the exceptional\ngeneralizability of MedSAM to infer the segmentation mask, which also updates\nthe box proposal seed in SBPG. Performance can be progressively improved with\nadequate iterations. We conducted an evaluation on BraTS2018 for the\nsegmentation of whole brain tumors and demonstrated its superior performance\ncompared to traditional PSS methods and on par with box-supervised methods.",
    "arxiv_id": "http://arxiv.org/abs/2408.00706v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00706v1",
    "primary_category": "cs.CV",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "You Can't Ignore Either: Unifying Structure and Feature Denoising for Robust Graph Learning",
    "authors": "Tianmeng Yang, Jiahao Meng, Min Zhou, Yaming Yang, Yujing Wang, Xiangtai Li, Yunhai Tong",
    "abstract": "Recent research on the robustness of Graph Neural Networks (GNNs) under\nnoises or attacks has attracted great attention due to its importance in\nreal-world applications. Most previous methods explore a single noise source,\nrecovering corrupt node embedding by reliable structures bias or developing\nstructure learning with reliable node features. However, the noises and attacks\nmay come from both structures and features in graphs, making the graph\ndenoising a dilemma and challenging problem. In this paper, we develop a\nunified graph denoising (UGD) framework to unravel the deadlock between\nstructure and feature denoising. Specifically, a high-order neighborhood\nproximity evaluation method is proposed to recognize noisy edges, considering\nfeatures may be perturbed simultaneously. Moreover, we propose to refine noisy\nfeatures with reconstruction based on a graph auto-encoder. An iterative\nupdating algorithm is further designed to optimize the framework and acquire a\nclean graph, thus enabling robust graph learning for downstream tasks. Our UGD\nframework is self-supervised and can be easily implemented as a plug-and-play\nmodule. We carry out extensive experiments, which proves the effectiveness and\nadvantages of our method. Code is avalaible at\nhttps://github.com/YoungTimmy/UGD.",
    "arxiv_id": "http://arxiv.org/abs/2408.00700v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00700v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Granular-Balls based Fuzzy Twin Support Vector Machine for Classification",
    "authors": "Lixi Zhao, Weiping Ding, Duoqian Miao, Guangming Lang",
    "abstract": "The twin support vector machine (TWSVM) classifier has attracted increasing\nattention because of its low computational complexity. However, its performance\ntends to degrade when samples are affected by noise. The granular-ball fuzzy\nsupport vector machine (GBFSVM) classifier partly alleviates the adverse\neffects of noise, but it relies solely on the distance between the\ngranular-ball's center and the class center to design the granular-ball\nmembership function. In this paper, we first introduce the granular-ball twin\nsupport vector machine (GBTWSVM) classifier, which integrates granular-ball\ncomputing (GBC) with the twin support vector machine (TWSVM) classifier. By\nreplacing traditional point inputs with granular-balls, we demonstrate how to\nderive a pair of non-parallel hyperplanes for the GBTWSVM classifier by solving\na quadratic programming problem. Subsequently, we design the membership and\nnon-membership functions of granular-balls using Pythagorean fuzzy sets to\ndifferentiate the contributions of granular-balls in various regions.\nAdditionally, we develop the granular-ball fuzzy twin support vector machine\n(GBFTSVM) classifier by incorporating GBC with the fuzzy twin support vector\nmachine (FTSVM) classifier. We demonstrate how to derive a pair of non-parallel\nhyperplanes for the GBFTSVM classifier by solving a quadratic programming\nproblem. We also design algorithms for the GBTSVM classifier and the GBFTSVM\nclassifier. Finally, the superior classification performance of the GBTWSVM\nclassifier and the GBFTSVM classifier on 20 benchmark datasets underscores\ntheir scalability, efficiency, and robustness in tackling classification tasks.",
    "arxiv_id": "http://arxiv.org/abs/2408.00699v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00699v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Accelerating Full Waveform Inversion By Transfer Learning",
    "authors": "Divya Shyam Singh, Leon Herrmann, Qing Sun, Tim B\u00fcrchner, Felix Dietrich, Stefan Kollmannsberger",
    "abstract": "Full waveform inversion (FWI) is a powerful tool for reconstructing material\nfields based on sparsely measured data obtained by wave propagation. For\nspecific problems, discretizing the material field with a neural network (NN)\nimproves the robustness and reconstruction quality of the corresponding\noptimization problem. We call this method NN-based FWI. Starting from an\ninitial guess, the weights of the NN are iteratively updated to fit the\nsimulated wave signals to the sparsely measured data set. For gradient-based\noptimization, a suitable choice of the initial guess, i.e., a suitable NN\nweight initialization, is crucial for fast and robust convergence.\n  In this paper, we introduce a novel transfer learning approach to further\nimprove NN-based FWI. This approach leverages supervised pretraining to provide\na better NN weight initialization, leading to faster convergence of the\nsubsequent optimization problem. Moreover, the inversions yield physically more\nmeaningful local minima. The network is pretrained to predict the unknown\nmaterial field using the gradient information from the first iteration of\nconventional FWI. In our computational experiments on two-dimensional domains,\nthe training data set consists of reference simulations with arbitrarily\npositioned elliptical voids of different shapes and orientations. We compare\nthe performance of the proposed transfer learning NN-based FWI with three other\nmethods: conventional FWI, NN-based FWI without pretraining and conventional\nFWI with an initial guess predicted from the pretrained NN. Our results show\nthat transfer learning NN-based FWI outperforms the other methods in terms of\nconvergence speed and reconstruction quality.",
    "arxiv_id": "http://arxiv.org/abs/2408.00695v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00695v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Alpha-VI DeepONet: A prior-robust variational Bayesian approach for enhancing DeepONets with uncertainty quantification",
    "authors": "Soban Nasir Lone, Subhayan De, Rajdip Nayek",
    "abstract": "We introduce a novel deep operator network (DeepONet) framework that\nincorporates generalised variational inference (GVI) using R\\'enyi's\n$\\alpha$-divergence to learn complex operators while quantifying uncertainty.\nBy incorporating Bayesian neural networks as the building blocks for the branch\nand trunk networks, our framework endows DeepONet with uncertainty\nquantification. The use of R\\'enyi's $\\alpha$-divergence, instead of the\nKullback-Leibler divergence (KLD), commonly used in standard variational\ninference, mitigates issues related to prior misspecification that are\nprevalent in Variational Bayesian DeepONets. This approach offers enhanced\nflexibility and robustness. We demonstrate that modifying the variational\nobjective function yields superior results in terms of minimising the mean\nsquared error and improving the negative log-likelihood on the test set. Our\nframework's efficacy is validated across various mechanical systems, where it\noutperforms both deterministic and standard KLD-based VI DeepONets in\npredictive accuracy and uncertainty quantification. The hyperparameter\n$\\alpha$, which controls the degree of robustness, can be tuned to optimise\nperformance for specific problems. We apply this approach to a range of\nmechanics problems, including gravity pendulum, advection-diffusion, and\ndiffusion-reaction systems. Our findings underscore the potential of\n$\\alpha$-VI DeepONet to advance the field of data-driven operator learning and\nits applications in engineering and scientific domains.",
    "arxiv_id": "http://arxiv.org/abs/2408.00681v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00681v1",
    "primary_category": "stat.ML",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "An effect analysis of the balancing techniques on the counterfactual explanations of student success prediction models",
    "authors": "Mustafa Cavus, Jakub Kuzilek",
    "abstract": "In the past decade, we have experienced a massive boom in the usage of\ndigital solutions in higher education. Due to this boom, large amounts of data\nhave enabled advanced data analysis methods to support learners and examine\nlearning processes. One of the dominant research directions in learning\nanalytics is predictive modeling of learners' success using various machine\nlearning methods. To build learners' and teachers' trust in such methods and\nsystems, exploring the methods and methodologies that enable relevant\nstakeholders to deeply understand the underlying machine-learning models is\nnecessary. In this context, counterfactual explanations from explainable\nmachine learning tools are promising. Several counterfactual generation methods\nhold much promise, but the features must be actionable and causal to be\neffective. Thus, obtaining which counterfactual generation method suits the\nstudent success prediction models in terms of desiderata, stability, and\nrobustness is essential. Although a few studies have been published in recent\nyears on the use of counterfactual explanations in educational sciences, they\nhave yet to discuss which counterfactual generation method is more suitable for\nthis problem. This paper analyzed the effectiveness of commonly used\ncounterfactual generation methods, such as WhatIf Counterfactual Explanations,\nMulti-Objective Counterfactual Explanations, and Nearest Instance\nCounterfactual Explanations after balancing. This contribution presents a case\nstudy using the Open University Learning Analytics dataset to demonstrate the\npractical usefulness of counterfactual explanations. The results illustrate the\nmethod's effectiveness and describe concrete steps that could be taken to alter\nthe model's prediction.",
    "arxiv_id": "http://arxiv.org/abs/2408.00676v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00676v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "ChordSync: Conformer-Based Alignment of Chord Annotations to Music Audio",
    "authors": "Andrea Poltronieri, Valentina Presutti, Mart\u00edn Rocamora",
    "abstract": "In the Western music tradition, chords are the main constituent components of\nharmony, a fundamental dimension of music. Despite its relevance for several\nMusic Information Retrieval (MIR) tasks, chord-annotated audio datasets are\nlimited and need more diversity. One way to improve those resources is to\nleverage the large number of chord annotations available online, but this\nrequires aligning them with music audio. However, existing audio-to-score\nalignment techniques, which typically rely on Dynamic Time Warping (DTW), fail\nto address this challenge, as they require weakly aligned data for precise\nsynchronisation. In this paper, we introduce ChordSync, a novel conformer-based\nmodel designed to seamlessly align chord annotations with audio, eliminating\nthe need for weak alignment. We also provide a pre-trained model and a\nuser-friendly library, enabling users to synchronise chord annotations with\naudio tracks effortlessly. In this way, ChordSync creates opportunities for\nharnessing crowd-sourced chord data for MIR, especially in audio chord\nestimation, thereby facilitating the generation of novel datasets.\nAdditionally, our system extends its utility to music education, enhancing\nmusic learning experiences by providing accurately aligned annotations, thus\nenabling learners to engage in synchronised musical practices.",
    "arxiv_id": "http://arxiv.org/abs/2408.00674v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00674v1",
    "primary_category": "cs.SD",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "AutoM3L: An Automated Multimodal Machine Learning Framework with Large Language Models",
    "authors": "Daqin Luo, Chengjian Feng, Yuxuan Nong, Yiqing Shen",
    "abstract": "Automated Machine Learning (AutoML) offers a promising approach to streamline\nthe training of machine learning models. However, existing AutoML frameworks\nare often limited to unimodal scenarios and require extensive manual\nconfiguration. Recent advancements in Large Language Models (LLMs) have\nshowcased their exceptional abilities in reasoning, interaction, and code\ngeneration, presenting an opportunity to develop a more automated and\nuser-friendly framework. To this end, we introduce AutoM3L, an innovative\nAutomated Multimodal Machine Learning framework that leverages LLMs as\ncontrollers to automatically construct multimodal training pipelines. AutoM3L\ncomprehends data modalities and selects appropriate models based on user\nrequirements, providing automation and interactivity. By eliminating the need\nfor manual feature engineering and hyperparameter optimization, our framework\nsimplifies user engagement and enables customization through directives,\naddressing the limitations of previous rule-based AutoML approaches. We\nevaluate the performance of AutoM3L on six diverse multimodal datasets spanning\nclassification, regression, and retrieval tasks, as well as a comprehensive set\nof unimodal datasets. The results demonstrate that AutoM3L achieves competitive\nor superior performance compared to traditional rule-based AutoML methods.\nFurthermore, a user study highlights the user-friendliness and usability of our\nframework, compared to the rule-based AutoML methods.",
    "arxiv_id": "http://arxiv.org/abs/2408.00665v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00665v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Aligning Multiple Knowledge Graphs in a Single Pass",
    "authors": "Yaming Yang, Zhe Wang, Ziyu Guan, Wei Zhao, Weigang Lu, Xinyan Huang",
    "abstract": "Entity alignment (EA) is to identify equivalent entities across different\nknowledge graphs (KGs), which can help fuse these KGs into a more comprehensive\none. Previous EA methods mainly focus on aligning a pair of KGs, and to the\nbest of our knowledge, no existing EA method considers aligning multiple (more\nthan two) KGs. To fill this research gap, in this work, we study a novel\nproblem of aligning multiple KGs and propose an effective framework named\nMultiEA to solve the problem. First, we embed the entities of all the candidate\nKGs into a common feature space by a shared KG encoder. Then, we explore three\nalignment strategies to minimize the distances among pre-aligned entities. In\nparticular, we propose an innovative inference enhancement technique to improve\nthe alignment performance by incorporating high-order similarities. Finally, to\nverify the effectiveness of MultiEA, we construct two new real-world benchmark\ndatasets and conduct extensive experiments on them. The results show that our\nMultiEA can effectively and efficiently align multiple KGs in a single pass.",
    "arxiv_id": "http://arxiv.org/abs/2408.00662v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00662v1",
    "primary_category": "cs.CL",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Disentangling Dense Embeddings with Sparse Autoencoders",
    "authors": "Charles O'Neill, Christine Ye, Kartheik Iyer, John F. Wu",
    "abstract": "Sparse autoencoders (SAEs) have shown promise in extracting interpretable\nfeatures from complex neural networks. We present one of the first applications\nof SAEs to dense text embeddings from large language models, demonstrating\ntheir effectiveness in disentangling semantic concepts. By training SAEs on\nembeddings of over 420,000 scientific paper abstracts from computer science and\nastronomy, we show that the resulting sparse representations maintain semantic\nfidelity while offering interpretability. We analyse these learned features,\nexploring their behaviour across different model capacities and introducing a\nnovel method for identifying ``feature families'' that represent related\nconcepts at varying levels of abstraction. To demonstrate the practical utility\nof our approach, we show how these interpretable features can be used to\nprecisely steer semantic search, allowing for fine-grained control over query\nsemantics. This work bridges the gap between the semantic richness of dense\nembeddings and the interpretability of sparse representations. We open source\nour embeddings, trained sparse autoencoders, and interpreted features, as well\nas a web app for exploring them.",
    "arxiv_id": "http://arxiv.org/abs/2408.00657v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00657v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Enhancing Multistep Prediction of Multivariate Market Indices Using Weighted Optical Reservoir Computing",
    "authors": "Fang Wang, Ting Bu, Yuping Huang",
    "abstract": "We propose and experimentally demonstrate an innovative stock index\nprediction method using a weighted optical reservoir computing system. We\nconstruct fundamental market data combined with macroeconomic data and\ntechnical indicators to capture the broader behavior of the stock market. Our\napproach shows significant higher performance than state-of-the-art methods\nsuch as linear regression, decision trees, and neural network architectures\nincluding long short-term memory. It captures well the market's high volatility\nand nonlinear behaviors despite limited data, demonstrating great potential for\nreal-time, parallel, multi-dimensional data processing and predictions.",
    "arxiv_id": "http://arxiv.org/abs/2408.00652v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00652v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Enhancing Ethereum Fraud Detection via Generative and Contrastive Self-supervision",
    "authors": "Chenxiang Jin, Jiajun Zhou, Chenxuan Xie, Shanqing Yu, Qi Xuan, Xiaoniu Yang",
    "abstract": "The rampant fraudulent activities on Ethereum hinder the healthy development\nof the blockchain ecosystem, necessitating the reinforcement of regulations.\nHowever, multiple imbalances involving account interaction frequencies and\ninteraction types in the Ethereum transaction environment pose significant\nchallenges to data mining-based fraud detection research. To address this, we\nfirst propose the concept of meta-interactions to refine interaction behaviors\nin Ethereum, and based on this, we present a dual self-supervision enhanced\nEthereum fraud detection framework, named Meta-IFD. This framework initially\nintroduces a generative self-supervision mechanism to augment the interaction\nfeatures of accounts, followed by a contrastive self-supervision mechanism to\ndifferentiate various behavior patterns, and ultimately characterizes the\nbehavioral representations of accounts and mines potential fraud risks through\nmulti-view interaction feature learning. Extensive experiments on real Ethereum\ndatasets demonstrate the effectiveness and superiority of our framework in\ndetecting common Ethereum fraud behaviors such as Ponzi schemes and phishing\nscams. Additionally, the generative module can effectively alleviate the\ninteraction distribution imbalance in Ethereum data, while the contrastive\nmodule significantly enhances the framework's ability to distinguish different\nbehavior patterns. The source code will be released on GitHub soon.",
    "arxiv_id": "http://arxiv.org/abs/2408.00641v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00641v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters",
    "authors": "Charlie Snell, Jaehoon Lee, Kelvin Xu, Aviral Kumar",
    "abstract": "Enabling LLMs to improve their outputs by using more test-time computation is\na critical step towards building generally self-improving agents that can\noperate on open-ended natural language. In this paper, we study the scaling of\ninference-time computation in LLMs, with a focus on answering the question: if\nan LLM is allowed to use a fixed but non-trivial amount of inference-time\ncompute, how much can it improve its performance on a challenging prompt?\nAnswering this question has implications not only on the achievable performance\nof LLMs, but also on the future of LLM pretraining and how one should tradeoff\ninference-time and pre-training compute. Despite its importance, little\nresearch attempted to understand the scaling behaviors of various test-time\ninference methods. Moreover, current work largely provides negative results for\na number of these strategies. In this work, we analyze two primary mechanisms\nto scale test-time computation: (1) searching against dense, process-based\nverifier reward models; and (2) updating the model's distribution over a\nresponse adaptively, given the prompt at test time. We find that in both cases,\nthe effectiveness of different approaches to scaling test-time compute\ncritically varies depending on the difficulty of the prompt. This observation\nmotivates applying a \"compute-optimal\" scaling strategy, which acts to most\neffectively allocate test-time compute adaptively per prompt. Using this\ncompute-optimal strategy, we can improve the efficiency of test-time compute\nscaling by more than 4x compared to a best-of-N baseline. Additionally, in a\nFLOPs-matched evaluation, we find that on problems where a smaller base model\nattains somewhat non-trivial success rates, test-time compute can be used to\noutperform a 14x larger model.",
    "arxiv_id": "http://arxiv.org/abs/2408.03314v1",
    "pdf_url": "http://arxiv.org/pdf/2408.03314v1",
    "primary_category": "cs.LG",
    "votes": 1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Pre-training and in-context learning IS Bayesian inference a la De Finetti",
    "authors": "Naimeng Ye, Hanming Yang, Andrew Siah, Hongseok Namkoong",
    "abstract": "Accurately gauging uncertainty on the underlying environment is a\nlongstanding goal of intelligent systems. We characterize which latent concepts\npre-trained sequence models are naturally able to reason with. We go back to De\nFinetti's predictive view of Bayesian reasoning: instead of modeling latent\nparameters through priors and likelihoods like topic models do, De Finetti has\nlong advocated for modeling exchangeable (permutation invariant) sequences of\nobservables. According to this view, pre-training autoregressive models\nformulates informed beliefs based on prior observations (\"empirical Bayes\"),\nand forward generation is a simulated instantiation of an environment\n(\"posterior inference\"). This connection allows extending in-context learning\n(ICL) beyond predictive settings, highlighting sequence models' ability to\nperform explicit statistical inference. In particular, we show the sequence\nprediction loss over exchangeable documents controls performance on downstream\ntasks where uncertainty quantification is key. Empirically, we propose and\ndemonstrate several approaches for encoding exchangeability in sequence model\narchitectures: data augmentation, regularization, and causal masking.",
    "arxiv_id": "http://arxiv.org/abs/2408.03307v1",
    "pdf_url": "http://arxiv.org/pdf/2408.03307v1",
    "primary_category": "stat.ML",
    "votes": 1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "SARA: Singular-Value Based Adaptive Low-Rank Adaption",
    "authors": "Jihao Gu, Shuai Chen, Zelin Wang, Yibo Zhang, Ping Gong",
    "abstract": "With the increasing number of parameters in large pre-trained models, LoRA as\na parameter-efficient fine-tuning(PEFT) method is widely used for not adding\ninference overhead. The LoRA method assumes that weight changes during\nfine-tuning can be approximated by low-rank matrices. However, the rank values\nneed to be manually verified to match different downstream tasks, and they\ncannot accommodate the varying importance of different layers in the model. In\nthis work, we first analyze the relationship between the performance of\ndifferent layers and their ranks using SVD. Based on this, we design the\nSingular-Value Based Adaptive Low-Rank Adaption(SARA), which adaptively finds\nthe rank during initialization by performing SVD on the pre-trained weights.\nAdditionally, we explore the Mixture-of-SARA(Mo-SARA), which significantly\nreduces the number of parameters by fine-tuning only multiple parallel sets of\nsingular values controlled by a router. Extensive experiments on various\ncomplex tasks demonstrate the simplicity and parameter efficiency of our\nmethods. They can effectively and adaptively find the most suitable rank for\neach layer of each model.",
    "arxiv_id": "http://arxiv.org/abs/2408.03290v1",
    "pdf_url": "http://arxiv.org/pdf/2408.03290v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "StructEval: Deepen and Broaden Large Language Model Assessment via Structured Evaluation",
    "authors": "Boxi Cao, Mengjie Ren, Hongyu Lin, Xianpei Han, Feng Zhang, Junfeng Zhan, Le Sun",
    "abstract": "Evaluation is the baton for the development of large language models. Current\nevaluations typically employ a single-item assessment paradigm for each atomic\ntest objective, which struggles to discern whether a model genuinely possesses\nthe required capabilities or merely memorizes/guesses the answers to specific\nquestions. To this end, we propose a novel evaluation framework referred to as\nStructEval. Starting from an atomic test objective, StructEval deepens and\nbroadens the evaluation by conducting a structured assessment across multiple\ncognitive levels and critical concepts, and therefore offers a comprehensive,\nrobust and consistent evaluation for LLMs. Experiments on three widely-used\nbenchmarks demonstrate that StructEval serves as a reliable tool for resisting\nthe risk of data contamination and reducing the interference of potential\nbiases, thereby providing more reliable and consistent conclusions regarding\nmodel capabilities. Our framework also sheds light on the design of future\nprincipled and trustworthy LLM evaluation protocols.",
    "arxiv_id": "http://arxiv.org/abs/2408.03281v1",
    "pdf_url": "http://arxiv.org/pdf/2408.03281v1",
    "primary_category": "cs.CL",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Learning to Learn without Forgetting using Attention",
    "authors": "Anna Vettoruzzo, Joaquin Vanschoren, Mohamed-Rafik Bouguelia, Thorsteinn R\u00f6gnvaldsson",
    "abstract": "Continual learning (CL) refers to the ability to continually learn over time\nby accommodating new knowledge while retaining previously learned experience.\nWhile this concept is inherent in human learning, current machine learning\nmethods are highly prone to overwrite previously learned patterns and thus\nforget past experience. Instead, model parameters should be updated selectively\nand carefully, avoiding unnecessary forgetting while optimally leveraging\npreviously learned patterns to accelerate future learning. Since hand-crafting\neffective update mechanisms is difficult, we propose meta-learning a\ntransformer-based optimizer to enhance CL. This meta-learned optimizer uses\nattention to learn the complex relationships between model parameters across a\nstream of tasks, and is designed to generate effective weight updates for the\ncurrent task while preventing catastrophic forgetting on previously encountered\ntasks. Evaluations on benchmark datasets like SplitMNIST, RotatedMNIST, and\nSplitCIFAR-100 affirm the efficacy of the proposed approach in terms of both\nforward and backward transfer, even on small sets of labeled data, highlighting\nthe advantages of integrating a meta-learned optimizer within the continual\nlearning framework.",
    "arxiv_id": "http://arxiv.org/abs/2408.03219v1",
    "pdf_url": "http://arxiv.org/pdf/2408.03219v1",
    "primary_category": "cs.LG",
    "votes": 1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "RELIEF: Reinforcement Learning Empowered Graph Feature Prompt Tuning",
    "authors": "Jiapeng Zhu, Zichen Ding, Jianxiang Yu, Jiaqi Tan, Xiang Li, Weining Qian",
    "abstract": "The advent of the \"pre-train, prompt\" paradigm has recently extended its\ngeneralization ability and data efficiency to graph representation learning,\nfollowing its achievements in Natural Language Processing (NLP). Initial graph\nprompt tuning approaches tailored specialized prompting functions for Graph\nNeural Network (GNN) models pre-trained with specific strategies, such as edge\nprediction, thus limiting their applicability. In contrast, another pioneering\nline of research has explored universal prompting via adding prompts to the\ninput graph's feature space, thereby removing the reliance on specific\npre-training strategies. However, the necessity to add feature prompts to all\nnodes remains an open question. Motivated by findings from prompt tuning\nresearch in the NLP domain, which suggest that highly capable pre-trained\nmodels need less conditioning signal to achieve desired behaviors, we advocate\nfor strategically incorporating necessary and lightweight feature prompts to\ncertain graph nodes to enhance downstream task performance. This introduces a\ncombinatorial optimization problem, requiring a policy to decide 1) which nodes\nto prompt and 2) what specific feature prompts to attach. We then address the\nproblem by framing the prompt incorporation process as a sequential\ndecision-making problem and propose our method, RELIEF, which employs\nReinforcement Learning (RL) to optimize it. At each step, the RL agent selects\na node (discrete action) and determines the prompt content (continuous action),\naiming to maximize cumulative performance gain. Extensive experiments on graph\nand node-level tasks with various pre-training strategies in few-shot scenarios\ndemonstrate that our RELIEF outperforms fine-tuning and other prompt-based\napproaches in classification performance and data efficiency.",
    "arxiv_id": "http://arxiv.org/abs/2408.03195v1",
    "pdf_url": "http://arxiv.org/pdf/2408.03195v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Highly Efficient Self-Adaptive Reward Shaping for Reinforcement Learning",
    "authors": "Haozhe Ma, Zhengding Luo, Thanh Vinh Vo, Kuankuan Sima, Tze-Yun Leong",
    "abstract": "Reward shaping addresses the challenge of sparse rewards in reinforcement\nlearning by constructing denser and more informative reward signals. To achieve\nself-adaptive and highly efficient reward shaping, we propose a novel method\nthat incorporates success rates derived from historical experiences into shaped\nrewards. Our approach utilizes success rates sampled from Beta distributions,\nwhich dynamically evolve from uncertain to reliable values as more data is\ncollected. Initially, the self-adaptive success rates exhibit more randomness\nto encourage exploration. Over time, they become more certain to enhance\nexploitation, thus achieving a better balance between exploration and\nexploitation. We employ Kernel Density Estimation (KDE) combined with Random\nFourier Features (RFF) to derive the Beta distributions, resulting in a\ncomputationally efficient implementation in high-dimensional continuous state\nspaces. This method provides a non-parametric and learning-free approach. The\nproposed method is evaluated on a wide range of continuous control tasks with\nsparse and delayed rewards, demonstrating significant improvements in sample\nefficiency and convergence stability compared to several baselines.",
    "arxiv_id": "http://arxiv.org/abs/2408.03029v1",
    "pdf_url": "http://arxiv.org/pdf/2408.03029v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Scaling Laws for Data Poisoning in LLMs",
    "authors": "Dillon Bowen, Brendan Murphy, Will Cai, David Khachaturov, Adam Gleave, Kellin Pelrine",
    "abstract": "Recent work shows that LLMs are vulnerable to data poisoning, in which they\nare trained on partially corrupted or harmful data. Poisoned data is hard to\ndetect, breaks guardrails, and leads to undesirable and harmful behavior. Given\nthe intense efforts by leading labs to train and deploy increasingly larger and\nmore capable LLMs, it is critical to ask if the risk of data poisoning will be\nnaturally mitigated by scale, or if it is an increasing threat. We consider\nthree threat models by which data poisoning can occur: malicious fine-tuning,\nimperfect data curation, and intentional data contamination. Our experiments\nevaluate the effects of data poisoning on 23 frontier LLMs ranging from 1.5-72\nbillion parameters on three datasets which speak to each of our threat models.\nWe find that larger LLMs are increasingly vulnerable, learning harmful behavior\n-- including sleeper agent behavior -- significantly more quickly than smaller\nLLMs with even minimal data poisoning. These results underscore the need for\nrobust safeguards against data poisoning in larger LLMs.",
    "arxiv_id": "http://arxiv.org/abs/2408.02946v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02946v1",
    "primary_category": "cs.CR",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "The Need for a Big World Simulator: A Scientific Challenge for Continual Learning",
    "authors": "Saurabh Kumar, Hong Jun Jeon, Alex Lewandowski, Benjamin Van Roy",
    "abstract": "The \"small agent, big world\" frame offers a conceptual view that motivates\nthe need for continual learning. The idea is that a small agent operating in a\nmuch bigger world cannot store all information that the world has to offer. To\nperform well, the agent must be carefully designed to ingest, retain, and eject\nthe right information. To enable the development of performant continual\nlearning agents, a number of synthetic environments have been proposed.\nHowever, these benchmarks suffer from limitations, including unnatural\ndistribution shifts and a lack of fidelity to the \"small agent, big world\"\nframing. This paper aims to formalize two desiderata for the design of future\nsimulated environments. These two criteria aim to reflect the objectives and\ncomplexity of continual learning in practical settings while enabling rapid\nprototyping of algorithms on a smaller scale.",
    "arxiv_id": "http://arxiv.org/abs/2408.02930v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02930v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "HARMONIC: Harnessing LLMs for Tabular Data Synthesis and Privacy Protection",
    "authors": "Yuxin Wang, Duanyu Feng, Yongfu Dai, Zhengyu Chen, Jimin Huang, Sophia Ananiadou, Qianqian Xie, Hao Wang",
    "abstract": "Data serves as the fundamental foundation for advancing deep learning,\nparticularly tabular data presented in a structured format, which is highly\nconducive to modeling. However, even in the era of LLM, obtaining tabular data\nfrom sensitive domains remains a challenge due to privacy or copyright\nconcerns. Hence, exploring how to effectively use models like LLMs to generate\nrealistic and privacy-preserving synthetic tabular data is urgent. In this\npaper, we take a step forward to explore LLMs for tabular data synthesis and\nprivacy protection, by introducing a new framework HARMONIC for tabular data\ngeneration and evaluation. In the tabular data generation of our framework,\nunlike previous small-scale LLM-based methods that rely on continued\npre-training, we explore the larger-scale LLMs with fine-tuning to generate\ntabular data and enhance privacy. Based on idea of the k-nearest neighbors\nalgorithm, an instruction fine-tuning dataset is constructed to inspire LLMs to\ndiscover inter-row relationships. Then, with fine-tuning, LLMs are trained to\nremember the format and connections of the data rather than the data itself,\nwhich reduces the risk of privacy leakage. In the evaluation part of our\nframework, we develop specific privacy risk metrics DLT for LLM synthetic data\ngeneration, as well as performance evaluation metrics LLE for downstream LLM\ntasks. Our experiments find that this tabular data generation framework\nachieves equivalent performance to existing methods with better privacy, which\nalso demonstrates our evaluation framework for the effectiveness of synthetic\ndata and privacy risks in LLM scenarios.",
    "arxiv_id": "http://arxiv.org/abs/2408.02927v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02927v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "A Metric Driven Approach to Mixed Precision Training",
    "authors": "Mitchelle Rasquinha, Gil Tabak",
    "abstract": "As deep learning methodologies have developed, it has been generally agreed\nthat increasing neural network size improves model quality. However, this is at\nthe expense of memory and compute requirements, which also need to be\nincreased. Various efficiency techniques have been proposed to rein in hardware\ncosts, one being the use of low precision numerics. Recent accelerators have\nintroduced several different 8-bit data types to help accommodate DNNs in terms\nof numerics. In this paper, we identify a metric driven methodology to aid in\nthe choice of numerics. We demonstrate how such a methodology can help scale\ntraining of a language representation model. The technique can be generalized\nto other model architectures.",
    "arxiv_id": "http://arxiv.org/abs/2408.02897v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02897v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Compromising Embodied Agents with Contextual Backdoor Attacks",
    "authors": "Aishan Liu, Yuguang Zhou, Xianglong Liu, Tianyuan Zhang, Siyuan Liang, Jiakai Wang, Yanjun Pu, Tianlin Li, Junqi Zhang, Wenbo Zhou, Qing Guo, Dacheng Tao",
    "abstract": "Large language models (LLMs) have transformed the development of embodied\nintelligence. By providing a few contextual demonstrations, developers can\nutilize the extensive internal knowledge of LLMs to effortlessly translate\ncomplex tasks described in abstract language into sequences of code snippets,\nwhich will serve as the execution logic for embodied agents. However, this\npaper uncovers a significant backdoor security threat within this process and\nintroduces a novel method called \\method{}. By poisoning just a few contextual\ndemonstrations, attackers can covertly compromise the contextual environment of\na black-box LLM, prompting it to generate programs with context-dependent\ndefects. These programs appear logically sound but contain defects that can\nactivate and induce unintended behaviors when the operational agent encounters\nspecific triggers in its interactive environment. To compromise the LLM's\ncontextual environment, we employ adversarial in-context generation to optimize\npoisoned demonstrations, where an LLM judge evaluates these poisoned prompts,\nreporting to an additional LLM that iteratively optimizes the demonstration in\na two-player adversarial game using chain-of-thought reasoning. To enable\ncontext-dependent behaviors in downstream agents, we implement a dual-modality\nactivation strategy that controls both the generation and execution of program\ndefects through textual and visual triggers. We expand the scope of our attack\nby developing five program defect modes that compromise key aspects of\nconfidentiality, integrity, and availability in embodied agents. To validate\nthe effectiveness of our approach, we conducted extensive experiments across\nvarious tasks, including robot planning, robot manipulation, and compositional\nvisual reasoning. Additionally, we demonstrate the potential impact of our\napproach by successfully attacking real-world autonomous driving systems.",
    "arxiv_id": "http://arxiv.org/abs/2408.02882v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02882v1",
    "primary_category": "cs.AI",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "A Framework for Fine-Tuning LLMs using Heterogeneous Feedback",
    "authors": "Ryan Aponte, Ryan A. Rossi, Shunan Guo, Franck Dernoncourt, Tong Yu, Xiang Chen, Subrata Mitra, Nedim Lipka",
    "abstract": "Large language models (LLMs) have been applied to a wide range of tasks,\nincluding text summarization, web navigation, and chatbots. They have\nbenefitted from supervised fine-tuning (SFT) and reinforcement learning from\nhuman feedback (RLHF) following an unsupervised pretraining. These datasets can\nbe difficult to collect, limited in scope, and vary in sample quality.\nAdditionally, datasets can vary extensively in supervision format, from\nnumerical to binary as well as multi-dimensional with many different values. We\npresent a framework for fine-tuning LLMs using heterogeneous feedback, which\nhas two main components. First, we combine the heterogeneous feedback data into\na single supervision format, compatible with methods like SFT and RLHF. Next,\ngiven this unified feedback dataset, we extract a high-quality and diverse\nsubset to obtain performance increases potentially exceeding the full dataset.\nWe conduct extensive experiments to understand the effectiveness of these\ntechniques for incorporating heterogeneous feedback, and demonstrate\nimprovements from using a high-quality and diverse subset of the data. We find\nthat our framework is able to improve models in multiple areas simultaneously,\nsuch as in instruction following and bias reduction.",
    "arxiv_id": "http://arxiv.org/abs/2408.02861v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02861v1",
    "primary_category": "cs.CL",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "RAG Foundry: A Framework for Enhancing LLMs for Retrieval Augmented Generation",
    "authors": "Daniel Fleischer, Moshe Berchansky, Moshe Wasserblat, Peter Izsak",
    "abstract": "Implementing Retrieval-Augmented Generation (RAG) systems is inherently\ncomplex, requiring deep understanding of data, use cases, and intricate design\ndecisions. Additionally, evaluating these systems presents significant\nchallenges, necessitating assessment of both retrieval accuracy and generative\nquality through a multi-faceted approach. We introduce RAG Foundry, an\nopen-source framework for augmenting large language models for RAG use cases.\nRAG Foundry integrates data creation, training, inference and evaluation into a\nsingle workflow, facilitating the creation of data-augmented datasets for\ntraining and evaluating large language models in RAG settings. This integration\nenables rapid prototyping and experimentation with various RAG techniques,\nallowing users to easily generate datasets and train RAG models using internal\nor specialized knowledge sources. We demonstrate the framework effectiveness by\naugmenting and fine-tuning Llama-3 and Phi-3 models with diverse RAG\nconfigurations, showcasing consistent improvements across three\nknowledge-intensive datasets. Code is released as open-source in\nhttps://github.com/IntelLabs/RAGFoundry.",
    "arxiv_id": "http://arxiv.org/abs/2408.02545v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02545v1",
    "primary_category": "cs.CL",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "MDM: Advancing Multi-Domain Distribution Matching for Automatic Modulation Recognition Dataset Synthesis",
    "authors": "Dongwei Xu, Jiajun Chen, Yao Lu, Tianhao Xia, Qi Xuan, Wei Wang, Yun Lin, Xiaoniu Yang",
    "abstract": "Recently, deep learning technology has been successfully introduced into\nAutomatic Modulation Recognition (AMR) tasks. However, the success of deep\nlearning is all attributed to the training on large-scale datasets. Such a\nlarge amount of data brings huge pressure on storage, transmission and model\ntraining. In order to solve the problem of large amount of data, some\nresearchers put forward the method of data distillation, which aims to compress\nlarge training data into smaller synthetic datasets to maintain its\nperformance. While numerous data distillation techniques have been developed\nwithin the realm of image processing, the unique characteristics of signals set\nthem apart. Signals exhibit distinct features across various domains,\nnecessitating specialized approaches for their analysis and processing. To this\nend, a novel dataset distillation method--Multi-domain Distribution Matching\n(MDM) is proposed. MDM employs the Discrete Fourier Transform (DFT) to\ntranslate timedomain signals into the frequency domain, and then uses a model\nto compute distribution matching losses between the synthetic and real\ndatasets, considering both the time and frequency domains. Ultimately, these\ntwo losses are integrated to update the synthetic dataset. We conduct extensive\nexperiments on three AMR datasets. Experimental results show that, compared\nwith baseline methods, our method achieves better performance under the same\ncompression ratio. Furthermore, we conduct crossarchitecture generalization\nexperiments on several models, and the experimental results show that our\nsynthetic datasets can generalize well on other unseen models.",
    "arxiv_id": "http://arxiv.org/abs/2408.02714v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02714v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Dialogue Ontology Relation Extraction via Constrained Chain-of-Thought Decoding",
    "authors": "Renato Vukovic, David Arps, Carel van Niekerk, Benjamin Matthias Ruppik, Hsien-Chin Lin, Michael Heck, Milica Ga\u0161i\u0107",
    "abstract": "State-of-the-art task-oriented dialogue systems typically rely on\ntask-specific ontologies for fulfilling user queries. The majority of\ntask-oriented dialogue data, such as customer service recordings, comes without\nontology and annotation. Such ontologies are normally built manually, limiting\nthe application of specialised systems. Dialogue ontology construction is an\napproach for automating that process and typically consists of two steps: term\nextraction and relation extraction. In this work, we focus on relation\nextraction in a transfer learning set-up. To improve the generalisation, we\npropose an extension to the decoding mechanism of large language models. We\nadapt Chain-of-Thought (CoT) decoding, recently developed for reasoning\nproblems, to generative relation extraction. Here, we generate multiple\nbranches in the decoding space and select the relations based on a confidence\nthreshold. By constraining the decoding to ontology terms and relations, we aim\nto decrease the risk of hallucination. We conduct extensive experimentation on\ntwo widely used datasets and find improvements in performance on target\nontology for source fine-tuned and one-shot prompted large language models.",
    "arxiv_id": "http://arxiv.org/abs/2408.02361v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02361v1",
    "primary_category": "cs.CL",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "On the consistent reasoning paradox of intelligence and optimal trust in AI: The power of 'I don't know'",
    "authors": "Alexander Bastounis, Paolo Campodonico, Mihaela van der Schaar, Ben Adcock, Anders C. Hansen",
    "abstract": "We introduce the Consistent Reasoning Paradox (CRP). Consistent reasoning,\nwhich lies at the core of human intelligence, is the ability to handle tasks\nthat are equivalent, yet described by different sentences ('Tell me the time!'\nand 'What is the time?'). The CRP asserts that consistent reasoning implies\nfallibility -- in particular, human-like intelligence in AI necessarily comes\nwith human-like fallibility. Specifically, it states that there are problems,\ne.g. in basic arithmetic, where any AI that always answers and strives to mimic\nhuman intelligence by reasoning consistently will hallucinate (produce wrong,\nyet plausible answers) infinitely often. The paradox is that there exists a\nnon-consistently reasoning AI (which therefore cannot be on the level of human\nintelligence) that will be correct on the same set of problems. The CRP also\nshows that detecting these hallucinations, even in a probabilistic sense, is\nstrictly harder than solving the original problems, and that there are problems\nthat an AI may answer correctly, but it cannot provide a correct logical\nexplanation for how it arrived at the answer. Therefore, the CRP implies that\nany trustworthy AI (i.e., an AI that never answers incorrectly) that also\nreasons consistently must be able to say 'I don't know'. Moreover, this can\nonly be done by implicitly computing a new concept that we introduce, termed\nthe 'I don't know' function -- something currently lacking in modern AI. In\nview of these insights, the CRP also provides a glimpse into the behaviour of\nArtificial General Intelligence (AGI). An AGI cannot be 'almost sure', nor can\nit always explain itself, and therefore to be trustworthy it must be able to\nsay 'I don't know'.",
    "arxiv_id": "http://arxiv.org/abs/2408.02357v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02357v1",
    "primary_category": "cs.AI",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Generalized Gaussian Temporal Difference Error For Uncertainty-aware Reinforcement Learning",
    "authors": "Seyeon Kim, Joonhun Lee, Namhoon Cho, Sungjun Han, Seungeon Baek",
    "abstract": "Conventional uncertainty-aware temporal difference (TD) learning methods\noften rely on simplistic assumptions, typically including a zero-mean Gaussian\ndistribution for TD errors. Such oversimplification can lead to inaccurate\nerror representations and compromised uncertainty estimation. In this paper, we\nintroduce a novel framework for generalized Gaussian error modeling in deep\nreinforcement learning, applicable to both discrete and continuous control\nsettings. Our framework enhances the flexibility of error distribution modeling\nby incorporating higher-order moments, particularly kurtosis, thereby improving\nthe estimation and mitigation of data-dependent noise, i.e., aleatoric\nuncertainty. We examine the influence of the shape parameter of the generalized\nGaussian distribution (GGD) on aleatoric uncertainty and provide a closed-form\nexpression that demonstrates an inverse relationship between uncertainty and\nthe shape parameter. Additionally, we propose a theoretically grounded\nweighting scheme to fully leverage the GGD. To address epistemic uncertainty,\nwe enhance the batch inverse variance weighting by incorporating bias reduction\nand kurtosis considerations, resulting in improved robustness. Extensive\nexperimental evaluations using policy gradient algorithms demonstrate the\nconsistent efficacy of our method, showcasing significant performance\nimprovements.",
    "arxiv_id": "http://arxiv.org/abs/2408.02295v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02295v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "One-Shot Collaborative Data Distillation",
    "authors": "Rayne Holland, Chandra Thapa, Sarah Ali Siddiqui, Wei Shao, Seyit Camtepe",
    "abstract": "Large machine-learning training datasets can be distilled into small\ncollections of informative synthetic data samples. These synthetic sets support\nefficient model learning and reduce the communication cost of data sharing.\nThus, high-fidelity distilled data can support the efficient deployment of\nmachine learning applications in distributed network environments. A naive way\nto construct a synthetic set in a distributed environment is to allow each\nclient to perform local data distillation and to merge local distillations at a\ncentral server. However, the quality of the resulting set is impaired by\nheterogeneity in the distributions of the local data held by clients. To\novercome this challenge, we introduce the first collaborative data distillation\ntechnique, called CollabDM, which captures the global distribution of the data\nand requires only a single round of communication between client and server.\nOur method outperforms the state-of-the-art one-shot learning method on skewed\ndata in distributed learning environments. We also show the promising practical\nbenefits of our method when applied to attack detection in 5G networks.",
    "arxiv_id": "http://arxiv.org/abs/2408.02266v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02266v1",
    "primary_category": "cs.LG",
    "votes": 1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "CodeACT: Code Adaptive Compute-efficient Tuning Framework for Code LLMs",
    "authors": "Weijie Lv, Xuan Xia, Sheng-Jun Huang",
    "abstract": "Large language models (LLMs) have shown great potential in code-related\ntasks, yet open-source models lag behind their closed-source counterparts. To\nbridge this performance gap, existing methods generate vast amounts of\nsynthetic data for fine-tuning, leading to inefficiencies in training.\nMotivated by the need for more effective and efficient training, we propose the\nCode Adaptive Compute-efficient Tuning (CodeACT) framework. CodeACT introduces\nthe Complexity and Diversity Aware Sampling (CDAS) method to select\nhigh-quality training data based on complexity and diversity, and the Dynamic\nPack padding strategy to reduce computational resource usage by minimizing\npadding tokens during training. Experimental results demonstrate that\nCodeACT-DeepSeek-Coder-6.7B, fine-tuned on only 40% of the EVOL-Instruct data,\nachieves an 8.6% performance increase on HumanEval, reduces training time by\n78%, and decreases peak GPU memory usage by 27%. These findings underscore\nCodeACT's ability to enhance the performance and efficiency of open-source\nmodels. By optimizing both the data selection and training processes, CodeACT\noffers a comprehensive approach to improving the capabilities of open-source\nLLMs while significantly reducing computational requirements, addressing the\ndual challenges of data quality and training efficiency, and paving the way for\nmore resource-efficient and performant models.",
    "arxiv_id": "http://arxiv.org/abs/2408.02193v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02193v1",
    "primary_category": "cs.CL",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "ARVO: Atlas of Reproducible Vulnerabilities for Open Source Software",
    "authors": "Xiang Mei, Pulkit Singh Singaria, Jordi Del Castillo, Haoran Xi, Abdelouahab, Benchikh, Tiffany Bao, Ruoyu Wang, Yan Shoshitaishvili, Adam Doup\u00e9, Hammond Pearce, Brendan Dolan-Gavitt",
    "abstract": "High-quality datasets of real-world vulnerabilities are enormously valuable\nfor downstream research in software security, but existing datasets are\ntypically small, require extensive manual effort to update, and are missing\ncrucial features that such research needs. In this paper, we introduce ARVO: an\nAtlas of Reproducible Vulnerabilities in Open-source software. By sourcing\nvulnerabilities from C/C++ projects that Google's OSS-Fuzz discovered and\nimplementing a reliable re-compilation system, we successfully reproduce more\nthan 5,000 memory vulnerabilities across over 250 projects, each with a\ntriggering input, the canonical developer-written patch for fixing the\nvulnerability, and the ability to automatically rebuild the project from source\nand run it at its vulnerable and patched revisions. Moreover, our dataset can\nbe automatically updated as OSS-Fuzz finds new vulnerabilities, allowing it to\ngrow over time. We provide a thorough characterization of the ARVO dataset,\nshow that it can locate fixes more accurately than Google's own OSV\nreproduction effort, and demonstrate its value for future research through two\ncase studies: firstly evaluating real-world LLM-based vulnerability repair, and\nsecondly identifying over 300 falsely patched (still-active) zero-day\nvulnerabilities from projects improperly labeled by OSS-Fuzz.",
    "arxiv_id": "http://arxiv.org/abs/2408.02153v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02153v1",
    "primary_category": "cs.CR",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Generative Retrieval with Few-shot Indexing",
    "authors": "Arian Askari, Chuan Meng, Mohammad Aliannejadi, Zhaochun Ren, Evangelos Kanoulas, Suzan Verberne",
    "abstract": "Existing generative retrieval (GR) approaches rely on training-based\nindexing, i.e., fine-tuning a model to memorise the associations between a\nquery and the document identifier (docid) of a relevant document.\nTraining-based indexing has three limitations: high training overhead,\nunder-utilization of the pre-trained knowledge of large language models (LLMs),\nand challenges in adapting to a dynamic document corpus. To address the above\nissues, we propose a novel few-shot indexing-based GR framework (Few-Shot GR).\nIt has a novel few-shot indexing process, where we prompt an LLM to generate\ndocids for all documents in a corpus, ultimately creating a docid bank for the\nentire corpus. During retrieval, we feed a query to the same LLM and constrain\nit to generate a docid within the docid bank created during indexing, and then\nmap the generated docid back to its corresponding document. Few-Shot GR relies\nsolely on prompting an LLM without requiring any training, making it more\nefficient. Moreover, we devise few-shot indexing with one-to-many mapping to\nfurther enhance Few-Shot GR. Experiments show that Few-Shot GR achieves\nsuperior performance to state-of-the-art GR methods that require heavy\ntraining.",
    "arxiv_id": "http://arxiv.org/abs/2408.02152v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02152v1",
    "primary_category": "cs.IR",
    "votes": 1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "VidModEx: Interpretable and Efficient Black Box Model Extraction for High-Dimensional Spaces",
    "authors": "Somnath Sendhil Kumar, Yuvaraj Govindarajulu, Pavan Kulkarni, Manojkumar Parmar",
    "abstract": "In the domain of black-box model extraction, conventional methods reliant on\nsoft labels or surrogate datasets struggle with scaling to high-dimensional\ninput spaces and managing the complexity of an extensive array of interrelated\nclasses. In this work, we present a novel approach that utilizes SHAP (SHapley\nAdditive exPlanations) to enhance synthetic data generation. SHAP quantifies\nthe individual contributions of each input feature towards the victim model's\noutput, facilitating the optimization of an energy-based GAN towards a\ndesirable output. This method significantly boosts performance, achieving a\n16.45% increase in the accuracy of image classification models and extending to\nvideo classification models with an average improvement of 26.11% and a maximum\nof 33.36% on challenging datasets such as UCF11, UCF101, Kinetics 400, Kinetics\n600, and Something-Something V2. We further demonstrate the effectiveness and\npractical utility of our method under various scenarios, including the\navailability of top-k prediction probabilities, top-k prediction labels, and\ntop-1 labels.",
    "arxiv_id": "http://arxiv.org/abs/2408.02140v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02140v1",
    "primary_category": "cs.CV",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "MedSyn: LLM-based Synthetic Medical Text Generation Framework",
    "authors": "Gleb Kumichev, Pavel Blinov, Yulia Kuzkina, Vasily Goncharov, Galina Zubkova, Nikolai Zenovkin, Aleksei Goncharov, Andrey Savchenko",
    "abstract": "Generating synthetic text addresses the challenge of data availability in\nprivacy-sensitive domains such as healthcare. This study explores the\napplicability of synthetic data in real-world medical settings. We introduce\nMedSyn, a novel medical text generation framework that integrates large\nlanguage models with a Medical Knowledge Graph (MKG). We use MKG to sample\nprior medical information for the prompt and generate synthetic clinical notes\nwith GPT-4 and fine-tuned LLaMA models. We assess the benefit of synthetic data\nthrough application in the ICD code prediction task. Our research indicates\nthat synthetic data can increase the classification accuracy of vital and\nchallenging codes by up to 17.8% compared to settings without synthetic data.\nFurthermore, to provide new data for further research in the healthcare domain,\nwe present the largest open-source synthetic dataset of clinical notes for the\nRussian language, comprising over 41k samples covering 219 ICD-10 codes.",
    "arxiv_id": "http://arxiv.org/abs/2408.02056v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02056v1",
    "primary_category": "cs.CL",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Walk Wisely on Graph: Knowledge Graph Reasoning with Dual Agents via Efficient Guidance-Exploration",
    "authors": "Zijian Wang, Bin Wang, Haifeng Jing, Huayu Li, Hongbo Dou",
    "abstract": "Recent years, multi-hop reasoning has been widely studied for knowledge graph\n(KG) reasoning due to its efficacy and interpretability. However, previous\nmulti-hop reasoning approaches are subject to two primary shortcomings. First,\nagents struggle to learn effective and robust policies at the early phase due\nto sparse rewards. Second, these approaches often falter on specific datasets\nlike sparse knowledge graphs, where agents are required to traverse lengthy\nreasoning paths. To address these problems, we propose a multi-hop reasoning\nmodel with dual agents based on hierarchical reinforcement learning (HRL),\nwhich is named FULORA. FULORA tackles the above reasoning challenges by\neFficient GUidance-ExpLORAtion between dual agents. The high-level agent walks\non the simplified knowledge graph to provide stage-wise hints for the low-level\nagent walking on the original knowledge graph. In this framework, the low-level\nagent optimizes a value function that balances two objectives: (1) maximizing\nreturn, and (2) integrating efficient guidance from the high-level agent.\nExperiments conducted on three real-word knowledge graph datasets demonstrate\nthat FULORA outperforms RL-based baselines, especially in the case of\nlong-distance reasoning.",
    "arxiv_id": "http://arxiv.org/abs/2408.01880v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01880v1",
    "primary_category": "cs.AI",
    "votes": 1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "MALADE: Orchestration of LLM-powered Agents with Retrieval Augmented Generation for Pharmacovigilance",
    "authors": "Jihye Choi, Nils Palumbo, Prasad Chalasani, Matthew M. Engelhard, Somesh Jha, Anivarya Kumar, David Page",
    "abstract": "In the era of Large Language Models (LLMs), given their remarkable text\nunderstanding and generation abilities, there is an unprecedented opportunity\nto develop new, LLM-based methods for trustworthy medical knowledge synthesis,\nextraction and summarization. This paper focuses on the problem of\nPharmacovigilance (PhV), where the significance and challenges lie in\nidentifying Adverse Drug Events (ADEs) from diverse text sources, such as\nmedical literature, clinical notes, and drug labels. Unfortunately, this task\nis hindered by factors including variations in the terminologies of drugs and\noutcomes, and ADE descriptions often being buried in large amounts of narrative\ntext. We present MALADE, the first effective collaborative multi-agent system\npowered by LLM with Retrieval Augmented Generation for ADE extraction from drug\nlabel data. This technique involves augmenting a query to an LLM with relevant\ninformation extracted from text resources, and instructing the LLM to compose a\nresponse consistent with the augmented data. MALADE is a general LLM-agnostic\narchitecture, and its unique capabilities are: (1) leveraging a variety of\nexternal sources, such as medical literature, drug labels, and FDA tools (e.g.,\nOpenFDA drug information API), (2) extracting drug-outcome association in a\nstructured format along with the strength of the association, and (3) providing\nexplanations for established associations. Instantiated with GPT-4 Turbo or\nGPT-4o, and FDA drug label data, MALADE demonstrates its efficacy with an Area\nUnder ROC Curve of 0.90 against the OMOP Ground Truth table of ADEs. Our\nimplementation leverages the Langroid multi-agent LLM framework and can be\nfound at https://github.com/jihyechoi77/malade.",
    "arxiv_id": "http://arxiv.org/abs/2408.01869v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01869v1",
    "primary_category": "cs.CL",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Efficient Solutions For An Intriguing Failure of LLMs: Long Context Window Does Not Mean LLMs Can Analyze Long Sequences Flawlessly",
    "authors": "Peyman Hosseini, Ignacio Castro, Iacopo Ghinassi, Matthew Purver",
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\ncomprehending and analyzing lengthy sequential inputs, owing to their extensive\ncontext windows that allow processing millions of tokens in a single forward\npass. However, this paper uncovers a surprising limitation: LLMs fall short\nwhen handling long input sequences. We investigate this issue using three\ndatasets and two tasks (sentiment analysis and news categorization) across\nvarious LLMs, including Claude 3, Gemini Pro, GPT 3.5 Turbo, Llama 3 Instruct,\nand Mistral Instruct models. To address this limitation, we propose and\nevaluate ad-hoc solutions that substantially enhance LLMs' performance on long\ninput sequences by up to 50%, while reducing API cost and latency by up to 93%\nand 50%, respectively.",
    "arxiv_id": "http://arxiv.org/abs/2408.01866v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01866v1",
    "primary_category": "cs.CL",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "STBLLM: Breaking the 1-Bit Barrier with Structured Binary LLMs",
    "authors": "Peijie Dong, Lujun Li, Dayou Du, Yuhan Chen, Zhenheng Tang, Qiang Wang, Wei Xue, Wenhan Luo, Qifeng Liu, Yike Guo, Xiaowen Chu",
    "abstract": "In this paper, we present STBLLM, the first structural binarization framework\nfor compressing Large Language Models (LLMs) to less than 1-bit precision. LLMs\nhave achieved remarkable performance, but their heavy memory requirements have\nhindered widespread adoption, particularly on resource-constrained devices.\nBinarization, which quantifies weights to a mere 1-bit, achieves a milestone in\nincreasing computational efficiency. However, we observe that some weights in\nbinarized LLMs can be randomly flipped without significant performance\ndegradation, indicating the potential for further compression. To exploit this,\nour STBLLM employs an N:M sparsity to perform structural binarization of the\nweights. First, we introduce a new Standardized Importance (SI) metric that\nconsiders weight magnitude and input feature norm to better evaluate weight\nsignificance. Then, we propose a layer-wise approach where different layers of\nthe LLM can be sparsified with varying N:M ratios, balancing compression and\naccuracy. Finally, we use residual approximation with double binarization to\npreserve information for salient weights. In addition, we utilize a\nfine-grained grouping strategy for less important weights that applies\ndifferent quantization schemes to sparse, intermediate, and dense regions. We\nconduct extensive experiments on various language models, including the\nLLaMA-1/2/3, OPT family, and Mistral, to evaluate the effectiveness of STBLLM.\nThe results demonstrate that our approach performs better than other compressed\nbinarization LLM methods while significantly reducing memory requirements.",
    "arxiv_id": "http://arxiv.org/abs/2408.01803v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01803v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Can LLMs predict the convergence of Stochastic Gradient Descent?",
    "authors": "Oussama Zekri, Abdelhakim Benechehab, Ievgen Redko",
    "abstract": "Large-language models are notoriously famous for their impressive performance\nacross a wide range of tasks. One surprising example of such impressive\nperformance is a recently identified capacity of LLMs to understand the\ngoverning principles of dynamical systems satisfying the Markovian property. In\nthis paper, we seek to explore this direction further by studying the dynamics\nof stochastic gradient descent in convex and non-convex optimization. By\nleveraging the theoretical link between the SGD and Markov chains, we show a\nremarkable zero-shot performance of LLMs in predicting the local minima to\nwhich SGD converges for previously unseen starting points. On a more general\nlevel, we inquire about the possibility of using LLMs to perform zero-shot\nrandomized trials for larger deep learning models used in practice.",
    "arxiv_id": "http://arxiv.org/abs/2408.01736v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01736v1",
    "primary_category": "cs.LG",
    "votes": 1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Mission Impossible: A Statistical Perspective on Jailbreaking LLMs",
    "authors": "Jingtong Su, Julia Kempe, Karen Ullrich",
    "abstract": "Large language models (LLMs) are trained on a deluge of text data with\nlimited quality control. As a result, LLMs can exhibit unintended or even\nharmful behaviours, such as leaking information, fake news or hate speech.\nCountermeasures, commonly referred to as preference alignment, include\nfine-tuning the pretrained LLMs with carefully crafted text examples of desired\nbehaviour. Even then, empirical evidence shows preference aligned LLMs can be\nenticed to harmful behaviour. This so called jailbreaking of LLMs is typically\nachieved by adversarially modifying the input prompt to the LLM. Our paper\nprovides theoretical insights into the phenomenon of preference alignment and\njailbreaking from a statistical perspective. Under our framework, we first show\nthat pretrained LLMs will mimic harmful behaviour if present in the training\ncorpus. Under that same framework, we then introduce a statistical notion of\nalignment, and lower-bound the jailbreaking probability, showing that it is\nunpreventable under reasonable assumptions. Based on our insights, we propose\nan alteration to the currently prevalent alignment strategy RLHF. Specifically,\nwe introduce a simple modification to the RLHF objective, we call E-RLHF, that\naims to increase the likelihood of safe responses. E-RLHF brings no additional\ntraining cost, and is compatible with other methods. Empirically, we\ndemonstrate that E-RLHF outperforms RLHF on all alignment problems put forward\nby the AdvBench and HarmBench project without sacrificing model performance as\nmeasured by the MT-Bench project.",
    "arxiv_id": "http://arxiv.org/abs/2408.01420v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01420v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Talk Less, Interact Better: Evaluating In-context Conversational Adaptation in Multimodal LLMs",
    "authors": "Yilun Hua, Yoav Artzi",
    "abstract": "Humans spontaneously use increasingly efficient language as interactions\nprogress, by adapting and forming ad-hoc conventions. This phenomenon has been\nstudied extensively using reference games, showing properties of human language\nthat go beyond relaying intents. It remains unexplored whether multimodal large\nlanguage models (MLLMs) similarly increase communication efficiency during\ninteractions, and what mechanisms they may adopt for this purpose. We introduce\nICCA, an automated framework to evaluate such conversational adaptation as an\nin-context behavior in MLLMs. We evaluate several state-of-the-art MLLMs, and\nobserve that while they may understand the increasingly efficient language of\ntheir interlocutor, they do not spontaneously make their own language more\nefficient over time. This latter ability can only be elicited in some models\n(e.g., GPT-4) with heavy-handed prompting. This shows that this property of\nlinguistic interaction does not arise from current training regimes, even\nthough it is a common hallmark of human language. ICCA is available at\nhttps://github.com/lil-lab/ICCA.",
    "arxiv_id": "http://arxiv.org/abs/2408.01417v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01417v1",
    "primary_category": "cs.CL",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Conditional LoRA Parameter Generation",
    "authors": "Xiaolong Jin, Kai Wang, Dongwen Tang, Wangbo Zhao, Yukun Zhou, Junshu Tang, Yang You",
    "abstract": "Generative models have achieved remarkable success in image, video, and text\ndomains. Inspired by this, researchers have explored utilizing generative\nmodels to generate neural network parameters. However, these efforts have been\nlimited by the parameter size and the practicality of generating\nhigh-performance parameters. In this paper, we propose COND P-DIFF, a novel\napproach that demonstrates the feasibility of controllable high-performance\nparameter generation, particularly for LoRA (Low-Rank Adaptation) weights,\nduring the fine-tuning process. Specifically, we employ an autoencoder to\nextract efficient latent representations for parameters. We then train a\nconditional latent diffusion model to synthesize high-performing model\nparameters from random noise based on specific task conditions. Experimental\nresults in both computer vision and natural language processing domains\nconsistently demonstrate that COND P-DIFF can generate high-performance\nparameters conditioned on the given task. Moreover, we observe that the\nparameter distribution generated by COND P-DIFF exhibits differences compared\nto the distribution obtained through normal optimization methods, indicating a\ncertain level of generalization capability. Our work paves the way for further\nexploration of condition-driven parameter generation, offering a promising\ndirection for task-specific adaptation of neural networks.",
    "arxiv_id": "http://arxiv.org/abs/2408.01415v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01415v1",
    "primary_category": "cs.AI",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Pre-trained Language Models Improve the Few-shot Prompt Ability of Decision Transformer",
    "authors": "Yu Yang, Pan Xu",
    "abstract": "Decision Transformer (DT) has emerged as a promising class of algorithms in\noffline reinforcement learning (RL) tasks, leveraging pre-collected datasets\nand Transformer's capability to model long sequences. Recent works have\ndemonstrated that using parts of trajectories from training tasks as prompts in\nDT enhances its performance on unseen tasks, giving rise to Prompt-DT methods.\nHowever, collecting data from specific environments can be both costly and\nunsafe in many scenarios, leading to suboptimal performance and limited\nfew-shot prompt abilities due to the data-hungry nature of Transformer-based\nmodels. Additionally, the limited datasets used in pre-training make it\nchallenging for Prompt-DT type of methods to distinguish between various RL\ntasks through prompts alone. To address these challenges, we introduce the\nLanguage model-initialized Prompt Decision Transformer (LPDT), which leverages\npre-trained language models for meta-RL tasks and fine-tunes the model using\nLow-rank Adaptation (LoRA). We further incorporate prompt regularization to\neffectively differentiate between tasks based on prompt feature\nrepresentations. Our approach integrates pre-trained language model and RL\ntasks seamlessly. Extensive empirical studies demonstrate that initializing\nwith a pre-trained language model significantly enhances the performance of\nPrompt-DT on unseen tasks compared to baseline methods.",
    "arxiv_id": "http://arxiv.org/abs/2408.01402v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01402v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "TCR-GPT: Integrating Autoregressive Model and Reinforcement Learning for T-Cell Receptor Repertoires Generation",
    "authors": "Yicheng Lin, Dandan Zhang, Yun Liu",
    "abstract": "T-cell receptors (TCRs) play a crucial role in the immune system by\nrecognizing and binding to specific antigens presented by infected or cancerous\ncells. Understanding the sequence patterns of TCRs is essential for developing\ntargeted immune therapies and designing effective vaccines. Language models,\nsuch as auto-regressive transformers, offer a powerful solution to this problem\nby learning the probability distributions of TCR repertoires, enabling the\ngeneration of new TCR sequences that inherit the underlying patterns of the\nrepertoire. We introduce TCR-GPT, a probabilistic model built on a decoder-only\ntransformer architecture, designed to uncover and replicate sequence patterns\nin TCR repertoires. TCR-GPT demonstrates an accuracy of 0.953 in inferring\nsequence probability distributions measured by Pearson correlation coefficient.\nFurthermore, by leveraging Reinforcement Learning(RL), we adapted the\ndistribution of TCR sequences to generate TCRs capable of recognizing specific\npeptides, offering significant potential for advancing targeted immune\ntherapies and vaccine development. With the efficacy of RL, fine-tuned\npretrained TCR-GPT models demonstrated the ability to produce TCR repertoires\nlikely to bind specific peptides, illustrating RL's efficiency in enhancing the\nmodel's adaptability to the probability distributions of biologically relevant\nTCR sequences.",
    "arxiv_id": "http://arxiv.org/abs/2408.01156v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01156v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Tensor Train Low-rank Approximation (TT-LoRA): Democratizing AI with Accelerated LLMs",
    "authors": "Afia Anjum, Maksim E. Eren, Ismael Boureima, Boian Alexandrov, Manish Bhattarai",
    "abstract": "In recent years, Large Language Models (LLMs) have demonstrated remarkable\ncapabilities across a wide range of natural language processing (NLP) tasks,\nsuch as question-answering, sentiment analysis, text summarization, and machine\ntranslation. However, the ever-growing complexity of LLMs demands immense\ncomputational resources, hindering the broader research and application of\nthese models. To address this, various parameter-efficient fine-tuning\nstrategies, such as Low-Rank Approximation (LoRA) and Adapters, have been\ndeveloped. Despite their potential, these methods often face limitations in\ncompressibility. Specifically, LoRA struggles to scale effectively with the\nincreasing number of trainable parameters in modern large scale LLMs.\nAdditionally, Low-Rank Economic Tensor-Train Adaptation (LoRETTA), which\nutilizes tensor train decomposition, has not yet achieved the level of\ncompression necessary for fine-tuning very large scale models with limited\nresources. This paper introduces Tensor Train Low-Rank Approximation (TT-LoRA),\na novel parameter-efficient fine-tuning (PEFT) approach that extends LoRETTA\nwith optimized tensor train (TT) decomposition integration. By eliminating\nAdapters and traditional LoRA-based structures, TT-LoRA achieves greater model\ncompression without compromising downstream task performance, along with\nreduced inference latency and computational overhead. We conduct an exhaustive\nparameter search to establish benchmarks that highlight the trade-off between\nmodel compression and performance. Our results demonstrate significant\ncompression of LLMs while maintaining comparable performance to larger models,\nfacilitating their deployment on resource-constraint platforms.",
    "arxiv_id": "http://arxiv.org/abs/2408.01008v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01008v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "AgentGen: Enhancing Planning Abilities for Large Language Model based Agent via Environment and Task Generation",
    "authors": "Mengkang Hu, Pu Zhao, Can Xu, Qingfeng Sun, Jianguang Lou, Qingwei Lin, Ping Luo, Saravan Rajmohan, Dongmei Zhang",
    "abstract": "Large Language Model (LLM) based agents have garnered significant attention\nand are becoming increasingly popular. Furthermore, planning ability is a\ncrucial component of an LLM-based agent, involving interaction with the\nenvironment and executing actions to complete a planning task, which generally\nentails achieving a desired goal from an initial state. This paper investigates\nenhancing the planning abilities of LLMs through instruction tuning, referred\nto as agent training. Recent studies have demonstrated that utilizing\nexpert-level trajectory for instruction-tuning LLMs effectively enhances their\nplanning capabilities. However, existing work primarily focuses on synthesizing\ntrajectories from manually designed planning tasks and environments. The\nlabor-intensive nature of creating these environments and tasks impedes the\ngeneration of sufficiently varied and extensive trajectories. To address this\nlimitation, this paper explores the automated synthesis of diverse environments\nand a gradual range of planning tasks, from easy to difficult. We introduce a\nframework, AgentGen, that leverages LLMs first to generate environments and\nsubsequently generate planning tasks conditioned on these environments.\nSpecifically, to improve environmental diversity, we propose using an\ninspiration corpus composed of various domain-specific text segments as the\ncontext for synthesizing environments. Moreover, to increase the difficulty\ndiversity of generated planning tasks, we propose a bidirectional evolution\nmethod, Bi-Evol, that evolves planning tasks from easier and harder directions\nto synthesize a task set with a smoother difficulty curve. The evaluation\nresults derived from AgentBoard show that AgentGen greatly improves LLMs'\nplanning ability, e.g., the AgentGen instruction-tuned Llama-3 8B surpasses\nGPT-3.5 in overall performance. Moreover, in certain tasks, it even outperforms\nGPT-4.",
    "arxiv_id": "http://arxiv.org/abs/2408.00764v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00764v1",
    "primary_category": "cs.CL",
    "votes": 1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  }
]