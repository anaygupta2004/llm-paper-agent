{"title": "Generalized Out-of-Distribution Detection and Beyond in Vision Language Model Era: A Survey", "authors": "Atsuyuki Miyai, Jingkang Yang, Jingyang Zhang, Yifei Ming, Yueqian Lin, Qing Yu, Go Irie, Shafiq Joty, Yixuan Li, Hai Li, Ziwei Liu, Toshihiko Yamasaki, Kiyoharu Aizawa", "abstract": "Detecting out-of-distribution (OOD) samples is crucial for ensuring the\nsafety of machine learning systems and has shaped the field of OOD detection.\nMeanwhile, several other problems are closely related to OOD detection,\nincluding anomaly detection (AD), novelty detection (ND), open set recognition\n(OSR), and outlier detection (OD). To unify these problems, a generalized OOD\ndetection framework was proposed, taxonomically categorizing these five\nproblems. However, Vision Language Models (VLMs) such as CLIP have\nsignificantly changed the paradigm and blurred the boundaries between these\nfields, again confusing researchers. In this survey, we first present a\ngeneralized OOD detection v2, encapsulating the evolution of AD, ND, OSR, OOD\ndetection, and OD in the VLM era. Our framework reveals that, with some field\ninactivity and integration, the demanding challenges have become OOD detection\nand AD. In addition, we also highlight the significant shift in the definition,\nproblem settings, and benchmarks; we thus feature a comprehensive review of the\nmethodology for OOD detection, including the discussion over other related\ntasks to clarify their relationship to OOD detection. Finally, we explore the\nadvancements in the emerging Large Vision Language Model (LVLM) era, such as\nGPT-4V. We conclude this survey with open challenges and future directions.", "arxiv_id": "http://arxiv.org/abs/2407.21794v1", "pdf_url": "http://arxiv.org/pdf/2407.21794v1", "primary_category": "cs.CV", "preferences": "I'm intersted in LLMs", "response": "RELEVANT"}
{"title": "Safetywashing: Do AI Safety Benchmarks Actually Measure Safety Progress?", "authors": "Richard Ren, Steven Basart, Adam Khoja, Alice Gatti, Long Phan, Xuwang Yin, Mantas Mazeika, Alexander Pan, Gabriel Mukobi, Ryan H. Kim, Stephen Fitz, Dan Hendrycks", "abstract": "As artificial intelligence systems grow more powerful, there has been\nincreasing interest in \"AI safety\" research to address emerging and future\nrisks. However, the field of AI safety remains poorly defined and\ninconsistently measured, leading to confusion about how researchers can\ncontribute. This lack of clarity is compounded by the unclear relationship\nbetween AI safety benchmarks and upstream general capabilities (e.g., general\nknowledge and reasoning). To address these issues, we conduct a comprehensive\nmeta-analysis of AI safety benchmarks, empirically analyzing their correlation\nwith general capabilities across dozens of models and providing a survey of\nexisting directions in AI safety. Our findings reveal that many safety\nbenchmarks highly correlate with upstream model capabilities, potentially\nenabling \"safetywashing\" -- where capability improvements are misrepresented as\nsafety advancements. Based on these findings, we propose an empirical\nfoundation for developing more meaningful safety metrics and define AI safety\nin a machine learning research context as a set of clearly delineated research\ngoals that are empirically separable from generic capabilities advancements. In\ndoing so, we aim to provide a more rigorous framework for AI safety research,\nadvancing the science of safety evaluations and clarifying the path towards\nmeasurable progress.", "arxiv_id": "http://arxiv.org/abs/2407.21792v1", "pdf_url": "http://arxiv.org/pdf/2407.21792v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "RELEVANT"}
{"title": "Deep Learning for Options Trading: An End-To-End Approach", "authors": "Wee Ling Tan, Stephen Roberts, Stefan Zohren", "abstract": "We introduce a novel approach to options trading strategies using a highly\nscalable and data-driven machine learning algorithm. In contrast to traditional\napproaches that often require specifications of underlying market dynamics or\nassumptions on an option pricing model, our models depart fundamentally from\nthe need for these prerequisites, directly learning non-trivial mappings from\nmarket data to optimal trading signals. Backtesting on more than a decade of\noption contracts for equities listed on the S&P 100, we demonstrate that deep\nlearning models trained according to our end-to-end approach exhibit\nsignificant improvements in risk-adjusted performance over existing rules-based\ntrading strategies. We find that incorporating turnover regularization into the\nmodels leads to further performance enhancements at prohibitively high levels\nof transaction costs.", "arxiv_id": "http://arxiv.org/abs/2407.21791v1", "pdf_url": "http://arxiv.org/pdf/2407.21791v1", "primary_category": "q-fin.PM", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Vision-Language Model Based Handwriting Verification", "authors": "Mihir Chauhan, Abhishek Satbhai, Mohammad Abuzar Hashemi, Mir Basheer Ali, Bina Ramamurthy, Mingchen Gao, Siwei Lyu, Sargur Srihari", "abstract": "Handwriting Verification is a critical in document forensics. Deep learning\nbased approaches often face skepticism from forensic document examiners due to\ntheir lack of explainability and reliance on extensive training data and\nhandcrafted features. This paper explores using Vision Language Models (VLMs),\nsuch as OpenAI's GPT-4o and Google's PaliGemma, to address these challenges. By\nleveraging their Visual Question Answering capabilities and 0-shot\nChain-of-Thought (CoT) reasoning, our goal is to provide clear,\nhuman-understandable explanations for model decisions. Our experiments on the\nCEDAR handwriting dataset demonstrate that VLMs offer enhanced\ninterpretability, reduce the need for large training datasets, and adapt better\nto diverse handwriting styles. However, results show that the CNN-based\nResNet-18 architecture outperforms the 0-shot CoT prompt engineering approach\nwith GPT-4o (Accuracy: 70%) and supervised fine-tuned PaliGemma (Accuracy:\n71%), achieving an accuracy of 84% on the CEDAR AND dataset. These findings\nhighlight the potential of VLMs in generating human-interpretable decisions\nwhile underscoring the need for further advancements to match the performance\nof specialized deep learning models.", "arxiv_id": "http://arxiv.org/abs/2407.21788v1", "pdf_url": "http://arxiv.org/pdf/2407.21788v1", "primary_category": "cs.CV", "preferences": "I'm intersted in LLMs", "response": "RELEVANT"}
{"title": "Large Language Monkeys: Scaling Inference Compute with Repeated Sampling", "authors": "Bradley Brown, Jordan Juravsky, Ryan Ehrlich, Ronald Clark, Quoc V. Le, Christopher R\u00e9, Azalia Mirhoseini", "abstract": "Scaling the amount of compute used to train language models has dramatically\nimproved their capabilities. However, when it comes to inference, we often\nlimit the amount of compute to only one attempt per problem. Here, we explore\ninference compute as another axis for scaling by increasing the number of\ngenerated samples. Across multiple tasks and models, we observe that coverage -\nthe fraction of problems solved by any attempt - scales with the number of\nsamples over four orders of magnitude. In domains like coding and formal\nproofs, where all answers can be automatically verified, these increases in\ncoverage directly translate into improved performance. When we apply repeated\nsampling to SWE-bench Lite, the fraction of issues solved with\nDeepSeek-V2-Coder-Instruct increases from 15.9% with one sample to 56% with 250\nsamples, outperforming the single-attempt state-of-the-art of 43% which uses\nmore capable frontier models. Moreover, using current API pricing, amplifying\nthe cheaper DeepSeek model with five samples is more cost-effective and solves\nmore issues than paying a premium for one sample from GPT-4o or Claude 3.5\nSonnet. Interestingly, the relationship between coverage and the number of\nsamples is often log-linear and can be modelled with an exponentiated power\nlaw, suggesting the existence of inference-time scaling laws. Finally, we find\nthat identifying correct samples out of many generations remains an important\ndirection for future research in domains without automatic verifiers. When\nsolving math word problems from GSM8K and MATH, coverage with Llama-3 models\ngrows to over 95% with 10,000 samples. However, common methods to pick correct\nsolutions from a sample collection, such as majority voting or reward models,\nplateau beyond several hundred samples and fail to fully scale with the sample\nbudget.", "arxiv_id": "http://arxiv.org/abs/2407.21787v1", "pdf_url": "http://arxiv.org/pdf/2407.21787v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "RELEVANT"}
{"title": "ShieldGemma: Generative AI Content Moderation Based on Gemma", "authors": "Wenjun Zeng, Yuchi Liu, Ryan Mullins, Ludovic Peran, Joe Fernandez, Hamza Harkous, Karthik Narasimhan, Drew Proud, Piyush Kumar, Bhaktipriya Radharapu, Olivia Sturman, Oscar Wahltinez", "abstract": "We present ShieldGemma, a comprehensive suite of LLM-based safety content\nmoderation models built upon Gemma2. These models provide robust,\nstate-of-the-art predictions of safety risks across key harm types (sexually\nexplicit, dangerous content, harassment, hate speech) in both user input and\nLLM-generated output. By evaluating on both public and internal benchmarks, we\ndemonstrate superior performance compared to existing models, such as Llama\nGuard (+10.8\\% AU-PRC on public benchmarks) and WildCard (+4.3\\%).\nAdditionally, we present a novel LLM-based data curation pipeline, adaptable to\na variety of safety-related tasks and beyond. We have shown strong\ngeneralization performance for model trained mainly on synthetic data. By\nreleasing ShieldGemma, we provide a valuable resource to the research\ncommunity, advancing LLM safety and enabling the creation of more effective\ncontent moderation solutions for developers.", "arxiv_id": "http://arxiv.org/abs/2407.21772v1", "pdf_url": "http://arxiv.org/pdf/2407.21772v1", "primary_category": "cs.CL", "preferences": "I'm intersted in LLMs", "response": "RELEVANT"}
{"title": "MoMa: Efficient Early-Fusion Pre-training with Mixture of Modality-Aware Experts", "authors": "Xi Victoria Lin, Akshat Shrivastava, Liang Luo, Srinivasan Iyer, Mike Lewis, Gargi Gosh, Luke Zettlemoyer, Armen Aghajanyan", "abstract": "We introduce MoMa, a novel modality-aware mixture-of-experts (MoE)\narchitecture designed for pre-training mixed-modal, early-fusion language\nmodels. MoMa processes images and text in arbitrary sequences by dividing\nexpert modules into modality-specific groups. These groups exclusively process\ndesignated tokens while employing learned routing within each group to maintain\nsemantically informed adaptivity. Our empirical results reveal substantial\npre-training efficiency gains through this modality-specific parameter\nallocation. Under a 1-trillion-token training budget, the MoMa 1.4B model,\nfeaturing 4 text experts and 4 image experts, achieves impressive FLOPs\nsavings: 3.7x overall, with 2.6x for text and 5.2x for image processing\ncompared to a compute-equivalent dense baseline, measured by pre-training loss.\nThis outperforms the standard expert-choice MoE with 8 mixed-modal experts,\nwhich achieves 3x overall FLOPs savings (3x for text, 2.8x for image).\nCombining MoMa with mixture-of-depths (MoD) further improves pre-training FLOPs\nsavings to 4.2x overall (text: 3.4x, image: 5.3x), although this combination\nhurts performance in causal inference due to increased sensitivity to router\naccuracy. These results demonstrate MoMa's potential to significantly advance\nthe efficiency of mixed-modal, early-fusion language model pre-training, paving\nthe way for more resource-efficient and capable multimodal AI systems.", "arxiv_id": "http://arxiv.org/abs/2407.21770v1", "pdf_url": "http://arxiv.org/pdf/2407.21770v1", "primary_category": "cs.AI", "preferences": "I'm intersted in LLMs", "response": "RELEVANT"}
{"title": "Diagnostic Runtime Monitoring with Martingales", "authors": "Ali Hindy, Rachel Luo, Somrita Banerjee, Jonathan Kuck, Edward Schmerling, Marco Pavone", "abstract": "Machine learning systems deployed in safety-critical robotics settings must\nbe robust to distribution shifts. However, system designers must understand the\ncause of a distribution shift in order to implement the appropriate\nintervention or mitigation strategy and prevent system failure. In this paper,\nwe present a novel framework for diagnosing distribution shifts in a streaming\nfashion by deploying multiple stochastic martingales simultaneously. We show\nthat knowledge of the underlying cause of a distribution shift can lead to\nproper interventions over the lifecycle of a deployed system. Our experimental\nframework can easily be adapted to different types of distribution shifts,\nmodels, and datasets. We find that our method outperforms existing work on\ndiagnosing distribution shifts in terms of speed, accuracy, and flexibility,\nand validate the efficiency of our model in both simulated and live hardware\nsettings.", "arxiv_id": "http://arxiv.org/abs/2407.21748v1", "pdf_url": "http://arxiv.org/pdf/2407.21748v1", "primary_category": "cs.RO", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "HGOE: Hybrid External and Internal Graph Outlier Exposure for Graph Out-of-Distribution Detection", "authors": "Junwei He, Qianqian Xu, Yangbangyan Jiang, Zitai Wang, Yuchen Sun, Qingming Huang", "abstract": "With the progressive advancements in deep graph learning, out-of-distribution\n(OOD) detection for graph data has emerged as a critical challenge. While the\nefficacy of auxiliary datasets in enhancing OOD detection has been extensively\nstudied for image and text data, such approaches have not yet been explored for\ngraph data. Unlike Euclidean data, graph data exhibits greater diversity but\nlower robustness to perturbations, complicating the integration of outliers. To\ntackle these challenges, we propose the introduction of \\textbf{H}ybrid\nExternal and Internal \\textbf{G}raph \\textbf{O}utlier \\textbf{E}xposure (HGOE)\nto improve graph OOD detection performance. Our framework involves using\nrealistic external graph data from various domains and synthesizing internal\noutliers within ID subgroups to address the poor robustness and presence of OOD\nsamples within the ID class. Furthermore, we develop a boundary-aware OE loss\nthat adaptively assigns weights to outliers, maximizing the use of high-quality\nOOD samples while minimizing the impact of low-quality ones. Our proposed HGOE\nframework is model-agnostic and designed to enhance the effectiveness of\nexisting graph OOD detection models. Experimental results demonstrate that our\nHGOE framework can significantly improve the performance of existing OOD\ndetection models across all 8 real datasets.", "arxiv_id": "http://arxiv.org/abs/2407.21742v1", "pdf_url": "http://arxiv.org/pdf/2407.21742v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Contrastive Factor Analysis", "authors": "Zhibin Duan, Tiansheng Wen, Yifei Wang, Chen Zhu, Bo Chen, Mingyuan Zhou", "abstract": "Factor analysis, often regarded as a Bayesian variant of matrix\nfactorization, offers superior capabilities in capturing uncertainty, modeling\ncomplex dependencies, and ensuring robustness. As the deep learning era\narrives, factor analysis is receiving less and less attention due to their\nlimited expressive ability. On the contrary, contrastive learning has emerged\nas a potent technique with demonstrated efficacy in unsupervised\nrepresentational learning. While the two methods are different paradigms,\nrecent theoretical analysis has revealed the mathematical equivalence between\ncontrastive learning and matrix factorization, providing a potential\npossibility for factor analysis combined with contrastive learning. Motivated\nby the interconnectedness of contrastive learning, matrix factorization, and\nfactor analysis, this paper introduces a novel Contrastive Factor Analysis\nframework, aiming to leverage factor analysis's advantageous properties within\nthe realm of contrastive learning. To further leverage the interpretability\nproperties of non-negative factor analysis, which can learn disentangled\nrepresentations, contrastive factor analysis is extended to a non-negative\nversion. Finally, extensive experimental validation showcases the efficacy of\nthe proposed contrastive (non-negative) factor analysis methodology across\nmultiple key properties, including expressiveness, robustness,\ninterpretability, and accurate uncertainty estimation.", "arxiv_id": "http://arxiv.org/abs/2407.21740v2", "pdf_url": "http://arxiv.org/pdf/2407.21740v2", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "A Federated Learning-Friendly Approach for Parameter-Efficient Fine-Tuning of SAM in 3D Segmentation", "authors": "Mothilal Asokan, Joseph Geo Benjamin, Mohammad Yaqub, Karthik Nandakumar", "abstract": "Adapting foundation models for medical image analysis requires finetuning\nthem on a considerable amount of data because of extreme distribution shifts\nbetween natural (source) data used for pretraining and medical (target) data.\nHowever, collecting task-specific medical data for such finetuning at a central\nlocation raises many privacy concerns. Although Federated learning (FL)\nprovides an effective means for training on private decentralized data,\ncommunication costs in federating large foundation models can quickly become a\nsignificant bottleneck, impacting the solution's scalability. In this work, we\naddress this problem of efficient communication while ensuring effective\nlearning in FL by combining the strengths of Parameter-Efficient Fine-tuning\n(PEFT) with FL. Specifically, we study plug-and-play Low-Rank Adapters (LoRA)\nin a federated manner to adapt the Segment Anything Model (SAM) for 3D medical\nimage segmentation. Unlike prior works that utilize LoRA and finetune the\nentire decoder, we critically analyze the contribution of each granular\ncomponent of SAM on finetuning performance. Thus, we identify specific layers\nto be federated that are very efficient in terms of communication cost while\nproducing on-par accuracy. Our experiments show that retaining the parameters\nof the SAM model (including most of the decoder) in their original state during\nadaptation is beneficial because fine-tuning on small datasets tends to distort\nthe inherent capabilities of the underlying foundation model. On Fed-KiTS, our\napproach decreases communication cost (~48x) compared to full fine-tuning while\nincreasing performance (~6% Dice score) in 3D segmentation tasks. Our approach\nperforms similar to SAMed while achieving ~2.8x reduction in communication and\nparameters to be finetuned. We further validate our approach with experiments\non Fed-IXI and Prostate MRI datasets.", "arxiv_id": "http://arxiv.org/abs/2407.21739v1", "pdf_url": "http://arxiv.org/pdf/2407.21739v1", "primary_category": "cs.CV", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Leveraging Self-Supervised Learning for Fetal Cardiac Planes Classification using Ultrasound Scan Videos", "authors": "Joseph Geo Benjamin, Mothilal Asokan, Amna Alhosani, Hussain Alasmawi, Werner Gerhard Diehl, Leanne Bricker, Karthik Nandakumar, Mohammad Yaqub", "abstract": "Self-supervised learning (SSL) methods are popular since they can address\nsituations with limited annotated data by directly utilising the underlying\ndata distribution. However, the adoption of such methods is not explored enough\nin ultrasound (US) imaging, especially for fetal assessment. We investigate the\npotential of dual-encoder SSL in utilizing unlabelled US video data to improve\nthe performance of challenging downstream Standard Fetal Cardiac Planes (SFCP)\nclassification using limited labelled 2D US images. We study 7 SSL approaches\nbased on reconstruction, contrastive loss, distillation, and information theory\nand evaluate them extensively on a large private US dataset. Our observations\nand findings are consolidated from more than 500 downstream training\nexperiments under different settings. Our primary observation shows that for\nSSL training, the variance of the dataset is more crucial than its size because\nit allows the model to learn generalisable representations, which improve the\nperformance of downstream tasks. Overall, the BarlowTwins method shows robust\nperformance, irrespective of the training settings and data variations, when\nused as an initialisation for downstream tasks. Notably, full fine-tuning with\n1% of labelled data outperforms ImageNet initialisation by 12% in F1-score and\noutperforms other SSL initialisations by at least 4% in F1-score, thus making\nit a promising candidate for transfer learning from US video to image data.", "arxiv_id": "http://arxiv.org/abs/2407.21738v1", "pdf_url": "http://arxiv.org/pdf/2407.21738v1", "primary_category": "eess.IV", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Social Learning through Interactions with Other Agents: A Survey", "authors": "Dylan hillier, Cheston Tan, Jing Jiang", "abstract": "Social learning plays an important role in the development of human\nintelligence. As children, we imitate our parents' speech patterns until we are\nable to produce sounds; we learn from them praising us and scolding us; and as\nadults, we learn by working with others. In this work, we survey the degree to\nwhich this paradigm -- social learning -- has been mirrored in machine\nlearning. In particular, since learning socially requires interacting with\nothers, we are interested in how embodied agents can and have utilised these\ntechniques. This is especially in light of the degree to which recent advances\nin natural language processing (NLP) enable us to perform new forms of social\nlearning. We look at how behavioural cloning and next-token prediction mirror\nhuman imitation, how learning from human feedback mirrors human education, and\nhow we can go further to enable fully communicative agents that learn from each\nother. We find that while individual social learning techniques have been used\nsuccessfully, there has been little unifying work showing how to bring them\ntogether into socially embodied agents.", "arxiv_id": "http://arxiv.org/abs/2407.21713v1", "pdf_url": "http://arxiv.org/pdf/2407.21713v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "RELEVANT"}
{"title": "Universal Approximation Theory: Foundations for Parallelism in Neural Networks", "authors": "Wei Wang, Qing Li", "abstract": "Neural networks are increasingly evolving towards training large models with\nbig data, a method that has demonstrated superior performance across many\ntasks. However, this approach introduces an urgent problem: current deep\nlearning models are predominantly serial, meaning that as the number of network\nlayers increases, so do the training and inference times. This is unacceptable\nif deep learning is to continue advancing. Therefore, this paper proposes a\ndeep learning parallelization strategy based on the Universal Approximation\nTheorem (UAT). From this foundation, we designed a parallel network called\nPara-Former to test our theory. Unlike traditional serial models, the inference\ntime of Para-Former does not increase with the number of layers, significantly\naccelerating the inference speed of multi-layer networks. Experimental results\nvalidate the effectiveness of this network.", "arxiv_id": "http://arxiv.org/abs/2407.21670v1", "pdf_url": "http://arxiv.org/pdf/2407.21670v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Synth-Empathy: Towards High-Quality Synthetic Empathy Data", "authors": "Hao Liang, Linzhuang Sun, Jingxuan Wei, Xijie Huang, Linkun Sun, Bihui Yu, Conghui He, Wentao Zhang", "abstract": "In recent years, with the rapid advancements in large language models (LLMs),\nachieving excellent empathetic response capabilities has become a crucial\nprerequisite. Consequently, managing and understanding empathetic datasets have\ngained increasing significance. However, empathetic data are typically\nhuman-labeled, leading to insufficient datasets and wasted human labor. In this\nwork, we present Synth-Empathy, an LLM-based data generation and quality and\ndiversity selection pipeline that automatically generates high-quality\nempathetic data while discarding low-quality data. With the data generated from\na low empathetic model, we are able to further improve empathetic response\nperformance and achieve state-of-the-art (SoTA) results across multiple\nbenchmarks. Moreover, our model achieves SoTA performance on various human\nevaluation benchmarks, demonstrating its effectiveness and robustness in\nreal-world applications. Furthermore, we show the trade-off between data\nquantity and quality, providing insights into empathetic data generation and\nselection.", "arxiv_id": "http://arxiv.org/abs/2407.21669v1", "pdf_url": "http://arxiv.org/pdf/2407.21669v1", "primary_category": "cs.CL", "preferences": "I'm intersted in LLMs", "response": "RELEVANT"}
{"title": "An Explainable Vision Transformer with Transfer Learning Combined with Support Vector Machine Based Efficient Drought Stress Identification", "authors": "Aswini Kumar Patra, Ankit Varshney, Lingaraj Sahoo", "abstract": "Early detection of drought stress is critical for taking timely measures for\nreducing crop loss before the drought impact becomes irreversible. The subtle\nphenotypical and physiological changes in response to drought stress are\ncaptured by non-invasive imaging techniques and these imaging data serve as\nvaluable resource for machine learning methods to identify drought stress.\nWhile convolutional neural networks (CNNs) are in wide use, vision transformers\n(ViTs) present a promising alternative in capturing long-range dependencies and\nintricate spatial relationships, thereby enhancing the detection of subtle\nindicators of drought stress. We propose an explainable deep learning pipeline\nthat leverages the power of ViTs for drought stress detection in potato crops\nusing aerial imagery. We applied two distinct approaches: a synergistic\ncombination of ViT and support vector machine (SVM), where ViT extracts\nintricate spatial features from aerial images, and SVM classifies the crops as\nstressed or healthy and an end-to-end approach using a dedicated classification\nlayer within ViT to directly detect drought stress. Our key findings explain\nthe ViT model's decision-making process by visualizing attention maps. These\nmaps highlight the specific spatial features within the aerial images that the\nViT model focuses as the drought stress signature. Our findings demonstrate\nthat the proposed methods not only achieve high accuracy in drought stress\nidentification but also shedding light on the diverse subtle plant features\nassociated with drought stress. This offers a robust and interpretable solution\nfor drought stress monitoring for farmers to undertake informed decisions for\nimproved crop management.", "arxiv_id": "http://arxiv.org/abs/2407.21666v1", "pdf_url": "http://arxiv.org/pdf/2407.21666v1", "primary_category": "cs.CV", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "A State-of-the-Art Review of Computational Models for Analyzing Longitudinal Wearable Sensor Data in Healthcare", "authors": "Paula Lago", "abstract": "Wearable devices are increasingly used as tools for biomedical research, as\nthe continuous stream of behavioral and physiological data they collect can\nprovide insights about our health in everyday contexts. Long-term tracking,\ndefined in the timescale of months of year, can provide insights of patterns\nand changes as indicators of health changes. These insights can make medicine\nand healthcare more predictive, preventive, personalized, and participative\n(The 4P's). However, the challenges in modeling, understanding and processing\nlongitudinal data are a significant barrier to their adoption in research\nstudies and clinical settings. In this paper, we review and discuss three\nmodels used to make sense of longitudinal data: routines, rhythms and stability\nmetrics. We present the challenges associated with the processing and analysis\nof longitudinal wearable sensor data, with a special focus on how to handle the\ndifferent temporal dynamics at various granularities. We then discuss current\nlimitations and identify directions for future work. This review is essential\nto the advancement of computational modeling and analysis of longitudinal\nsensor data for pervasive healthcare.", "arxiv_id": "http://arxiv.org/abs/2407.21665v1", "pdf_url": "http://arxiv.org/pdf/2407.21665v1", "primary_category": "cs.HC", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Beat this! Accurate beat tracking without DBN postprocessing", "authors": "Francesco Foscarin, Jan Schl\u00fcter, Gerhard Widmer", "abstract": "We propose a system for tracking beats and downbeats with two objectives:\ngenerality across a diverse music range, and high accuracy. We achieve\ngenerality by training on multiple datasets -- including solo instrument\nrecordings, pieces with time signature changes, and classical music with high\ntempo variations -- and by removing the commonly used Dynamic Bayesian Network\n(DBN) postprocessing, which introduces constraints on the meter and tempo. For\nhigh accuracy, among other improvements, we develop a loss function tolerant to\nsmall time shifts of annotations, and an architecture alternating convolutions\nwith transformers either over frequency or time. Our system surpasses the\ncurrent state of the art in F1 score despite using no DBN. However, it can\nstill fail, especially for difficult and underrepresented genres, and performs\nworse on continuity metrics, so we publish our model, code, and preprocessed\ndatasets, and invite others to beat this.", "arxiv_id": "http://arxiv.org/abs/2407.21658v1", "pdf_url": "http://arxiv.org/pdf/2407.21658v1", "primary_category": "cs.SD", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Comgra: A Tool for Analyzing and Debugging Neural Networks", "authors": "Florian Dietz, Sophie Fellenz, Dietrich Klakow, Marius Kloft", "abstract": "Neural Networks are notoriously difficult to inspect. We introduce comgra, an\nopen source python library for use with PyTorch. Comgra extracts data about the\ninternal activations of a model and organizes it in a GUI (graphical user\ninterface). It can show both summary statistics and individual data points,\ncompare early and late stages of training, focus on individual samples of\ninterest, and visualize the flow of the gradient through the network. This\nmakes it possible to inspect the model's behavior from many different angles\nand save time by rapidly testing different hypotheses without having to rerun\nit. Comgra has applications for debugging, neural architecture design, and\nmechanistic interpretability. We publish our library through Python Package\nIndex (PyPI) and provide code, documentation, and tutorials at\nhttps://github.com/FlorianDietz/comgra.", "arxiv_id": "http://arxiv.org/abs/2407.21656v1", "pdf_url": "http://arxiv.org/pdf/2407.21656v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Spatial Transformer Network YOLO Model for Agricultural Object Detection", "authors": "Yash Zambre, Ekdev Rajkitkul, Akshatha Mohan, Joshua Peeples", "abstract": "Object detection plays a crucial role in the field of computer vision by\nautonomously identifying and locating objects of interest. The You Only Look\nOnce (YOLO) model is an effective single-shot detector. However, YOLO faces\nchallenges in cluttered or partially occluded scenes and can struggle with\nsmall, low-contrast objects. We propose a new method that integrates spatial\ntransformer networks (STNs) into YOLO to improve performance. The proposed\nSTN-YOLO aims to enhance the model's effectiveness by focusing on important\nareas of the image and improving the spatial invariance of the model before the\ndetection process. Our proposed method improved object detection performance\nboth qualitatively and quantitatively. We explore the impact of different\nlocalization networks within the STN module as well as the robustness of the\nmodel across different spatial transformations. We apply the STN-YOLO on\nbenchmark datasets for Agricultural object detection as well as a new dataset\nfrom a state-of-the-art plant phenotyping greenhouse facility. Our code and\ndataset are publicly available.", "arxiv_id": "http://arxiv.org/abs/2407.21652v1", "pdf_url": "http://arxiv.org/pdf/2407.21652v1", "primary_category": "cs.CV", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Lyapunov weights to convey the meaning of time in physics-informed neural networks", "authors": "Gabriel Turinici", "abstract": "Time is not a dimension as the others. In Physics-Informed Neural Networks\n(PINN) several proposals attempted to adapt the time sampling or time weighting\nto take into account the specifics of this special dimension. But these\nproposals are not principled and need guidance to be used. We explain here\ntheoretically why the Lyapunov exponents give actionable insights and propose a\nweighting scheme to automatically adapt to chaotic, periodic or stable\ndynamics. We characterize theoretically the best weighting scheme under\ncomputational constraints as a cumulative exponential integral of the local\nLyapunov exponent estimators and show that it performs well in practice under\nthe regimes mentioned above.", "arxiv_id": "http://arxiv.org/abs/2407.21642v1", "pdf_url": "http://arxiv.org/pdf/2407.21642v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "MART: MultiscAle Relational Transformer Networks for Multi-agent Trajectory Prediction", "authors": "Seongju Lee, Junseok Lee, Yeonguk Yu, Taeri Kim, Kyoobin Lee", "abstract": "Multi-agent trajectory prediction is crucial to autonomous driving and\nunderstanding the surrounding environment. Learning-based approaches for\nmulti-agent trajectory prediction, such as primarily relying on graph neural\nnetworks, graph transformers, and hypergraph neural networks, have demonstrated\noutstanding performance on real-world datasets in recent years. However, the\nhypergraph transformer-based method for trajectory prediction is yet to be\nexplored. Therefore, we present a MultiscAle Relational Transformer (MART)\nnetwork for multi-agent trajectory prediction. MART is a hypergraph transformer\narchitecture to consider individual and group behaviors in transformer\nmachinery. The core module of MART is the encoder, which comprises a Pair-wise\nRelational Transformer (PRT) and a Hyper Relational Transformer (HRT). The\nencoder extends the capabilities of a relational transformer by introducing\nHRT, which integrates hyperedge features into the transformer mechanism,\npromoting attention weights to focus on group-wise relations. In addition, we\npropose an Adaptive Group Estimator (AGE) designed to infer complex group\nrelations in real-world environments. Extensive experiments on three real-world\ndatasets (NBA, SDD, and ETH-UCY) demonstrate that our method achieves\nstate-of-the-art performance, enhancing ADE/FDE by 3.9%/11.8% on the NBA\ndataset. Code is available at https://github.com/gist-ailab/MART.", "arxiv_id": "http://arxiv.org/abs/2407.21635v1", "pdf_url": "http://arxiv.org/pdf/2407.21635v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Extended Fiducial Inference: Toward an Automated Process of Statistical Inference", "authors": "Faming Liang, Sehwan Kim, Yan Sun", "abstract": "While fiducial inference was widely considered a big blunder by R.A. Fisher,\nthe goal he initially set --`inferring the uncertainty of model parameters on\nthe basis of observations' -- has been continually pursued by many\nstatisticians. To this end, we develop a new statistical inference method\ncalled extended Fiducial inference (EFI). The new method achieves the goal of\nfiducial inference by leveraging advanced statistical computing techniques\nwhile remaining scalable for big data. EFI involves jointly imputing random\nerrors realized in observations using stochastic gradient Markov chain Monte\nCarlo and estimating the inverse function using a sparse deep neural network\n(DNN). The consistency of the sparse DNN estimator ensures that the uncertainty\nembedded in observations is properly propagated to model parameters through the\nestimated inverse function, thereby validating downstream statistical\ninference. Compared to frequentist and Bayesian methods, EFI offers significant\nadvantages in parameter estimation and hypothesis testing. Specifically, EFI\nprovides higher fidelity in parameter estimation, especially when outliers are\npresent in the observations; and eliminates the need for theoretical reference\ndistributions in hypothesis testing, thereby automating the statistical\ninference process. EFI also provides an innovative framework for\nsemi-supervised learning.", "arxiv_id": "http://arxiv.org/abs/2407.21622v1", "pdf_url": "http://arxiv.org/pdf/2407.21622v1", "primary_category": "stat.ML", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Ironing the Graphs: Toward a Correct Geometric Analysis of Large-Scale Graphs", "authors": "Saloua Naama, Kav\u00e9 Salamatian, Francesco Bronzino", "abstract": "Graph embedding approaches attempt to project graphs into geometric entities,\ni.e, manifolds. The idea is that the geometric properties of the projected\nmanifolds are helpful in the inference of graph properties. However, if the\nchoice of the embedding manifold is incorrectly performed, it can lead to\nincorrect geometric inference. In this paper, we argue that the classical\nembedding techniques cannot lead to correct geometric interpretation as they\nmiss the curvature at each point, of manifold. We advocate that for doing\ncorrect geometric interpretation the embedding of graph should be done over\nregular constant curvature manifolds. To this end, we present an embedding\napproach, the discrete Ricci flow graph embedding (dRfge) based on the discrete\nRicci flow that adapts the distance between nodes in a graph so that the graph\ncan be embedded onto a constant curvature manifold that is homogeneous and\nisotropic, i.e., all directions are equivalent and distances comparable,\nresulting in correct geometric interpretations. A major contribution of this\npaper is that for the first time, we prove the convergence of discrete Ricci\nflow to a constant curvature and stable distance metrics over the edges. A\ndrawback of using the discrete Ricci flow is the high computational complexity\nthat prevented its usage in large-scale graph analysis. Another contribution of\nthis paper is a new algorithmic solution that makes it feasible to calculate\nthe Ricci flow for graphs of up to 50k nodes, and beyond. The intuitions behind\nthe discrete Ricci flow make it possible to obtain new insights into the\nstructure of large-scale graphs. We demonstrate this through a case study on\nanalyzing the internet connectivity structure between countries at the BGP\nlevel.", "arxiv_id": "http://arxiv.org/abs/2407.21609v1", "pdf_url": "http://arxiv.org/pdf/2407.21609v1", "primary_category": "cs.CG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Higher order quantum reservoir computing for non-intrusive reduced-order models", "authors": "Vinamr Jain, Romit Maulik", "abstract": "Forecasting dynamical systems is of importance to numerous real-world\napplications. When possible, dynamical systems forecasts are constructed based\non first-principles-based models such as through the use of differential\nequations. When these equations are unknown, non-intrusive techniques must be\nutilized to build predictive models from data alone. Machine learning (ML)\nmethods have recently been used for such tasks. Moreover, ML methods provide\nthe added advantage of significant reductions in time-to-solution for\npredictions in contrast with first-principle based models. However, many\nstate-of-the-art ML-based methods for forecasting rely on neural networks,\nwhich may be expensive to train and necessitate requirements for large amounts\nof memory. In this work, we propose a quantum mechanics inspired ML modeling\nstrategy for learning nonlinear dynamical systems that provides data-driven\nforecasts for complex dynamical systems with reduced training time and memory\ncosts. This approach, denoted the quantum reservoir computing technique (QRC),\nis a hybrid quantum-classical framework employing an ensemble of interconnected\nsmall quantum systems via classical linear feedback connections. By mapping the\ndynamical state to a suitable quantum representation amenable to unitary\noperations, QRC is able to predict complex nonlinear dynamical systems in a\nstable and accurate manner. We demonstrate the efficacy of this framework\nthrough benchmark forecasts of the NOAA Optimal Interpolation Sea Surface\nTemperature dataset and compare the performance of QRC to other ML methods.", "arxiv_id": "http://arxiv.org/abs/2407.21602v1", "pdf_url": "http://arxiv.org/pdf/2407.21602v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Measuring What Matters: Intrinsic Distance Preservation as a Robust Metric for Embedding Quality", "authors": "Steven N. Hart, Thomas E. Tavolara", "abstract": "Unsupervised embeddings are fundamental to numerous machine learning\napplications, yet their evaluation remains a challenging task. Traditional\nassessment methods often rely on extrinsic variables, such as performance in\ndownstream tasks, which can introduce confounding factors and mask the true\nquality of embeddings. This paper introduces the Intrinsic Distance\nPreservation Evaluation (IDPE) method, a novel approach for assessing embedding\nquality based on the preservation of Mahalanobis distances between data points\nin the original and embedded spaces. We demonstrate the limitations of\nextrinsic evaluation methods through a simple example, highlighting how they\ncan lead to misleading conclusions about embedding quality. IDPE addresses\nthese issues by providing a task-independent measure of how well embeddings\npreserve the intrinsic structure of the original data. Our method leverages\nefficient similarity search techniques to make it applicable to large-scale\ndatasets. We compare IDPE with established intrinsic metrics like\ntrustworthiness and continuity, as well as extrinsic metrics such as Average\nRank and Mean Reciprocal Rank. Our results show that IDPE offers a more\ncomprehensive and reliable assessment of embedding quality across various\nscenarios. We evaluate PCA and t-SNE embeddings using IDPE, revealing insights\ninto their performance that are not captured by traditional metrics. This work\ncontributes to the field by providing a robust, efficient, and interpretable\nmethod for embedding evaluation. IDPE's focus on intrinsic properties offers a\nvaluable tool for researchers and practitioners seeking to develop and assess\nhigh-quality embeddings for diverse machine learning applications.", "arxiv_id": "http://arxiv.org/abs/2407.21590v1", "pdf_url": "http://arxiv.org/pdf/2407.21590v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Multi-agent reinforcement learning for the control of three-dimensional Rayleigh-B\u00e9nard convection", "authors": "Joel Vasanth, Jean Rabault, Francisco Alc\u00e1ntara-\u00c1vila, Mikael Mortensen, Ricardo Vinuesa", "abstract": "Deep reinforcement learning (DRL) has found application in numerous use-cases\npertaining to flow control. Multi-agent RL (MARL), a variant of DRL, has shown\nto be more effective than single-agent RL in controlling flows exhibiting\nlocality and translational invariance. We present, for the first time, an\nimplementation of MARL-based control of three-dimensional Rayleigh-B\\'enard\nconvection (RBC). Control is executed by modifying the temperature distribution\nalong the bottom wall divided into multiple control segments, each of which\nacts as an independent agent. Two regimes of RBC are considered at Rayleigh\nnumbers $\\mathrm{Ra}=500$ and $750$. Evaluation of the learned control policy\nreveals a reduction in convection intensity by $23.5\\%$ and $8.7\\%$ at\n$\\mathrm{Ra}=500$ and $750$, respectively. The MARL controller converts\nirregularly shaped convective patterns to regular straight rolls with lower\nconvection that resemble flow in a relatively more stable regime. We draw\ncomparisons with proportional control at both $\\mathrm{Ra}$ and show that MARL\nis able to outperform the proportional controller. The learned control strategy\nis complex, featuring different non-linear segment-wise actuator delays and\nactuation magnitudes. We also perform successful evaluations on a larger domain\nthan used for training, demonstrating that the invariant property of MARL\nallows direct transfer of the learnt policy.", "arxiv_id": "http://arxiv.org/abs/2407.21565v1", "pdf_url": "http://arxiv.org/pdf/2407.21565v1", "primary_category": "physics.flu-dyn", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "CXSimulator: A User Behavior Simulation using LLM Embeddings for Web-Marketing Campaign Assessment", "authors": "Akira Kasuga, Ryo Yonetani", "abstract": "This paper presents the Customer Experience (CX) Simulator, a novel framework\ndesigned to assess the effects of untested web-marketing campaigns through user\nbehavior simulations. The proposed framework leverages large language models\n(LLMs) to represent various events in a user's behavioral history, such as\nviewing an item, applying a coupon, or purchasing an item, as semantic\nembedding vectors. We train a model to predict transitions between events from\ntheir LLM embeddings, which can even generalize to unseen events by learning\nfrom diverse training data. In web-marketing applications, we leverage this\ntransition prediction model to simulate how users might react differently when\nnew campaigns or products are presented to them. This allows us to eliminate\nthe need for costly online testing and enhance the marketers' abilities to\nreveal insights. Our numerical evaluation and user study, utilizing BigQuery\nPublic Datasets from the Google Merchandise Store, demonstrate the\neffectiveness of our framework.", "arxiv_id": "http://arxiv.org/abs/2407.21553v1", "pdf_url": "http://arxiv.org/pdf/2407.21553v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "RELEVANT"}
{"title": "Black box meta-learning intrinsic rewards for sparse-reward environments", "authors": "Octavio Pappalardo, Rodrigo Ramele, Juan Miguel Santos", "abstract": "Despite the successes and progress of deep reinforcement learning over the\nlast decade, several challenges remain that hinder its broader application.\nSome fundamental aspects to improve include data efficiency, generalization\ncapability, and ability to learn in sparse-reward environments, which often\nrequire human-designed dense rewards. Meta-learning has emerged as a promising\napproach to address these issues by optimizing components of the learning\nalgorithm to meet desired characteristics. Additionally, a different line of\nwork has extensively studied the use of intrinsic rewards to enhance the\nexploration capabilities of algorithms. This work investigates how\nmeta-learning can improve the training signal received by RL agents. The focus\nis on meta-learning intrinsic rewards under a framework that doesn't rely on\nthe use of meta-gradients. We analyze and compare this approach to the use of\nextrinsic rewards and a meta-learned advantage function. The developed\nalgorithms are evaluated on distributions of continuous control tasks with both\nparametric and non-parametric variations, and with only sparse rewards\naccessible for the evaluation tasks.", "arxiv_id": "http://arxiv.org/abs/2407.21546v1", "pdf_url": "http://arxiv.org/pdf/2407.21546v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Probabilistic Scoring Lists for Interpretable Machine Learning", "authors": "Jonas Hanselle, Stefan Heid, Johannes F\u00fcrnkranz, Eyke H\u00fcllermeier", "abstract": "A scoring system is a simple decision model that checks a set of features,\nadds a certain number of points to a total score for each feature that is\nsatisfied, and finally makes a decision by comparing the total score to a\nthreshold. Scoring systems have a long history of active use in safety-critical\ndomains such as healthcare and justice, where they provide guidance for making\nobjective and accurate decisions. Given their genuine interpretability, the\nidea of learning scoring systems from data is obviously appealing from the\nperspective of explainable AI. In this paper, we propose a practically\nmotivated extension of scoring systems called probabilistic scoring lists\n(PSL), as well as a method for learning PSLs from data. Instead of making a\ndeterministic decision, a PSL represents uncertainty in the form of probability\ndistributions, or, more generally, probability intervals. Moreover, in the\nspirit of decision lists, a PSL evaluates features one by one and stops as soon\nas a decision can be made with enough confidence. To evaluate our approach, we\nconduct a case study in the medical domain.", "arxiv_id": "http://arxiv.org/abs/2407.21535v1", "pdf_url": "http://arxiv.org/pdf/2407.21535v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Data Contamination Report from the 2024 CONDA Shared Task", "authors": "Oscar Sainz, Iker Garc\u00eda-Ferrero, Alon Jacovi, Jon Ander Campos, Yanai Elazar, Eneko Agirre, Yoav Goldberg, Wei-Lin Chen, Jenny Chim, Leshem Choshen, Luca D'Amico-Wong, Melissa Dell, Run-Ze Fan, Shahriar Golchin, Yucheng Li, Pengfei Liu, Bhavish Pahwa, Ameya Prabhu, Suryansh Sharma, Emily Silcock, Kateryna Solonko, David Stap, Mihai Surdeanu, Yu-Min Tseng, Vishaal Udandarao, Zengzhi Wang, Ruijie Xu, Jinglin Yang", "abstract": "The 1st Workshop on Data Contamination (CONDA 2024) focuses on all relevant\naspects of data contamination in natural language processing, where data\ncontamination is understood as situations where evaluation data is included in\npre-training corpora used to train large scale models, compromising evaluation\nresults. The workshop fostered a shared task to collect evidence on data\ncontamination in current available datasets and models. The goal of the shared\ntask and associated database is to assist the community in understanding the\nextent of the problem and to assist researchers in avoiding reporting\nevaluation results on known contaminated resources. The shared task provides a\nstructured, centralized public database for the collection of contamination\nevidence, open to contributions from the community via GitHub pool requests.\nThis first compilation paper is based on 566 reported entries over 91\ncontaminated sources from a total of 23 contributors. The details of the\nindividual contamination events are available in the platform. The platform\ncontinues to be online, open to contributions from the community.", "arxiv_id": "http://arxiv.org/abs/2407.21530v1", "pdf_url": "http://arxiv.org/pdf/2407.21530v1", "primary_category": "cs.CL", "preferences": "I'm intersted in LLMs", "response": "RELEVANT"}
{"title": "Tabular Data Augmentation for Machine Learning: Progress and Prospects of Embracing Generative AI", "authors": "Lingxi Cui, Huan Li, Ke Chen, Lidan Shou, Gang Chen", "abstract": "Machine learning (ML) on tabular data is ubiquitous, yet obtaining abundant\nhigh-quality tabular data for model training remains a significant obstacle.\nNumerous works have focused on tabular data augmentation (TDA) to enhance the\noriginal table with additional data, thereby improving downstream ML tasks.\nRecently, there has been a growing interest in leveraging the capabilities of\ngenerative AI for TDA. Therefore, we believe it is time to provide a\ncomprehensive review of the progress and future prospects of TDA, with a\nparticular emphasis on the trending generative AI. Specifically, we present an\narchitectural view of the TDA pipeline, comprising three main procedures:\npre-augmentation, augmentation, and post-augmentation. Pre-augmentation\nencompasses preparation tasks that facilitate subsequent TDA, including error\nhandling, table annotation, table simplification, table representation, table\nindexing, table navigation, schema matching, and entity matching. Augmentation\nsystematically analyzes current TDA methods, categorized into retrieval-based\nmethods, which retrieve external data, and generation-based methods, which\ngenerate synthetic data. We further subdivide these methods based on the\ngranularity of the augmentation process at the row, column, cell, and table\nlevels. Post-augmentation focuses on the datasets, evaluation and optimization\naspects of TDA. We also summarize current trends and future directions for TDA,\nhighlighting promising opportunities in the era of generative AI. In addition,\nthe accompanying papers and related resources are continuously updated and\nmaintained in the GitHub repository at\nhttps://github.com/SuDIS-ZJU/awesome-tabular-data-augmentation to reflect\nongoing advancements in the field.", "arxiv_id": "http://arxiv.org/abs/2407.21523v1", "pdf_url": "http://arxiv.org/pdf/2407.21523v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "FSSC: Federated Learning of Transformer Neural Networks for Semantic Image Communication", "authors": "Yuna Yan, Xin Zhang, Lixin Li, Wensheng Lin, Rui Li, Wenchi Cheng, Zhu Han", "abstract": "In this paper, we address the problem of image semantic communication in a\nmulti-user deployment scenario and propose a federated learning (FL) strategy\nfor a Swin Transformer-based semantic communication system (FSSC). Firstly, we\ndemonstrate that the adoption of a Swin Transformer for joint source-channel\ncoding (JSCC) effectively extracts semantic information in the communication\nsystem. Next, the FL framework is introduced to collaboratively learn a global\nmodel by aggregating local model parameters, rather than directly sharing\nclients' data. This approach enhances user privacy protection and reduces the\nworkload on the server or mobile edge. Simulation evaluations indicate that our\nmethod outperforms the typical JSCC algorithm and traditional separate-based\ncommunication algorithms. Particularly after integrating local semantics, the\nglobal aggregation model has further increased the Peak Signal-to-Noise Ratio\n(PSNR) by more than 2dB, thoroughly proving the effectiveness of our algorithm.", "arxiv_id": "http://arxiv.org/abs/2407.21507v1", "pdf_url": "http://arxiv.org/pdf/2407.21507v1", "primary_category": "cs.AI", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Root Cause Analysis Of Productivity Losses In Manufacturing Systems Utilizing Ensemble Machine Learning", "authors": "Jonas Gram, Brandon K. Sai, Thomas Bauernhansl", "abstract": "In today's rapidly evolving landscape of automation and manufacturing\nsystems, the efficient resolution of productivity losses is paramount. This\nstudy introduces a data-driven ensemble approach, utilizing the cyclic\nmultivariate time series data from binary sensors and signals from Programmable\nLogic Controllers (PLCs) within these systems. The objective is to\nautomatically analyze productivity losses per cycle and pinpoint their root\ncauses by assigning the loss to a system element. The ensemble approach\nintroduced in this publication integrates various methods, including\ninformation theory and machine learning behavior models, to provide a robust\nanalysis for each production cycle. To expedite the resolution of productivity\nlosses and ensure short response times, stream processing becomes a necessity.\nAddressing this, the approach is implemented as data-stream analysis and can be\ntransferred to batch processing, seamlessly integrating into existing systems\nwithout the need for extensive historical data analysis. This method has two\npositive effects. Firstly, the result of the analysis ensures that the period\nof lower productivity is reduced by identifying the likely root cause of the\nproductivity loss. Secondly, these results are more reliable due to the\nensemble approach and therefore avoid dependency on technical experts. The\napproach is validated using a semi-automated welding manufacturing system, an\ninjection molding automation system, and a synthetically generated test PLC\ndataset. The results demonstrate the method's efficacy in offering a\ndata-driven understanding of process behavior and mark an advancement in\nautonomous manufacturing system analysis.", "arxiv_id": "http://arxiv.org/abs/2407.21503v1", "pdf_url": "http://arxiv.org/pdf/2407.21503v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Explainable and Controllable Motion Curve Guided Cardiac Ultrasound Video Generation", "authors": "Junxuan Yu, Rusi Chen, Yongsong Zhou, Yanlin Chen, Yaofei Duan, Yuhao Huang, Han Zhou, Tan Tao, Xin Yang, Dong Ni", "abstract": "Echocardiography video is a primary modality for diagnosing heart diseases,\nbut the limited data poses challenges for both clinical teaching and machine\nlearning training. Recently, video generative models have emerged as a\npromising strategy to alleviate this issue. However, previous methods often\nrelied on holistic conditions during generation, hindering the flexible\nmovement control over specific cardiac structures. In this context, we propose\nan explainable and controllable method for echocardiography video generation,\ntaking an initial frame and a motion curve as guidance. Our contributions are\nthree-fold. First, we extract motion information from each heart substructure\nto construct motion curves, enabling the diffusion model to synthesize\ncustomized echocardiography videos by modifying these curves. Second, we\npropose the structure-to-motion alignment module, which can map semantic\nfeatures onto motion curves across cardiac structures. Third, The\nposition-aware attention mechanism is designed to enhance video consistency\nutilizing Gaussian masks with structural position information. Extensive\nexperiments on three echocardiography datasets show that our method outperforms\nothers regarding fidelity and consistency. The full code will be released at\nhttps://github.com/mlmi-2024-72/ECM.", "arxiv_id": "http://arxiv.org/abs/2407.21490v1", "pdf_url": "http://arxiv.org/pdf/2407.21490v1", "primary_category": "eess.IV", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "On the Problem of Text-To-Speech Model Selection for Synthetic Data Generation in Automatic Speech Recognition", "authors": "Nick Rossenbach, Ralf Schl\u00fcter, Sakriani Sakti", "abstract": "The rapid development of neural text-to-speech (TTS) systems enabled its\nusage in other areas of natural language processing such as automatic speech\nrecognition (ASR) or spoken language translation (SLT). Due to the large number\nof different TTS architectures and their extensions, selecting which TTS\nsystems to use for synthetic data creation is not an easy task. We use the\ncomparison of five different TTS decoder architectures in the scope of\nsynthetic data generation to show the impact on CTC-based speech recognition\ntraining. We compare the recognition results to computable metrics like NISQA\nMOS and intelligibility, finding that there are no clear relations to the ASR\nperformance. We also observe that for data generation auto-regressive decoding\nperforms better than non-autoregressive decoding, and propose an approach to\nquantify TTS generalization capabilities.", "arxiv_id": "http://arxiv.org/abs/2407.21476v1", "pdf_url": "http://arxiv.org/pdf/2407.21476v1", "primary_category": "cs.CL", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Multi-agent Assessment with QoS Enhancement for HD Map Updates in a Vehicular Network", "authors": "Jeffrey Redondo, Nauman Aslam, Juan Zhang, Zhenhui Yuan", "abstract": "Reinforcement Learning (RL) algorithms have been used to address the\nchallenging problems in the offloading process of vehicular ad hoc networks\n(VANET). More recently, they have been utilized to improve the dissemination of\nhigh-definition (HD) Maps. Nevertheless, implementing solutions such as deep\nQ-learning (DQN) and Actor-critic at the autonomous vehicle (AV) may lead to an\nincrease in the computational load, causing a heavy burden on the computational\ndevices and higher costs. Moreover, their implementation might raise\ncompatibility issues between technologies due to the required modifications to\nthe standards. Therefore, in this paper, we assess the scalability of an\napplication utilizing a Q-learning single-agent solution in a distributed\nmulti-agent environment. This application improves the network performance by\ntaking advantage of a smaller state, and action space whilst using a\nmulti-agent approach. The proposed solution is extensively evaluated with\ndifferent test cases involving reward function considering individual or\noverall network performance, number of agents, and centralized and distributed\nlearning comparison. The experimental results demonstrate that the time\nlatencies of our proposed solution conducted in voice, video, HD Map, and\nbest-effort cases have significant improvements, with 40.4%, 36%, 43%, and 12%\nrespectively, compared to the performances with the single-agent approach.", "arxiv_id": "http://arxiv.org/abs/2407.21460v1", "pdf_url": "http://arxiv.org/pdf/2407.21460v1", "primary_category": "cs.AI", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "TinyChirp: Bird Song Recognition Using TinyML Models on Low-power Wireless Acoustic Sensors", "authors": "Zhaolan Huang, Adrien Tousnakhoff, Polina Kozyr, Roman Rehausen, Felix Bie\u00dfmann, Robert Lachlan, Cedric Adjih, Emmanuel Baccelli", "abstract": "Monitoring biodiversity at scale is challenging. Detecting and identifying\nspecies in fine grained taxonomies requires highly accurate machine learning\n(ML) methods. Training such models requires large high quality data sets. And\ndeploying these models to low power devices requires novel compression\ntechniques and model architectures. While species classification methods have\nprofited from novel data sets and advances in ML methods, in particular neural\nnetworks, deploying these state of the art models to low power devices remains\ndifficult. Here we present a comprehensive empirical comparison of various\ntinyML neural network architectures and compression techniques for species\nclassification. We focus on the example of bird song detection, more concretely\na data set curated for studying the corn bunting bird species. The data set is\nreleased along with all code and experiments of this study. In our experiments\nwe compare predictive performance, memory and time complexity of classical\nspectrogram based methods and recent approaches operating on raw audio signal.\nOur results indicate that individual bird species can be robustly detected with\nrelatively simple architectures that can be readily deployed to low power\ndevices.", "arxiv_id": "http://arxiv.org/abs/2407.21453v1", "pdf_url": "http://arxiv.org/pdf/2407.21453v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "MLLM Is a Strong Reranker: Advancing Multimodal Retrieval-augmented Generation via Knowledge-enhanced Reranking and Noise-injected Training", "authors": "Zhanpeng Chen, Chengjin Xu, Yiyan Qi, Jian Guo", "abstract": "Multimodal Large Language Models (MLLMs) have demonstrated remarkable\ncapabilities in processing and generating content across multiple data\nmodalities, including text, images, audio, and video. However, a significant\ndrawback of MLLMs is their reliance on static training data, leading to\noutdated information and limited contextual awareness. This static nature\nhampers their ability to provide accurate, up-to-date responses, particularly\nin dynamic or rapidly evolving contexts. Integrating Multimodal\nRetrieval-augmented Generation (Multimodal RAG) offers a promising solution,\nbut the system would inevitably encounter the multi-granularity noisy\ncorrespondence (MNC) problem, which involves two types of noise: coarse-grained\n(query-caption) and fine-grained (query-image). This noise hinders accurate\nretrieval and generation. In this work, we propose \\textbf{RagLLaVA}, a novel\nframework with knowledge-enhanced reranking and noise-injected training, to\naddress these limitations. We instruction-tune the MLLM with a simple yet\neffective instruction template to induce its ranking ability and serve it as a\nreranker to precisely filter the top-k retrieved images. For generation, we\ninject visual noise during training at the data and token levels to enhance the\ngenerator's robustness. Extensive experiments are conducted on the subsets of\ntwo datasets that require retrieving and reasoning over images to answer a\ngiven query. Our results demonstrate the superiority of RagLLaVA in retrieving\naccurately and generating robustly. Code and models are available at\nhttps://github.com/IDEA-FinAI/RagLLaVA.", "arxiv_id": "http://arxiv.org/abs/2407.21439v1", "pdf_url": "http://arxiv.org/pdf/2407.21439v1", "primary_category": "cs.AI", "preferences": "I'm intersted in LLMs", "response": "RELEVANT"}
{"title": "Transient anisotropic kernel for probabilistic learning on manifolds", "authors": "Christian Soize, Roger Ghanem", "abstract": "PLoM (Probabilistic Learning on Manifolds) is a method introduced in 2016 for\nhandling small training datasets by projecting an It\\^o equation from a\nstochastic dissipative Hamiltonian dynamical system, acting as the MCMC\ngenerator, for which the KDE-estimated probability measure with the training\ndataset is the invariant measure. PLoM performs a projection on a reduced-order\nvector basis related to the training dataset, using the diffusion maps (DMAPS)\nbasis constructed with a time-independent isotropic kernel. In this paper, we\npropose a new ISDE projection vector basis built from a transient anisotropic\nkernel, providing an alternative to the DMAPS basis to improve statistical\nsurrogates for stochastic manifolds with heterogeneous data. The construction\nensures that for times near the initial time, the DMAPS basis coincides with\nthe transient basis. For larger times, the differences between the two bases\nare characterized by the angle of their spanned vector subspaces. The optimal\ninstant yielding the optimal transient basis is determined using an estimation\nof mutual information from Information Theory, which is normalized by the\nentropy estimation to account for the effects of the number of realizations\nused in the estimations. Consequently, this new vector basis better represents\nstatistical dependencies in the learned probability measure for any dimension.\nThree applications with varying levels of statistical complexity and data\nheterogeneity validate the proposed theory, showing that the transient\nanisotropic kernel improves the learned probability measure.", "arxiv_id": "http://arxiv.org/abs/2407.21435v1", "pdf_url": "http://arxiv.org/pdf/2407.21435v1", "primary_category": "stat.ML", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Cost-Effective Hallucination Detection for LLMs", "authors": "Simon Valentin, Jinmiao Fu, Gianluca Detommaso, Shaoyuan Xu, Giovanni Zappella, Bryan Wang", "abstract": "Large language models (LLMs) can be prone to hallucinations - generating\nunreliable outputs that are unfaithful to their inputs, external facts or\ninternally inconsistent. In this work, we address several challenges for\npost-hoc hallucination detection in production settings. Our pipeline for\nhallucination detection entails: first, producing a confidence score\nrepresenting the likelihood that a generated answer is a hallucination; second,\ncalibrating the score conditional on attributes of the inputs and candidate\nresponse; finally, performing detection by thresholding the calibrated score.\nWe benchmark a variety of state-of-the-art scoring methods on different\ndatasets, encompassing question answering, fact checking, and summarization\ntasks. We employ diverse LLMs to ensure a comprehensive assessment of\nperformance. We show that calibrating individual scoring methods is critical\nfor ensuring risk-aware downstream decision making. Based on findings that no\nindividual score performs best in all situations, we propose a multi-scoring\nframework, which combines different scores and achieves top performance across\nall datasets. We further introduce cost-effective multi-scoring, which can\nmatch or even outperform more expensive detection methods, while significantly\nreducing computational overhead.", "arxiv_id": "http://arxiv.org/abs/2407.21424v1", "pdf_url": "http://arxiv.org/pdf/2407.21424v1", "primary_category": "cs.CL", "preferences": "I'm intersted in LLMs", "response": "RELEVANT"}
{"title": "FTuner: A Fast Dynamic Shape Tensors Program Auto-Tuner for Deep Learning Compilers", "authors": "Pengyu Mu, Linquan Wei, Yi Liu, Rui Wang", "abstract": "Many artificial intelligence models process input data of different lengths\nand resolutions, making the shape of the tensors dynamic. The performance of\nthese models depends on the shape of the tensors, which makes it difficult to\noptimize the tensors before the model runs. There are two common solutions to\nthis problem. The first is to add useless data to the input to match a\npre-optimized tensor library. The second is to use small basic tensors to\ncreate a tensor that is closest in size to the input data and then tune it to\nminimize padding. However, this second solution can be time-consuming.\n  This paper proposes a new technique for deep learning compilers called\nFTuner. Instead of using a large design space or training a cost model, we use\nan abstract computational unit called the uKernel to patch together small,\nvarious-sized tensors to match the shape of the input tensor. We determine the\nshape of the uKernel using an analytic hardware information model. Experiments\nshow that the FTuner can achieve comparable operators and end-to-end\nperformance to vendor libraries and achieves 3\\% speedup on existing auto-tuner\nwith the model-training compiler while reducing tuning time by two orders of\nmagnitude.", "arxiv_id": "http://arxiv.org/abs/2407.21418v1", "pdf_url": "http://arxiv.org/pdf/2407.21418v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Deep Fr\u00e9chet Regression", "authors": "Su I Iao, Yidong Zhou, Hans-Georg M\u00fcller", "abstract": "Advancements in modern science have led to the increasing availability of\nnon-Euclidean data in metric spaces. This paper addresses the challenge of\nmodeling relationships between non-Euclidean responses and multivariate\nEuclidean predictors. We propose a flexible regression model capable of\nhandling high-dimensional predictors without imposing parametric assumptions.\nTwo primary challenges are addressed: the curse of dimensionality in\nnonparametric regression and the absence of linear structure in general metric\nspaces. The former is tackled using deep neural networks, while for the latter\nwe demonstrate the feasibility of mapping the metric space where responses\nreside to a low-dimensional Euclidean space using manifold learning. We\nintroduce a reverse mapping approach, employing local Fr\\'echet regression, to\nmap the low-dimensional manifold representations back to objects in the\noriginal metric space. We develop a theoretical framework, investigating the\nconvergence rate of deep neural networks under dependent sub-Gaussian noise\nwith bias. The convergence rate of the proposed regression model is then\nobtained by expanding the scope of local Fr\\'echet regression to accommodate\nmultivariate predictors in the presence of errors in predictors. Simulations\nand case studies show that the proposed model outperforms existing methods for\nnon-Euclidean responses, focusing on the special cases of probability measures\nand networks.", "arxiv_id": "http://arxiv.org/abs/2407.21407v1", "pdf_url": "http://arxiv.org/pdf/2407.21407v1", "primary_category": "stat.ME", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "SmileyNet -- Towards the Prediction of the Lottery by Reading Tea Leaves with AI", "authors": "Andreas Birk", "abstract": "We introduce SmileyNet, a novel neural network with psychic abilities. It is\ninspired by the fact that a positive mood can lead to improved cognitive\ncapabilities including classification tasks. The network is hence presented in\na first phase with smileys and an encouraging loss function is defined to bias\nit into a good mood. SmileyNet is then used to forecast the flipping of a coin\nbased on an established method of Tasseology, namely by reading tea leaves.\nTraining and testing in this second phase are done with a high-fidelity\nsimulation based on real-world pixels sampled from a professional tea-reading\ncup. SmileyNet has an amazing accuracy of 72% to correctly predict the flip of\na coin. Resnet-34, respectively YOLOv5 achieve only 49%, respectively 53%. It\nis then shown how multiple SmileyNets can be combined to win the lottery.", "arxiv_id": "http://arxiv.org/abs/2407.21385v1", "pdf_url": "http://arxiv.org/pdf/2407.21385v1", "primary_category": "cs.AI", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Dynamic Gesture Recognition in Ultra-Range Distance for Effective Human-Robot Interaction", "authors": "Eran Bamani Beeri, Eden Nissinman, Avishai Sintov", "abstract": "This paper presents a novel approach for ultra-range gesture recognition,\naddressing Human-Robot Interaction (HRI) challenges over extended distances. By\nleveraging human gestures in video data, we propose the Temporal-Spatiotemporal\nFusion Network (TSFN) model that surpasses the limitations of current methods,\nenabling robots to understand gestures from long distances. With applications\nin service robots, search and rescue operations, and drone-based interactions,\nour approach enhances HRI in expansive environments. Experimental validation\ndemonstrates significant advancements in gesture recognition accuracy,\nparticularly in prolonged gesture sequences.", "arxiv_id": "http://arxiv.org/abs/2407.21374v1", "pdf_url": "http://arxiv.org/pdf/2407.21374v1", "primary_category": "cs.RO", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Two Completely Parameter-Free Alternating Gradient Projection Algorithms for Nonconvex-(strongly) Concave Minimax Problems", "authors": "Junnan Yang, Huiling Zhang, Zi Xu", "abstract": "Due to their importance in various emerging applications, efficient\nalgorithms for solving minimax problems have recently received increasing\nattention. However, many existing algorithms require prior knowledge of the\nproblem parameters in order to achieve optimal iteration complexity. In this\npaper, we propose a completely parameter-free alternating gradient projection\n(PF-AGP) algorithm to solve the smooth nonconvex-(strongly) concave minimax\nproblems using a backtracking strategy, which does not require prior knowledge\nof parameters such as the Lipschtiz constant $L$ or the strongly concave\nconstant $\\mu$. The PF-AGP algorithm utilizes a parameter-free gradient\nprojection step to alternately update the outer and inner variables in each\niteration. We show that the total number of gradient calls of the PF-AGP\nalgorithm to obtain an $\\varepsilon$-stationary point for nonconvex-strongly\nconcave minimax problems is upper bounded by $\\mathcal{O}\\left(\nL\\kappa^3\\varepsilon^{-2} \\right)$ where $\\kappa$ is the condition number,\nwhile the total number of gradient calls to obtain an $\\varepsilon$-stationary\npoint for nonconvex-concave minimax problems is upper bounded by\n$\\mathcal{O}\\left( L^4\\varepsilon^{-4} \\right)$. As far as we know, this is the\nfirst completely parameter-free algorithm for solving nonconvex-strongly\nconcave minimax problems, and it is also the completely parameter-free\nalgorithm which achieves the best iteration complexity in single loop method\nfor solving nonconvex-concave minimax problems. Numerical results validate the\nefficiency of the proposed PF-AGP algorithm.", "arxiv_id": "http://arxiv.org/abs/2407.21372v1", "pdf_url": "http://arxiv.org/pdf/2407.21372v1", "primary_category": "math.OC", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Prompting Medical Large Vision-Language Models to Diagnose Pathologies by Visual Question Answering", "authors": "Danfeng Guo, Demetri Terzopoulos", "abstract": "Large Vision-Language Models (LVLMs) have achieved significant success in\nrecent years, and they have been extended to the medical domain. Although\ndemonstrating satisfactory performance on medical Visual Question Answering\n(VQA) tasks, Medical LVLMs (MLVLMs) suffer from the hallucination problem,\nwhich makes them fail to diagnose complex pathologies. Moreover, they readily\nfail to learn minority pathologies due to imbalanced training data. We propose\ntwo prompting strategies for MLVLMs that reduce hallucination and improve VQA\nperformance. In the first strategy, we provide a detailed explanation of the\nqueried pathology. In the second strategy, we fine-tune a cheap, weak learner\nto achieve high performance on a specific metric, and textually provide its\njudgment to the MLVLM. Tested on the MIMIC-CXR-JPG and Chexpert datasets, our\nmethods significantly improve the diagnostic F1 score, with the highest\nincrease being 0.27. We also demonstrate that our prompting strategies can be\nextended to general LVLM domains. Based on POPE metrics, it effectively\nsuppresses the false negative predictions of existing LVLMs and improves Recall\nby approximately 0.07.", "arxiv_id": "http://arxiv.org/abs/2407.21368v1", "pdf_url": "http://arxiv.org/pdf/2407.21368v1", "primary_category": "cs.CV", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "ProSpec RL: Plan Ahead, then Execute", "authors": "Liangliang Liu, Yi Guan, BoRan Wang, Rujia Shen, Yi Lin, Chaoran Kong, Lian Yan, Jingchi Jiang", "abstract": "Imagining potential outcomes of actions before execution helps agents make\nmore informed decisions, a prospective thinking ability fundamental to human\ncognition. However, mainstream model-free Reinforcement Learning (RL) methods\nlack the ability to proactively envision future scenarios, plan, and guide\nstrategies. These methods typically rely on trial and error to adjust policy\nfunctions, aiming to maximize cumulative rewards or long-term value, even if\nsuch high-reward decisions place the environment in extremely dangerous states.\nTo address this, we propose the Prospective (ProSpec) RL method, which makes\nhigher-value, lower-risk optimal decisions by imagining future n-stream\ntrajectories. Specifically, ProSpec employs a dynamic model to predict future\nstates (termed \"imagined states\") based on the current state and a series of\nsampled actions. Furthermore, we integrate the concept of Model Predictive\nControl and introduce a cycle consistency constraint that allows the agent to\nevaluate and select the optimal actions from these trajectories. Moreover,\nProSpec employs cycle consistency to mitigate two fundamental issues in RL:\naugmenting state reversibility to avoid irreversible events (low risk) and\naugmenting actions to generate numerous virtual trajectories, thereby improving\ndata efficiency. We validated the effectiveness of our method on the DMControl\nbenchmarks, where our approach achieved significant performance improvements.\nCode will be open-sourced upon acceptance.", "arxiv_id": "http://arxiv.org/abs/2407.21359v1", "pdf_url": "http://arxiv.org/pdf/2407.21359v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Differentially Private Block-wise Gradient Shuffle for Deep Learning", "authors": "David Zagardo", "abstract": "Traditional Differentially Private Stochastic Gradient Descent (DP-SGD)\nintroduces statistical noise on top of gradients drawn from a Gaussian\ndistribution to ensure privacy. This paper introduces the novel Differentially\nPrivate Block-wise Gradient Shuffle (DP-BloGS) algorithm for deep learning.\nBloGS builds off of existing private deep learning literature, but makes a\ndefinitive shift by taking a probabilistic approach to gradient noise\nintroduction through shuffling modeled after information theoretic privacy\nanalyses. The theoretical results presented in this paper show that the\ncombination of shuffling, parameter-specific block size selection, batch layer\nclipping, and gradient accumulation allows DP-BloGS to achieve training times\nclose to that of non-private training while maintaining similar privacy and\nutility guarantees to DP-SGD. DP-BloGS is found to be significantly more\nresistant to data extraction attempts than DP-SGD. The theoretical results are\nvalidated by the experimental findings.", "arxiv_id": "http://arxiv.org/abs/2407.21347v1", "pdf_url": "http://arxiv.org/pdf/2407.21347v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "MIST: A Simple and Scalable End-To-End 3D Medical Imaging Segmentation Framework", "authors": "Adrian Celaya, Evan Lim, Rachel Glenn, Brayden Mi, Alex Balsells, Tucker Netherton, Caroline Chung, Beatrice Riviere, David Fuentes", "abstract": "Medical imaging segmentation is a highly active area of research, with deep\nlearning-based methods achieving state-of-the-art results in several\nbenchmarks. However, the lack of standardized tools for training, testing, and\nevaluating new methods makes the comparison of methods difficult. To address\nthis, we introduce the Medical Imaging Segmentation Toolkit (MIST), a simple,\nmodular, and end-to-end medical imaging segmentation framework designed to\nfacilitate consistent training, testing, and evaluation of deep learning-based\nmedical imaging segmentation methods. MIST standardizes data analysis,\npreprocessing, and evaluation pipelines, accommodating multiple architectures\nand loss functions. This standardization ensures reproducible and fair\ncomparisons across different methods. We detail MIST's data format\nrequirements, pipelines, and auxiliary features and demonstrate its efficacy\nusing the BraTS Adult Glioma Post-Treatment Challenge dataset. Our results\nhighlight MIST's ability to produce accurate segmentation masks and its\nscalability across multiple GPUs, showcasing its potential as a powerful tool\nfor future medical imaging research and development.", "arxiv_id": "http://arxiv.org/abs/2407.21343v1", "pdf_url": "http://arxiv.org/pdf/2407.21343v1", "primary_category": "eess.IV", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Image-Based Deep Reinforcement Learning with Intrinsically Motivated Stimuli: On the Execution of Complex Robotic Tasks", "authors": "David Valencia, Henry Williams, Yuning Xing, Trevor Gee, Minas Liarokapis, Bruce A. MacDonald", "abstract": "Reinforcement Learning (RL) has been widely used to solve tasks where the\nenvironment consistently provides a dense reward value. However, in real-world\nscenarios, rewards can often be poorly defined or sparse. Auxiliary signals are\nindispensable for discovering efficient exploration strategies and aiding the\nlearning process. In this work, inspired by intrinsic motivation theory, we\npostulate that the intrinsic stimuli of novelty and surprise can assist in\nimproving exploration in complex, sparsely rewarded environments. We introduce\na novel sample-efficient method able to learn directly from pixels, an\nimage-based extension of TD3 with an autoencoder called \\textit{NaSA-TD3}. The\nexperiments demonstrate that NaSA-TD3 is easy to train and an efficient method\nfor tackling complex continuous-control robotic tasks, both in simulated\nenvironments and real-world settings. NaSA-TD3 outperforms existing\nstate-of-the-art RL image-based methods in terms of final performance without\nrequiring pre-trained models or human demonstrations.", "arxiv_id": "http://arxiv.org/abs/2407.21338v1", "pdf_url": "http://arxiv.org/pdf/2407.21338v1", "primary_category": "cs.AI", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Big Cooperative Learning", "authors": "Yulai Cong", "abstract": "Cooperation plays a pivotal role in the evolution of human intelligence;\nmoreover, it also underlies the recent revolutionary advancement of artificial\nintelligence (AI) that is driven by foundation models. Specifically, we reveal\nthat the training of foundation models can be interpreted as a form of big\ncooperative learning (\\textit{abbr.} big learning), where massive learning\nindividuals/tasks \\emph{cooperate} to approach the unique essence of data from\ndiverse perspectives of data prediction, leveraging a universal model. The\npresented big learning therefore unifies most training objectives of foundation\nmodels within a consistent framework, where their underlying assumptions are\nexposed simultaneously. We design tailored simulations to demonstrate the\nprinciple of big learning, based on which we provide learning-perspective\njustifications for the successes of foundation models, with interesting\nside-products. Furthermore, we reveal that big learning is a new dimension for\nupgrading conventional machine learning paradigms, valuable for endowing\nreinvigorations to associated applications; as an illustrative example, we\npropose the BigLearn-GAN, which is a novel adversarially-trained foundation\nmodel with versatile data sampling capabilities. Code is available at\n\\texttt{https://github.com/YulaiCong/BigCooperativeLearning}.", "arxiv_id": "http://arxiv.org/abs/2407.21319v1", "pdf_url": "http://arxiv.org/pdf/2407.21319v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "RELEVANT"}
{"title": "Diff-Cleanse: Identifying and Mitigating Backdoor Attacks in Diffusion Models", "authors": "Jiang Hao, Xiao Jin, Hu Xiaoguang, Chen Tianyou", "abstract": "Diffusion models (DM) represent one of the most advanced generative models\ntoday, yet recent studies suggest that DMs are vulnerable to backdoor attacks.\nBackdoor attacks establish hidden associations between particular input\npatterns and model behaviors, compromising model integrity by triggering\nundesirable actions with manipulated input data. This vulnerability poses\nsubstantial risks, including reputational damage to model owners and the\ndissemination of harmful content. To mitigate the threat of backdoor attacks,\nthere have been some investigations on backdoor detection and model repair.\nHowever, previous work fails to purify the backdoored DMs created by\nstate-of-the-art attacks, rendering the field much underexplored. To bridge\nthis gap, we introduce \\textbf{Diff-Cleanse}, a novel two-stage backdoor\ndefense framework specifically designed for DMs. The first stage employs a\ninnovative trigger inversion technique to detect the backdoor and reconstruct\nthe trigger, and the second stage utilizes a structural pruning method to\neliminate the backdoor. We evaluate our framework on hundreds of DMs attacked\nby 3 existing backdoor attack methods. Extensive experiments demonstrate that\nDiff-Cleanse achieves nearly 100\\% detection accuracy and effectively mitigates\nbackdoor impacts, preserving the model's benign performance with minimal\ncompromise. Our code is avaliable at https://github.com/shymuel/diff-cleanse.", "arxiv_id": "http://arxiv.org/abs/2407.21316v1", "pdf_url": "http://arxiv.org/pdf/2407.21316v1", "primary_category": "cs.CR", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "State-observation augmented diffusion model for nonlinear assimilation", "authors": "Zhuoyuan Li, Bin Dong, Pingwen Zhang", "abstract": "Data assimilation has become a crucial technique aiming to combine physical\nmodels with observational data to estimate state variables. Traditional\nassimilation algorithms often face challenges of high nonlinearity brought by\nboth the physical and observational models. In this work, we propose a novel\ndata-driven assimilation algorithm based on generative models to address such\nconcerns. Our State-Observation Augmented Diffusion (SOAD) model is designed to\nhandle nonlinear physical and observational models more effectively. The\nmarginal posterior associated with SOAD has been derived and then proved to\nmatch the real posterior under mild assumptions, which shows theoretical\nsuperiority over previous score-based assimilation works. Experimental results\nalso indicate that our SOAD model may offer improved accuracy over existing\ndata-driven methods.", "arxiv_id": "http://arxiv.org/abs/2407.21314v1", "pdf_url": "http://arxiv.org/pdf/2407.21314v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "EUDA: An Efficient Unsupervised Domain Adaptation via Self-Supervised Vision Transformer", "authors": "Ali Abedi, Q. M. Jonathan Wu, Ning Zhang, Farhad Pourpanah", "abstract": "Unsupervised domain adaptation (UDA) aims to mitigate the domain shift issue,\nwhere the distribution of training (source) data differs from that of testing\n(target) data. Many models have been developed to tackle this problem, and\nrecently vision transformers (ViTs) have shown promising results. However, the\ncomplexity and large number of trainable parameters of ViTs restrict their\ndeployment in practical applications. This underscores the need for an\nefficient model that not only reduces trainable parameters but also allows for\nadjustable complexity based on specific needs while delivering comparable\nperformance. To achieve this, in this paper we introduce an Efficient\nUnsupervised Domain Adaptation (EUDA) framework. EUDA employs the DINOv2, which\nis a self-supervised ViT, as a feature extractor followed by a simplified\nbottleneck of fully connected layers to refine features for enhanced domain\nadaptation. Additionally, EUDA employs the synergistic domain alignment loss\n(SDAL), which integrates cross-entropy (CE) and maximum mean discrepancy (MMD)\nlosses, to balance adaptation by minimizing classification errors in the source\ndomain while aligning the source and target domain distributions. The\nexperimental results indicate the effectiveness of EUDA in producing comparable\nresults as compared with other state-of-the-art methods in domain adaptation\nwith significantly fewer trainable parameters, between 42% to 99.7% fewer. This\nshowcases the ability to train the model in a resource-limited environment. The\ncode of the model is available at: https://github.com/A-Abedi/EUDA.", "arxiv_id": "http://arxiv.org/abs/2407.21311v1", "pdf_url": "http://arxiv.org/pdf/2407.21311v1", "primary_category": "cs.CV", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "MSMA: Multi-agent Trajectory Prediction in Connected and Autonomous Vehicle Environment with Multi-source Data Integration", "authors": "Xi Chen, Rahul Bhadani, Zhanbo Sun, Larry Head", "abstract": "The prediction of surrounding vehicle trajectories is crucial for\ncollision-free path planning. In this study, we focus on a scenario where a\nconnected and autonomous vehicle (CAV) serves as the central agent, utilizing\nboth sensors and communication technologies to perceive its surrounding\ntraffics consisting of autonomous vehicles (AVs), connected vehicles (CVs), and\nhuman-driven vehicles (HDVs). Our trajectory prediction task is aimed at all\nthe detected surrounding vehicles. To effectively integrate the multi-source\ndata from both sensor and communication technologies, we propose a deep\nlearning framework called MSMA utilizing a cross-attention module for\nmulti-source data fusion. Vector map data is utilized to provide contextual\ninformation. The trajectory dataset is collected in CARLA simulator with\nsynthesized data errors introduced. Numerical experiments demonstrate that in a\nmixed traffic flow scenario, the integration of data from different sources\nenhances our understanding of the environment. This notably improves trajectory\nprediction accuracy, particularly in situations with a high CV market\npenetration rate. The code is available at: https://github.com/xichennn/MSMA.", "arxiv_id": "http://arxiv.org/abs/2407.21310v1", "pdf_url": "http://arxiv.org/pdf/2407.21310v1", "primary_category": "cs.RO", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Who should I trust? A Visual Analytics Approach for Comparing Net Load Forecasting Models", "authors": "Kaustav Bhattacharjee, Soumya Kundu, Indrasis Chakraborty, Aritra Dasgupta", "abstract": "Net load forecasting is crucial for energy planning and facilitating informed\ndecision-making regarding trade and load distributions. However, evaluating\nforecasting models' performance against benchmark models remains challenging,\nthereby impeding experts' trust in the model's performance. In this context,\nthere is a demand for technological interventions that allow scientists to\ncompare models across various timeframes and solar penetration levels. This\npaper introduces a visual analytics-based application designed to compare the\nperformance of deep-learning-based net load forecasting models with other\nmodels for probabilistic net load forecasting. This application employs\ncarefully selected visual analytic interventions, enabling users to discern\ndifferences in model performance across different solar penetration levels,\ndataset resolutions, and hours of the day over multiple months. We also present\nobservations made using our application through a case study, demonstrating the\neffectiveness of visualizations in aiding scientists in making informed\ndecisions and enhancing trust in net load forecasting models.", "arxiv_id": "http://arxiv.org/abs/2407.21299v1", "pdf_url": "http://arxiv.org/pdf/2407.21299v1", "primary_category": "cs.HC", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "A Vectorization Method Induced By Maximal Margin Classification For Persistent Diagrams", "authors": "An Wu, Yu Pan, Fuqi Zhou, Jinghui Yan, Chuanlu Liu", "abstract": "Persistent homology is an effective method for extracting topological\ninformation, represented as persistent diagrams, of spatial structure data.\nHence it is well-suited for the study of protein structures. Attempts to\nincorporate Persistent homology in machine learning methods of protein function\nprediction have resulted in several techniques for vectorizing persistent\ndiagrams. However, current vectorization methods are excessively artificial and\ncannot ensure the effective utilization of information or the rationality of\nthe methods. To address this problem, we propose a more geometrical\nvectorization method of persistent diagrams based on maximal margin\nclassification for Banach space, and additionaly propose a framework that\nutilizes topological data analysis to identify proteins with specific\nfunctions. We evaluated our vectorization method using a binary classification\ntask on proteins and compared it with the statistical methods that exhibit the\nbest performance among thirteen commonly used vectorization methods. The\nexperimental results indicate that our approach surpasses the statistical\nmethods in both robustness and precision.", "arxiv_id": "http://arxiv.org/abs/2407.21298v1", "pdf_url": "http://arxiv.org/pdf/2407.21298v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Decentralized and Uncoordinated Learning of Stable Matchings: A Game-Theoretic Approach", "authors": "S. Rasoul Etesami, R. Srikant", "abstract": "We consider the problem of learning stable matchings in a fully decentralized\nand uncoordinated manner. In this problem, there are $n$ men and $n$ women,\neach having preference over the other side. It is assumed that women know their\npreferences over men, but men are not aware of their preferences over women,\nand they only learn them if they propose and successfully get matched to women.\nA matching is called stable if no man and woman prefer each other over their\ncurrent matches. When all the preferences are known a priori, the celebrated\nDeferred-Acceptance algorithm proposed by Gale and Shapley provides a\ndecentralized and uncoordinated algorithm to obtain a stable matching. However,\nwhen the preferences are unknown, developing such an algorithm faces major\nchallenges due to a lack of coordination. We achieve this goal by making a\nconnection between stable matchings and learning Nash equilibria (NE) in\nnoncooperative games. First, we provide a complete information game formulation\nfor the stable matching problem with known preferences such that its set of\npure NE coincides with the set of stable matchings, while its mixed NE can be\nrounded in a decentralized manner to a stable matching. Relying on such a\ngame-theoretic formulation, we show that for hierarchical markets, adopting the\nexponential weight (EXP) learning algorithm for the stable matching game\nachieves logarithmic regret with polynomial dependence on the number of\nplayers, thus answering a question posed in previous literature. Moreover, we\nshow that the same EXP learning algorithm converges locally and exponentially\nfast to a stable matching in general matching markets. We complement this\nresult by introducing another decentralized and uncoordinated learning\nalgorithm that globally converges to a stable matching with arbitrarily high\nprobability, leveraging the weak acyclicity property of the stable matching\ngame.", "arxiv_id": "http://arxiv.org/abs/2407.21294v1", "pdf_url": "http://arxiv.org/pdf/2407.21294v1", "primary_category": "cs.GT", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "TrackSorter: A Transformer-based sorting algorithm for track finding in High Energy Physics", "authors": "Yash Melkani, Xiangyang Ju", "abstract": "Track finding in particle data is a challenging pattern recognition problem\nin High Energy Physics. It takes as inputs a point cloud of space points and\nlabels them so that space points created by the same particle have the same\nlabel. The list of space points with the same label is a track candidate. We\nargue that this pattern recognition problem can be formulated as a sorting\nproblem, of which the inputs are a list of space points sorted by their\ndistances away from the collision points and the outputs are the space points\nsorted by their labels. In this paper, we propose the TrackSorter algorithm: a\nTransformer-based algorithm for pattern recognition in particle data.\nTrackSorter uses a simple tokenization scheme to convert space points into\ndiscrete tokens. It then uses the tokenized space points as inputs and sorts\nthe input tokens into track candidates. TrackSorter is a novel end-to-end track\nfinding algorithm that leverages Transformer-based models to solve pattern\nrecognition problems. It is evaluated on the TrackML dataset and has good track\nfinding performance.", "arxiv_id": "http://arxiv.org/abs/2407.21290v1", "pdf_url": "http://arxiv.org/pdf/2407.21290v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Robust Box Prompt based SAM for Medical Image Segmentation", "authors": "Yuhao Huang, Xin Yang, Han Zhou, Yan Cao, Haoran Dou, Fajin Dong, Dong Ni", "abstract": "The Segment Anything Model (SAM) can achieve satisfactory segmentation\nperformance under high-quality box prompts. However, SAM's robustness is\ncompromised by the decline in box quality, limiting its practicality in\nclinical reality. In this study, we propose a novel Robust Box prompt based SAM\n(\\textbf{RoBox-SAM}) to ensure SAM's segmentation performance under prompts\nwith different qualities. Our contribution is three-fold. First, we propose a\nprompt refinement module to implicitly perceive the potential targets, and\noutput the offsets to directly transform the low-quality box prompt into a\nhigh-quality one. We then provide an online iterative strategy for further\nprompt refinement. Second, we introduce a prompt enhancement module to\nautomatically generate point prompts to assist the box-promptable segmentation\neffectively. Last, we build a self-information extractor to encode the prior\ninformation from the input image. These features can optimize the image\nembeddings and attention calculation, thus, the robustness of SAM can be\nfurther enhanced. Extensive experiments on the large medical segmentation\ndataset including 99,299 images, 5 modalities, and 25 organs/targets validated\nthe efficacy of our proposed RoBox-SAM.", "arxiv_id": "http://arxiv.org/abs/2407.21284v1", "pdf_url": "http://arxiv.org/pdf/2407.21284v1", "primary_category": "cs.CV", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "FedBChain: A Blockchain-enabled Federated Learning Framework for Improving DeepConvLSTM with Comparative Strategy Insights", "authors": "Gaoxuan Li, Chern Hong Lim, Qiyao Ma, Xinyu Tang, Hwa Hui Tew", "abstract": "Recent research in the field of Human Activity Recognition has shown that an\nimprovement in prediction performance can be achieved by reducing the number of\nLSTM layers. However, this kind of enhancement is only significant on\nmonolithic architectures, and when it runs on large-scale distributed training,\ndata security and privacy issues will be reconsidered, and its prediction\nperformance is unknown. In this paper, we introduce a novel framework:\nFedBChain, which integrates the federated learning paradigm based on a modified\nDeepConvLSTM architecture with a single LSTM layer. This framework performs\ncomparative tests of prediction performance on three different real-world\ndatasets based on three different hidden layer units (128, 256, and 512)\ncombined with five different federated learning strategies, respectively. The\nresults show that our architecture has significant improvements in Precision,\nRecall and F1-score compared to the centralized training approach on all\ndatasets with all hidden layer units for all strategies: FedAvg strategy\nimproves on average by 4.54%, FedProx improves on average by 4.57%,\nFedTrimmedAvg improves on average by 4.35%, Krum improves by 4.18% on average,\nand FedAvgM improves by 4.46% on average. Based on our results, it can be seen\nthat FedBChain not only improves in performance, but also guarantees the\nsecurity and privacy of user data compared to centralized training methods\nduring the training process. The code for our experiments is publicly available\n(https://github.com/Glen909/FedBChain).", "arxiv_id": "http://arxiv.org/abs/2407.21282v1", "pdf_url": "http://arxiv.org/pdf/2407.21282v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Enhanced Uncertainty Estimation in Ultrasound Image Segmentation with MSU-Net", "authors": "Rohini Banerjee, Cecilia G. Morales, Artur Dubrawski", "abstract": "Efficient intravascular access in trauma and critical care significantly\nimpacts patient outcomes. However, the availability of skilled medical\npersonnel in austere environments is often limited. Autonomous robotic\nultrasound systems can aid in needle insertion for medication delivery and\nsupport non-experts in such tasks. Despite advances in autonomous needle\ninsertion, inaccuracies in vessel segmentation predictions pose risks.\nUnderstanding the uncertainty of predictive models in ultrasound imaging is\ncrucial for assessing their reliability. We introduce MSU-Net, a novel\nmultistage approach for training an ensemble of U-Nets to yield accurate\nultrasound image segmentation maps. We demonstrate substantial improvements,\n18.1% over a single Monte Carlo U-Net, enhancing uncertainty evaluations, model\ntransparency, and trustworthiness. By highlighting areas of model certainty,\nMSU-Net can guide safe needle insertions, empowering non-experts to accomplish\nsuch tasks.", "arxiv_id": "http://arxiv.org/abs/2407.21273v1", "pdf_url": "http://arxiv.org/pdf/2407.21273v1", "primary_category": "cs.CV", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "DDU-Net: A Domain Decomposition-based CNN for High-Resolution Image Segmentation on Multiple GPUs", "authors": "Corn\u00e9 Verburg, Alexander Heinlein, Eric C. Cyr", "abstract": "The segmentation of ultra-high resolution images poses challenges such as\nloss of spatial information or computational inefficiency. In this work, a\nnovel approach that combines encoder-decoder architectures with domain\ndecomposition strategies to address these challenges is proposed. Specifically,\na domain decomposition-based U-Net (DDU-Net) architecture is introduced, which\npartitions input images into non-overlapping patches that can be processed\nindependently on separate devices. A communication network is added to\nfacilitate inter-patch information exchange to enhance the understanding of\nspatial context. Experimental validation is performed on a synthetic dataset\nthat is designed to measure the effectiveness of the communication network.\nThen, the performance is tested on the DeepGlobe land cover classification\ndataset as a real-world benchmark data set. The results demonstrate that the\napproach, which includes inter-patch communication for images divided into\n$16\\times16$ non-overlapping subimages, achieves a $2-3\\,\\%$ higher\nintersection over union (IoU) score compared to the same network without\ninter-patch communication. The performance of the network which includes\ncommunication is equivalent to that of a baseline U-Net trained on the full\nimage, showing that our model provides an effective solution for segmenting\nultra-high-resolution images while preserving spatial context. The code is\navailable at https://github.com/corne00/HiRes-Seg-CNN.", "arxiv_id": "http://arxiv.org/abs/2407.21266v2", "pdf_url": "http://arxiv.org/pdf/2407.21266v2", "primary_category": "cs.CV", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Tractable and Provably Efficient Distributional Reinforcement Learning with General Value Function Approximation", "authors": "Taehyun Cho, Seungyub Han, Kyungjae Lee, Seokhun Ju, Dohyeong Kim, Jungwoo Lee", "abstract": "Distributional reinforcement learning improves performance by effectively\ncapturing environmental stochasticity, but a comprehensive theoretical\nunderstanding of its effectiveness remains elusive. In this paper, we present a\nregret analysis for distributional reinforcement learning with general value\nfunction approximation in a finite episodic Markov decision process setting. We\nfirst introduce a key notion of Bellman unbiasedness for a tractable and\nexactly learnable update via statistical functional dynamic programming. Our\ntheoretical results show that approximating the infinite-dimensional return\ndistribution with a finite number of moment functionals is the only method to\nlearn the statistical information unbiasedly, including nonlinear statistical\nfunctionals. Second, we propose a provably efficient algorithm,\n$\\texttt{SF-LSVI}$, achieving a regret bound of $\\tilde{O}(d_E\nH^{\\frac{3}{2}}\\sqrt{K})$ where $H$ is the horizon, $K$ is the number of\nepisodes, and $d_E$ is the eluder dimension of a function class.", "arxiv_id": "http://arxiv.org/abs/2407.21260v1", "pdf_url": "http://arxiv.org/pdf/2407.21260v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Adaptive Pre-training Data Detection for Large Language Models via Surprising Tokens", "authors": "Anqi Zhang, Chaofeng Wu", "abstract": "While large language models (LLMs) are extensively used, there are raising\nconcerns regarding privacy, security, and copyright due to their opaque\ntraining data, which brings the problem of detecting pre-training data on the\ntable. Current solutions to this problem leverage techniques explored in\nmachine learning privacy such as Membership Inference Attacks (MIAs), which\nheavily depend on LLMs' capability of verbatim memorization. However, this\nreliance presents challenges, especially given the vast amount of training data\nand the restricted number of effective training epochs. In this paper, we\npropose an adaptive pre-training data detection method which alleviates this\nreliance and effectively amplify the identification. Our method adaptively\nlocates \\textit{surprising tokens} of the input. A token is surprising to a LLM\nif the prediction on the token is \"certain but wrong\", which refers to low\nShannon entropy of the probability distribution and low probability of the\nground truth token at the same time. By using the prediction probability of\nsurprising tokens to measure \\textit{surprising}, the detection method is\nachieved based on the simple hypothesis that seeing seen data is less\nsurprising for the model compared with seeing unseen data. The method can be\napplied without any access to the the pre-training data corpus or additional\ntraining like reference models. Our approach exhibits a consistent enhancement\ncompared to existing methods in diverse experiments conducted on various\nbenchmarks and models, achieving a maximum improvement of 29.5\\%. We also\nintroduce a new benchmark Dolma-Book developed upon a novel framework, which\nemploys book data collected both before and after model training to provide\nfurther evaluation.", "arxiv_id": "http://arxiv.org/abs/2407.21248v1", "pdf_url": "http://arxiv.org/pdf/2407.21248v1", "primary_category": "cs.CL", "preferences": "I'm intersted in LLMs", "response": "RELEVANT"}
{"title": "Informed Correctors for Discrete Diffusion Models", "authors": "Yixiu Zhao, Jiaxin Shi, Lester Mackey, Scott Linderman", "abstract": "Discrete diffusion modeling is a promising framework for modeling and\ngenerating data in discrete spaces. To sample from these models, different\nstrategies present trade-offs between computation and sample quality. A\npredominant sampling strategy is predictor-corrector $\\tau$-leaping, which\nsimulates the continuous time generative process with discretized predictor\nsteps and counteracts the accumulation of discretization error via corrector\nsteps. However, for absorbing state diffusion, an important class of discrete\ndiffusion models, the standard forward-backward corrector can be ineffective in\nfixing such errors, resulting in subpar sample quality. To remedy this problem,\nwe propose a family of informed correctors that more reliably counteracts\ndiscretization error by leveraging information learned by the model. For\nfurther efficiency gains, we also propose $k$-Gillespie's, a sampling algorithm\nthat better utilizes each model evaluation, while still enjoying the speed and\nflexibility of $\\tau$-leaping. Across several real and synthetic datasets, we\nshow that $k$-Gillespie's with informed correctors reliably produces higher\nquality samples at lower computational cost.", "arxiv_id": "http://arxiv.org/abs/2407.21243v1", "pdf_url": "http://arxiv.org/pdf/2407.21243v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "GNUMAP: A Parameter-Free Approach to Unsupervised Dimensionality Reduction via Graph Neural Networks", "authors": "Jihee You, So Won Jeong, Claire Donnat", "abstract": "With the proliferation of Graph Neural Network (GNN) methods stemming from\ncontrastive learning, unsupervised node representation learning for graph data\nis rapidly gaining traction across various fields, from biology to molecular\ndynamics, where it is often used as a dimensionality reduction tool. However,\nthere remains a significant gap in understanding the quality of the\nlow-dimensional node representations these methods produce, particularly beyond\nwell-curated academic datasets. To address this gap, we propose here the first\ncomprehensive benchmarking of various unsupervised node embedding techniques\ntailored for dimensionality reduction, encompassing a range of manifold\nlearning tasks, along with various performance metrics. We emphasize the\nsensitivity of current methods to hyperparameter choices -- highlighting a\nfundamental issue as to their applicability in real-world settings where there\nis no established methodology for rigorous hyperparameter selection. Addressing\nthis issue, we introduce GNUMAP, a robust and parameter-free method for\nunsupervised node representation learning that merges the traditional UMAP\napproach with the expressivity of the GNN framework. We show that GNUMAP\nconsistently outperforms existing state-of-the-art GNN embedding methods in a\nvariety of contexts, including synthetic geometric datasets, citation networks,\nand real-world biomedical data -- making it a simple but reliable\ndimensionality reduction tool.", "arxiv_id": "http://arxiv.org/abs/2407.21236v1", "pdf_url": "http://arxiv.org/pdf/2407.21236v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Towards an Integrated Performance Framework for Fire Science and Management Workflows", "authors": "H. Ahmed, R. Shende, I. Perez, D. Crawl, S. Purawat, I. Altintas", "abstract": "Reliable performance metrics are necessary prerequisites to building\nlarge-scale end-to-end integrated workflows for collaborative scientific\nresearch, particularly within context of use-inspired decision making platforms\nwith many concurrent users and when computing real-time and urgent results\nusing large data. This work is a building block for the National Data Platform,\nwhich leverages multiple use-cases including the WIFIRE Data and Model Commons\nfor wildfire behavior modeling and the EarthScope Consortium for collaborative\ngeophysical research. This paper presents an artificial intelligence and\nmachine learning (AI/ML) approach to performance assessment and optimization of\nscientific workflows. An associated early AI/ML framework spanning performance\ndata collection, prediction and optimization is applied to wildfire science\napplications within the WIFIRE BurnPro3D (BP3D) platform for proactive fire\nmanagement and mitigation.", "arxiv_id": "http://arxiv.org/abs/2407.21231v1", "pdf_url": "http://arxiv.org/pdf/2407.21231v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "DeepBaR: Fault Backdoor Attack on Deep Neural Network Layers", "authors": "C. A. Mart\u00ednez-Mej\u00eda, J. Solano, J. Breier, D. Bucko, X. Hou", "abstract": "Machine Learning using neural networks has received prominent attention\nrecently because of its success in solving a wide variety of computational\ntasks, in particular in the field of computer vision. However, several works\nhave drawn attention to potential security risks involved with the training and\nimplementation of such networks. In this work, we introduce DeepBaR, a novel\napproach that implants backdoors on neural networks by faulting their behavior\nat training, especially during fine-tuning. Our technique aims to generate\nadversarial samples by optimizing a custom loss function that mimics the\nimplanted backdoors while adding an almost non-visible trigger in the image. We\nattack three popular convolutional neural network architectures and show that\nDeepBaR attacks have a success rate of up to 98.30\\%. Furthermore, DeepBaR does\nnot significantly affect the accuracy of the attacked networks after deployment\nwhen non-malicious inputs are given. Remarkably, DeepBaR allows attackers to\nchoose an input that looks similar to a given class, from a human perspective,\nbut that will be classified as belonging to an arbitrary target class.", "arxiv_id": "http://arxiv.org/abs/2407.21220v1", "pdf_url": "http://arxiv.org/pdf/2407.21220v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "NeuroSEM: A hybrid framework for simulating multiphysics problems by coupling PINNs and spectral elements", "authors": "Khemraj Shukla, Zongren Zou, Chi Hin Chan, Additi Pandey, Zhicheng Wang, George Em Karniadakis", "abstract": "Multiphysics problems that are characterized by complex interactions among\nfluid dynamics, heat transfer, structural mechanics, and electromagnetics, are\ninherently challenging due to their coupled nature. While experimental data on\ncertain state variables may be available, integrating these data with numerical\nsolvers remains a significant challenge. Physics-informed neural networks\n(PINNs) have shown promising results in various engineering disciplines,\nparticularly in handling noisy data and solving inverse problems. However,\ntheir effectiveness in forecasting nonlinear phenomena in multiphysics regimes\nis yet to be fully established. This study introduces NeuroSEM, a hybrid\nframework integrating PINNs with the high-fidelity Spectral Element Method\n(SEM) solver, Nektar++. NeuroSEM leverages strengths of both PINNs and SEM,\nproviding robust solutions for multiphysics problems. PINNs are trained to\nassimilate data and model physical phenomena in specific subdomains, which are\nthen integrated into Nektar++. We demonstrate the efficiency and accuracy of\nNeuroSEM for thermal convection in cavity flow and flow past a cylinder. The\nframework effectively handles data assimilation by addressing those subdomains\nand state variables where data are available. We applied NeuroSEM to the\nRayleigh-B\\'enard convection system, including cases with missing thermal\nboundary conditions. Our results indicate that NeuroSEM accurately models the\nphysical phenomena and assimilates the data within the specified subdomains.\nThe framework's plug-and-play nature facilitates its extension to other\nmultiphysics or multiscale problems. Furthermore, NeuroSEM is optimized for an\nefficient execution on emerging integrated GPU-CPU architectures. This hybrid\napproach enhances the accuracy and efficiency of simulations, making it a\npowerful tool for tackling complex engineering challenges in various scientific\ndomains.", "arxiv_id": "http://arxiv.org/abs/2407.21217v1", "pdf_url": "http://arxiv.org/pdf/2407.21217v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Diffusion-Based Generation of Neural Activity from Disentangled Latent Codes", "authors": "Jonathan D. McCart, Andrew R. Sedler, Christopher Versteeg, Domenick Mifsud, Mattia Rigotti-Thompson, Chethan Pandarinath", "abstract": "Recent advances in recording technology have allowed neuroscientists to\nmonitor activity from thousands of neurons simultaneously. Latent variable\nmodels are increasingly valuable for distilling these recordings into compact\nand interpretable representations. Here we propose a new approach to neural\ndata analysis that leverages advances in conditional generative modeling to\nenable the unsupervised inference of disentangled behavioral variables from\nrecorded neural activity. Our approach builds on InfoDiffusion, which augments\ndiffusion models with a set of latent variables that capture important factors\nof variation in the data. We apply our model, called Generating Neural\nObservations Conditioned on Codes with High Information (GNOCCHI), to time\nseries neural data and test its application to synthetic and biological\nrecordings of neural activity during reaching. In comparison to a VAE-based\nsequential autoencoder, GNOCCHI learns higher-quality latent spaces that are\nmore clearly structured and more disentangled with respect to key behavioral\nvariables. These properties enable accurate generation of novel samples (unseen\nbehavioral conditions) through simple linear traversal of the latent spaces\nproduced by GNOCCHI. Our work demonstrates the potential of unsupervised,\ninformation-based models for the discovery of interpretable latent spaces from\nneural data, enabling researchers to generate high-quality samples from unseen\nconditions.", "arxiv_id": "http://arxiv.org/abs/2407.21195v1", "pdf_url": "http://arxiv.org/pdf/2407.21195v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Analyzing Customer-Facing Vendor Experiences with Time Series Forecasting and Monte Carlo Techniques", "authors": "Vivek Kaushik, Jason Tang", "abstract": "eBay partners with external vendors, which allows customers to freely select\na vendor to complete their eBay experiences. However, vendor outages can hinder\ncustomer experiences. Consequently, eBay can disable a problematic vendor to\nprevent customer loss. Disabling the vendor too late risks losing customers\nwilling to switch to other vendors, while disabling it too early risks losing\nthose unwilling to switch. In this paper, we propose a data-driven solution to\nanswer whether eBay should disable a problematic vendor and when to disable it.\nOur solution involves forecasting customer behavior. First, we use a\nmultiplicative seasonality model to represent behavior if all vendors are fully\nfunctioning. Next, we use a Monte Carlo simulation to represent behavior if the\nproblematic vendor remains enabled. Finally, we use a linear model to represent\nbehavior if the vendor is disabled. By comparing these forecasts, we determine\nthe optimal time for eBay to disable the problematic vendor.", "arxiv_id": "http://arxiv.org/abs/2407.21193v1", "pdf_url": "http://arxiv.org/pdf/2407.21193v1", "primary_category": "stat.ML", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "GenRec: Generative Personalized Sequential Recommendation", "authors": "Panfeng Cao, Pietro Lio", "abstract": "Sequential recommendation is a task to capture hidden user preferences from\nhistorical user item interaction data. Significant progress has been made in\nthis domain by leveraging classification based learning methods. Inspired by\nthe recent paradigm of 'pretrain, prompt and predict' in NLP, we consider\nsequential recommendation as a sequence to sequence generation task and propose\na novel model named Generative Recommendation (GenRec). Unlike classification\nbased models that learn explicit user and item representations, GenRec utilizes\nthe sequence modeling capability of Transformer and adopts the masked item\nprediction objective to effectively learn the hidden bidirectional sequential\npatterns. Different from existing generative sequential recommendation models,\nGenRec does not rely on manually designed hard prompts. The input to GenRec is\ntextual user item sequence and the output is top ranked next items. Moreover,\nGenRec is lightweight and requires only a few hours to train effectively in\nlow-resource settings, making it highly applicable to real-world scenarios and\nhelping to democratize large language models in the sequential recommendation\ndomain. Our extensive experiments have demonstrated that GenRec generalizes on\nvarious public real-world datasets and achieves state-of-the-art results. Our\nexperiments also validate the effectiveness of the the proposed masked item\nprediction objective that improves the model performance by a large margin.", "arxiv_id": "http://arxiv.org/abs/2407.21191v1", "pdf_url": "http://arxiv.org/pdf/2407.21191v1", "primary_category": "cs.IR", "preferences": "I'm intersted in LLMs", "response": "RELEVANT"}
{"title": "Multi-task Photonic Reservoir Computing: Wavelength Division Multiplexing for Parallel Computing with a Silicon Microring Resonator", "authors": "Bernard J. Giron Castro, Christophe Peucheret, Darko Zibar, Francesco Da Ros", "abstract": "Nowadays, as the ever-increasing demand for more powerful computing resources\ncontinues, alternative advanced computing paradigms are under extensive\ninvestigation. Significant effort has been made to deviate from conventional\nVon Neumann architectures. In-memory computing has emerged in the field of\nelectronics as a possible solution to the infamous bottleneck between memory\nand computing processors, which reduces the effective throughput of data. In\nphotonics, novel schemes attempt to collocate the computing processor and\nmemory in a single device. Photonics offers the flexibility of multiplexing\nstreams of data not only spatially and in time, but also in frequency or,\nequivalently, in wavelength, which makes it highly suitable for parallel\ncomputing. Here, we numerically show the use of time and wavelength division\nmultiplexing (WDM) to solve four independent tasks at the same time in a single\nphotonic chip, serving as a proof of concept for our proposal. The system is a\ntime-delay reservoir computing (TDRC) based on a microring resonator (MRR). The\naddressed tasks cover different applications: Time-series prediction, waveform\nsignal classification, wireless channel equalization, and radar signal\nprediction. The system is also tested for simultaneous computing of up to 10\ninstances of the same task, exhibiting excellent performance. The footprint of\nthe system is reduced by using time-division multiplexing of the nodes that act\nas the neurons of the studied neural network scheme. WDM is used for the\nparallelization of wavelength channels, each addressing a single task. By\nadjusting the input power and frequency of each optical channel, we can achieve\nlevels of performance for each of the tasks that are comparable to those quoted\nin state-of-the-art reports focusing on single-task operation...", "arxiv_id": "http://arxiv.org/abs/2407.21189v1", "pdf_url": "http://arxiv.org/pdf/2407.21189v1", "primary_category": "cs.NE", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Amelia: A Large Model and Dataset for Airport Surface Movement Forecasting", "authors": "Ingrid Navarro, Pablo Ortega-Kral, Jay Patrikar, Haichuan Wang, Zelin Ye, Jong Hoon Park, Jean Oh, Sebastian Scherer", "abstract": "The growing demand for air travel requires technological advancements in air\ntraffic management as well as mechanisms for monitoring and ensuring safe and\nefficient operations. In terminal airspaces, predictive models of future\nmovements and traffic flows can help with proactive planning and efficient\ncoordination; however, varying airport topologies, and interactions with other\nagents, among other factors, make accurate predictions challenging. Data-driven\npredictive models have shown promise for handling numerous variables to enable\nvarious downstream tasks, including collision risk assessment, taxi-out time\nprediction, departure metering, and emission estimations. While data-driven\nmethods have shown improvements in these tasks, prior works lack large-scale\ncurated surface movement datasets within the public domain and the development\nof generalizable trajectory forecasting models. In response to this, we propose\ntwo contributions: (1) Amelia-48, a large surface movement dataset collected\nusing the System Wide Information Management (SWIM) Surface Movement Event\nService (SMES). With data collection beginning in Dec 2022, the dataset\nprovides more than a year's worth of SMES data (~30TB) and covers 48 airports\nwithin the US National Airspace System. In addition to releasing this data in\nthe public domain, we also provide post-processing scripts and associated\nairport maps to enable research in the forecasting domain and beyond. (2)\nAmelia-TF model, a transformer-based next-token-prediction large multi-agent\nmulti-airport trajectory forecasting model trained on 292 days or 9.4 billion\ntokens of position data encompassing 10 different airports with varying\ntopology. The open-sourced model is validated on unseen airports with\nexperiments showcasing the different prediction horizon lengths, ego-agent\nselection strategies, and training recipes to demonstrate the generalization\ncapabilities.", "arxiv_id": "http://arxiv.org/abs/2407.21185v1", "pdf_url": "http://arxiv.org/pdf/2407.21185v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "RELEVANT"}
{"title": "Optical Computing for Deep Neural Network Acceleration: Foundations, Recent Developments, and Emerging Directions", "authors": "Sudeep Pasricha", "abstract": "Emerging artificial intelligence applications across the domains of computer\nvision, natural language processing, graph processing, and sequence prediction\nincreasingly rely on deep neural networks (DNNs). These DNNs require\nsignificant compute and memory resources for training and inference.\nTraditional computing platforms such as CPUs, GPUs, and TPUs are struggling to\nkeep up with the demands of the increasingly complex and diverse DNNs. Optical\ncomputing represents an exciting new paradigm for light-speed acceleration of\nDNN workloads. In this article, we discuss the fundamentals and\nstate-of-the-art developments in optical computing, with an emphasis on DNN\nacceleration. Various promising approaches are described for engineering\noptical devices, enhancing optical circuits, and designing architectures that\ncan adapt optical computing to a variety of DNN workloads. Novel techniques for\nhardware/software co-design that can intelligently tune and map DNN models to\nimprove performance and energy-efficiency on optical computing platforms across\nhigh performance and resource constrained embedded, edge, and IoT platforms are\nalso discussed. Lastly, several open problems and future directions for\nresearch in this domain are highlighted.", "arxiv_id": "http://arxiv.org/abs/2407.21184v1", "pdf_url": "http://arxiv.org/pdf/2407.21184v1", "primary_category": "cs.AR", "preferences": "I'm intersted in LLMs", "response": "RELEVANT"}
{"title": "DKL-KAN: Scalable Deep Kernel Learning using Kolmogorov-Arnold Networks", "authors": "Shrenik Zinage, Sudeepta Mondal, Soumalya Sarkar", "abstract": "The need for scalable and expressive models in machine learning is paramount,\nparticularly in applications requiring both structural depth and flexibility.\nTraditional deep learning methods, such as multilayer perceptrons (MLP), offer\ndepth but lack ability to integrate structural characteristics of deep learning\narchitectures with non-parametric flexibility of kernel methods. To address\nthis, deep kernel learning (DKL) was introduced, where inputs to a base kernel\nare transformed using a deep learning architecture. These kernels can replace\nstandard kernels, allowing both expressive power and scalability. The advent of\nKolmogorov-Arnold Networks (KAN) has generated considerable attention and\ndiscussion among researchers in scientific domain. In this paper, we introduce\na scalable deep kernel using KAN (DKL-KAN) as an effective alternative to DKL\nusing MLP (DKL-MLP). Our approach involves simultaneously optimizing these\nkernel attributes using marginal likelihood within a Gaussian process\nframework. We analyze two variants of DKL-KAN for a fair comparison with\nDKL-MLP: one with same number of neurons and layers as DKL-MLP, and another\nwith approximately same number of trainable parameters. To handle large\ndatasets, we use kernel interpolation for scalable structured Gaussian\nprocesses (KISS-GP) for low-dimensional inputs and KISS-GP with product kernels\nfor high-dimensional inputs. The efficacy of DKL-KAN is evaluated in terms of\ncomputational training time and test prediction accuracy across a wide range of\napplications. Additionally, the effectiveness of DKL-KAN is also examined in\nmodeling discontinuities and accurately estimating prediction uncertainty. The\nresults indicate that DKL-KAN outperforms DKL-MLP on datasets with a low number\nof observations. Conversely, DKL-MLP exhibits better scalability and higher\ntest prediction accuracy on datasets with large number of observations.", "arxiv_id": "http://arxiv.org/abs/2407.21176v1", "pdf_url": "http://arxiv.org/pdf/2407.21176v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Embedding Space Selection for Detecting Memorization and Fingerprinting in Generative Models", "authors": "Jack He, Jianxing Zhao, Andrew Bai, Cho-Jui Hsieh", "abstract": "In the rapidly evolving landscape of artificial intelligence, generative\nmodels such as Generative Adversarial Networks (GANs) and Diffusion Models have\nbecome cornerstone technologies, driving innovation in diverse fields from art\ncreation to healthcare. Despite their potential, these models face the\nsignificant challenge of data memorization, which poses risks to privacy and\nthe integrity of generated content. Among various metrics of memorization\ndetection, our study delves into the memorization scores calculated from\nencoder layer embeddings, which involves measuring distances between samples in\nthe embedding spaces. Particularly, we find that the memorization scores\ncalculated from layer embeddings of Vision Transformers (ViTs) show an notable\ntrend - the latter (deeper) the layer, the less the memorization measured. It\nhas been found that the memorization scores from the early layers' embeddings\nare more sensitive to low-level memorization (e.g. colors and simple patterns\nfor an image), while those from the latter layers are more sensitive to\nhigh-level memorization (e.g. semantic meaning of an image). We also observe\nthat, for a specific model architecture, its degree of memorization on\ndifferent levels of information is unique. It can be viewed as an inherent\nproperty of the architecture. Building upon this insight, we introduce a unique\nfingerprinting methodology. This method capitalizes on the unique distributions\nof the memorization score across different layers of ViTs, providing a novel\napproach to identifying models involved in generating deepfakes and malicious\ncontent. Our approach demonstrates a marked 30% enhancement in identification\naccuracy over existing baseline methods, offering a more effective tool for\ncombating digital misinformation.", "arxiv_id": "http://arxiv.org/abs/2407.21159v1", "pdf_url": "http://arxiv.org/pdf/2407.21159v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "RELEVANT"}
{"title": "Private Collaborative Edge Inference via Over-the-Air Computation", "authors": "Selim F. Yilmaz, Burak Hasircioglu, Li Qiao, Deniz Gunduz", "abstract": "We consider collaborative inference at the wireless edge, where each client's\nmodel is trained independently on their local datasets. Clients are queried in\nparallel to make an accurate decision collaboratively. In addition to\nmaximizing the inference accuracy, we also want to ensure the privacy of local\nmodels. To this end, we leverage the superposition property of the multiple\naccess channel to implement bandwidth-efficient multi-user inference methods.\nSpecifically, we propose different methods for ensemble and multi-view\nclassification that exploit over-the-air computation. We show that these\nschemes perform better than their orthogonal counterparts with statistically\nsignificant differences while using fewer resources and providing privacy\nguarantees. We also provide experimental results verifying the benefits of the\nproposed over-the-air multi-user inference approach and perform an ablation\nstudy to demonstrate the effectiveness of our design choices. We share the\nsource code of the framework publicly on Github to facilitate further research\nand reproducibility.", "arxiv_id": "http://arxiv.org/abs/2407.21151v1", "pdf_url": "http://arxiv.org/pdf/2407.21151v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Enhancing Deep Hedging of Options with Implied Volatility Surface Feedback Information", "authors": "Pascal Fran\u00e7ois, Genevi\u00e8ve Gauthier, Fr\u00e9d\u00e9ric Godin, Carlos Octavio P\u00e9rez Mendoza", "abstract": "We present a dynamic hedging scheme for S&P 500 options, where rebalancing\ndecisions are enhanced by integrating information about the implied volatility\nsurface dynamics. The optimal hedging strategy is obtained through a deep\npolicy gradient-type reinforcement learning algorithm, with a novel hybrid\nneural network architecture improving the training performance. The favorable\ninclusion of forward-looking information embedded in the volatility surface\nallows our procedure to outperform several conventional benchmarks such as\npractitioner and smiled-implied delta hedging procedures, both in simulation\nand backtesting experiments.", "arxiv_id": "http://arxiv.org/abs/2407.21138v1", "pdf_url": "http://arxiv.org/pdf/2407.21138v1", "primary_category": "q-fin.RM", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Computational music analysis from first principles", "authors": "Dmitri Tymoczko, Mark Newman", "abstract": "We use coupled hidden Markov models to automatically annotate the 371 Bach\nchorales in the Riemenschneider edition, a corpus containing approximately\n100,000 notes and 20,000 chords. We give three separate analyses that achieve\nprogressively greater accuracy at the cost of making increasingly strong\nassumptions about musical syntax. Although our method makes almost no use of\nhuman input, we are able to identify both chords and keys with an accuracy of\n85% or greater when compared to an expert human analysis, resulting in\nannotations accurate enough to be used for a range of music-theoretical\npurposes, while also being free of subjective human judgments. Our work bears\non longstanding debates about the objective reality of the structures\npostulated by standard Western harmonic theory, as well as on specific\nquestions about the nature of Western harmonic syntax.", "arxiv_id": "http://arxiv.org/abs/2407.21130v1", "pdf_url": "http://arxiv.org/pdf/2407.21130v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Zero Shot Health Trajectory Prediction Using Transformer", "authors": "Pawel Renc, Yugang Jia, Anthony E. Samir, Jaroslaw Was, Quanzheng Li, David W. Bates, Arkadiusz Sitek", "abstract": "Integrating modern machine learning and clinical decision-making has great\npromise for mitigating healthcare's increasing cost and complexity. We\nintroduce the Enhanced Transformer for Health Outcome Simulation (ETHOS), a\nnovel application of the transformer deep-learning architecture for analyzing\nhigh-dimensional, heterogeneous, and episodic health data. ETHOS is trained\nusing Patient Health Timelines (PHTs)-detailed, tokenized records of health\nevents-to predict future health trajectories, leveraging a zero-shot learning\napproach. ETHOS represents a significant advancement in foundation model\ndevelopment for healthcare analytics, eliminating the need for labeled data and\nmodel fine-tuning. Its ability to simulate various treatment pathways and\nconsider patient-specific factors positions ETHOS as a tool for care\noptimization and addressing biases in healthcare delivery. Future developments\nwill expand ETHOS' capabilities to incorporate a wider range of data types and\ndata sources. Our work demonstrates a pathway toward accelerated AI development\nand deployment in healthcare.", "arxiv_id": "http://arxiv.org/abs/2407.21124v1", "pdf_url": "http://arxiv.org/pdf/2407.21124v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "RELEVANT"}
{"title": "Taming the Frequency Factory of Sinusoidal Networks", "authors": "Tiago Novello, Diana Aldana, Luiz Velho", "abstract": "This work investigates the structure and representation capacity of\n$sinusoidal$ MLPs, which have recently shown promising results in encoding\nlow-dimensional signals. This success can be attributed to its smoothness and\nhigh representation capacity. The first allows the use of the network's\nderivatives during training, enabling regularization. However, defining the\narchitecture and initializing its parameters to achieve a desired capacity\nremains an empirical task. This work provides theoretical and experimental\nresults justifying the capacity property of sinusoidal MLPs and offers control\nmechanisms for their initialization and training.\n  We approach this from a Fourier series perspective and link the training with\nthe model's spectrum. Our analysis is based on a $harmonic$ expansion of the\nsinusoidal MLP, which says that the composition of sinusoidal layers produces a\nlarge number of new frequencies expressed as integer linear combinations of the\ninput frequencies (weights of the input layer). We use this novel $identity$ to\ninitialize the input neurons which work as a sampling in the signal spectrum.\nWe also note that each hidden neuron produces the same frequencies with\namplitudes completely determined by the hidden weights. Finally, we give an\nupper bound for these amplitudes, which results in a $bounding$ scheme for the\nnetwork's spectrum during training.", "arxiv_id": "http://arxiv.org/abs/2407.21121v1", "pdf_url": "http://arxiv.org/pdf/2407.21121v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Palu: Compressing KV-Cache with Low-Rank Projection", "authors": "Chi-Chih Chang, Wei-Cheng Lin, Chien-Yu Lin, Chong-Yan Chen, Yu-Fang Hu, Pei-Shuo Wang, Ning-Chi Huang, Luis Ceze, Kai-Chiang Wu", "abstract": "KV-Cache compression methods generally sample a KV-Cache of effectual tokens\nor quantize it into lower bits. However, these methods cannot exploit the\nredundancy of the hidden dimension of KV tensors. This paper investigates a\nunique hidden dimension approach called Palu, a novel KV-Cache compression\nframework that utilizes low-rank projection. Palu decomposes the linear layers\ninto low-rank matrices, caches the smaller intermediate states, and\nreconstructs the full keys and values on the fly. To improve accuracy,\ncompression rate, and efficiency, Palu further encompasses (1) a medium-grained\nlow-rank decomposition scheme, (2) an efficient rank search algorithm, (3) a\nlow-rank-aware quantization algorithm, and (4) matrix fusion with optimized GPU\nkernels. Our extensive experiments with popular LLMs show that Palu can\ncompress KV-Cache by more than 91.25% while maintaining a significantly better\naccuracy (up to 1.19 lower perplexity) than state-of-the-art KV-Cache\nquantization methods at a similar or even higher memory usage. When compressing\nKV-Cache for 50%, Palu delivers up to 1.61x end-to-end speedup for the\nattention module. Our code is publicly available at\nhttps://github.com/shadowpa0327/Palu.", "arxiv_id": "http://arxiv.org/abs/2407.21118v1", "pdf_url": "http://arxiv.org/pdf/2407.21118v1", "primary_category": "cs.AI", "preferences": "I'm intersted in LLMs", "response": "RELEVANT"}
{"title": "CLEFT: Language-Image Contrastive Learning with Efficient Large Language Model and Prompt Fine-Tuning", "authors": "Yuexi Du, Brian Chang, Nicha C. Dvornek", "abstract": "Recent advancements in Contrastive Language-Image Pre-training (CLIP) have\ndemonstrated notable success in self-supervised representation learning across\nvarious tasks. However, the existing CLIP-like approaches often demand\nextensive GPU resources and prolonged training times due to the considerable\nsize of the model and dataset, making them poor for medical applications, in\nwhich large datasets are not always common. Meanwhile, the language model\nprompts are mainly manually derived from labels tied to images, potentially\noverlooking the richness of information within training samples. We introduce a\nnovel language-image Contrastive Learning method with an Efficient large\nlanguage model and prompt Fine-Tuning (CLEFT) that harnesses the strengths of\nthe extensive pre-trained language and visual models. Furthermore, we present\nan efficient strategy for learning context-based prompts that mitigates the gap\nbetween informative clinical diagnostic data and simple class labels. Our\nmethod demonstrates state-of-the-art performance on multiple chest X-ray and\nmammography datasets compared with various baselines. The proposed parameter\nefficient framework can reduce the total trainable model size by 39% and reduce\nthe trainable language model to only 4% compared with the current BERT encoder.", "arxiv_id": "http://arxiv.org/abs/2407.21011v1", "pdf_url": "http://arxiv.org/pdf/2407.21011v1", "primary_category": "cs.CV", "preferences": "I'm intersted in LLMs", "response": "RELEVANT"}
{"title": "GABInsight: Exploring Gender-Activity Binding Bias in Vision-Language Models", "authors": "Ali Abdollahi, Mahdi Ghaznavi, Mohammad Reza Karimi Nejad, Arash Mari Oriyad, Reza Abbasi, Ali Salesi, Melika Behjati, Mohammad Hossein Rohban, Mahdieh Soleymani Baghshah", "abstract": "Vision-language models (VLMs) are intensively used in many downstream tasks,\nincluding those requiring assessments of individuals appearing in the images.\nWhile VLMs perform well in simple single-person scenarios, in real-world\napplications, we often face complex situations in which there are persons of\ndifferent genders doing different activities. We show that in such cases, VLMs\nare biased towards identifying the individual with the expected gender\n(according to ingrained gender stereotypes in the model or other forms of\nsample selection bias) as the performer of the activity. We refer to this bias\nin associating an activity with the gender of its actual performer in an image\nor text as the Gender-Activity Binding (GAB) bias and analyze how this bias is\ninternalized in VLMs. To assess this bias, we have introduced the GAB dataset\nwith approximately 5500 AI-generated images that represent a variety of\nactivities, addressing the scarcity of real-world images for some scenarios. To\nhave extensive quality control, the generated images are evaluated for their\ndiversity, quality, and realism. We have tested 12 renowned pre-trained VLMs on\nthis dataset in the context of text-to-image and image-to-text retrieval to\nmeasure the effect of this bias on their predictions. Additionally, we have\ncarried out supplementary experiments to quantify the bias in VLMs' text\nencoders and to evaluate VLMs' capability to recognize activities. Our\nexperiments indicate that VLMs experience an average performance decline of\nabout 13.2% when confronted with gender-activity binding bias.", "arxiv_id": "http://arxiv.org/abs/2407.21001v1", "pdf_url": "http://arxiv.org/pdf/2407.21001v1", "primary_category": "cs.CV", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "MoFO: Momentum-Filtered Optimizer for Mitigating Forgetting in LLM Fine-Tuning", "authors": "Yupeng Chen, Senmiao Wang, Zhihang Lin, Zeyu Qin, Yushun Zhang, Tian Ding, Ruoyu Sun", "abstract": "Recently, large language models (LLMs) have demonstrated remarkable\ncapabilities in a wide range of tasks. Typically, an LLM is pre-trained on\nlarge corpora and subsequently fine-tuned on task-specific datasets. However,\nduring fine-tuning, LLMs may forget the knowledge acquired in the pre-training\nstage, leading to a decline in general capabilities. To address this issue, we\npropose a new fine-tuning algorithm termed Momentum-Filtered Optimizer (MoFO).\nThe key idea of MoFO is to iteratively select and update the model parameters\nwith the largest momentum magnitudes. Compared to full-parameter training, MoFO\nachieves similar fine-tuning performance while keeping parameters closer to the\npre-trained model, thereby mitigating knowledge forgetting. Unlike most\nexisting methods for forgetting mitigation, MoFO combines the following two\nadvantages. First, MoFO does not require access to pre-training data. This\nmakes MoFO particularly suitable for fine-tuning scenarios where pre-training\ndata is unavailable, such as fine-tuning checkpoint-only open-source LLMs.\nSecond, MoFO does not alter the original loss function. This could avoid\nimpairing the model performance on the fine-tuning tasks. We validate MoFO\nthrough rigorous convergence analysis and extensive experiments, demonstrating\nits superiority over existing methods in mitigating forgetting and enhancing\nfine-tuning performance.", "arxiv_id": "http://arxiv.org/abs/2407.20999v2", "pdf_url": "http://arxiv.org/pdf/2407.20999v2", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "RELEVANT"}
{"title": "From Feature Importance to Natural Language Explanations Using LLMs with RAG", "authors": "Sule Tekkesinoglu, Lars Kunze", "abstract": "As machine learning becomes increasingly integral to autonomous\ndecision-making processes involving human interaction, the necessity of\ncomprehending the model's outputs through conversational means increases. Most\nrecently, foundation models are being explored for their potential as post hoc\nexplainers, providing a pathway to elucidate the decision-making mechanisms of\npredictive models. In this work, we introduce traceable question-answering,\nleveraging an external knowledge repository to inform the responses of Large\nLanguage Models (LLMs) to user queries within a scene understanding task. This\nknowledge repository comprises contextual details regarding the model's output,\ncontaining high-level features, feature importance, and alternative\nprobabilities. We employ subtractive counterfactual reasoning to compute\nfeature importance, a method that entails analysing output variations resulting\nfrom decomposing semantic features. Furthermore, to maintain a seamless\nconversational flow, we integrate four key characteristics - social, causal,\nselective, and contrastive - drawn from social science research on human\nexplanations into a single-shot prompt, guiding the response generation\nprocess. Our evaluation demonstrates that explanations generated by the LLMs\nencompassed these elements, indicating its potential to bridge the gap between\ncomplex model outputs and natural language expressions.", "arxiv_id": "http://arxiv.org/abs/2407.20990v1", "pdf_url": "http://arxiv.org/pdf/2407.20990v1", "primary_category": "cs.AI", "preferences": "I'm intersted in LLMs", "response": "RELEVANT"}
{"title": "Contrasting Deep Learning Models for Direct Respiratory Insufficiency Detection Versus Blood Oxygen Saturation Estimation", "authors": "Marcelo Matheus Gauy, Natalia Hitomi Koza, Ricardo Mikio Morita, Gabriel Rocha Stanzione, Arnaldo Candido Junior, Larissa Cristina Berti, Anna Sara Shafferman Levin, Ester Cerdeira Sabino, Flaviane Romani Fernandes Svartman, Marcelo Finger", "abstract": "We contrast high effectiveness of state of the art deep learning\narchitectures designed for general audio classification tasks, refined for\nrespiratory insufficiency (RI) detection and blood oxygen saturation (SpO2)\nestimation and classification through automated audio analysis. Recently,\nmultiple deep learning architectures have been proposed to detect RI in COVID\npatients through audio analysis, achieving accuracy above 95% and F1-score\nabove 0.93. RI is a condition associated with low SpO2 levels, commonly defined\nas the threshold SpO2 <92%. While SpO2 serves as a crucial determinant of RI, a\nmedical doctor's diagnosis typically relies on multiple factors. These include\nrespiratory frequency, heart rate, SpO2 levels, among others. Here we study\npretrained audio neural networks (CNN6, CNN10 and CNN14) and the Masked\nAutoencoder (Audio-MAE) for RI detection, where these models achieve near\nperfect accuracy, surpassing previous results. Yet, for the regression task of\nestimating SpO2 levels, the models achieve root mean square error values\nexceeding the accepted clinical range of 3.5% for finger oximeters.\nAdditionally, Pearson correlation coefficients fail to surpass 0.3. As deep\nlearning models perform better in classification than regression, we transform\nSpO2-regression into a SpO2-threshold binary classification problem, with a\nthreshold of 92%. However, this task still yields an F1-score below 0.65. Thus,\naudio analysis offers valuable insights into a patient's RI status, but does\nnot provide accurate information about actual SpO2 levels, indicating a\nseparation of domains in which voice and speech biomarkers may and may not be\nuseful in medical diagnostics under current technologies.", "arxiv_id": "http://arxiv.org/abs/2407.20989v1", "pdf_url": "http://arxiv.org/pdf/2407.20989v1", "primary_category": "cs.SD", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "The Stochastic Conjugate Subgradient Algorithm For Kernel Support Vector Machines", "authors": "Di Zhang, Suvrajeet Sen", "abstract": "Stochastic First-Order (SFO) methods have been a cornerstone in addressing a\nbroad spectrum of modern machine learning (ML) challenges. However, their\nefficacy is increasingly questioned, especially in large-scale applications\nwhere empirical evidence indicates potential performance limitations. In\nresponse, this paper proposes an innovative method specifically designed for\nkernel support vector machines (SVMs). This method not only achieves faster\nconvergence per iteration but also exhibits enhanced scalability when compared\nto conventional SFO techniques. Diverging from traditional sample average\napproximation strategies that typically frame kernel SVM as an 'all-in-one'\nQuadratic Program (QP), our approach adopts adaptive sampling. This strategy\nincrementally refines approximation accuracy on an 'as-needed' basis.\nCrucially, this approach also inspires a decomposition-based algorithm,\neffectively decomposing parameter selection from error estimation, with the\nlatter being independently determined for each data point. To exploit the\nquadratic nature of the kernel matrix, we introduce a stochastic conjugate\nsubgradient method. This method preserves many benefits of first-order\napproaches while adeptly handling both nonlinearity and non-smooth aspects of\nthe SVM problem. Thus, it extends beyond the capabilities of standard SFO\nalgorithms for non-smooth convex optimization. The convergence rate of this\nnovel method is thoroughly analyzed within this paper. Our experimental results\ndemonstrate that the proposed algorithm not only maintains but potentially\nexceeds the scalability of SFO methods. Moreover, it significantly enhances\nboth speed and accuracy of the optimization process.", "arxiv_id": "http://arxiv.org/abs/2407.21091v1", "pdf_url": "http://arxiv.org/pdf/2407.21091v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Learning Optimal Signal Temporal Logic Decision Trees for Classification: A Max-Flow MILP Formulation", "authors": "Kaier Liang, Gustavo A. Cardona, Disha Kamale, Cristian-Ioan Vasile", "abstract": "This paper presents a novel framework for inferring timed temporal logic\nproperties from data. The dataset comprises pairs of finite-time system traces\nand corresponding labels, denoting whether the traces demonstrate specific\ndesired behaviors, e.g. whether the ship follows a safe route or not. Our\nproposed approach leverages decision-tree-based methods to infer Signal\nTemporal Logic classifiers using primitive formulae. We formulate the inference\nprocess as a mixed integer linear programming optimization problem, recursively\ngenerating constraints to determine both data classification and tree\nstructure. Applying a max-flow algorithm on the resultant tree transforms the\nproblem into a global optimization challenge, leading to improved\nclassification rates compared to prior methodologies. Moreover, we introduce a\ntechnique to reduce the number of constraints by exploiting the symmetry\ninherent in STL primitives, which enhances the algorithm's time performance and\ninterpretability. To assess our algorithm's effectiveness and classification\nperformance, we conduct three case studies involving two-class, multi-class,\nand complex formula classification scenarios.", "arxiv_id": "http://arxiv.org/abs/2407.21090v1", "pdf_url": "http://arxiv.org/pdf/2407.21090v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Learning Ordinality in Semantic Segmentation", "authors": "Rafael Cristino, Ricardo P. M. Cruz, Jaime S. Cardoso", "abstract": "Semantic segmentation consists of predicting a semantic label for each image\npixel. Conventional deep learning models do not take advantage of ordinal\nrelations that might exist in the domain at hand. For example, it is known that\nthe pupil is inside the iris, and the lane markings are inside the road. Such\ndomain knowledge can be employed as constraints to make the model more robust.\nThe current literature on this topic has explored pixel-wise ordinal\nsegmentation methods, which treat each pixel as an independent observation and\npromote ordinality in its representation. This paper proposes novel spatial\nordinal segmentation methods, which take advantage of the structured image\nspace by considering each pixel as an observation dependent on its neighborhood\ncontext to also promote ordinal spatial consistency. When evaluated with five\nbiomedical datasets and multiple configurations of autonomous driving datasets,\nordinal methods resulted in more ordinally-consistent models, with substantial\nimprovements in ordinal metrics and some increase in the Dice coefficient. It\nwas also shown that the incorporation of ordinal consistency results in models\nwith better generalization abilities.", "arxiv_id": "http://arxiv.org/abs/2407.20959v1", "pdf_url": "http://arxiv.org/pdf/2407.20959v1", "primary_category": "cs.CV", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "An Effective Dynamic Gradient Calibration Method for Continual Learning", "authors": "Weichen Lin, Jiaxiang Chen, Ruomin Huang, Hu Ding", "abstract": "Continual learning (CL) is a fundamental topic in machine learning, where the\ngoal is to train a model with continuously incoming data and tasks. Due to the\nmemory limit, we cannot store all the historical data, and therefore confront\nthe ``catastrophic forgetting'' problem, i.e., the performance on the previous\ntasks can substantially decrease because of the missing information in the\nlatter period. Though a number of elegant methods have been proposed, the\ncatastrophic forgetting phenomenon still cannot be well avoided in practice. In\nthis paper, we study the problem from the gradient perspective, where our aim\nis to develop an effective algorithm to calibrate the gradient in each updating\nstep of the model; namely, our goal is to guide the model to be updated in the\nright direction under the situation that a large amount of historical data are\nunavailable. Our idea is partly inspired by the seminal stochastic variance\nreduction methods (e.g., SVRG and SAGA) for reducing the variance of gradient\nestimation in stochastic gradient descent algorithms. Another benefit is that\nour approach can be used as a general tool, which is able to be incorporated\nwith several existing popular CL methods to achieve better performance. We also\nconduct a set of experiments on several benchmark datasets to evaluate the\nperformance in practice.", "arxiv_id": "http://arxiv.org/abs/2407.20956v1", "pdf_url": "http://arxiv.org/pdf/2407.20956v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "How to Choose a Reinforcement-Learning Algorithm", "authors": "Fabian Bongratz, Vladimir Golkov, Lukas Mautner, Luca Della Libera, Frederik Heetmeyer, Felix Czaja, Julian Rodemann, Daniel Cremers", "abstract": "The field of reinforcement learning offers a large variety of concepts and\nmethods to tackle sequential decision-making problems. This variety has become\nso large that choosing an algorithm for a task at hand can be challenging. In\nthis work, we streamline the process of choosing reinforcement-learning\nalgorithms and action-distribution families. We provide a structured overview\nof existing methods and their properties, as well as guidelines for when to\nchoose which methods. An interactive version of these guidelines is available\nonline at https://rl-picker.github.io/.", "arxiv_id": "http://arxiv.org/abs/2407.20917v1", "pdf_url": "http://arxiv.org/pdf/2407.20917v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "What Are Good Positional Encodings for Directed Graphs?", "authors": "Yinan Huang, Haoyu Wang, Pan Li", "abstract": "Positional encodings (PE) for graphs are essential in constructing powerful\nand expressive graph neural networks and graph transformers as they effectively\ncapture relative spatial relations between nodes. While PEs for undirected\ngraphs have been extensively studied, those for directed graphs remain largely\nunexplored, despite the fundamental role of directed graphs in representing\nentities with strong logical dependencies, such as those in program analysis\nand circuit designs. This work studies the design of PEs for directed graphs\nthat are expressive to represent desired directed spatial relations. We first\npropose walk profile, a generalization of walk counting sequence to directed\ngraphs. We identify limitations in existing PE methods, including symmetrized\nLaplacian PE, Singular Value Decomposition PE, and Magnetic Laplacian PE, in\ntheir ability to express walk profiles. To address these limitations, we\npropose the Multi-q Magnetic Laplacian PE, which extends Magnetic Laplacian PE\nwith multiple potential factors. This simple variant turns out to be capable of\nprovably expressing walk profiles. Furthermore, we generalize previous\nbasis-invariant and stable networks to handle complex-domain PEs decomposed\nfrom Magnetic Laplacians. Our numerical experiments demonstrate the\neffectiveness of Multi-q Magnetic Laplacian PE with a stable neural\narchitecture, outperforming previous PE methods (with stable networks) on\npredicting directed distances/walk profiles, sorting network satisfiability,\nand on general circuit benchmarks. Our code is available at\nhttps://github.com/Graph-COM/Multi-q-Maglap.", "arxiv_id": "http://arxiv.org/abs/2407.20912v1", "pdf_url": "http://arxiv.org/pdf/2407.20912v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Machine learning surrogates for efficient hydrologic modeling: Insights from stochastic simulations of managed aquifer recharge", "authors": "Timothy Dai, Kate Maher, Zach Perzan", "abstract": "Process-based hydrologic models are invaluable tools for understanding the\nterrestrial water cycle and addressing modern water resources problems.\nHowever, many hydrologic models are computationally expensive and, depending on\nthe resolution and scale, simulations can take on the order of hours to days to\ncomplete. While techniques such as uncertainty quantification and optimization\nhave become valuable tools for supporting management decisions, these analyses\ntypically require hundreds of model simulations, which are too computationally\nexpensive to perform with a process-based hydrologic model. To address this\ngap, we propose a hybrid modeling workflow in which a process-based model is\nused to generate an initial set of simulations and a machine learning (ML)\nsurrogate model is then trained to perform the remaining simulations required\nfor downstream analysis. As a case study, we apply this workflow to simulations\nof variably saturated groundwater flow at a prospective managed aquifer\nrecharge (MAR) site. We compare the accuracy and computational efficiency of\nseveral ML architectures, including deep convolutional networks, recurrent\nneural networks, vision transformers, and networks with Fourier transforms. Our\nresults demonstrate that ML surrogate models can achieve under 10% mean\nabsolute percentage error and yield order-of-magnitude runtime savings over\nprocessed-based models. We also offer practical recommendations for training\nhydrologic surrogate models, including implementing data normalization to\nimprove accuracy, using a normalized loss function to improve training\nstability and downsampling input features to decrease memory requirements.", "arxiv_id": "http://arxiv.org/abs/2407.20902v1", "pdf_url": "http://arxiv.org/pdf/2407.20902v1", "primary_category": "physics.geo-ph", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "MambaCapsule: Towards Transparent Cardiac Disease Diagnosis with Electrocardiography Using Mamba Capsule Network", "authors": "Yinlong Xu, Xiaoqiang Liu, Zitai Kong, Yixuan Wu, Yue Wang, Yingzhou Lu, Honghao Gao, Jian Wu, Hongxia Xu", "abstract": "Cardiac arrhythmia, a condition characterized by irregular heartbeats, often\nserves as an early indication of various heart ailments. With the advent of\ndeep learning, numerous innovative models have been introduced for diagnosing\narrhythmias using Electrocardiogram (ECG) signals. However, recent studies\nsolely focus on the performance of models, neglecting the interpretation of\ntheir results. This leads to a considerable lack of transparency, posing a\nsignificant risk in the actual diagnostic process. To solve this problem, this\npaper introduces MambaCapsule, a deep neural networks for ECG arrhythmias\nclassification, which increases the explainability of the model while enhancing\nthe accuracy.Our model utilizes Mamba for feature extraction and Capsule\nnetworks for prediction, providing not only a confidence score but also signal\nfeatures. Akin to the processing mechanism of human brain, the model learns\nsignal features and their relationship between them by reconstructing ECG\nsignals in the predicted selection. The model evaluation was conducted on\nMIT-BIH and PTB dataset, following the AAMI standard. MambaCapsule has achieved\na total accuracy of 99.54% and 99.59% on the test sets respectively. These\nresults demonstrate the promising performance of under the standard test\nprotocol.", "arxiv_id": "http://arxiv.org/abs/2407.20893v1", "pdf_url": "http://arxiv.org/pdf/2407.20893v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Bayesian Low-Rank LeArning (Bella): A Practical Approach to Bayesian Neural Networks", "authors": "Bao Gia Doan, Afshar Shamsi, Xiao-Yu Guo, Arash Mohammadi, Hamid Alinejad-Rokny, Dino Sejdinovic, Damith C. Ranasinghe, Ehsan Abbasnejad", "abstract": "Computational complexity of Bayesian learning is impeding its adoption in\npractical, large-scale tasks. Despite demonstrations of significant merits such\nas improved robustness and resilience to unseen or out-of-distribution inputs\nover their non- Bayesian counterparts, their practical use has faded to near\ninsignificance. In this study, we introduce an innovative framework to mitigate\nthe computational burden of Bayesian neural networks (BNNs). Our approach\nfollows the principle of Bayesian techniques based on deep ensembles, but\nsignificantly reduces their cost via multiple low-rank perturbations of\nparameters arising from a pre-trained neural network. Both vanilla version of\nensembles as well as more sophisticated schemes such as Bayesian learning with\nStein Variational Gradient Descent (SVGD), previously deemed impractical for\nlarge models, can be seamlessly implemented within the proposed framework,\ncalled Bayesian Low-Rank LeArning (Bella). In a nutshell, i) Bella achieves a\ndramatic reduction in the number of trainable parameters required to\napproximate a Bayesian posterior; and ii) it not only maintains, but in some\ninstances, surpasses the performance of conventional Bayesian learning methods\nand non-Bayesian baselines. Our results with large-scale tasks such as\nImageNet, CAMELYON17, DomainNet, VQA with CLIP, LLaVA demonstrate the\neffectiveness and versatility of Bella in building highly scalable and\npractical Bayesian deep models for real-world applications.", "arxiv_id": "http://arxiv.org/abs/2407.20891v1", "pdf_url": "http://arxiv.org/pdf/2407.20891v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Co-Neighbor Encoding Schema: A Light-cost Structure Encoding Method for Dynamic Link Prediction", "authors": "Ke Cheng, Linzhi Peng, Junchen Ye, Leilei Sun, Bowen Du", "abstract": "Structure encoding has proven to be the key feature to distinguishing links\nin a graph. However, Structure encoding in the temporal graph keeps changing as\nthe graph evolves, repeatedly computing such features can be time-consuming due\nto the high-order subgraph construction. We develop the Co-Neighbor Encoding\nSchema (CNES) to address this issue. Instead of recomputing the feature by the\nlink, CNES stores information in the memory to avoid redundant calculations.\nBesides, unlike the existing memory-based dynamic graph learning method that\nstores node hidden states, we introduce a hashtable-based memory to compress\nthe adjacency matrix for efficient structure feature construction and updating\nwith vector computation in parallel. Furthermore, CNES introduces a\nTemporal-Diverse Memory to generate long-term and short-term structure encoding\nfor neighbors with different structural information. A dynamic graph learning\nframework, Co-Neighbor Encoding Network (CNE-N), is proposed using the\naforementioned techniques. Extensive experiments on thirteen public datasets\nverify the effectiveness and efficiency of the proposed method.", "arxiv_id": "http://arxiv.org/abs/2407.20871v1", "pdf_url": "http://arxiv.org/pdf/2407.20871v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Generalized Out-of-Distribution Detection and Beyond in Vision Language Model Era: A Survey", "authors": "Atsuyuki Miyai, Jingkang Yang, Jingyang Zhang, Yifei Ming, Yueqian Lin, Qing Yu, Go Irie, Shafiq Joty, Yixuan Li, Hai Li, Ziwei Liu, Toshihiko Yamasaki, Kiyoharu Aizawa", "abstract": "Detecting out-of-distribution (OOD) samples is crucial for ensuring the\nsafety of machine learning systems and has shaped the field of OOD detection.\nMeanwhile, several other problems are closely related to OOD detection,\nincluding anomaly detection (AD), novelty detection (ND), open set recognition\n(OSR), and outlier detection (OD). To unify these problems, a generalized OOD\ndetection framework was proposed, taxonomically categorizing these five\nproblems. However, Vision Language Models (VLMs) such as CLIP have\nsignificantly changed the paradigm and blurred the boundaries between these\nfields, again confusing researchers. In this survey, we first present a\ngeneralized OOD detection v2, encapsulating the evolution of AD, ND, OSR, OOD\ndetection, and OD in the VLM era. Our framework reveals that, with some field\ninactivity and integration, the demanding challenges have become OOD detection\nand AD. In addition, we also highlight the significant shift in the definition,\nproblem settings, and benchmarks; we thus feature a comprehensive review of the\nmethodology for OOD detection, including the discussion over other related\ntasks to clarify their relationship to OOD detection. Finally, we explore the\nadvancements in the emerging Large Vision Language Model (LVLM) era, such as\nGPT-4V. We conclude this survey with open challenges and future directions.", "arxiv_id": "http://arxiv.org/abs/2407.21794v1", "pdf_url": "http://arxiv.org/pdf/2407.21794v1", "primary_category": "cs.CV", "preferences": "I'm intersted in LLMs", "response": "RELEVANT"}
{"title": "Safetywashing: Do AI Safety Benchmarks Actually Measure Safety Progress?", "authors": "Richard Ren, Steven Basart, Adam Khoja, Alice Gatti, Long Phan, Xuwang Yin, Mantas Mazeika, Alexander Pan, Gabriel Mukobi, Ryan H. Kim, Stephen Fitz, Dan Hendrycks", "abstract": "As artificial intelligence systems grow more powerful, there has been\nincreasing interest in \"AI safety\" research to address emerging and future\nrisks. However, the field of AI safety remains poorly defined and\ninconsistently measured, leading to confusion about how researchers can\ncontribute. This lack of clarity is compounded by the unclear relationship\nbetween AI safety benchmarks and upstream general capabilities (e.g., general\nknowledge and reasoning). To address these issues, we conduct a comprehensive\nmeta-analysis of AI safety benchmarks, empirically analyzing their correlation\nwith general capabilities across dozens of models and providing a survey of\nexisting directions in AI safety. Our findings reveal that many safety\nbenchmarks highly correlate with upstream model capabilities, potentially\nenabling \"safetywashing\" -- where capability improvements are misrepresented as\nsafety advancements. Based on these findings, we propose an empirical\nfoundation for developing more meaningful safety metrics and define AI safety\nin a machine learning research context as a set of clearly delineated research\ngoals that are empirically separable from generic capabilities advancements. In\ndoing so, we aim to provide a more rigorous framework for AI safety research,\nadvancing the science of safety evaluations and clarifying the path towards\nmeasurable progress.", "arxiv_id": "http://arxiv.org/abs/2407.21792v1", "pdf_url": "http://arxiv.org/pdf/2407.21792v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "RELEVANT"}
{"title": "Deep Learning for Options Trading: An End-To-End Approach", "authors": "Wee Ling Tan, Stephen Roberts, Stefan Zohren", "abstract": "We introduce a novel approach to options trading strategies using a highly\nscalable and data-driven machine learning algorithm. In contrast to traditional\napproaches that often require specifications of underlying market dynamics or\nassumptions on an option pricing model, our models depart fundamentally from\nthe need for these prerequisites, directly learning non-trivial mappings from\nmarket data to optimal trading signals. Backtesting on more than a decade of\noption contracts for equities listed on the S&P 100, we demonstrate that deep\nlearning models trained according to our end-to-end approach exhibit\nsignificant improvements in risk-adjusted performance over existing rules-based\ntrading strategies. We find that incorporating turnover regularization into the\nmodels leads to further performance enhancements at prohibitively high levels\nof transaction costs.", "arxiv_id": "http://arxiv.org/abs/2407.21791v1", "pdf_url": "http://arxiv.org/pdf/2407.21791v1", "primary_category": "q-fin.PM", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Vision-Language Model Based Handwriting Verification", "authors": "Mihir Chauhan, Abhishek Satbhai, Mohammad Abuzar Hashemi, Mir Basheer Ali, Bina Ramamurthy, Mingchen Gao, Siwei Lyu, Sargur Srihari", "abstract": "Handwriting Verification is a critical in document forensics. Deep learning\nbased approaches often face skepticism from forensic document examiners due to\ntheir lack of explainability and reliance on extensive training data and\nhandcrafted features. This paper explores using Vision Language Models (VLMs),\nsuch as OpenAI's GPT-4o and Google's PaliGemma, to address these challenges. By\nleveraging their Visual Question Answering capabilities and 0-shot\nChain-of-Thought (CoT) reasoning, our goal is to provide clear,\nhuman-understandable explanations for model decisions. Our experiments on the\nCEDAR handwriting dataset demonstrate that VLMs offer enhanced\ninterpretability, reduce the need for large training datasets, and adapt better\nto diverse handwriting styles. However, results show that the CNN-based\nResNet-18 architecture outperforms the 0-shot CoT prompt engineering approach\nwith GPT-4o (Accuracy: 70%) and supervised fine-tuned PaliGemma (Accuracy:\n71%), achieving an accuracy of 84% on the CEDAR AND dataset. These findings\nhighlight the potential of VLMs in generating human-interpretable decisions\nwhile underscoring the need for further advancements to match the performance\nof specialized deep learning models.", "arxiv_id": "http://arxiv.org/abs/2407.21788v1", "pdf_url": "http://arxiv.org/pdf/2407.21788v1", "primary_category": "cs.CV", "preferences": "I'm intersted in LLMs", "response": "RELEVANT"}
{"title": "Large Language Monkeys: Scaling Inference Compute with Repeated Sampling", "authors": "Bradley Brown, Jordan Juravsky, Ryan Ehrlich, Ronald Clark, Quoc V. Le, Christopher R\u00e9, Azalia Mirhoseini", "abstract": "Scaling the amount of compute used to train language models has dramatically\nimproved their capabilities. However, when it comes to inference, we often\nlimit the amount of compute to only one attempt per problem. Here, we explore\ninference compute as another axis for scaling by increasing the number of\ngenerated samples. Across multiple tasks and models, we observe that coverage -\nthe fraction of problems solved by any attempt - scales with the number of\nsamples over four orders of magnitude. In domains like coding and formal\nproofs, where all answers can be automatically verified, these increases in\ncoverage directly translate into improved performance. When we apply repeated\nsampling to SWE-bench Lite, the fraction of issues solved with\nDeepSeek-V2-Coder-Instruct increases from 15.9% with one sample to 56% with 250\nsamples, outperforming the single-attempt state-of-the-art of 43% which uses\nmore capable frontier models. Moreover, using current API pricing, amplifying\nthe cheaper DeepSeek model with five samples is more cost-effective and solves\nmore issues than paying a premium for one sample from GPT-4o or Claude 3.5\nSonnet. Interestingly, the relationship between coverage and the number of\nsamples is often log-linear and can be modelled with an exponentiated power\nlaw, suggesting the existence of inference-time scaling laws. Finally, we find\nthat identifying correct samples out of many generations remains an important\ndirection for future research in domains without automatic verifiers. When\nsolving math word problems from GSM8K and MATH, coverage with Llama-3 models\ngrows to over 95% with 10,000 samples. However, common methods to pick correct\nsolutions from a sample collection, such as majority voting or reward models,\nplateau beyond several hundred samples and fail to fully scale with the sample\nbudget.", "arxiv_id": "http://arxiv.org/abs/2407.21787v1", "pdf_url": "http://arxiv.org/pdf/2407.21787v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "RELEVANT"}
{"title": "ShieldGemma: Generative AI Content Moderation Based on Gemma", "authors": "Wenjun Zeng, Yuchi Liu, Ryan Mullins, Ludovic Peran, Joe Fernandez, Hamza Harkous, Karthik Narasimhan, Drew Proud, Piyush Kumar, Bhaktipriya Radharapu, Olivia Sturman, Oscar Wahltinez", "abstract": "We present ShieldGemma, a comprehensive suite of LLM-based safety content\nmoderation models built upon Gemma2. These models provide robust,\nstate-of-the-art predictions of safety risks across key harm types (sexually\nexplicit, dangerous content, harassment, hate speech) in both user input and\nLLM-generated output. By evaluating on both public and internal benchmarks, we\ndemonstrate superior performance compared to existing models, such as Llama\nGuard (+10.8\\% AU-PRC on public benchmarks) and WildCard (+4.3\\%).\nAdditionally, we present a novel LLM-based data curation pipeline, adaptable to\na variety of safety-related tasks and beyond. We have shown strong\ngeneralization performance for model trained mainly on synthetic data. By\nreleasing ShieldGemma, we provide a valuable resource to the research\ncommunity, advancing LLM safety and enabling the creation of more effective\ncontent moderation solutions for developers.", "arxiv_id": "http://arxiv.org/abs/2407.21772v1", "pdf_url": "http://arxiv.org/pdf/2407.21772v1", "primary_category": "cs.CL", "preferences": "I'm intersted in LLMs", "response": "RELEVANT"}
{"title": "MoMa: Efficient Early-Fusion Pre-training with Mixture of Modality-Aware Experts", "authors": "Xi Victoria Lin, Akshat Shrivastava, Liang Luo, Srinivasan Iyer, Mike Lewis, Gargi Gosh, Luke Zettlemoyer, Armen Aghajanyan", "abstract": "We introduce MoMa, a novel modality-aware mixture-of-experts (MoE)\narchitecture designed for pre-training mixed-modal, early-fusion language\nmodels. MoMa processes images and text in arbitrary sequences by dividing\nexpert modules into modality-specific groups. These groups exclusively process\ndesignated tokens while employing learned routing within each group to maintain\nsemantically informed adaptivity. Our empirical results reveal substantial\npre-training efficiency gains through this modality-specific parameter\nallocation. Under a 1-trillion-token training budget, the MoMa 1.4B model,\nfeaturing 4 text experts and 4 image experts, achieves impressive FLOPs\nsavings: 3.7x overall, with 2.6x for text and 5.2x for image processing\ncompared to a compute-equivalent dense baseline, measured by pre-training loss.\nThis outperforms the standard expert-choice MoE with 8 mixed-modal experts,\nwhich achieves 3x overall FLOPs savings (3x for text, 2.8x for image).\nCombining MoMa with mixture-of-depths (MoD) further improves pre-training FLOPs\nsavings to 4.2x overall (text: 3.4x, image: 5.3x), although this combination\nhurts performance in causal inference due to increased sensitivity to router\naccuracy. These results demonstrate MoMa's potential to significantly advance\nthe efficiency of mixed-modal, early-fusion language model pre-training, paving\nthe way for more resource-efficient and capable multimodal AI systems.", "arxiv_id": "http://arxiv.org/abs/2407.21770v1", "pdf_url": "http://arxiv.org/pdf/2407.21770v1", "primary_category": "cs.AI", "preferences": "I'm intersted in LLMs", "response": "RELEVANT"}
{"title": "Diagnostic Runtime Monitoring with Martingales", "authors": "Ali Hindy, Rachel Luo, Somrita Banerjee, Jonathan Kuck, Edward Schmerling, Marco Pavone", "abstract": "Machine learning systems deployed in safety-critical robotics settings must\nbe robust to distribution shifts. However, system designers must understand the\ncause of a distribution shift in order to implement the appropriate\nintervention or mitigation strategy and prevent system failure. In this paper,\nwe present a novel framework for diagnosing distribution shifts in a streaming\nfashion by deploying multiple stochastic martingales simultaneously. We show\nthat knowledge of the underlying cause of a distribution shift can lead to\nproper interventions over the lifecycle of a deployed system. Our experimental\nframework can easily be adapted to different types of distribution shifts,\nmodels, and datasets. We find that our method outperforms existing work on\ndiagnosing distribution shifts in terms of speed, accuracy, and flexibility,\nand validate the efficiency of our model in both simulated and live hardware\nsettings.", "arxiv_id": "http://arxiv.org/abs/2407.21748v1", "pdf_url": "http://arxiv.org/pdf/2407.21748v1", "primary_category": "cs.RO", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "HGOE: Hybrid External and Internal Graph Outlier Exposure for Graph Out-of-Distribution Detection", "authors": "Junwei He, Qianqian Xu, Yangbangyan Jiang, Zitai Wang, Yuchen Sun, Qingming Huang", "abstract": "With the progressive advancements in deep graph learning, out-of-distribution\n(OOD) detection for graph data has emerged as a critical challenge. While the\nefficacy of auxiliary datasets in enhancing OOD detection has been extensively\nstudied for image and text data, such approaches have not yet been explored for\ngraph data. Unlike Euclidean data, graph data exhibits greater diversity but\nlower robustness to perturbations, complicating the integration of outliers. To\ntackle these challenges, we propose the introduction of \\textbf{H}ybrid\nExternal and Internal \\textbf{G}raph \\textbf{O}utlier \\textbf{E}xposure (HGOE)\nto improve graph OOD detection performance. Our framework involves using\nrealistic external graph data from various domains and synthesizing internal\noutliers within ID subgroups to address the poor robustness and presence of OOD\nsamples within the ID class. Furthermore, we develop a boundary-aware OE loss\nthat adaptively assigns weights to outliers, maximizing the use of high-quality\nOOD samples while minimizing the impact of low-quality ones. Our proposed HGOE\nframework is model-agnostic and designed to enhance the effectiveness of\nexisting graph OOD detection models. Experimental results demonstrate that our\nHGOE framework can significantly improve the performance of existing OOD\ndetection models across all 8 real datasets.", "arxiv_id": "http://arxiv.org/abs/2407.21742v1", "pdf_url": "http://arxiv.org/pdf/2407.21742v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Contrastive Factor Analysis", "authors": "Zhibin Duan, Tiansheng Wen, Yifei Wang, Chen Zhu, Bo Chen, Mingyuan Zhou", "abstract": "Factor analysis, often regarded as a Bayesian variant of matrix\nfactorization, offers superior capabilities in capturing uncertainty, modeling\ncomplex dependencies, and ensuring robustness. As the deep learning era\narrives, factor analysis is receiving less and less attention due to their\nlimited expressive ability. On the contrary, contrastive learning has emerged\nas a potent technique with demonstrated efficacy in unsupervised\nrepresentational learning. While the two methods are different paradigms,\nrecent theoretical analysis has revealed the mathematical equivalence between\ncontrastive learning and matrix factorization, providing a potential\npossibility for factor analysis combined with contrastive learning. Motivated\nby the interconnectedness of contrastive learning, matrix factorization, and\nfactor analysis, this paper introduces a novel Contrastive Factor Analysis\nframework, aiming to leverage factor analysis's advantageous properties within\nthe realm of contrastive learning. To further leverage the interpretability\nproperties of non-negative factor analysis, which can learn disentangled\nrepresentations, contrastive factor analysis is extended to a non-negative\nversion. Finally, extensive experimental validation showcases the efficacy of\nthe proposed contrastive (non-negative) factor analysis methodology across\nmultiple key properties, including expressiveness, robustness,\ninterpretability, and accurate uncertainty estimation.", "arxiv_id": "http://arxiv.org/abs/2407.21740v2", "pdf_url": "http://arxiv.org/pdf/2407.21740v2", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "A Federated Learning-Friendly Approach for Parameter-Efficient Fine-Tuning of SAM in 3D Segmentation", "authors": "Mothilal Asokan, Joseph Geo Benjamin, Mohammad Yaqub, Karthik Nandakumar", "abstract": "Adapting foundation models for medical image analysis requires finetuning\nthem on a considerable amount of data because of extreme distribution shifts\nbetween natural (source) data used for pretraining and medical (target) data.\nHowever, collecting task-specific medical data for such finetuning at a central\nlocation raises many privacy concerns. Although Federated learning (FL)\nprovides an effective means for training on private decentralized data,\ncommunication costs in federating large foundation models can quickly become a\nsignificant bottleneck, impacting the solution's scalability. In this work, we\naddress this problem of efficient communication while ensuring effective\nlearning in FL by combining the strengths of Parameter-Efficient Fine-tuning\n(PEFT) with FL. Specifically, we study plug-and-play Low-Rank Adapters (LoRA)\nin a federated manner to adapt the Segment Anything Model (SAM) for 3D medical\nimage segmentation. Unlike prior works that utilize LoRA and finetune the\nentire decoder, we critically analyze the contribution of each granular\ncomponent of SAM on finetuning performance. Thus, we identify specific layers\nto be federated that are very efficient in terms of communication cost while\nproducing on-par accuracy. Our experiments show that retaining the parameters\nof the SAM model (including most of the decoder) in their original state during\nadaptation is beneficial because fine-tuning on small datasets tends to distort\nthe inherent capabilities of the underlying foundation model. On Fed-KiTS, our\napproach decreases communication cost (~48x) compared to full fine-tuning while\nincreasing performance (~6% Dice score) in 3D segmentation tasks. Our approach\nperforms similar to SAMed while achieving ~2.8x reduction in communication and\nparameters to be finetuned. We further validate our approach with experiments\non Fed-IXI and Prostate MRI datasets.", "arxiv_id": "http://arxiv.org/abs/2407.21739v1", "pdf_url": "http://arxiv.org/pdf/2407.21739v1", "primary_category": "cs.CV", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Leveraging Self-Supervised Learning for Fetal Cardiac Planes Classification using Ultrasound Scan Videos", "authors": "Joseph Geo Benjamin, Mothilal Asokan, Amna Alhosani, Hussain Alasmawi, Werner Gerhard Diehl, Leanne Bricker, Karthik Nandakumar, Mohammad Yaqub", "abstract": "Self-supervised learning (SSL) methods are popular since they can address\nsituations with limited annotated data by directly utilising the underlying\ndata distribution. However, the adoption of such methods is not explored enough\nin ultrasound (US) imaging, especially for fetal assessment. We investigate the\npotential of dual-encoder SSL in utilizing unlabelled US video data to improve\nthe performance of challenging downstream Standard Fetal Cardiac Planes (SFCP)\nclassification using limited labelled 2D US images. We study 7 SSL approaches\nbased on reconstruction, contrastive loss, distillation, and information theory\nand evaluate them extensively on a large private US dataset. Our observations\nand findings are consolidated from more than 500 downstream training\nexperiments under different settings. Our primary observation shows that for\nSSL training, the variance of the dataset is more crucial than its size because\nit allows the model to learn generalisable representations, which improve the\nperformance of downstream tasks. Overall, the BarlowTwins method shows robust\nperformance, irrespective of the training settings and data variations, when\nused as an initialisation for downstream tasks. Notably, full fine-tuning with\n1% of labelled data outperforms ImageNet initialisation by 12% in F1-score and\noutperforms other SSL initialisations by at least 4% in F1-score, thus making\nit a promising candidate for transfer learning from US video to image data.", "arxiv_id": "http://arxiv.org/abs/2407.21738v1", "pdf_url": "http://arxiv.org/pdf/2407.21738v1", "primary_category": "eess.IV", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Social Learning through Interactions with Other Agents: A Survey", "authors": "Dylan hillier, Cheston Tan, Jing Jiang", "abstract": "Social learning plays an important role in the development of human\nintelligence. As children, we imitate our parents' speech patterns until we are\nable to produce sounds; we learn from them praising us and scolding us; and as\nadults, we learn by working with others. In this work, we survey the degree to\nwhich this paradigm -- social learning -- has been mirrored in machine\nlearning. In particular, since learning socially requires interacting with\nothers, we are interested in how embodied agents can and have utilised these\ntechniques. This is especially in light of the degree to which recent advances\nin natural language processing (NLP) enable us to perform new forms of social\nlearning. We look at how behavioural cloning and next-token prediction mirror\nhuman imitation, how learning from human feedback mirrors human education, and\nhow we can go further to enable fully communicative agents that learn from each\nother. We find that while individual social learning techniques have been used\nsuccessfully, there has been little unifying work showing how to bring them\ntogether into socially embodied agents.", "arxiv_id": "http://arxiv.org/abs/2407.21713v1", "pdf_url": "http://arxiv.org/pdf/2407.21713v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "RELEVANT"}
{"title": "Universal Approximation Theory: Foundations for Parallelism in Neural Networks", "authors": "Wei Wang, Qing Li", "abstract": "Neural networks are increasingly evolving towards training large models with\nbig data, a method that has demonstrated superior performance across many\ntasks. However, this approach introduces an urgent problem: current deep\nlearning models are predominantly serial, meaning that as the number of network\nlayers increases, so do the training and inference times. This is unacceptable\nif deep learning is to continue advancing. Therefore, this paper proposes a\ndeep learning parallelization strategy based on the Universal Approximation\nTheorem (UAT). From this foundation, we designed a parallel network called\nPara-Former to test our theory. Unlike traditional serial models, the inference\ntime of Para-Former does not increase with the number of layers, significantly\naccelerating the inference speed of multi-layer networks. Experimental results\nvalidate the effectiveness of this network.", "arxiv_id": "http://arxiv.org/abs/2407.21670v1", "pdf_url": "http://arxiv.org/pdf/2407.21670v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Synth-Empathy: Towards High-Quality Synthetic Empathy Data", "authors": "Hao Liang, Linzhuang Sun, Jingxuan Wei, Xijie Huang, Linkun Sun, Bihui Yu, Conghui He, Wentao Zhang", "abstract": "In recent years, with the rapid advancements in large language models (LLMs),\nachieving excellent empathetic response capabilities has become a crucial\nprerequisite. Consequently, managing and understanding empathetic datasets have\ngained increasing significance. However, empathetic data are typically\nhuman-labeled, leading to insufficient datasets and wasted human labor. In this\nwork, we present Synth-Empathy, an LLM-based data generation and quality and\ndiversity selection pipeline that automatically generates high-quality\nempathetic data while discarding low-quality data. With the data generated from\na low empathetic model, we are able to further improve empathetic response\nperformance and achieve state-of-the-art (SoTA) results across multiple\nbenchmarks. Moreover, our model achieves SoTA performance on various human\nevaluation benchmarks, demonstrating its effectiveness and robustness in\nreal-world applications. Furthermore, we show the trade-off between data\nquantity and quality, providing insights into empathetic data generation and\nselection.", "arxiv_id": "http://arxiv.org/abs/2407.21669v1", "pdf_url": "http://arxiv.org/pdf/2407.21669v1", "primary_category": "cs.CL", "preferences": "I'm intersted in LLMs", "response": "RELEVANT"}
{"title": "An Explainable Vision Transformer with Transfer Learning Combined with Support Vector Machine Based Efficient Drought Stress Identification", "authors": "Aswini Kumar Patra, Ankit Varshney, Lingaraj Sahoo", "abstract": "Early detection of drought stress is critical for taking timely measures for\nreducing crop loss before the drought impact becomes irreversible. The subtle\nphenotypical and physiological changes in response to drought stress are\ncaptured by non-invasive imaging techniques and these imaging data serve as\nvaluable resource for machine learning methods to identify drought stress.\nWhile convolutional neural networks (CNNs) are in wide use, vision transformers\n(ViTs) present a promising alternative in capturing long-range dependencies and\nintricate spatial relationships, thereby enhancing the detection of subtle\nindicators of drought stress. We propose an explainable deep learning pipeline\nthat leverages the power of ViTs for drought stress detection in potato crops\nusing aerial imagery. We applied two distinct approaches: a synergistic\ncombination of ViT and support vector machine (SVM), where ViT extracts\nintricate spatial features from aerial images, and SVM classifies the crops as\nstressed or healthy and an end-to-end approach using a dedicated classification\nlayer within ViT to directly detect drought stress. Our key findings explain\nthe ViT model's decision-making process by visualizing attention maps. These\nmaps highlight the specific spatial features within the aerial images that the\nViT model focuses as the drought stress signature. Our findings demonstrate\nthat the proposed methods not only achieve high accuracy in drought stress\nidentification but also shedding light on the diverse subtle plant features\nassociated with drought stress. This offers a robust and interpretable solution\nfor drought stress monitoring for farmers to undertake informed decisions for\nimproved crop management.", "arxiv_id": "http://arxiv.org/abs/2407.21666v1", "pdf_url": "http://arxiv.org/pdf/2407.21666v1", "primary_category": "cs.CV", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "A State-of-the-Art Review of Computational Models for Analyzing Longitudinal Wearable Sensor Data in Healthcare", "authors": "Paula Lago", "abstract": "Wearable devices are increasingly used as tools for biomedical research, as\nthe continuous stream of behavioral and physiological data they collect can\nprovide insights about our health in everyday contexts. Long-term tracking,\ndefined in the timescale of months of year, can provide insights of patterns\nand changes as indicators of health changes. These insights can make medicine\nand healthcare more predictive, preventive, personalized, and participative\n(The 4P's). However, the challenges in modeling, understanding and processing\nlongitudinal data are a significant barrier to their adoption in research\nstudies and clinical settings. In this paper, we review and discuss three\nmodels used to make sense of longitudinal data: routines, rhythms and stability\nmetrics. We present the challenges associated with the processing and analysis\nof longitudinal wearable sensor data, with a special focus on how to handle the\ndifferent temporal dynamics at various granularities. We then discuss current\nlimitations and identify directions for future work. This review is essential\nto the advancement of computational modeling and analysis of longitudinal\nsensor data for pervasive healthcare.", "arxiv_id": "http://arxiv.org/abs/2407.21665v1", "pdf_url": "http://arxiv.org/pdf/2407.21665v1", "primary_category": "cs.HC", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Beat this! Accurate beat tracking without DBN postprocessing", "authors": "Francesco Foscarin, Jan Schl\u00fcter, Gerhard Widmer", "abstract": "We propose a system for tracking beats and downbeats with two objectives:\ngenerality across a diverse music range, and high accuracy. We achieve\ngenerality by training on multiple datasets -- including solo instrument\nrecordings, pieces with time signature changes, and classical music with high\ntempo variations -- and by removing the commonly used Dynamic Bayesian Network\n(DBN) postprocessing, which introduces constraints on the meter and tempo. For\nhigh accuracy, among other improvements, we develop a loss function tolerant to\nsmall time shifts of annotations, and an architecture alternating convolutions\nwith transformers either over frequency or time. Our system surpasses the\ncurrent state of the art in F1 score despite using no DBN. However, it can\nstill fail, especially for difficult and underrepresented genres, and performs\nworse on continuity metrics, so we publish our model, code, and preprocessed\ndatasets, and invite others to beat this.", "arxiv_id": "http://arxiv.org/abs/2407.21658v1", "pdf_url": "http://arxiv.org/pdf/2407.21658v1", "primary_category": "cs.SD", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Comgra: A Tool for Analyzing and Debugging Neural Networks", "authors": "Florian Dietz, Sophie Fellenz, Dietrich Klakow, Marius Kloft", "abstract": "Neural Networks are notoriously difficult to inspect. We introduce comgra, an\nopen source python library for use with PyTorch. Comgra extracts data about the\ninternal activations of a model and organizes it in a GUI (graphical user\ninterface). It can show both summary statistics and individual data points,\ncompare early and late stages of training, focus on individual samples of\ninterest, and visualize the flow of the gradient through the network. This\nmakes it possible to inspect the model's behavior from many different angles\nand save time by rapidly testing different hypotheses without having to rerun\nit. Comgra has applications for debugging, neural architecture design, and\nmechanistic interpretability. We publish our library through Python Package\nIndex (PyPI) and provide code, documentation, and tutorials at\nhttps://github.com/FlorianDietz/comgra.", "arxiv_id": "http://arxiv.org/abs/2407.21656v1", "pdf_url": "http://arxiv.org/pdf/2407.21656v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Spatial Transformer Network YOLO Model for Agricultural Object Detection", "authors": "Yash Zambre, Ekdev Rajkitkul, Akshatha Mohan, Joshua Peeples", "abstract": "Object detection plays a crucial role in the field of computer vision by\nautonomously identifying and locating objects of interest. The You Only Look\nOnce (YOLO) model is an effective single-shot detector. However, YOLO faces\nchallenges in cluttered or partially occluded scenes and can struggle with\nsmall, low-contrast objects. We propose a new method that integrates spatial\ntransformer networks (STNs) into YOLO to improve performance. The proposed\nSTN-YOLO aims to enhance the model's effectiveness by focusing on important\nareas of the image and improving the spatial invariance of the model before the\ndetection process. Our proposed method improved object detection performance\nboth qualitatively and quantitatively. We explore the impact of different\nlocalization networks within the STN module as well as the robustness of the\nmodel across different spatial transformations. We apply the STN-YOLO on\nbenchmark datasets for Agricultural object detection as well as a new dataset\nfrom a state-of-the-art plant phenotyping greenhouse facility. Our code and\ndataset are publicly available.", "arxiv_id": "http://arxiv.org/abs/2407.21652v1", "pdf_url": "http://arxiv.org/pdf/2407.21652v1", "primary_category": "cs.CV", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Lyapunov weights to convey the meaning of time in physics-informed neural networks", "authors": "Gabriel Turinici", "abstract": "Time is not a dimension as the others. In Physics-Informed Neural Networks\n(PINN) several proposals attempted to adapt the time sampling or time weighting\nto take into account the specifics of this special dimension. But these\nproposals are not principled and need guidance to be used. We explain here\ntheoretically why the Lyapunov exponents give actionable insights and propose a\nweighting scheme to automatically adapt to chaotic, periodic or stable\ndynamics. We characterize theoretically the best weighting scheme under\ncomputational constraints as a cumulative exponential integral of the local\nLyapunov exponent estimators and show that it performs well in practice under\nthe regimes mentioned above.", "arxiv_id": "http://arxiv.org/abs/2407.21642v1", "pdf_url": "http://arxiv.org/pdf/2407.21642v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "MART: MultiscAle Relational Transformer Networks for Multi-agent Trajectory Prediction", "authors": "Seongju Lee, Junseok Lee, Yeonguk Yu, Taeri Kim, Kyoobin Lee", "abstract": "Multi-agent trajectory prediction is crucial to autonomous driving and\nunderstanding the surrounding environment. Learning-based approaches for\nmulti-agent trajectory prediction, such as primarily relying on graph neural\nnetworks, graph transformers, and hypergraph neural networks, have demonstrated\noutstanding performance on real-world datasets in recent years. However, the\nhypergraph transformer-based method for trajectory prediction is yet to be\nexplored. Therefore, we present a MultiscAle Relational Transformer (MART)\nnetwork for multi-agent trajectory prediction. MART is a hypergraph transformer\narchitecture to consider individual and group behaviors in transformer\nmachinery. The core module of MART is the encoder, which comprises a Pair-wise\nRelational Transformer (PRT) and a Hyper Relational Transformer (HRT). The\nencoder extends the capabilities of a relational transformer by introducing\nHRT, which integrates hyperedge features into the transformer mechanism,\npromoting attention weights to focus on group-wise relations. In addition, we\npropose an Adaptive Group Estimator (AGE) designed to infer complex group\nrelations in real-world environments. Extensive experiments on three real-world\ndatasets (NBA, SDD, and ETH-UCY) demonstrate that our method achieves\nstate-of-the-art performance, enhancing ADE/FDE by 3.9%/11.8% on the NBA\ndataset. Code is available at https://github.com/gist-ailab/MART.", "arxiv_id": "http://arxiv.org/abs/2407.21635v1", "pdf_url": "http://arxiv.org/pdf/2407.21635v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Extended Fiducial Inference: Toward an Automated Process of Statistical Inference", "authors": "Faming Liang, Sehwan Kim, Yan Sun", "abstract": "While fiducial inference was widely considered a big blunder by R.A. Fisher,\nthe goal he initially set --`inferring the uncertainty of model parameters on\nthe basis of observations' -- has been continually pursued by many\nstatisticians. To this end, we develop a new statistical inference method\ncalled extended Fiducial inference (EFI). The new method achieves the goal of\nfiducial inference by leveraging advanced statistical computing techniques\nwhile remaining scalable for big data. EFI involves jointly imputing random\nerrors realized in observations using stochastic gradient Markov chain Monte\nCarlo and estimating the inverse function using a sparse deep neural network\n(DNN). The consistency of the sparse DNN estimator ensures that the uncertainty\nembedded in observations is properly propagated to model parameters through the\nestimated inverse function, thereby validating downstream statistical\ninference. Compared to frequentist and Bayesian methods, EFI offers significant\nadvantages in parameter estimation and hypothesis testing. Specifically, EFI\nprovides higher fidelity in parameter estimation, especially when outliers are\npresent in the observations; and eliminates the need for theoretical reference\ndistributions in hypothesis testing, thereby automating the statistical\ninference process. EFI also provides an innovative framework for\nsemi-supervised learning.", "arxiv_id": "http://arxiv.org/abs/2407.21622v1", "pdf_url": "http://arxiv.org/pdf/2407.21622v1", "primary_category": "stat.ML", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Ironing the Graphs: Toward a Correct Geometric Analysis of Large-Scale Graphs", "authors": "Saloua Naama, Kav\u00e9 Salamatian, Francesco Bronzino", "abstract": "Graph embedding approaches attempt to project graphs into geometric entities,\ni.e, manifolds. The idea is that the geometric properties of the projected\nmanifolds are helpful in the inference of graph properties. However, if the\nchoice of the embedding manifold is incorrectly performed, it can lead to\nincorrect geometric inference. In this paper, we argue that the classical\nembedding techniques cannot lead to correct geometric interpretation as they\nmiss the curvature at each point, of manifold. We advocate that for doing\ncorrect geometric interpretation the embedding of graph should be done over\nregular constant curvature manifolds. To this end, we present an embedding\napproach, the discrete Ricci flow graph embedding (dRfge) based on the discrete\nRicci flow that adapts the distance between nodes in a graph so that the graph\ncan be embedded onto a constant curvature manifold that is homogeneous and\nisotropic, i.e., all directions are equivalent and distances comparable,\nresulting in correct geometric interpretations. A major contribution of this\npaper is that for the first time, we prove the convergence of discrete Ricci\nflow to a constant curvature and stable distance metrics over the edges. A\ndrawback of using the discrete Ricci flow is the high computational complexity\nthat prevented its usage in large-scale graph analysis. Another contribution of\nthis paper is a new algorithmic solution that makes it feasible to calculate\nthe Ricci flow for graphs of up to 50k nodes, and beyond. The intuitions behind\nthe discrete Ricci flow make it possible to obtain new insights into the\nstructure of large-scale graphs. We demonstrate this through a case study on\nanalyzing the internet connectivity structure between countries at the BGP\nlevel.", "arxiv_id": "http://arxiv.org/abs/2407.21609v1", "pdf_url": "http://arxiv.org/pdf/2407.21609v1", "primary_category": "cs.CG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Higher order quantum reservoir computing for non-intrusive reduced-order models", "authors": "Vinamr Jain, Romit Maulik", "abstract": "Forecasting dynamical systems is of importance to numerous real-world\napplications. When possible, dynamical systems forecasts are constructed based\non first-principles-based models such as through the use of differential\nequations. When these equations are unknown, non-intrusive techniques must be\nutilized to build predictive models from data alone. Machine learning (ML)\nmethods have recently been used for such tasks. Moreover, ML methods provide\nthe added advantage of significant reductions in time-to-solution for\npredictions in contrast with first-principle based models. However, many\nstate-of-the-art ML-based methods for forecasting rely on neural networks,\nwhich may be expensive to train and necessitate requirements for large amounts\nof memory. In this work, we propose a quantum mechanics inspired ML modeling\nstrategy for learning nonlinear dynamical systems that provides data-driven\nforecasts for complex dynamical systems with reduced training time and memory\ncosts. This approach, denoted the quantum reservoir computing technique (QRC),\nis a hybrid quantum-classical framework employing an ensemble of interconnected\nsmall quantum systems via classical linear feedback connections. By mapping the\ndynamical state to a suitable quantum representation amenable to unitary\noperations, QRC is able to predict complex nonlinear dynamical systems in a\nstable and accurate manner. We demonstrate the efficacy of this framework\nthrough benchmark forecasts of the NOAA Optimal Interpolation Sea Surface\nTemperature dataset and compare the performance of QRC to other ML methods.", "arxiv_id": "http://arxiv.org/abs/2407.21602v1", "pdf_url": "http://arxiv.org/pdf/2407.21602v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Measuring What Matters: Intrinsic Distance Preservation as a Robust Metric for Embedding Quality", "authors": "Steven N. Hart, Thomas E. Tavolara", "abstract": "Unsupervised embeddings are fundamental to numerous machine learning\napplications, yet their evaluation remains a challenging task. Traditional\nassessment methods often rely on extrinsic variables, such as performance in\ndownstream tasks, which can introduce confounding factors and mask the true\nquality of embeddings. This paper introduces the Intrinsic Distance\nPreservation Evaluation (IDPE) method, a novel approach for assessing embedding\nquality based on the preservation of Mahalanobis distances between data points\nin the original and embedded spaces. We demonstrate the limitations of\nextrinsic evaluation methods through a simple example, highlighting how they\ncan lead to misleading conclusions about embedding quality. IDPE addresses\nthese issues by providing a task-independent measure of how well embeddings\npreserve the intrinsic structure of the original data. Our method leverages\nefficient similarity search techniques to make it applicable to large-scale\ndatasets. We compare IDPE with established intrinsic metrics like\ntrustworthiness and continuity, as well as extrinsic metrics such as Average\nRank and Mean Reciprocal Rank. Our results show that IDPE offers a more\ncomprehensive and reliable assessment of embedding quality across various\nscenarios. We evaluate PCA and t-SNE embeddings using IDPE, revealing insights\ninto their performance that are not captured by traditional metrics. This work\ncontributes to the field by providing a robust, efficient, and interpretable\nmethod for embedding evaluation. IDPE's focus on intrinsic properties offers a\nvaluable tool for researchers and practitioners seeking to develop and assess\nhigh-quality embeddings for diverse machine learning applications.", "arxiv_id": "http://arxiv.org/abs/2407.21590v1", "pdf_url": "http://arxiv.org/pdf/2407.21590v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Multi-agent reinforcement learning for the control of three-dimensional Rayleigh-B\u00e9nard convection", "authors": "Joel Vasanth, Jean Rabault, Francisco Alc\u00e1ntara-\u00c1vila, Mikael Mortensen, Ricardo Vinuesa", "abstract": "Deep reinforcement learning (DRL) has found application in numerous use-cases\npertaining to flow control. Multi-agent RL (MARL), a variant of DRL, has shown\nto be more effective than single-agent RL in controlling flows exhibiting\nlocality and translational invariance. We present, for the first time, an\nimplementation of MARL-based control of three-dimensional Rayleigh-B\\'enard\nconvection (RBC). Control is executed by modifying the temperature distribution\nalong the bottom wall divided into multiple control segments, each of which\nacts as an independent agent. Two regimes of RBC are considered at Rayleigh\nnumbers $\\mathrm{Ra}=500$ and $750$. Evaluation of the learned control policy\nreveals a reduction in convection intensity by $23.5\\%$ and $8.7\\%$ at\n$\\mathrm{Ra}=500$ and $750$, respectively. The MARL controller converts\nirregularly shaped convective patterns to regular straight rolls with lower\nconvection that resemble flow in a relatively more stable regime. We draw\ncomparisons with proportional control at both $\\mathrm{Ra}$ and show that MARL\nis able to outperform the proportional controller. The learned control strategy\nis complex, featuring different non-linear segment-wise actuator delays and\nactuation magnitudes. We also perform successful evaluations on a larger domain\nthan used for training, demonstrating that the invariant property of MARL\nallows direct transfer of the learnt policy.", "arxiv_id": "http://arxiv.org/abs/2407.21565v1", "pdf_url": "http://arxiv.org/pdf/2407.21565v1", "primary_category": "physics.flu-dyn", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "CXSimulator: A User Behavior Simulation using LLM Embeddings for Web-Marketing Campaign Assessment", "authors": "Akira Kasuga, Ryo Yonetani", "abstract": "This paper presents the Customer Experience (CX) Simulator, a novel framework\ndesigned to assess the effects of untested web-marketing campaigns through user\nbehavior simulations. The proposed framework leverages large language models\n(LLMs) to represent various events in a user's behavioral history, such as\nviewing an item, applying a coupon, or purchasing an item, as semantic\nembedding vectors. We train a model to predict transitions between events from\ntheir LLM embeddings, which can even generalize to unseen events by learning\nfrom diverse training data. In web-marketing applications, we leverage this\ntransition prediction model to simulate how users might react differently when\nnew campaigns or products are presented to them. This allows us to eliminate\nthe need for costly online testing and enhance the marketers' abilities to\nreveal insights. Our numerical evaluation and user study, utilizing BigQuery\nPublic Datasets from the Google Merchandise Store, demonstrate the\neffectiveness of our framework.", "arxiv_id": "http://arxiv.org/abs/2407.21553v1", "pdf_url": "http://arxiv.org/pdf/2407.21553v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "RELEVANT"}
{"title": "Black box meta-learning intrinsic rewards for sparse-reward environments", "authors": "Octavio Pappalardo, Rodrigo Ramele, Juan Miguel Santos", "abstract": "Despite the successes and progress of deep reinforcement learning over the\nlast decade, several challenges remain that hinder its broader application.\nSome fundamental aspects to improve include data efficiency, generalization\ncapability, and ability to learn in sparse-reward environments, which often\nrequire human-designed dense rewards. Meta-learning has emerged as a promising\napproach to address these issues by optimizing components of the learning\nalgorithm to meet desired characteristics. Additionally, a different line of\nwork has extensively studied the use of intrinsic rewards to enhance the\nexploration capabilities of algorithms. This work investigates how\nmeta-learning can improve the training signal received by RL agents. The focus\nis on meta-learning intrinsic rewards under a framework that doesn't rely on\nthe use of meta-gradients. We analyze and compare this approach to the use of\nextrinsic rewards and a meta-learned advantage function. The developed\nalgorithms are evaluated on distributions of continuous control tasks with both\nparametric and non-parametric variations, and with only sparse rewards\naccessible for the evaluation tasks.", "arxiv_id": "http://arxiv.org/abs/2407.21546v1", "pdf_url": "http://arxiv.org/pdf/2407.21546v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Probabilistic Scoring Lists for Interpretable Machine Learning", "authors": "Jonas Hanselle, Stefan Heid, Johannes F\u00fcrnkranz, Eyke H\u00fcllermeier", "abstract": "A scoring system is a simple decision model that checks a set of features,\nadds a certain number of points to a total score for each feature that is\nsatisfied, and finally makes a decision by comparing the total score to a\nthreshold. Scoring systems have a long history of active use in safety-critical\ndomains such as healthcare and justice, where they provide guidance for making\nobjective and accurate decisions. Given their genuine interpretability, the\nidea of learning scoring systems from data is obviously appealing from the\nperspective of explainable AI. In this paper, we propose a practically\nmotivated extension of scoring systems called probabilistic scoring lists\n(PSL), as well as a method for learning PSLs from data. Instead of making a\ndeterministic decision, a PSL represents uncertainty in the form of probability\ndistributions, or, more generally, probability intervals. Moreover, in the\nspirit of decision lists, a PSL evaluates features one by one and stops as soon\nas a decision can be made with enough confidence. To evaluate our approach, we\nconduct a case study in the medical domain.", "arxiv_id": "http://arxiv.org/abs/2407.21535v1", "pdf_url": "http://arxiv.org/pdf/2407.21535v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Data Contamination Report from the 2024 CONDA Shared Task", "authors": "Oscar Sainz, Iker Garc\u00eda-Ferrero, Alon Jacovi, Jon Ander Campos, Yanai Elazar, Eneko Agirre, Yoav Goldberg, Wei-Lin Chen, Jenny Chim, Leshem Choshen, Luca D'Amico-Wong, Melissa Dell, Run-Ze Fan, Shahriar Golchin, Yucheng Li, Pengfei Liu, Bhavish Pahwa, Ameya Prabhu, Suryansh Sharma, Emily Silcock, Kateryna Solonko, David Stap, Mihai Surdeanu, Yu-Min Tseng, Vishaal Udandarao, Zengzhi Wang, Ruijie Xu, Jinglin Yang", "abstract": "The 1st Workshop on Data Contamination (CONDA 2024) focuses on all relevant\naspects of data contamination in natural language processing, where data\ncontamination is understood as situations where evaluation data is included in\npre-training corpora used to train large scale models, compromising evaluation\nresults. The workshop fostered a shared task to collect evidence on data\ncontamination in current available datasets and models. The goal of the shared\ntask and associated database is to assist the community in understanding the\nextent of the problem and to assist researchers in avoiding reporting\nevaluation results on known contaminated resources. The shared task provides a\nstructured, centralized public database for the collection of contamination\nevidence, open to contributions from the community via GitHub pool requests.\nThis first compilation paper is based on 566 reported entries over 91\ncontaminated sources from a total of 23 contributors. The details of the\nindividual contamination events are available in the platform. The platform\ncontinues to be online, open to contributions from the community.", "arxiv_id": "http://arxiv.org/abs/2407.21530v1", "pdf_url": "http://arxiv.org/pdf/2407.21530v1", "primary_category": "cs.CL", "preferences": "I'm intersted in LLMs", "response": "RELEVANT"}
{"title": "Tabular Data Augmentation for Machine Learning: Progress and Prospects of Embracing Generative AI", "authors": "Lingxi Cui, Huan Li, Ke Chen, Lidan Shou, Gang Chen", "abstract": "Machine learning (ML) on tabular data is ubiquitous, yet obtaining abundant\nhigh-quality tabular data for model training remains a significant obstacle.\nNumerous works have focused on tabular data augmentation (TDA) to enhance the\noriginal table with additional data, thereby improving downstream ML tasks.\nRecently, there has been a growing interest in leveraging the capabilities of\ngenerative AI for TDA. Therefore, we believe it is time to provide a\ncomprehensive review of the progress and future prospects of TDA, with a\nparticular emphasis on the trending generative AI. Specifically, we present an\narchitectural view of the TDA pipeline, comprising three main procedures:\npre-augmentation, augmentation, and post-augmentation. Pre-augmentation\nencompasses preparation tasks that facilitate subsequent TDA, including error\nhandling, table annotation, table simplification, table representation, table\nindexing, table navigation, schema matching, and entity matching. Augmentation\nsystematically analyzes current TDA methods, categorized into retrieval-based\nmethods, which retrieve external data, and generation-based methods, which\ngenerate synthetic data. We further subdivide these methods based on the\ngranularity of the augmentation process at the row, column, cell, and table\nlevels. Post-augmentation focuses on the datasets, evaluation and optimization\naspects of TDA. We also summarize current trends and future directions for TDA,\nhighlighting promising opportunities in the era of generative AI. In addition,\nthe accompanying papers and related resources are continuously updated and\nmaintained in the GitHub repository at\nhttps://github.com/SuDIS-ZJU/awesome-tabular-data-augmentation to reflect\nongoing advancements in the field.", "arxiv_id": "http://arxiv.org/abs/2407.21523v1", "pdf_url": "http://arxiv.org/pdf/2407.21523v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "FSSC: Federated Learning of Transformer Neural Networks for Semantic Image Communication", "authors": "Yuna Yan, Xin Zhang, Lixin Li, Wensheng Lin, Rui Li, Wenchi Cheng, Zhu Han", "abstract": "In this paper, we address the problem of image semantic communication in a\nmulti-user deployment scenario and propose a federated learning (FL) strategy\nfor a Swin Transformer-based semantic communication system (FSSC). Firstly, we\ndemonstrate that the adoption of a Swin Transformer for joint source-channel\ncoding (JSCC) effectively extracts semantic information in the communication\nsystem. Next, the FL framework is introduced to collaboratively learn a global\nmodel by aggregating local model parameters, rather than directly sharing\nclients' data. This approach enhances user privacy protection and reduces the\nworkload on the server or mobile edge. Simulation evaluations indicate that our\nmethod outperforms the typical JSCC algorithm and traditional separate-based\ncommunication algorithms. Particularly after integrating local semantics, the\nglobal aggregation model has further increased the Peak Signal-to-Noise Ratio\n(PSNR) by more than 2dB, thoroughly proving the effectiveness of our algorithm.", "arxiv_id": "http://arxiv.org/abs/2407.21507v1", "pdf_url": "http://arxiv.org/pdf/2407.21507v1", "primary_category": "cs.AI", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Root Cause Analysis Of Productivity Losses In Manufacturing Systems Utilizing Ensemble Machine Learning", "authors": "Jonas Gram, Brandon K. Sai, Thomas Bauernhansl", "abstract": "In today's rapidly evolving landscape of automation and manufacturing\nsystems, the efficient resolution of productivity losses is paramount. This\nstudy introduces a data-driven ensemble approach, utilizing the cyclic\nmultivariate time series data from binary sensors and signals from Programmable\nLogic Controllers (PLCs) within these systems. The objective is to\nautomatically analyze productivity losses per cycle and pinpoint their root\ncauses by assigning the loss to a system element. The ensemble approach\nintroduced in this publication integrates various methods, including\ninformation theory and machine learning behavior models, to provide a robust\nanalysis for each production cycle. To expedite the resolution of productivity\nlosses and ensure short response times, stream processing becomes a necessity.\nAddressing this, the approach is implemented as data-stream analysis and can be\ntransferred to batch processing, seamlessly integrating into existing systems\nwithout the need for extensive historical data analysis. This method has two\npositive effects. Firstly, the result of the analysis ensures that the period\nof lower productivity is reduced by identifying the likely root cause of the\nproductivity loss. Secondly, these results are more reliable due to the\nensemble approach and therefore avoid dependency on technical experts. The\napproach is validated using a semi-automated welding manufacturing system, an\ninjection molding automation system, and a synthetically generated test PLC\ndataset. The results demonstrate the method's efficacy in offering a\ndata-driven understanding of process behavior and mark an advancement in\nautonomous manufacturing system analysis.", "arxiv_id": "http://arxiv.org/abs/2407.21503v1", "pdf_url": "http://arxiv.org/pdf/2407.21503v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Explainable and Controllable Motion Curve Guided Cardiac Ultrasound Video Generation", "authors": "Junxuan Yu, Rusi Chen, Yongsong Zhou, Yanlin Chen, Yaofei Duan, Yuhao Huang, Han Zhou, Tan Tao, Xin Yang, Dong Ni", "abstract": "Echocardiography video is a primary modality for diagnosing heart diseases,\nbut the limited data poses challenges for both clinical teaching and machine\nlearning training. Recently, video generative models have emerged as a\npromising strategy to alleviate this issue. However, previous methods often\nrelied on holistic conditions during generation, hindering the flexible\nmovement control over specific cardiac structures. In this context, we propose\nan explainable and controllable method for echocardiography video generation,\ntaking an initial frame and a motion curve as guidance. Our contributions are\nthree-fold. First, we extract motion information from each heart substructure\nto construct motion curves, enabling the diffusion model to synthesize\ncustomized echocardiography videos by modifying these curves. Second, we\npropose the structure-to-motion alignment module, which can map semantic\nfeatures onto motion curves across cardiac structures. Third, The\nposition-aware attention mechanism is designed to enhance video consistency\nutilizing Gaussian masks with structural position information. Extensive\nexperiments on three echocardiography datasets show that our method outperforms\nothers regarding fidelity and consistency. The full code will be released at\nhttps://github.com/mlmi-2024-72/ECM.", "arxiv_id": "http://arxiv.org/abs/2407.21490v1", "pdf_url": "http://arxiv.org/pdf/2407.21490v1", "primary_category": "eess.IV", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "On the Problem of Text-To-Speech Model Selection for Synthetic Data Generation in Automatic Speech Recognition", "authors": "Nick Rossenbach, Ralf Schl\u00fcter, Sakriani Sakti", "abstract": "The rapid development of neural text-to-speech (TTS) systems enabled its\nusage in other areas of natural language processing such as automatic speech\nrecognition (ASR) or spoken language translation (SLT). Due to the large number\nof different TTS architectures and their extensions, selecting which TTS\nsystems to use for synthetic data creation is not an easy task. We use the\ncomparison of five different TTS decoder architectures in the scope of\nsynthetic data generation to show the impact on CTC-based speech recognition\ntraining. We compare the recognition results to computable metrics like NISQA\nMOS and intelligibility, finding that there are no clear relations to the ASR\nperformance. We also observe that for data generation auto-regressive decoding\nperforms better than non-autoregressive decoding, and propose an approach to\nquantify TTS generalization capabilities.", "arxiv_id": "http://arxiv.org/abs/2407.21476v1", "pdf_url": "http://arxiv.org/pdf/2407.21476v1", "primary_category": "cs.CL", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Multi-agent Assessment with QoS Enhancement for HD Map Updates in a Vehicular Network", "authors": "Jeffrey Redondo, Nauman Aslam, Juan Zhang, Zhenhui Yuan", "abstract": "Reinforcement Learning (RL) algorithms have been used to address the\nchallenging problems in the offloading process of vehicular ad hoc networks\n(VANET). More recently, they have been utilized to improve the dissemination of\nhigh-definition (HD) Maps. Nevertheless, implementing solutions such as deep\nQ-learning (DQN) and Actor-critic at the autonomous vehicle (AV) may lead to an\nincrease in the computational load, causing a heavy burden on the computational\ndevices and higher costs. Moreover, their implementation might raise\ncompatibility issues between technologies due to the required modifications to\nthe standards. Therefore, in this paper, we assess the scalability of an\napplication utilizing a Q-learning single-agent solution in a distributed\nmulti-agent environment. This application improves the network performance by\ntaking advantage of a smaller state, and action space whilst using a\nmulti-agent approach. The proposed solution is extensively evaluated with\ndifferent test cases involving reward function considering individual or\noverall network performance, number of agents, and centralized and distributed\nlearning comparison. The experimental results demonstrate that the time\nlatencies of our proposed solution conducted in voice, video, HD Map, and\nbest-effort cases have significant improvements, with 40.4%, 36%, 43%, and 12%\nrespectively, compared to the performances with the single-agent approach.", "arxiv_id": "http://arxiv.org/abs/2407.21460v1", "pdf_url": "http://arxiv.org/pdf/2407.21460v1", "primary_category": "cs.AI", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "TinyChirp: Bird Song Recognition Using TinyML Models on Low-power Wireless Acoustic Sensors", "authors": "Zhaolan Huang, Adrien Tousnakhoff, Polina Kozyr, Roman Rehausen, Felix Bie\u00dfmann, Robert Lachlan, Cedric Adjih, Emmanuel Baccelli", "abstract": "Monitoring biodiversity at scale is challenging. Detecting and identifying\nspecies in fine grained taxonomies requires highly accurate machine learning\n(ML) methods. Training such models requires large high quality data sets. And\ndeploying these models to low power devices requires novel compression\ntechniques and model architectures. While species classification methods have\nprofited from novel data sets and advances in ML methods, in particular neural\nnetworks, deploying these state of the art models to low power devices remains\ndifficult. Here we present a comprehensive empirical comparison of various\ntinyML neural network architectures and compression techniques for species\nclassification. We focus on the example of bird song detection, more concretely\na data set curated for studying the corn bunting bird species. The data set is\nreleased along with all code and experiments of this study. In our experiments\nwe compare predictive performance, memory and time complexity of classical\nspectrogram based methods and recent approaches operating on raw audio signal.\nOur results indicate that individual bird species can be robustly detected with\nrelatively simple architectures that can be readily deployed to low power\ndevices.", "arxiv_id": "http://arxiv.org/abs/2407.21453v1", "pdf_url": "http://arxiv.org/pdf/2407.21453v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "MLLM Is a Strong Reranker: Advancing Multimodal Retrieval-augmented Generation via Knowledge-enhanced Reranking and Noise-injected Training", "authors": "Zhanpeng Chen, Chengjin Xu, Yiyan Qi, Jian Guo", "abstract": "Multimodal Large Language Models (MLLMs) have demonstrated remarkable\ncapabilities in processing and generating content across multiple data\nmodalities, including text, images, audio, and video. However, a significant\ndrawback of MLLMs is their reliance on static training data, leading to\noutdated information and limited contextual awareness. This static nature\nhampers their ability to provide accurate, up-to-date responses, particularly\nin dynamic or rapidly evolving contexts. Integrating Multimodal\nRetrieval-augmented Generation (Multimodal RAG) offers a promising solution,\nbut the system would inevitably encounter the multi-granularity noisy\ncorrespondence (MNC) problem, which involves two types of noise: coarse-grained\n(query-caption) and fine-grained (query-image). This noise hinders accurate\nretrieval and generation. In this work, we propose \\textbf{RagLLaVA}, a novel\nframework with knowledge-enhanced reranking and noise-injected training, to\naddress these limitations. We instruction-tune the MLLM with a simple yet\neffective instruction template to induce its ranking ability and serve it as a\nreranker to precisely filter the top-k retrieved images. For generation, we\ninject visual noise during training at the data and token levels to enhance the\ngenerator's robustness. Extensive experiments are conducted on the subsets of\ntwo datasets that require retrieving and reasoning over images to answer a\ngiven query. Our results demonstrate the superiority of RagLLaVA in retrieving\naccurately and generating robustly. Code and models are available at\nhttps://github.com/IDEA-FinAI/RagLLaVA.", "arxiv_id": "http://arxiv.org/abs/2407.21439v1", "pdf_url": "http://arxiv.org/pdf/2407.21439v1", "primary_category": "cs.AI", "preferences": "I'm intersted in LLMs", "response": "RELEVANT"}
{"title": "Transient anisotropic kernel for probabilistic learning on manifolds", "authors": "Christian Soize, Roger Ghanem", "abstract": "PLoM (Probabilistic Learning on Manifolds) is a method introduced in 2016 for\nhandling small training datasets by projecting an It\\^o equation from a\nstochastic dissipative Hamiltonian dynamical system, acting as the MCMC\ngenerator, for which the KDE-estimated probability measure with the training\ndataset is the invariant measure. PLoM performs a projection on a reduced-order\nvector basis related to the training dataset, using the diffusion maps (DMAPS)\nbasis constructed with a time-independent isotropic kernel. In this paper, we\npropose a new ISDE projection vector basis built from a transient anisotropic\nkernel, providing an alternative to the DMAPS basis to improve statistical\nsurrogates for stochastic manifolds with heterogeneous data. The construction\nensures that for times near the initial time, the DMAPS basis coincides with\nthe transient basis. For larger times, the differences between the two bases\nare characterized by the angle of their spanned vector subspaces. The optimal\ninstant yielding the optimal transient basis is determined using an estimation\nof mutual information from Information Theory, which is normalized by the\nentropy estimation to account for the effects of the number of realizations\nused in the estimations. Consequently, this new vector basis better represents\nstatistical dependencies in the learned probability measure for any dimension.\nThree applications with varying levels of statistical complexity and data\nheterogeneity validate the proposed theory, showing that the transient\nanisotropic kernel improves the learned probability measure.", "arxiv_id": "http://arxiv.org/abs/2407.21435v1", "pdf_url": "http://arxiv.org/pdf/2407.21435v1", "primary_category": "stat.ML", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Cost-Effective Hallucination Detection for LLMs", "authors": "Simon Valentin, Jinmiao Fu, Gianluca Detommaso, Shaoyuan Xu, Giovanni Zappella, Bryan Wang", "abstract": "Large language models (LLMs) can be prone to hallucinations - generating\nunreliable outputs that are unfaithful to their inputs, external facts or\ninternally inconsistent. In this work, we address several challenges for\npost-hoc hallucination detection in production settings. Our pipeline for\nhallucination detection entails: first, producing a confidence score\nrepresenting the likelihood that a generated answer is a hallucination; second,\ncalibrating the score conditional on attributes of the inputs and candidate\nresponse; finally, performing detection by thresholding the calibrated score.\nWe benchmark a variety of state-of-the-art scoring methods on different\ndatasets, encompassing question answering, fact checking, and summarization\ntasks. We employ diverse LLMs to ensure a comprehensive assessment of\nperformance. We show that calibrating individual scoring methods is critical\nfor ensuring risk-aware downstream decision making. Based on findings that no\nindividual score performs best in all situations, we propose a multi-scoring\nframework, which combines different scores and achieves top performance across\nall datasets. We further introduce cost-effective multi-scoring, which can\nmatch or even outperform more expensive detection methods, while significantly\nreducing computational overhead.", "arxiv_id": "http://arxiv.org/abs/2407.21424v1", "pdf_url": "http://arxiv.org/pdf/2407.21424v1", "primary_category": "cs.CL", "preferences": "I'm intersted in LLMs", "response": "RELEVANT"}
{"title": "FTuner: A Fast Dynamic Shape Tensors Program Auto-Tuner for Deep Learning Compilers", "authors": "Pengyu Mu, Linquan Wei, Yi Liu, Rui Wang", "abstract": "Many artificial intelligence models process input data of different lengths\nand resolutions, making the shape of the tensors dynamic. The performance of\nthese models depends on the shape of the tensors, which makes it difficult to\noptimize the tensors before the model runs. There are two common solutions to\nthis problem. The first is to add useless data to the input to match a\npre-optimized tensor library. The second is to use small basic tensors to\ncreate a tensor that is closest in size to the input data and then tune it to\nminimize padding. However, this second solution can be time-consuming.\n  This paper proposes a new technique for deep learning compilers called\nFTuner. Instead of using a large design space or training a cost model, we use\nan abstract computational unit called the uKernel to patch together small,\nvarious-sized tensors to match the shape of the input tensor. We determine the\nshape of the uKernel using an analytic hardware information model. Experiments\nshow that the FTuner can achieve comparable operators and end-to-end\nperformance to vendor libraries and achieves 3\\% speedup on existing auto-tuner\nwith the model-training compiler while reducing tuning time by two orders of\nmagnitude.", "arxiv_id": "http://arxiv.org/abs/2407.21418v1", "pdf_url": "http://arxiv.org/pdf/2407.21418v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Deep Fr\u00e9chet Regression", "authors": "Su I Iao, Yidong Zhou, Hans-Georg M\u00fcller", "abstract": "Advancements in modern science have led to the increasing availability of\nnon-Euclidean data in metric spaces. This paper addresses the challenge of\nmodeling relationships between non-Euclidean responses and multivariate\nEuclidean predictors. We propose a flexible regression model capable of\nhandling high-dimensional predictors without imposing parametric assumptions.\nTwo primary challenges are addressed: the curse of dimensionality in\nnonparametric regression and the absence of linear structure in general metric\nspaces. The former is tackled using deep neural networks, while for the latter\nwe demonstrate the feasibility of mapping the metric space where responses\nreside to a low-dimensional Euclidean space using manifold learning. We\nintroduce a reverse mapping approach, employing local Fr\\'echet regression, to\nmap the low-dimensional manifold representations back to objects in the\noriginal metric space. We develop a theoretical framework, investigating the\nconvergence rate of deep neural networks under dependent sub-Gaussian noise\nwith bias. The convergence rate of the proposed regression model is then\nobtained by expanding the scope of local Fr\\'echet regression to accommodate\nmultivariate predictors in the presence of errors in predictors. Simulations\nand case studies show that the proposed model outperforms existing methods for\nnon-Euclidean responses, focusing on the special cases of probability measures\nand networks.", "arxiv_id": "http://arxiv.org/abs/2407.21407v1", "pdf_url": "http://arxiv.org/pdf/2407.21407v1", "primary_category": "stat.ME", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "SmileyNet -- Towards the Prediction of the Lottery by Reading Tea Leaves with AI", "authors": "Andreas Birk", "abstract": "We introduce SmileyNet, a novel neural network with psychic abilities. It is\ninspired by the fact that a positive mood can lead to improved cognitive\ncapabilities including classification tasks. The network is hence presented in\na first phase with smileys and an encouraging loss function is defined to bias\nit into a good mood. SmileyNet is then used to forecast the flipping of a coin\nbased on an established method of Tasseology, namely by reading tea leaves.\nTraining and testing in this second phase are done with a high-fidelity\nsimulation based on real-world pixels sampled from a professional tea-reading\ncup. SmileyNet has an amazing accuracy of 72% to correctly predict the flip of\na coin. Resnet-34, respectively YOLOv5 achieve only 49%, respectively 53%. It\nis then shown how multiple SmileyNets can be combined to win the lottery.", "arxiv_id": "http://arxiv.org/abs/2407.21385v1", "pdf_url": "http://arxiv.org/pdf/2407.21385v1", "primary_category": "cs.AI", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Dynamic Gesture Recognition in Ultra-Range Distance for Effective Human-Robot Interaction", "authors": "Eran Bamani Beeri, Eden Nissinman, Avishai Sintov", "abstract": "This paper presents a novel approach for ultra-range gesture recognition,\naddressing Human-Robot Interaction (HRI) challenges over extended distances. By\nleveraging human gestures in video data, we propose the Temporal-Spatiotemporal\nFusion Network (TSFN) model that surpasses the limitations of current methods,\nenabling robots to understand gestures from long distances. With applications\nin service robots, search and rescue operations, and drone-based interactions,\nour approach enhances HRI in expansive environments. Experimental validation\ndemonstrates significant advancements in gesture recognition accuracy,\nparticularly in prolonged gesture sequences.", "arxiv_id": "http://arxiv.org/abs/2407.21374v1", "pdf_url": "http://arxiv.org/pdf/2407.21374v1", "primary_category": "cs.RO", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Two Completely Parameter-Free Alternating Gradient Projection Algorithms for Nonconvex-(strongly) Concave Minimax Problems", "authors": "Junnan Yang, Huiling Zhang, Zi Xu", "abstract": "Due to their importance in various emerging applications, efficient\nalgorithms for solving minimax problems have recently received increasing\nattention. However, many existing algorithms require prior knowledge of the\nproblem parameters in order to achieve optimal iteration complexity. In this\npaper, we propose a completely parameter-free alternating gradient projection\n(PF-AGP) algorithm to solve the smooth nonconvex-(strongly) concave minimax\nproblems using a backtracking strategy, which does not require prior knowledge\nof parameters such as the Lipschtiz constant $L$ or the strongly concave\nconstant $\\mu$. The PF-AGP algorithm utilizes a parameter-free gradient\nprojection step to alternately update the outer and inner variables in each\niteration. We show that the total number of gradient calls of the PF-AGP\nalgorithm to obtain an $\\varepsilon$-stationary point for nonconvex-strongly\nconcave minimax problems is upper bounded by $\\mathcal{O}\\left(\nL\\kappa^3\\varepsilon^{-2} \\right)$ where $\\kappa$ is the condition number,\nwhile the total number of gradient calls to obtain an $\\varepsilon$-stationary\npoint for nonconvex-concave minimax problems is upper bounded by\n$\\mathcal{O}\\left( L^4\\varepsilon^{-4} \\right)$. As far as we know, this is the\nfirst completely parameter-free algorithm for solving nonconvex-strongly\nconcave minimax problems, and it is also the completely parameter-free\nalgorithm which achieves the best iteration complexity in single loop method\nfor solving nonconvex-concave minimax problems. Numerical results validate the\nefficiency of the proposed PF-AGP algorithm.", "arxiv_id": "http://arxiv.org/abs/2407.21372v1", "pdf_url": "http://arxiv.org/pdf/2407.21372v1", "primary_category": "math.OC", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Prompting Medical Large Vision-Language Models to Diagnose Pathologies by Visual Question Answering", "authors": "Danfeng Guo, Demetri Terzopoulos", "abstract": "Large Vision-Language Models (LVLMs) have achieved significant success in\nrecent years, and they have been extended to the medical domain. Although\ndemonstrating satisfactory performance on medical Visual Question Answering\n(VQA) tasks, Medical LVLMs (MLVLMs) suffer from the hallucination problem,\nwhich makes them fail to diagnose complex pathologies. Moreover, they readily\nfail to learn minority pathologies due to imbalanced training data. We propose\ntwo prompting strategies for MLVLMs that reduce hallucination and improve VQA\nperformance. In the first strategy, we provide a detailed explanation of the\nqueried pathology. In the second strategy, we fine-tune a cheap, weak learner\nto achieve high performance on a specific metric, and textually provide its\njudgment to the MLVLM. Tested on the MIMIC-CXR-JPG and Chexpert datasets, our\nmethods significantly improve the diagnostic F1 score, with the highest\nincrease being 0.27. We also demonstrate that our prompting strategies can be\nextended to general LVLM domains. Based on POPE metrics, it effectively\nsuppresses the false negative predictions of existing LVLMs and improves Recall\nby approximately 0.07.", "arxiv_id": "http://arxiv.org/abs/2407.21368v1", "pdf_url": "http://arxiv.org/pdf/2407.21368v1", "primary_category": "cs.CV", "preferences": "I'm intersted in LLMs", "response": "RELEVANT"}
{"title": "ProSpec RL: Plan Ahead, then Execute", "authors": "Liangliang Liu, Yi Guan, BoRan Wang, Rujia Shen, Yi Lin, Chaoran Kong, Lian Yan, Jingchi Jiang", "abstract": "Imagining potential outcomes of actions before execution helps agents make\nmore informed decisions, a prospective thinking ability fundamental to human\ncognition. However, mainstream model-free Reinforcement Learning (RL) methods\nlack the ability to proactively envision future scenarios, plan, and guide\nstrategies. These methods typically rely on trial and error to adjust policy\nfunctions, aiming to maximize cumulative rewards or long-term value, even if\nsuch high-reward decisions place the environment in extremely dangerous states.\nTo address this, we propose the Prospective (ProSpec) RL method, which makes\nhigher-value, lower-risk optimal decisions by imagining future n-stream\ntrajectories. Specifically, ProSpec employs a dynamic model to predict future\nstates (termed \"imagined states\") based on the current state and a series of\nsampled actions. Furthermore, we integrate the concept of Model Predictive\nControl and introduce a cycle consistency constraint that allows the agent to\nevaluate and select the optimal actions from these trajectories. Moreover,\nProSpec employs cycle consistency to mitigate two fundamental issues in RL:\naugmenting state reversibility to avoid irreversible events (low risk) and\naugmenting actions to generate numerous virtual trajectories, thereby improving\ndata efficiency. We validated the effectiveness of our method on the DMControl\nbenchmarks, where our approach achieved significant performance improvements.\nCode will be open-sourced upon acceptance.", "arxiv_id": "http://arxiv.org/abs/2407.21359v1", "pdf_url": "http://arxiv.org/pdf/2407.21359v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Differentially Private Block-wise Gradient Shuffle for Deep Learning", "authors": "David Zagardo", "abstract": "Traditional Differentially Private Stochastic Gradient Descent (DP-SGD)\nintroduces statistical noise on top of gradients drawn from a Gaussian\ndistribution to ensure privacy. This paper introduces the novel Differentially\nPrivate Block-wise Gradient Shuffle (DP-BloGS) algorithm for deep learning.\nBloGS builds off of existing private deep learning literature, but makes a\ndefinitive shift by taking a probabilistic approach to gradient noise\nintroduction through shuffling modeled after information theoretic privacy\nanalyses. The theoretical results presented in this paper show that the\ncombination of shuffling, parameter-specific block size selection, batch layer\nclipping, and gradient accumulation allows DP-BloGS to achieve training times\nclose to that of non-private training while maintaining similar privacy and\nutility guarantees to DP-SGD. DP-BloGS is found to be significantly more\nresistant to data extraction attempts than DP-SGD. The theoretical results are\nvalidated by the experimental findings.", "arxiv_id": "http://arxiv.org/abs/2407.21347v1", "pdf_url": "http://arxiv.org/pdf/2407.21347v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "MIST: A Simple and Scalable End-To-End 3D Medical Imaging Segmentation Framework", "authors": "Adrian Celaya, Evan Lim, Rachel Glenn, Brayden Mi, Alex Balsells, Tucker Netherton, Caroline Chung, Beatrice Riviere, David Fuentes", "abstract": "Medical imaging segmentation is a highly active area of research, with deep\nlearning-based methods achieving state-of-the-art results in several\nbenchmarks. However, the lack of standardized tools for training, testing, and\nevaluating new methods makes the comparison of methods difficult. To address\nthis, we introduce the Medical Imaging Segmentation Toolkit (MIST), a simple,\nmodular, and end-to-end medical imaging segmentation framework designed to\nfacilitate consistent training, testing, and evaluation of deep learning-based\nmedical imaging segmentation methods. MIST standardizes data analysis,\npreprocessing, and evaluation pipelines, accommodating multiple architectures\nand loss functions. This standardization ensures reproducible and fair\ncomparisons across different methods. We detail MIST's data format\nrequirements, pipelines, and auxiliary features and demonstrate its efficacy\nusing the BraTS Adult Glioma Post-Treatment Challenge dataset. Our results\nhighlight MIST's ability to produce accurate segmentation masks and its\nscalability across multiple GPUs, showcasing its potential as a powerful tool\nfor future medical imaging research and development.", "arxiv_id": "http://arxiv.org/abs/2407.21343v1", "pdf_url": "http://arxiv.org/pdf/2407.21343v1", "primary_category": "eess.IV", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Image-Based Deep Reinforcement Learning with Intrinsically Motivated Stimuli: On the Execution of Complex Robotic Tasks", "authors": "David Valencia, Henry Williams, Yuning Xing, Trevor Gee, Minas Liarokapis, Bruce A. MacDonald", "abstract": "Reinforcement Learning (RL) has been widely used to solve tasks where the\nenvironment consistently provides a dense reward value. However, in real-world\nscenarios, rewards can often be poorly defined or sparse. Auxiliary signals are\nindispensable for discovering efficient exploration strategies and aiding the\nlearning process. In this work, inspired by intrinsic motivation theory, we\npostulate that the intrinsic stimuli of novelty and surprise can assist in\nimproving exploration in complex, sparsely rewarded environments. We introduce\na novel sample-efficient method able to learn directly from pixels, an\nimage-based extension of TD3 with an autoencoder called \\textit{NaSA-TD3}. The\nexperiments demonstrate that NaSA-TD3 is easy to train and an efficient method\nfor tackling complex continuous-control robotic tasks, both in simulated\nenvironments and real-world settings. NaSA-TD3 outperforms existing\nstate-of-the-art RL image-based methods in terms of final performance without\nrequiring pre-trained models or human demonstrations.", "arxiv_id": "http://arxiv.org/abs/2407.21338v1", "pdf_url": "http://arxiv.org/pdf/2407.21338v1", "primary_category": "cs.AI", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Big Cooperative Learning", "authors": "Yulai Cong", "abstract": "Cooperation plays a pivotal role in the evolution of human intelligence;\nmoreover, it also underlies the recent revolutionary advancement of artificial\nintelligence (AI) that is driven by foundation models. Specifically, we reveal\nthat the training of foundation models can be interpreted as a form of big\ncooperative learning (\\textit{abbr.} big learning), where massive learning\nindividuals/tasks \\emph{cooperate} to approach the unique essence of data from\ndiverse perspectives of data prediction, leveraging a universal model. The\npresented big learning therefore unifies most training objectives of foundation\nmodels within a consistent framework, where their underlying assumptions are\nexposed simultaneously. We design tailored simulations to demonstrate the\nprinciple of big learning, based on which we provide learning-perspective\njustifications for the successes of foundation models, with interesting\nside-products. Furthermore, we reveal that big learning is a new dimension for\nupgrading conventional machine learning paradigms, valuable for endowing\nreinvigorations to associated applications; as an illustrative example, we\npropose the BigLearn-GAN, which is a novel adversarially-trained foundation\nmodel with versatile data sampling capabilities. Code is available at\n\\texttt{https://github.com/YulaiCong/BigCooperativeLearning}.", "arxiv_id": "http://arxiv.org/abs/2407.21319v1", "pdf_url": "http://arxiv.org/pdf/2407.21319v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "RELEVANT"}
{"title": "Diff-Cleanse: Identifying and Mitigating Backdoor Attacks in Diffusion Models", "authors": "Jiang Hao, Xiao Jin, Hu Xiaoguang, Chen Tianyou", "abstract": "Diffusion models (DM) represent one of the most advanced generative models\ntoday, yet recent studies suggest that DMs are vulnerable to backdoor attacks.\nBackdoor attacks establish hidden associations between particular input\npatterns and model behaviors, compromising model integrity by triggering\nundesirable actions with manipulated input data. This vulnerability poses\nsubstantial risks, including reputational damage to model owners and the\ndissemination of harmful content. To mitigate the threat of backdoor attacks,\nthere have been some investigations on backdoor detection and model repair.\nHowever, previous work fails to purify the backdoored DMs created by\nstate-of-the-art attacks, rendering the field much underexplored. To bridge\nthis gap, we introduce \\textbf{Diff-Cleanse}, a novel two-stage backdoor\ndefense framework specifically designed for DMs. The first stage employs a\ninnovative trigger inversion technique to detect the backdoor and reconstruct\nthe trigger, and the second stage utilizes a structural pruning method to\neliminate the backdoor. We evaluate our framework on hundreds of DMs attacked\nby 3 existing backdoor attack methods. Extensive experiments demonstrate that\nDiff-Cleanse achieves nearly 100\\% detection accuracy and effectively mitigates\nbackdoor impacts, preserving the model's benign performance with minimal\ncompromise. Our code is avaliable at https://github.com/shymuel/diff-cleanse.", "arxiv_id": "http://arxiv.org/abs/2407.21316v1", "pdf_url": "http://arxiv.org/pdf/2407.21316v1", "primary_category": "cs.CR", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "State-observation augmented diffusion model for nonlinear assimilation", "authors": "Zhuoyuan Li, Bin Dong, Pingwen Zhang", "abstract": "Data assimilation has become a crucial technique aiming to combine physical\nmodels with observational data to estimate state variables. Traditional\nassimilation algorithms often face challenges of high nonlinearity brought by\nboth the physical and observational models. In this work, we propose a novel\ndata-driven assimilation algorithm based on generative models to address such\nconcerns. Our State-Observation Augmented Diffusion (SOAD) model is designed to\nhandle nonlinear physical and observational models more effectively. The\nmarginal posterior associated with SOAD has been derived and then proved to\nmatch the real posterior under mild assumptions, which shows theoretical\nsuperiority over previous score-based assimilation works. Experimental results\nalso indicate that our SOAD model may offer improved accuracy over existing\ndata-driven methods.", "arxiv_id": "http://arxiv.org/abs/2407.21314v1", "pdf_url": "http://arxiv.org/pdf/2407.21314v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "EUDA: An Efficient Unsupervised Domain Adaptation via Self-Supervised Vision Transformer", "authors": "Ali Abedi, Q. M. Jonathan Wu, Ning Zhang, Farhad Pourpanah", "abstract": "Unsupervised domain adaptation (UDA) aims to mitigate the domain shift issue,\nwhere the distribution of training (source) data differs from that of testing\n(target) data. Many models have been developed to tackle this problem, and\nrecently vision transformers (ViTs) have shown promising results. However, the\ncomplexity and large number of trainable parameters of ViTs restrict their\ndeployment in practical applications. This underscores the need for an\nefficient model that not only reduces trainable parameters but also allows for\nadjustable complexity based on specific needs while delivering comparable\nperformance. To achieve this, in this paper we introduce an Efficient\nUnsupervised Domain Adaptation (EUDA) framework. EUDA employs the DINOv2, which\nis a self-supervised ViT, as a feature extractor followed by a simplified\nbottleneck of fully connected layers to refine features for enhanced domain\nadaptation. Additionally, EUDA employs the synergistic domain alignment loss\n(SDAL), which integrates cross-entropy (CE) and maximum mean discrepancy (MMD)\nlosses, to balance adaptation by minimizing classification errors in the source\ndomain while aligning the source and target domain distributions. The\nexperimental results indicate the effectiveness of EUDA in producing comparable\nresults as compared with other state-of-the-art methods in domain adaptation\nwith significantly fewer trainable parameters, between 42% to 99.7% fewer. This\nshowcases the ability to train the model in a resource-limited environment. The\ncode of the model is available at: https://github.com/A-Abedi/EUDA.", "arxiv_id": "http://arxiv.org/abs/2407.21311v1", "pdf_url": "http://arxiv.org/pdf/2407.21311v1", "primary_category": "cs.CV", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "MSMA: Multi-agent Trajectory Prediction in Connected and Autonomous Vehicle Environment with Multi-source Data Integration", "authors": "Xi Chen, Rahul Bhadani, Zhanbo Sun, Larry Head", "abstract": "The prediction of surrounding vehicle trajectories is crucial for\ncollision-free path planning. In this study, we focus on a scenario where a\nconnected and autonomous vehicle (CAV) serves as the central agent, utilizing\nboth sensors and communication technologies to perceive its surrounding\ntraffics consisting of autonomous vehicles (AVs), connected vehicles (CVs), and\nhuman-driven vehicles (HDVs). Our trajectory prediction task is aimed at all\nthe detected surrounding vehicles. To effectively integrate the multi-source\ndata from both sensor and communication technologies, we propose a deep\nlearning framework called MSMA utilizing a cross-attention module for\nmulti-source data fusion. Vector map data is utilized to provide contextual\ninformation. The trajectory dataset is collected in CARLA simulator with\nsynthesized data errors introduced. Numerical experiments demonstrate that in a\nmixed traffic flow scenario, the integration of data from different sources\nenhances our understanding of the environment. This notably improves trajectory\nprediction accuracy, particularly in situations with a high CV market\npenetration rate. The code is available at: https://github.com/xichennn/MSMA.", "arxiv_id": "http://arxiv.org/abs/2407.21310v1", "pdf_url": "http://arxiv.org/pdf/2407.21310v1", "primary_category": "cs.RO", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Who should I trust? A Visual Analytics Approach for Comparing Net Load Forecasting Models", "authors": "Kaustav Bhattacharjee, Soumya Kundu, Indrasis Chakraborty, Aritra Dasgupta", "abstract": "Net load forecasting is crucial for energy planning and facilitating informed\ndecision-making regarding trade and load distributions. However, evaluating\nforecasting models' performance against benchmark models remains challenging,\nthereby impeding experts' trust in the model's performance. In this context,\nthere is a demand for technological interventions that allow scientists to\ncompare models across various timeframes and solar penetration levels. This\npaper introduces a visual analytics-based application designed to compare the\nperformance of deep-learning-based net load forecasting models with other\nmodels for probabilistic net load forecasting. This application employs\ncarefully selected visual analytic interventions, enabling users to discern\ndifferences in model performance across different solar penetration levels,\ndataset resolutions, and hours of the day over multiple months. We also present\nobservations made using our application through a case study, demonstrating the\neffectiveness of visualizations in aiding scientists in making informed\ndecisions and enhancing trust in net load forecasting models.", "arxiv_id": "http://arxiv.org/abs/2407.21299v1", "pdf_url": "http://arxiv.org/pdf/2407.21299v1", "primary_category": "cs.HC", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "A Vectorization Method Induced By Maximal Margin Classification For Persistent Diagrams", "authors": "An Wu, Yu Pan, Fuqi Zhou, Jinghui Yan, Chuanlu Liu", "abstract": "Persistent homology is an effective method for extracting topological\ninformation, represented as persistent diagrams, of spatial structure data.\nHence it is well-suited for the study of protein structures. Attempts to\nincorporate Persistent homology in machine learning methods of protein function\nprediction have resulted in several techniques for vectorizing persistent\ndiagrams. However, current vectorization methods are excessively artificial and\ncannot ensure the effective utilization of information or the rationality of\nthe methods. To address this problem, we propose a more geometrical\nvectorization method of persistent diagrams based on maximal margin\nclassification for Banach space, and additionaly propose a framework that\nutilizes topological data analysis to identify proteins with specific\nfunctions. We evaluated our vectorization method using a binary classification\ntask on proteins and compared it with the statistical methods that exhibit the\nbest performance among thirteen commonly used vectorization methods. The\nexperimental results indicate that our approach surpasses the statistical\nmethods in both robustness and precision.", "arxiv_id": "http://arxiv.org/abs/2407.21298v1", "pdf_url": "http://arxiv.org/pdf/2407.21298v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Decentralized and Uncoordinated Learning of Stable Matchings: A Game-Theoretic Approach", "authors": "S. Rasoul Etesami, R. Srikant", "abstract": "We consider the problem of learning stable matchings in a fully decentralized\nand uncoordinated manner. In this problem, there are $n$ men and $n$ women,\neach having preference over the other side. It is assumed that women know their\npreferences over men, but men are not aware of their preferences over women,\nand they only learn them if they propose and successfully get matched to women.\nA matching is called stable if no man and woman prefer each other over their\ncurrent matches. When all the preferences are known a priori, the celebrated\nDeferred-Acceptance algorithm proposed by Gale and Shapley provides a\ndecentralized and uncoordinated algorithm to obtain a stable matching. However,\nwhen the preferences are unknown, developing such an algorithm faces major\nchallenges due to a lack of coordination. We achieve this goal by making a\nconnection between stable matchings and learning Nash equilibria (NE) in\nnoncooperative games. First, we provide a complete information game formulation\nfor the stable matching problem with known preferences such that its set of\npure NE coincides with the set of stable matchings, while its mixed NE can be\nrounded in a decentralized manner to a stable matching. Relying on such a\ngame-theoretic formulation, we show that for hierarchical markets, adopting the\nexponential weight (EXP) learning algorithm for the stable matching game\nachieves logarithmic regret with polynomial dependence on the number of\nplayers, thus answering a question posed in previous literature. Moreover, we\nshow that the same EXP learning algorithm converges locally and exponentially\nfast to a stable matching in general matching markets. We complement this\nresult by introducing another decentralized and uncoordinated learning\nalgorithm that globally converges to a stable matching with arbitrarily high\nprobability, leveraging the weak acyclicity property of the stable matching\ngame.", "arxiv_id": "http://arxiv.org/abs/2407.21294v1", "pdf_url": "http://arxiv.org/pdf/2407.21294v1", "primary_category": "cs.GT", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "TrackSorter: A Transformer-based sorting algorithm for track finding in High Energy Physics", "authors": "Yash Melkani, Xiangyang Ju", "abstract": "Track finding in particle data is a challenging pattern recognition problem\nin High Energy Physics. It takes as inputs a point cloud of space points and\nlabels them so that space points created by the same particle have the same\nlabel. The list of space points with the same label is a track candidate. We\nargue that this pattern recognition problem can be formulated as a sorting\nproblem, of which the inputs are a list of space points sorted by their\ndistances away from the collision points and the outputs are the space points\nsorted by their labels. In this paper, we propose the TrackSorter algorithm: a\nTransformer-based algorithm for pattern recognition in particle data.\nTrackSorter uses a simple tokenization scheme to convert space points into\ndiscrete tokens. It then uses the tokenized space points as inputs and sorts\nthe input tokens into track candidates. TrackSorter is a novel end-to-end track\nfinding algorithm that leverages Transformer-based models to solve pattern\nrecognition problems. It is evaluated on the TrackML dataset and has good track\nfinding performance.", "arxiv_id": "http://arxiv.org/abs/2407.21290v1", "pdf_url": "http://arxiv.org/pdf/2407.21290v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Robust Box Prompt based SAM for Medical Image Segmentation", "authors": "Yuhao Huang, Xin Yang, Han Zhou, Yan Cao, Haoran Dou, Fajin Dong, Dong Ni", "abstract": "The Segment Anything Model (SAM) can achieve satisfactory segmentation\nperformance under high-quality box prompts. However, SAM's robustness is\ncompromised by the decline in box quality, limiting its practicality in\nclinical reality. In this study, we propose a novel Robust Box prompt based SAM\n(\\textbf{RoBox-SAM}) to ensure SAM's segmentation performance under prompts\nwith different qualities. Our contribution is three-fold. First, we propose a\nprompt refinement module to implicitly perceive the potential targets, and\noutput the offsets to directly transform the low-quality box prompt into a\nhigh-quality one. We then provide an online iterative strategy for further\nprompt refinement. Second, we introduce a prompt enhancement module to\nautomatically generate point prompts to assist the box-promptable segmentation\neffectively. Last, we build a self-information extractor to encode the prior\ninformation from the input image. These features can optimize the image\nembeddings and attention calculation, thus, the robustness of SAM can be\nfurther enhanced. Extensive experiments on the large medical segmentation\ndataset including 99,299 images, 5 modalities, and 25 organs/targets validated\nthe efficacy of our proposed RoBox-SAM.", "arxiv_id": "http://arxiv.org/abs/2407.21284v1", "pdf_url": "http://arxiv.org/pdf/2407.21284v1", "primary_category": "cs.CV", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "FedBChain: A Blockchain-enabled Federated Learning Framework for Improving DeepConvLSTM with Comparative Strategy Insights", "authors": "Gaoxuan Li, Chern Hong Lim, Qiyao Ma, Xinyu Tang, Hwa Hui Tew", "abstract": "Recent research in the field of Human Activity Recognition has shown that an\nimprovement in prediction performance can be achieved by reducing the number of\nLSTM layers. However, this kind of enhancement is only significant on\nmonolithic architectures, and when it runs on large-scale distributed training,\ndata security and privacy issues will be reconsidered, and its prediction\nperformance is unknown. In this paper, we introduce a novel framework:\nFedBChain, which integrates the federated learning paradigm based on a modified\nDeepConvLSTM architecture with a single LSTM layer. This framework performs\ncomparative tests of prediction performance on three different real-world\ndatasets based on three different hidden layer units (128, 256, and 512)\ncombined with five different federated learning strategies, respectively. The\nresults show that our architecture has significant improvements in Precision,\nRecall and F1-score compared to the centralized training approach on all\ndatasets with all hidden layer units for all strategies: FedAvg strategy\nimproves on average by 4.54%, FedProx improves on average by 4.57%,\nFedTrimmedAvg improves on average by 4.35%, Krum improves by 4.18% on average,\nand FedAvgM improves by 4.46% on average. Based on our results, it can be seen\nthat FedBChain not only improves in performance, but also guarantees the\nsecurity and privacy of user data compared to centralized training methods\nduring the training process. The code for our experiments is publicly available\n(https://github.com/Glen909/FedBChain).", "arxiv_id": "http://arxiv.org/abs/2407.21282v1", "pdf_url": "http://arxiv.org/pdf/2407.21282v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Enhanced Uncertainty Estimation in Ultrasound Image Segmentation with MSU-Net", "authors": "Rohini Banerjee, Cecilia G. Morales, Artur Dubrawski", "abstract": "Efficient intravascular access in trauma and critical care significantly\nimpacts patient outcomes. However, the availability of skilled medical\npersonnel in austere environments is often limited. Autonomous robotic\nultrasound systems can aid in needle insertion for medication delivery and\nsupport non-experts in such tasks. Despite advances in autonomous needle\ninsertion, inaccuracies in vessel segmentation predictions pose risks.\nUnderstanding the uncertainty of predictive models in ultrasound imaging is\ncrucial for assessing their reliability. We introduce MSU-Net, a novel\nmultistage approach for training an ensemble of U-Nets to yield accurate\nultrasound image segmentation maps. We demonstrate substantial improvements,\n18.1% over a single Monte Carlo U-Net, enhancing uncertainty evaluations, model\ntransparency, and trustworthiness. By highlighting areas of model certainty,\nMSU-Net can guide safe needle insertions, empowering non-experts to accomplish\nsuch tasks.", "arxiv_id": "http://arxiv.org/abs/2407.21273v1", "pdf_url": "http://arxiv.org/pdf/2407.21273v1", "primary_category": "cs.CV", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "DDU-Net: A Domain Decomposition-based CNN for High-Resolution Image Segmentation on Multiple GPUs", "authors": "Corn\u00e9 Verburg, Alexander Heinlein, Eric C. Cyr", "abstract": "The segmentation of ultra-high resolution images poses challenges such as\nloss of spatial information or computational inefficiency. In this work, a\nnovel approach that combines encoder-decoder architectures with domain\ndecomposition strategies to address these challenges is proposed. Specifically,\na domain decomposition-based U-Net (DDU-Net) architecture is introduced, which\npartitions input images into non-overlapping patches that can be processed\nindependently on separate devices. A communication network is added to\nfacilitate inter-patch information exchange to enhance the understanding of\nspatial context. Experimental validation is performed on a synthetic dataset\nthat is designed to measure the effectiveness of the communication network.\nThen, the performance is tested on the DeepGlobe land cover classification\ndataset as a real-world benchmark data set. The results demonstrate that the\napproach, which includes inter-patch communication for images divided into\n$16\\times16$ non-overlapping subimages, achieves a $2-3\\,\\%$ higher\nintersection over union (IoU) score compared to the same network without\ninter-patch communication. The performance of the network which includes\ncommunication is equivalent to that of a baseline U-Net trained on the full\nimage, showing that our model provides an effective solution for segmenting\nultra-high-resolution images while preserving spatial context. The code is\navailable at https://github.com/corne00/HiRes-Seg-CNN.", "arxiv_id": "http://arxiv.org/abs/2407.21266v2", "pdf_url": "http://arxiv.org/pdf/2407.21266v2", "primary_category": "cs.CV", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Tractable and Provably Efficient Distributional Reinforcement Learning with General Value Function Approximation", "authors": "Taehyun Cho, Seungyub Han, Kyungjae Lee, Seokhun Ju, Dohyeong Kim, Jungwoo Lee", "abstract": "Distributional reinforcement learning improves performance by effectively\ncapturing environmental stochasticity, but a comprehensive theoretical\nunderstanding of its effectiveness remains elusive. In this paper, we present a\nregret analysis for distributional reinforcement learning with general value\nfunction approximation in a finite episodic Markov decision process setting. We\nfirst introduce a key notion of Bellman unbiasedness for a tractable and\nexactly learnable update via statistical functional dynamic programming. Our\ntheoretical results show that approximating the infinite-dimensional return\ndistribution with a finite number of moment functionals is the only method to\nlearn the statistical information unbiasedly, including nonlinear statistical\nfunctionals. Second, we propose a provably efficient algorithm,\n$\\texttt{SF-LSVI}$, achieving a regret bound of $\\tilde{O}(d_E\nH^{\\frac{3}{2}}\\sqrt{K})$ where $H$ is the horizon, $K$ is the number of\nepisodes, and $d_E$ is the eluder dimension of a function class.", "arxiv_id": "http://arxiv.org/abs/2407.21260v1", "pdf_url": "http://arxiv.org/pdf/2407.21260v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Adaptive Pre-training Data Detection for Large Language Models via Surprising Tokens", "authors": "Anqi Zhang, Chaofeng Wu", "abstract": "While large language models (LLMs) are extensively used, there are raising\nconcerns regarding privacy, security, and copyright due to their opaque\ntraining data, which brings the problem of detecting pre-training data on the\ntable. Current solutions to this problem leverage techniques explored in\nmachine learning privacy such as Membership Inference Attacks (MIAs), which\nheavily depend on LLMs' capability of verbatim memorization. However, this\nreliance presents challenges, especially given the vast amount of training data\nand the restricted number of effective training epochs. In this paper, we\npropose an adaptive pre-training data detection method which alleviates this\nreliance and effectively amplify the identification. Our method adaptively\nlocates \\textit{surprising tokens} of the input. A token is surprising to a LLM\nif the prediction on the token is \"certain but wrong\", which refers to low\nShannon entropy of the probability distribution and low probability of the\nground truth token at the same time. By using the prediction probability of\nsurprising tokens to measure \\textit{surprising}, the detection method is\nachieved based on the simple hypothesis that seeing seen data is less\nsurprising for the model compared with seeing unseen data. The method can be\napplied without any access to the the pre-training data corpus or additional\ntraining like reference models. Our approach exhibits a consistent enhancement\ncompared to existing methods in diverse experiments conducted on various\nbenchmarks and models, achieving a maximum improvement of 29.5\\%. We also\nintroduce a new benchmark Dolma-Book developed upon a novel framework, which\nemploys book data collected both before and after model training to provide\nfurther evaluation.", "arxiv_id": "http://arxiv.org/abs/2407.21248v1", "pdf_url": "http://arxiv.org/pdf/2407.21248v1", "primary_category": "cs.CL", "preferences": "I'm intersted in LLMs", "response": "RELEVANT"}
{"title": "Informed Correctors for Discrete Diffusion Models", "authors": "Yixiu Zhao, Jiaxin Shi, Lester Mackey, Scott Linderman", "abstract": "Discrete diffusion modeling is a promising framework for modeling and\ngenerating data in discrete spaces. To sample from these models, different\nstrategies present trade-offs between computation and sample quality. A\npredominant sampling strategy is predictor-corrector $\\tau$-leaping, which\nsimulates the continuous time generative process with discretized predictor\nsteps and counteracts the accumulation of discretization error via corrector\nsteps. However, for absorbing state diffusion, an important class of discrete\ndiffusion models, the standard forward-backward corrector can be ineffective in\nfixing such errors, resulting in subpar sample quality. To remedy this problem,\nwe propose a family of informed correctors that more reliably counteracts\ndiscretization error by leveraging information learned by the model. For\nfurther efficiency gains, we also propose $k$-Gillespie's, a sampling algorithm\nthat better utilizes each model evaluation, while still enjoying the speed and\nflexibility of $\\tau$-leaping. Across several real and synthetic datasets, we\nshow that $k$-Gillespie's with informed correctors reliably produces higher\nquality samples at lower computational cost.", "arxiv_id": "http://arxiv.org/abs/2407.21243v1", "pdf_url": "http://arxiv.org/pdf/2407.21243v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "GNUMAP: A Parameter-Free Approach to Unsupervised Dimensionality Reduction via Graph Neural Networks", "authors": "Jihee You, So Won Jeong, Claire Donnat", "abstract": "With the proliferation of Graph Neural Network (GNN) methods stemming from\ncontrastive learning, unsupervised node representation learning for graph data\nis rapidly gaining traction across various fields, from biology to molecular\ndynamics, where it is often used as a dimensionality reduction tool. However,\nthere remains a significant gap in understanding the quality of the\nlow-dimensional node representations these methods produce, particularly beyond\nwell-curated academic datasets. To address this gap, we propose here the first\ncomprehensive benchmarking of various unsupervised node embedding techniques\ntailored for dimensionality reduction, encompassing a range of manifold\nlearning tasks, along with various performance metrics. We emphasize the\nsensitivity of current methods to hyperparameter choices -- highlighting a\nfundamental issue as to their applicability in real-world settings where there\nis no established methodology for rigorous hyperparameter selection. Addressing\nthis issue, we introduce GNUMAP, a robust and parameter-free method for\nunsupervised node representation learning that merges the traditional UMAP\napproach with the expressivity of the GNN framework. We show that GNUMAP\nconsistently outperforms existing state-of-the-art GNN embedding methods in a\nvariety of contexts, including synthetic geometric datasets, citation networks,\nand real-world biomedical data -- making it a simple but reliable\ndimensionality reduction tool.", "arxiv_id": "http://arxiv.org/abs/2407.21236v1", "pdf_url": "http://arxiv.org/pdf/2407.21236v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Towards an Integrated Performance Framework for Fire Science and Management Workflows", "authors": "H. Ahmed, R. Shende, I. Perez, D. Crawl, S. Purawat, I. Altintas", "abstract": "Reliable performance metrics are necessary prerequisites to building\nlarge-scale end-to-end integrated workflows for collaborative scientific\nresearch, particularly within context of use-inspired decision making platforms\nwith many concurrent users and when computing real-time and urgent results\nusing large data. This work is a building block for the National Data Platform,\nwhich leverages multiple use-cases including the WIFIRE Data and Model Commons\nfor wildfire behavior modeling and the EarthScope Consortium for collaborative\ngeophysical research. This paper presents an artificial intelligence and\nmachine learning (AI/ML) approach to performance assessment and optimization of\nscientific workflows. An associated early AI/ML framework spanning performance\ndata collection, prediction and optimization is applied to wildfire science\napplications within the WIFIRE BurnPro3D (BP3D) platform for proactive fire\nmanagement and mitigation.", "arxiv_id": "http://arxiv.org/abs/2407.21231v1", "pdf_url": "http://arxiv.org/pdf/2407.21231v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "DeepBaR: Fault Backdoor Attack on Deep Neural Network Layers", "authors": "C. A. Mart\u00ednez-Mej\u00eda, J. Solano, J. Breier, D. Bucko, X. Hou", "abstract": "Machine Learning using neural networks has received prominent attention\nrecently because of its success in solving a wide variety of computational\ntasks, in particular in the field of computer vision. However, several works\nhave drawn attention to potential security risks involved with the training and\nimplementation of such networks. In this work, we introduce DeepBaR, a novel\napproach that implants backdoors on neural networks by faulting their behavior\nat training, especially during fine-tuning. Our technique aims to generate\nadversarial samples by optimizing a custom loss function that mimics the\nimplanted backdoors while adding an almost non-visible trigger in the image. We\nattack three popular convolutional neural network architectures and show that\nDeepBaR attacks have a success rate of up to 98.30\\%. Furthermore, DeepBaR does\nnot significantly affect the accuracy of the attacked networks after deployment\nwhen non-malicious inputs are given. Remarkably, DeepBaR allows attackers to\nchoose an input that looks similar to a given class, from a human perspective,\nbut that will be classified as belonging to an arbitrary target class.", "arxiv_id": "http://arxiv.org/abs/2407.21220v1", "pdf_url": "http://arxiv.org/pdf/2407.21220v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "NeuroSEM: A hybrid framework for simulating multiphysics problems by coupling PINNs and spectral elements", "authors": "Khemraj Shukla, Zongren Zou, Chi Hin Chan, Additi Pandey, Zhicheng Wang, George Em Karniadakis", "abstract": "Multiphysics problems that are characterized by complex interactions among\nfluid dynamics, heat transfer, structural mechanics, and electromagnetics, are\ninherently challenging due to their coupled nature. While experimental data on\ncertain state variables may be available, integrating these data with numerical\nsolvers remains a significant challenge. Physics-informed neural networks\n(PINNs) have shown promising results in various engineering disciplines,\nparticularly in handling noisy data and solving inverse problems. However,\ntheir effectiveness in forecasting nonlinear phenomena in multiphysics regimes\nis yet to be fully established. This study introduces NeuroSEM, a hybrid\nframework integrating PINNs with the high-fidelity Spectral Element Method\n(SEM) solver, Nektar++. NeuroSEM leverages strengths of both PINNs and SEM,\nproviding robust solutions for multiphysics problems. PINNs are trained to\nassimilate data and model physical phenomena in specific subdomains, which are\nthen integrated into Nektar++. We demonstrate the efficiency and accuracy of\nNeuroSEM for thermal convection in cavity flow and flow past a cylinder. The\nframework effectively handles data assimilation by addressing those subdomains\nand state variables where data are available. We applied NeuroSEM to the\nRayleigh-B\\'enard convection system, including cases with missing thermal\nboundary conditions. Our results indicate that NeuroSEM accurately models the\nphysical phenomena and assimilates the data within the specified subdomains.\nThe framework's plug-and-play nature facilitates its extension to other\nmultiphysics or multiscale problems. Furthermore, NeuroSEM is optimized for an\nefficient execution on emerging integrated GPU-CPU architectures. This hybrid\napproach enhances the accuracy and efficiency of simulations, making it a\npowerful tool for tackling complex engineering challenges in various scientific\ndomains.", "arxiv_id": "http://arxiv.org/abs/2407.21217v1", "pdf_url": "http://arxiv.org/pdf/2407.21217v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Diffusion-Based Generation of Neural Activity from Disentangled Latent Codes", "authors": "Jonathan D. McCart, Andrew R. Sedler, Christopher Versteeg, Domenick Mifsud, Mattia Rigotti-Thompson, Chethan Pandarinath", "abstract": "Recent advances in recording technology have allowed neuroscientists to\nmonitor activity from thousands of neurons simultaneously. Latent variable\nmodels are increasingly valuable for distilling these recordings into compact\nand interpretable representations. Here we propose a new approach to neural\ndata analysis that leverages advances in conditional generative modeling to\nenable the unsupervised inference of disentangled behavioral variables from\nrecorded neural activity. Our approach builds on InfoDiffusion, which augments\ndiffusion models with a set of latent variables that capture important factors\nof variation in the data. We apply our model, called Generating Neural\nObservations Conditioned on Codes with High Information (GNOCCHI), to time\nseries neural data and test its application to synthetic and biological\nrecordings of neural activity during reaching. In comparison to a VAE-based\nsequential autoencoder, GNOCCHI learns higher-quality latent spaces that are\nmore clearly structured and more disentangled with respect to key behavioral\nvariables. These properties enable accurate generation of novel samples (unseen\nbehavioral conditions) through simple linear traversal of the latent spaces\nproduced by GNOCCHI. Our work demonstrates the potential of unsupervised,\ninformation-based models for the discovery of interpretable latent spaces from\nneural data, enabling researchers to generate high-quality samples from unseen\nconditions.", "arxiv_id": "http://arxiv.org/abs/2407.21195v1", "pdf_url": "http://arxiv.org/pdf/2407.21195v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Analyzing Customer-Facing Vendor Experiences with Time Series Forecasting and Monte Carlo Techniques", "authors": "Vivek Kaushik, Jason Tang", "abstract": "eBay partners with external vendors, which allows customers to freely select\na vendor to complete their eBay experiences. However, vendor outages can hinder\ncustomer experiences. Consequently, eBay can disable a problematic vendor to\nprevent customer loss. Disabling the vendor too late risks losing customers\nwilling to switch to other vendors, while disabling it too early risks losing\nthose unwilling to switch. In this paper, we propose a data-driven solution to\nanswer whether eBay should disable a problematic vendor and when to disable it.\nOur solution involves forecasting customer behavior. First, we use a\nmultiplicative seasonality model to represent behavior if all vendors are fully\nfunctioning. Next, we use a Monte Carlo simulation to represent behavior if the\nproblematic vendor remains enabled. Finally, we use a linear model to represent\nbehavior if the vendor is disabled. By comparing these forecasts, we determine\nthe optimal time for eBay to disable the problematic vendor.", "arxiv_id": "http://arxiv.org/abs/2407.21193v1", "pdf_url": "http://arxiv.org/pdf/2407.21193v1", "primary_category": "stat.ML", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "GenRec: Generative Personalized Sequential Recommendation", "authors": "Panfeng Cao, Pietro Lio", "abstract": "Sequential recommendation is a task to capture hidden user preferences from\nhistorical user item interaction data. Significant progress has been made in\nthis domain by leveraging classification based learning methods. Inspired by\nthe recent paradigm of 'pretrain, prompt and predict' in NLP, we consider\nsequential recommendation as a sequence to sequence generation task and propose\na novel model named Generative Recommendation (GenRec). Unlike classification\nbased models that learn explicit user and item representations, GenRec utilizes\nthe sequence modeling capability of Transformer and adopts the masked item\nprediction objective to effectively learn the hidden bidirectional sequential\npatterns. Different from existing generative sequential recommendation models,\nGenRec does not rely on manually designed hard prompts. The input to GenRec is\ntextual user item sequence and the output is top ranked next items. Moreover,\nGenRec is lightweight and requires only a few hours to train effectively in\nlow-resource settings, making it highly applicable to real-world scenarios and\nhelping to democratize large language models in the sequential recommendation\ndomain. Our extensive experiments have demonstrated that GenRec generalizes on\nvarious public real-world datasets and achieves state-of-the-art results. Our\nexperiments also validate the effectiveness of the the proposed masked item\nprediction objective that improves the model performance by a large margin.", "arxiv_id": "http://arxiv.org/abs/2407.21191v1", "pdf_url": "http://arxiv.org/pdf/2407.21191v1", "primary_category": "cs.IR", "preferences": "I'm intersted in LLMs", "response": "RELEVANT"}
{"title": "Multi-task Photonic Reservoir Computing: Wavelength Division Multiplexing for Parallel Computing with a Silicon Microring Resonator", "authors": "Bernard J. Giron Castro, Christophe Peucheret, Darko Zibar, Francesco Da Ros", "abstract": "Nowadays, as the ever-increasing demand for more powerful computing resources\ncontinues, alternative advanced computing paradigms are under extensive\ninvestigation. Significant effort has been made to deviate from conventional\nVon Neumann architectures. In-memory computing has emerged in the field of\nelectronics as a possible solution to the infamous bottleneck between memory\nand computing processors, which reduces the effective throughput of data. In\nphotonics, novel schemes attempt to collocate the computing processor and\nmemory in a single device. Photonics offers the flexibility of multiplexing\nstreams of data not only spatially and in time, but also in frequency or,\nequivalently, in wavelength, which makes it highly suitable for parallel\ncomputing. Here, we numerically show the use of time and wavelength division\nmultiplexing (WDM) to solve four independent tasks at the same time in a single\nphotonic chip, serving as a proof of concept for our proposal. The system is a\ntime-delay reservoir computing (TDRC) based on a microring resonator (MRR). The\naddressed tasks cover different applications: Time-series prediction, waveform\nsignal classification, wireless channel equalization, and radar signal\nprediction. The system is also tested for simultaneous computing of up to 10\ninstances of the same task, exhibiting excellent performance. The footprint of\nthe system is reduced by using time-division multiplexing of the nodes that act\nas the neurons of the studied neural network scheme. WDM is used for the\nparallelization of wavelength channels, each addressing a single task. By\nadjusting the input power and frequency of each optical channel, we can achieve\nlevels of performance for each of the tasks that are comparable to those quoted\nin state-of-the-art reports focusing on single-task operation...", "arxiv_id": "http://arxiv.org/abs/2407.21189v1", "pdf_url": "http://arxiv.org/pdf/2407.21189v1", "primary_category": "cs.NE", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Amelia: A Large Model and Dataset for Airport Surface Movement Forecasting", "authors": "Ingrid Navarro, Pablo Ortega-Kral, Jay Patrikar, Haichuan Wang, Zelin Ye, Jong Hoon Park, Jean Oh, Sebastian Scherer", "abstract": "The growing demand for air travel requires technological advancements in air\ntraffic management as well as mechanisms for monitoring and ensuring safe and\nefficient operations. In terminal airspaces, predictive models of future\nmovements and traffic flows can help with proactive planning and efficient\ncoordination; however, varying airport topologies, and interactions with other\nagents, among other factors, make accurate predictions challenging. Data-driven\npredictive models have shown promise for handling numerous variables to enable\nvarious downstream tasks, including collision risk assessment, taxi-out time\nprediction, departure metering, and emission estimations. While data-driven\nmethods have shown improvements in these tasks, prior works lack large-scale\ncurated surface movement datasets within the public domain and the development\nof generalizable trajectory forecasting models. In response to this, we propose\ntwo contributions: (1) Amelia-48, a large surface movement dataset collected\nusing the System Wide Information Management (SWIM) Surface Movement Event\nService (SMES). With data collection beginning in Dec 2022, the dataset\nprovides more than a year's worth of SMES data (~30TB) and covers 48 airports\nwithin the US National Airspace System. In addition to releasing this data in\nthe public domain, we also provide post-processing scripts and associated\nairport maps to enable research in the forecasting domain and beyond. (2)\nAmelia-TF model, a transformer-based next-token-prediction large multi-agent\nmulti-airport trajectory forecasting model trained on 292 days or 9.4 billion\ntokens of position data encompassing 10 different airports with varying\ntopology. The open-sourced model is validated on unseen airports with\nexperiments showcasing the different prediction horizon lengths, ego-agent\nselection strategies, and training recipes to demonstrate the generalization\ncapabilities.", "arxiv_id": "http://arxiv.org/abs/2407.21185v1", "pdf_url": "http://arxiv.org/pdf/2407.21185v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "RELEVANT"}
{"title": "Optical Computing for Deep Neural Network Acceleration: Foundations, Recent Developments, and Emerging Directions", "authors": "Sudeep Pasricha", "abstract": "Emerging artificial intelligence applications across the domains of computer\nvision, natural language processing, graph processing, and sequence prediction\nincreasingly rely on deep neural networks (DNNs). These DNNs require\nsignificant compute and memory resources for training and inference.\nTraditional computing platforms such as CPUs, GPUs, and TPUs are struggling to\nkeep up with the demands of the increasingly complex and diverse DNNs. Optical\ncomputing represents an exciting new paradigm for light-speed acceleration of\nDNN workloads. In this article, we discuss the fundamentals and\nstate-of-the-art developments in optical computing, with an emphasis on DNN\nacceleration. Various promising approaches are described for engineering\noptical devices, enhancing optical circuits, and designing architectures that\ncan adapt optical computing to a variety of DNN workloads. Novel techniques for\nhardware/software co-design that can intelligently tune and map DNN models to\nimprove performance and energy-efficiency on optical computing platforms across\nhigh performance and resource constrained embedded, edge, and IoT platforms are\nalso discussed. Lastly, several open problems and future directions for\nresearch in this domain are highlighted.", "arxiv_id": "http://arxiv.org/abs/2407.21184v1", "pdf_url": "http://arxiv.org/pdf/2407.21184v1", "primary_category": "cs.AR", "preferences": "I'm intersted in LLMs", "response": "RELEVANT"}
{"title": "DKL-KAN: Scalable Deep Kernel Learning using Kolmogorov-Arnold Networks", "authors": "Shrenik Zinage, Sudeepta Mondal, Soumalya Sarkar", "abstract": "The need for scalable and expressive models in machine learning is paramount,\nparticularly in applications requiring both structural depth and flexibility.\nTraditional deep learning methods, such as multilayer perceptrons (MLP), offer\ndepth but lack ability to integrate structural characteristics of deep learning\narchitectures with non-parametric flexibility of kernel methods. To address\nthis, deep kernel learning (DKL) was introduced, where inputs to a base kernel\nare transformed using a deep learning architecture. These kernels can replace\nstandard kernels, allowing both expressive power and scalability. The advent of\nKolmogorov-Arnold Networks (KAN) has generated considerable attention and\ndiscussion among researchers in scientific domain. In this paper, we introduce\na scalable deep kernel using KAN (DKL-KAN) as an effective alternative to DKL\nusing MLP (DKL-MLP). Our approach involves simultaneously optimizing these\nkernel attributes using marginal likelihood within a Gaussian process\nframework. We analyze two variants of DKL-KAN for a fair comparison with\nDKL-MLP: one with same number of neurons and layers as DKL-MLP, and another\nwith approximately same number of trainable parameters. To handle large\ndatasets, we use kernel interpolation for scalable structured Gaussian\nprocesses (KISS-GP) for low-dimensional inputs and KISS-GP with product kernels\nfor high-dimensional inputs. The efficacy of DKL-KAN is evaluated in terms of\ncomputational training time and test prediction accuracy across a wide range of\napplications. Additionally, the effectiveness of DKL-KAN is also examined in\nmodeling discontinuities and accurately estimating prediction uncertainty. The\nresults indicate that DKL-KAN outperforms DKL-MLP on datasets with a low number\nof observations. Conversely, DKL-MLP exhibits better scalability and higher\ntest prediction accuracy on datasets with large number of observations.", "arxiv_id": "http://arxiv.org/abs/2407.21176v1", "pdf_url": "http://arxiv.org/pdf/2407.21176v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Embedding Space Selection for Detecting Memorization and Fingerprinting in Generative Models", "authors": "Jack He, Jianxing Zhao, Andrew Bai, Cho-Jui Hsieh", "abstract": "In the rapidly evolving landscape of artificial intelligence, generative\nmodels such as Generative Adversarial Networks (GANs) and Diffusion Models have\nbecome cornerstone technologies, driving innovation in diverse fields from art\ncreation to healthcare. Despite their potential, these models face the\nsignificant challenge of data memorization, which poses risks to privacy and\nthe integrity of generated content. Among various metrics of memorization\ndetection, our study delves into the memorization scores calculated from\nencoder layer embeddings, which involves measuring distances between samples in\nthe embedding spaces. Particularly, we find that the memorization scores\ncalculated from layer embeddings of Vision Transformers (ViTs) show an notable\ntrend - the latter (deeper) the layer, the less the memorization measured. It\nhas been found that the memorization scores from the early layers' embeddings\nare more sensitive to low-level memorization (e.g. colors and simple patterns\nfor an image), while those from the latter layers are more sensitive to\nhigh-level memorization (e.g. semantic meaning of an image). We also observe\nthat, for a specific model architecture, its degree of memorization on\ndifferent levels of information is unique. It can be viewed as an inherent\nproperty of the architecture. Building upon this insight, we introduce a unique\nfingerprinting methodology. This method capitalizes on the unique distributions\nof the memorization score across different layers of ViTs, providing a novel\napproach to identifying models involved in generating deepfakes and malicious\ncontent. Our approach demonstrates a marked 30% enhancement in identification\naccuracy over existing baseline methods, offering a more effective tool for\ncombating digital misinformation.", "arxiv_id": "http://arxiv.org/abs/2407.21159v1", "pdf_url": "http://arxiv.org/pdf/2407.21159v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Private Collaborative Edge Inference via Over-the-Air Computation", "authors": "Selim F. Yilmaz, Burak Hasircioglu, Li Qiao, Deniz Gunduz", "abstract": "We consider collaborative inference at the wireless edge, where each client's\nmodel is trained independently on their local datasets. Clients are queried in\nparallel to make an accurate decision collaboratively. In addition to\nmaximizing the inference accuracy, we also want to ensure the privacy of local\nmodels. To this end, we leverage the superposition property of the multiple\naccess channel to implement bandwidth-efficient multi-user inference methods.\nSpecifically, we propose different methods for ensemble and multi-view\nclassification that exploit over-the-air computation. We show that these\nschemes perform better than their orthogonal counterparts with statistically\nsignificant differences while using fewer resources and providing privacy\nguarantees. We also provide experimental results verifying the benefits of the\nproposed over-the-air multi-user inference approach and perform an ablation\nstudy to demonstrate the effectiveness of our design choices. We share the\nsource code of the framework publicly on Github to facilitate further research\nand reproducibility.", "arxiv_id": "http://arxiv.org/abs/2407.21151v1", "pdf_url": "http://arxiv.org/pdf/2407.21151v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Enhancing Deep Hedging of Options with Implied Volatility Surface Feedback Information", "authors": "Pascal Fran\u00e7ois, Genevi\u00e8ve Gauthier, Fr\u00e9d\u00e9ric Godin, Carlos Octavio P\u00e9rez Mendoza", "abstract": "We present a dynamic hedging scheme for S&P 500 options, where rebalancing\ndecisions are enhanced by integrating information about the implied volatility\nsurface dynamics. The optimal hedging strategy is obtained through a deep\npolicy gradient-type reinforcement learning algorithm, with a novel hybrid\nneural network architecture improving the training performance. The favorable\ninclusion of forward-looking information embedded in the volatility surface\nallows our procedure to outperform several conventional benchmarks such as\npractitioner and smiled-implied delta hedging procedures, both in simulation\nand backtesting experiments.", "arxiv_id": "http://arxiv.org/abs/2407.21138v1", "pdf_url": "http://arxiv.org/pdf/2407.21138v1", "primary_category": "q-fin.RM", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Computational music analysis from first principles", "authors": "Dmitri Tymoczko, Mark Newman", "abstract": "We use coupled hidden Markov models to automatically annotate the 371 Bach\nchorales in the Riemenschneider edition, a corpus containing approximately\n100,000 notes and 20,000 chords. We give three separate analyses that achieve\nprogressively greater accuracy at the cost of making increasingly strong\nassumptions about musical syntax. Although our method makes almost no use of\nhuman input, we are able to identify both chords and keys with an accuracy of\n85% or greater when compared to an expert human analysis, resulting in\nannotations accurate enough to be used for a range of music-theoretical\npurposes, while also being free of subjective human judgments. Our work bears\non longstanding debates about the objective reality of the structures\npostulated by standard Western harmonic theory, as well as on specific\nquestions about the nature of Western harmonic syntax.", "arxiv_id": "http://arxiv.org/abs/2407.21130v1", "pdf_url": "http://arxiv.org/pdf/2407.21130v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Zero Shot Health Trajectory Prediction Using Transformer", "authors": "Pawel Renc, Yugang Jia, Anthony E. Samir, Jaroslaw Was, Quanzheng Li, David W. Bates, Arkadiusz Sitek", "abstract": "Integrating modern machine learning and clinical decision-making has great\npromise for mitigating healthcare's increasing cost and complexity. We\nintroduce the Enhanced Transformer for Health Outcome Simulation (ETHOS), a\nnovel application of the transformer deep-learning architecture for analyzing\nhigh-dimensional, heterogeneous, and episodic health data. ETHOS is trained\nusing Patient Health Timelines (PHTs)-detailed, tokenized records of health\nevents-to predict future health trajectories, leveraging a zero-shot learning\napproach. ETHOS represents a significant advancement in foundation model\ndevelopment for healthcare analytics, eliminating the need for labeled data and\nmodel fine-tuning. Its ability to simulate various treatment pathways and\nconsider patient-specific factors positions ETHOS as a tool for care\noptimization and addressing biases in healthcare delivery. Future developments\nwill expand ETHOS' capabilities to incorporate a wider range of data types and\ndata sources. Our work demonstrates a pathway toward accelerated AI development\nand deployment in healthcare.", "arxiv_id": "http://arxiv.org/abs/2407.21124v1", "pdf_url": "http://arxiv.org/pdf/2407.21124v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "RELEVANT"}
{"title": "Taming the Frequency Factory of Sinusoidal Networks", "authors": "Tiago Novello, Diana Aldana, Luiz Velho", "abstract": "This work investigates the structure and representation capacity of\n$sinusoidal$ MLPs, which have recently shown promising results in encoding\nlow-dimensional signals. This success can be attributed to its smoothness and\nhigh representation capacity. The first allows the use of the network's\nderivatives during training, enabling regularization. However, defining the\narchitecture and initializing its parameters to achieve a desired capacity\nremains an empirical task. This work provides theoretical and experimental\nresults justifying the capacity property of sinusoidal MLPs and offers control\nmechanisms for their initialization and training.\n  We approach this from a Fourier series perspective and link the training with\nthe model's spectrum. Our analysis is based on a $harmonic$ expansion of the\nsinusoidal MLP, which says that the composition of sinusoidal layers produces a\nlarge number of new frequencies expressed as integer linear combinations of the\ninput frequencies (weights of the input layer). We use this novel $identity$ to\ninitialize the input neurons which work as a sampling in the signal spectrum.\nWe also note that each hidden neuron produces the same frequencies with\namplitudes completely determined by the hidden weights. Finally, we give an\nupper bound for these amplitudes, which results in a $bounding$ scheme for the\nnetwork's spectrum during training.", "arxiv_id": "http://arxiv.org/abs/2407.21121v1", "pdf_url": "http://arxiv.org/pdf/2407.21121v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Palu: Compressing KV-Cache with Low-Rank Projection", "authors": "Chi-Chih Chang, Wei-Cheng Lin, Chien-Yu Lin, Chong-Yan Chen, Yu-Fang Hu, Pei-Shuo Wang, Ning-Chi Huang, Luis Ceze, Kai-Chiang Wu", "abstract": "KV-Cache compression methods generally sample a KV-Cache of effectual tokens\nor quantize it into lower bits. However, these methods cannot exploit the\nredundancy of the hidden dimension of KV tensors. This paper investigates a\nunique hidden dimension approach called Palu, a novel KV-Cache compression\nframework that utilizes low-rank projection. Palu decomposes the linear layers\ninto low-rank matrices, caches the smaller intermediate states, and\nreconstructs the full keys and values on the fly. To improve accuracy,\ncompression rate, and efficiency, Palu further encompasses (1) a medium-grained\nlow-rank decomposition scheme, (2) an efficient rank search algorithm, (3) a\nlow-rank-aware quantization algorithm, and (4) matrix fusion with optimized GPU\nkernels. Our extensive experiments with popular LLMs show that Palu can\ncompress KV-Cache by more than 91.25% while maintaining a significantly better\naccuracy (up to 1.19 lower perplexity) than state-of-the-art KV-Cache\nquantization methods at a similar or even higher memory usage. When compressing\nKV-Cache for 50%, Palu delivers up to 1.61x end-to-end speedup for the\nattention module. Our code is publicly available at\nhttps://github.com/shadowpa0327/Palu.", "arxiv_id": "http://arxiv.org/abs/2407.21118v1", "pdf_url": "http://arxiv.org/pdf/2407.21118v1", "primary_category": "cs.AI", "preferences": "I'm intersted in LLMs", "response": "RELEVANT"}
{"title": "CLEFT: Language-Image Contrastive Learning with Efficient Large Language Model and Prompt Fine-Tuning", "authors": "Yuexi Du, Brian Chang, Nicha C. Dvornek", "abstract": "Recent advancements in Contrastive Language-Image Pre-training (CLIP) have\ndemonstrated notable success in self-supervised representation learning across\nvarious tasks. However, the existing CLIP-like approaches often demand\nextensive GPU resources and prolonged training times due to the considerable\nsize of the model and dataset, making them poor for medical applications, in\nwhich large datasets are not always common. Meanwhile, the language model\nprompts are mainly manually derived from labels tied to images, potentially\noverlooking the richness of information within training samples. We introduce a\nnovel language-image Contrastive Learning method with an Efficient large\nlanguage model and prompt Fine-Tuning (CLEFT) that harnesses the strengths of\nthe extensive pre-trained language and visual models. Furthermore, we present\nan efficient strategy for learning context-based prompts that mitigates the gap\nbetween informative clinical diagnostic data and simple class labels. Our\nmethod demonstrates state-of-the-art performance on multiple chest X-ray and\nmammography datasets compared with various baselines. The proposed parameter\nefficient framework can reduce the total trainable model size by 39% and reduce\nthe trainable language model to only 4% compared with the current BERT encoder.", "arxiv_id": "http://arxiv.org/abs/2407.21011v1", "pdf_url": "http://arxiv.org/pdf/2407.21011v1", "primary_category": "cs.CV", "preferences": "I'm intersted in LLMs", "response": "RELEVANT"}
{"title": "GABInsight: Exploring Gender-Activity Binding Bias in Vision-Language Models", "authors": "Ali Abdollahi, Mahdi Ghaznavi, Mohammad Reza Karimi Nejad, Arash Mari Oriyad, Reza Abbasi, Ali Salesi, Melika Behjati, Mohammad Hossein Rohban, Mahdieh Soleymani Baghshah", "abstract": "Vision-language models (VLMs) are intensively used in many downstream tasks,\nincluding those requiring assessments of individuals appearing in the images.\nWhile VLMs perform well in simple single-person scenarios, in real-world\napplications, we often face complex situations in which there are persons of\ndifferent genders doing different activities. We show that in such cases, VLMs\nare biased towards identifying the individual with the expected gender\n(according to ingrained gender stereotypes in the model or other forms of\nsample selection bias) as the performer of the activity. We refer to this bias\nin associating an activity with the gender of its actual performer in an image\nor text as the Gender-Activity Binding (GAB) bias and analyze how this bias is\ninternalized in VLMs. To assess this bias, we have introduced the GAB dataset\nwith approximately 5500 AI-generated images that represent a variety of\nactivities, addressing the scarcity of real-world images for some scenarios. To\nhave extensive quality control, the generated images are evaluated for their\ndiversity, quality, and realism. We have tested 12 renowned pre-trained VLMs on\nthis dataset in the context of text-to-image and image-to-text retrieval to\nmeasure the effect of this bias on their predictions. Additionally, we have\ncarried out supplementary experiments to quantify the bias in VLMs' text\nencoders and to evaluate VLMs' capability to recognize activities. Our\nexperiments indicate that VLMs experience an average performance decline of\nabout 13.2% when confronted with gender-activity binding bias.", "arxiv_id": "http://arxiv.org/abs/2407.21001v1", "pdf_url": "http://arxiv.org/pdf/2407.21001v1", "primary_category": "cs.CV", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "MoFO: Momentum-Filtered Optimizer for Mitigating Forgetting in LLM Fine-Tuning", "authors": "Yupeng Chen, Senmiao Wang, Zhihang Lin, Zeyu Qin, Yushun Zhang, Tian Ding, Ruoyu Sun", "abstract": "Recently, large language models (LLMs) have demonstrated remarkable\ncapabilities in a wide range of tasks. Typically, an LLM is pre-trained on\nlarge corpora and subsequently fine-tuned on task-specific datasets. However,\nduring fine-tuning, LLMs may forget the knowledge acquired in the pre-training\nstage, leading to a decline in general capabilities. To address this issue, we\npropose a new fine-tuning algorithm termed Momentum-Filtered Optimizer (MoFO).\nThe key idea of MoFO is to iteratively select and update the model parameters\nwith the largest momentum magnitudes. Compared to full-parameter training, MoFO\nachieves similar fine-tuning performance while keeping parameters closer to the\npre-trained model, thereby mitigating knowledge forgetting. Unlike most\nexisting methods for forgetting mitigation, MoFO combines the following two\nadvantages. First, MoFO does not require access to pre-training data. This\nmakes MoFO particularly suitable for fine-tuning scenarios where pre-training\ndata is unavailable, such as fine-tuning checkpoint-only open-source LLMs.\nSecond, MoFO does not alter the original loss function. This could avoid\nimpairing the model performance on the fine-tuning tasks. We validate MoFO\nthrough rigorous convergence analysis and extensive experiments, demonstrating\nits superiority over existing methods in mitigating forgetting and enhancing\nfine-tuning performance.", "arxiv_id": "http://arxiv.org/abs/2407.20999v2", "pdf_url": "http://arxiv.org/pdf/2407.20999v2", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "RELEVANT"}
{"title": "From Feature Importance to Natural Language Explanations Using LLMs with RAG", "authors": "Sule Tekkesinoglu, Lars Kunze", "abstract": "As machine learning becomes increasingly integral to autonomous\ndecision-making processes involving human interaction, the necessity of\ncomprehending the model's outputs through conversational means increases. Most\nrecently, foundation models are being explored for their potential as post hoc\nexplainers, providing a pathway to elucidate the decision-making mechanisms of\npredictive models. In this work, we introduce traceable question-answering,\nleveraging an external knowledge repository to inform the responses of Large\nLanguage Models (LLMs) to user queries within a scene understanding task. This\nknowledge repository comprises contextual details regarding the model's output,\ncontaining high-level features, feature importance, and alternative\nprobabilities. We employ subtractive counterfactual reasoning to compute\nfeature importance, a method that entails analysing output variations resulting\nfrom decomposing semantic features. Furthermore, to maintain a seamless\nconversational flow, we integrate four key characteristics - social, causal,\nselective, and contrastive - drawn from social science research on human\nexplanations into a single-shot prompt, guiding the response generation\nprocess. Our evaluation demonstrates that explanations generated by the LLMs\nencompassed these elements, indicating its potential to bridge the gap between\ncomplex model outputs and natural language expressions.", "arxiv_id": "http://arxiv.org/abs/2407.20990v1", "pdf_url": "http://arxiv.org/pdf/2407.20990v1", "primary_category": "cs.AI", "preferences": "I'm intersted in LLMs", "response": "RELEVANT"}
{"title": "Contrasting Deep Learning Models for Direct Respiratory Insufficiency Detection Versus Blood Oxygen Saturation Estimation", "authors": "Marcelo Matheus Gauy, Natalia Hitomi Koza, Ricardo Mikio Morita, Gabriel Rocha Stanzione, Arnaldo Candido Junior, Larissa Cristina Berti, Anna Sara Shafferman Levin, Ester Cerdeira Sabino, Flaviane Romani Fernandes Svartman, Marcelo Finger", "abstract": "We contrast high effectiveness of state of the art deep learning\narchitectures designed for general audio classification tasks, refined for\nrespiratory insufficiency (RI) detection and blood oxygen saturation (SpO2)\nestimation and classification through automated audio analysis. Recently,\nmultiple deep learning architectures have been proposed to detect RI in COVID\npatients through audio analysis, achieving accuracy above 95% and F1-score\nabove 0.93. RI is a condition associated with low SpO2 levels, commonly defined\nas the threshold SpO2 <92%. While SpO2 serves as a crucial determinant of RI, a\nmedical doctor's diagnosis typically relies on multiple factors. These include\nrespiratory frequency, heart rate, SpO2 levels, among others. Here we study\npretrained audio neural networks (CNN6, CNN10 and CNN14) and the Masked\nAutoencoder (Audio-MAE) for RI detection, where these models achieve near\nperfect accuracy, surpassing previous results. Yet, for the regression task of\nestimating SpO2 levels, the models achieve root mean square error values\nexceeding the accepted clinical range of 3.5% for finger oximeters.\nAdditionally, Pearson correlation coefficients fail to surpass 0.3. As deep\nlearning models perform better in classification than regression, we transform\nSpO2-regression into a SpO2-threshold binary classification problem, with a\nthreshold of 92%. However, this task still yields an F1-score below 0.65. Thus,\naudio analysis offers valuable insights into a patient's RI status, but does\nnot provide accurate information about actual SpO2 levels, indicating a\nseparation of domains in which voice and speech biomarkers may and may not be\nuseful in medical diagnostics under current technologies.", "arxiv_id": "http://arxiv.org/abs/2407.20989v1", "pdf_url": "http://arxiv.org/pdf/2407.20989v1", "primary_category": "cs.SD", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "The Stochastic Conjugate Subgradient Algorithm For Kernel Support Vector Machines", "authors": "Di Zhang, Suvrajeet Sen", "abstract": "Stochastic First-Order (SFO) methods have been a cornerstone in addressing a\nbroad spectrum of modern machine learning (ML) challenges. However, their\nefficacy is increasingly questioned, especially in large-scale applications\nwhere empirical evidence indicates potential performance limitations. In\nresponse, this paper proposes an innovative method specifically designed for\nkernel support vector machines (SVMs). This method not only achieves faster\nconvergence per iteration but also exhibits enhanced scalability when compared\nto conventional SFO techniques. Diverging from traditional sample average\napproximation strategies that typically frame kernel SVM as an 'all-in-one'\nQuadratic Program (QP), our approach adopts adaptive sampling. This strategy\nincrementally refines approximation accuracy on an 'as-needed' basis.\nCrucially, this approach also inspires a decomposition-based algorithm,\neffectively decomposing parameter selection from error estimation, with the\nlatter being independently determined for each data point. To exploit the\nquadratic nature of the kernel matrix, we introduce a stochastic conjugate\nsubgradient method. This method preserves many benefits of first-order\napproaches while adeptly handling both nonlinearity and non-smooth aspects of\nthe SVM problem. Thus, it extends beyond the capabilities of standard SFO\nalgorithms for non-smooth convex optimization. The convergence rate of this\nnovel method is thoroughly analyzed within this paper. Our experimental results\ndemonstrate that the proposed algorithm not only maintains but potentially\nexceeds the scalability of SFO methods. Moreover, it significantly enhances\nboth speed and accuracy of the optimization process.", "arxiv_id": "http://arxiv.org/abs/2407.21091v1", "pdf_url": "http://arxiv.org/pdf/2407.21091v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Learning Optimal Signal Temporal Logic Decision Trees for Classification: A Max-Flow MILP Formulation", "authors": "Kaier Liang, Gustavo A. Cardona, Disha Kamale, Cristian-Ioan Vasile", "abstract": "This paper presents a novel framework for inferring timed temporal logic\nproperties from data. The dataset comprises pairs of finite-time system traces\nand corresponding labels, denoting whether the traces demonstrate specific\ndesired behaviors, e.g. whether the ship follows a safe route or not. Our\nproposed approach leverages decision-tree-based methods to infer Signal\nTemporal Logic classifiers using primitive formulae. We formulate the inference\nprocess as a mixed integer linear programming optimization problem, recursively\ngenerating constraints to determine both data classification and tree\nstructure. Applying a max-flow algorithm on the resultant tree transforms the\nproblem into a global optimization challenge, leading to improved\nclassification rates compared to prior methodologies. Moreover, we introduce a\ntechnique to reduce the number of constraints by exploiting the symmetry\ninherent in STL primitives, which enhances the algorithm's time performance and\ninterpretability. To assess our algorithm's effectiveness and classification\nperformance, we conduct three case studies involving two-class, multi-class,\nand complex formula classification scenarios.", "arxiv_id": "http://arxiv.org/abs/2407.21090v1", "pdf_url": "http://arxiv.org/pdf/2407.21090v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Learning Ordinality in Semantic Segmentation", "authors": "Rafael Cristino, Ricardo P. M. Cruz, Jaime S. Cardoso", "abstract": "Semantic segmentation consists of predicting a semantic label for each image\npixel. Conventional deep learning models do not take advantage of ordinal\nrelations that might exist in the domain at hand. For example, it is known that\nthe pupil is inside the iris, and the lane markings are inside the road. Such\ndomain knowledge can be employed as constraints to make the model more robust.\nThe current literature on this topic has explored pixel-wise ordinal\nsegmentation methods, which treat each pixel as an independent observation and\npromote ordinality in its representation. This paper proposes novel spatial\nordinal segmentation methods, which take advantage of the structured image\nspace by considering each pixel as an observation dependent on its neighborhood\ncontext to also promote ordinal spatial consistency. When evaluated with five\nbiomedical datasets and multiple configurations of autonomous driving datasets,\nordinal methods resulted in more ordinally-consistent models, with substantial\nimprovements in ordinal metrics and some increase in the Dice coefficient. It\nwas also shown that the incorporation of ordinal consistency results in models\nwith better generalization abilities.", "arxiv_id": "http://arxiv.org/abs/2407.20959v1", "pdf_url": "http://arxiv.org/pdf/2407.20959v1", "primary_category": "cs.CV", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "An Effective Dynamic Gradient Calibration Method for Continual Learning", "authors": "Weichen Lin, Jiaxiang Chen, Ruomin Huang, Hu Ding", "abstract": "Continual learning (CL) is a fundamental topic in machine learning, where the\ngoal is to train a model with continuously incoming data and tasks. Due to the\nmemory limit, we cannot store all the historical data, and therefore confront\nthe ``catastrophic forgetting'' problem, i.e., the performance on the previous\ntasks can substantially decrease because of the missing information in the\nlatter period. Though a number of elegant methods have been proposed, the\ncatastrophic forgetting phenomenon still cannot be well avoided in practice. In\nthis paper, we study the problem from the gradient perspective, where our aim\nis to develop an effective algorithm to calibrate the gradient in each updating\nstep of the model; namely, our goal is to guide the model to be updated in the\nright direction under the situation that a large amount of historical data are\nunavailable. Our idea is partly inspired by the seminal stochastic variance\nreduction methods (e.g., SVRG and SAGA) for reducing the variance of gradient\nestimation in stochastic gradient descent algorithms. Another benefit is that\nour approach can be used as a general tool, which is able to be incorporated\nwith several existing popular CL methods to achieve better performance. We also\nconduct a set of experiments on several benchmark datasets to evaluate the\nperformance in practice.", "arxiv_id": "http://arxiv.org/abs/2407.20956v1", "pdf_url": "http://arxiv.org/pdf/2407.20956v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "How to Choose a Reinforcement-Learning Algorithm", "authors": "Fabian Bongratz, Vladimir Golkov, Lukas Mautner, Luca Della Libera, Frederik Heetmeyer, Felix Czaja, Julian Rodemann, Daniel Cremers", "abstract": "The field of reinforcement learning offers a large variety of concepts and\nmethods to tackle sequential decision-making problems. This variety has become\nso large that choosing an algorithm for a task at hand can be challenging. In\nthis work, we streamline the process of choosing reinforcement-learning\nalgorithms and action-distribution families. We provide a structured overview\nof existing methods and their properties, as well as guidelines for when to\nchoose which methods. An interactive version of these guidelines is available\nonline at https://rl-picker.github.io/.", "arxiv_id": "http://arxiv.org/abs/2407.20917v1", "pdf_url": "http://arxiv.org/pdf/2407.20917v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "What Are Good Positional Encodings for Directed Graphs?", "authors": "Yinan Huang, Haoyu Wang, Pan Li", "abstract": "Positional encodings (PE) for graphs are essential in constructing powerful\nand expressive graph neural networks and graph transformers as they effectively\ncapture relative spatial relations between nodes. While PEs for undirected\ngraphs have been extensively studied, those for directed graphs remain largely\nunexplored, despite the fundamental role of directed graphs in representing\nentities with strong logical dependencies, such as those in program analysis\nand circuit designs. This work studies the design of PEs for directed graphs\nthat are expressive to represent desired directed spatial relations. We first\npropose walk profile, a generalization of walk counting sequence to directed\ngraphs. We identify limitations in existing PE methods, including symmetrized\nLaplacian PE, Singular Value Decomposition PE, and Magnetic Laplacian PE, in\ntheir ability to express walk profiles. To address these limitations, we\npropose the Multi-q Magnetic Laplacian PE, which extends Magnetic Laplacian PE\nwith multiple potential factors. This simple variant turns out to be capable of\nprovably expressing walk profiles. Furthermore, we generalize previous\nbasis-invariant and stable networks to handle complex-domain PEs decomposed\nfrom Magnetic Laplacians. Our numerical experiments demonstrate the\neffectiveness of Multi-q Magnetic Laplacian PE with a stable neural\narchitecture, outperforming previous PE methods (with stable networks) on\npredicting directed distances/walk profiles, sorting network satisfiability,\nand on general circuit benchmarks. Our code is available at\nhttps://github.com/Graph-COM/Multi-q-Maglap.", "arxiv_id": "http://arxiv.org/abs/2407.20912v1", "pdf_url": "http://arxiv.org/pdf/2407.20912v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Machine learning surrogates for efficient hydrologic modeling: Insights from stochastic simulations of managed aquifer recharge", "authors": "Timothy Dai, Kate Maher, Zach Perzan", "abstract": "Process-based hydrologic models are invaluable tools for understanding the\nterrestrial water cycle and addressing modern water resources problems.\nHowever, many hydrologic models are computationally expensive and, depending on\nthe resolution and scale, simulations can take on the order of hours to days to\ncomplete. While techniques such as uncertainty quantification and optimization\nhave become valuable tools for supporting management decisions, these analyses\ntypically require hundreds of model simulations, which are too computationally\nexpensive to perform with a process-based hydrologic model. To address this\ngap, we propose a hybrid modeling workflow in which a process-based model is\nused to generate an initial set of simulations and a machine learning (ML)\nsurrogate model is then trained to perform the remaining simulations required\nfor downstream analysis. As a case study, we apply this workflow to simulations\nof variably saturated groundwater flow at a prospective managed aquifer\nrecharge (MAR) site. We compare the accuracy and computational efficiency of\nseveral ML architectures, including deep convolutional networks, recurrent\nneural networks, vision transformers, and networks with Fourier transforms. Our\nresults demonstrate that ML surrogate models can achieve under 10% mean\nabsolute percentage error and yield order-of-magnitude runtime savings over\nprocessed-based models. We also offer practical recommendations for training\nhydrologic surrogate models, including implementing data normalization to\nimprove accuracy, using a normalized loss function to improve training\nstability and downsampling input features to decrease memory requirements.", "arxiv_id": "http://arxiv.org/abs/2407.20902v1", "pdf_url": "http://arxiv.org/pdf/2407.20902v1", "primary_category": "physics.geo-ph", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "MambaCapsule: Towards Transparent Cardiac Disease Diagnosis with Electrocardiography Using Mamba Capsule Network", "authors": "Yinlong Xu, Xiaoqiang Liu, Zitai Kong, Yixuan Wu, Yue Wang, Yingzhou Lu, Honghao Gao, Jian Wu, Hongxia Xu", "abstract": "Cardiac arrhythmia, a condition characterized by irregular heartbeats, often\nserves as an early indication of various heart ailments. With the advent of\ndeep learning, numerous innovative models have been introduced for diagnosing\narrhythmias using Electrocardiogram (ECG) signals. However, recent studies\nsolely focus on the performance of models, neglecting the interpretation of\ntheir results. This leads to a considerable lack of transparency, posing a\nsignificant risk in the actual diagnostic process. To solve this problem, this\npaper introduces MambaCapsule, a deep neural networks for ECG arrhythmias\nclassification, which increases the explainability of the model while enhancing\nthe accuracy.Our model utilizes Mamba for feature extraction and Capsule\nnetworks for prediction, providing not only a confidence score but also signal\nfeatures. Akin to the processing mechanism of human brain, the model learns\nsignal features and their relationship between them by reconstructing ECG\nsignals in the predicted selection. The model evaluation was conducted on\nMIT-BIH and PTB dataset, following the AAMI standard. MambaCapsule has achieved\na total accuracy of 99.54% and 99.59% on the test sets respectively. These\nresults demonstrate the promising performance of under the standard test\nprotocol.", "arxiv_id": "http://arxiv.org/abs/2407.20893v1", "pdf_url": "http://arxiv.org/pdf/2407.20893v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Bayesian Low-Rank LeArning (Bella): A Practical Approach to Bayesian Neural Networks", "authors": "Bao Gia Doan, Afshar Shamsi, Xiao-Yu Guo, Arash Mohammadi, Hamid Alinejad-Rokny, Dino Sejdinovic, Damith C. Ranasinghe, Ehsan Abbasnejad", "abstract": "Computational complexity of Bayesian learning is impeding its adoption in\npractical, large-scale tasks. Despite demonstrations of significant merits such\nas improved robustness and resilience to unseen or out-of-distribution inputs\nover their non- Bayesian counterparts, their practical use has faded to near\ninsignificance. In this study, we introduce an innovative framework to mitigate\nthe computational burden of Bayesian neural networks (BNNs). Our approach\nfollows the principle of Bayesian techniques based on deep ensembles, but\nsignificantly reduces their cost via multiple low-rank perturbations of\nparameters arising from a pre-trained neural network. Both vanilla version of\nensembles as well as more sophisticated schemes such as Bayesian learning with\nStein Variational Gradient Descent (SVGD), previously deemed impractical for\nlarge models, can be seamlessly implemented within the proposed framework,\ncalled Bayesian Low-Rank LeArning (Bella). In a nutshell, i) Bella achieves a\ndramatic reduction in the number of trainable parameters required to\napproximate a Bayesian posterior; and ii) it not only maintains, but in some\ninstances, surpasses the performance of conventional Bayesian learning methods\nand non-Bayesian baselines. Our results with large-scale tasks such as\nImageNet, CAMELYON17, DomainNet, VQA with CLIP, LLaVA demonstrate the\neffectiveness and versatility of Bella in building highly scalable and\npractical Bayesian deep models for real-world applications.", "arxiv_id": "http://arxiv.org/abs/2407.20891v1", "pdf_url": "http://arxiv.org/pdf/2407.20891v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
{"title": "Co-Neighbor Encoding Schema: A Light-cost Structure Encoding Method for Dynamic Link Prediction", "authors": "Ke Cheng, Linzhi Peng, Junchen Ye, Leilei Sun, Bowen Du", "abstract": "Structure encoding has proven to be the key feature to distinguishing links\nin a graph. However, Structure encoding in the temporal graph keeps changing as\nthe graph evolves, repeatedly computing such features can be time-consuming due\nto the high-order subgraph construction. We develop the Co-Neighbor Encoding\nSchema (CNES) to address this issue. Instead of recomputing the feature by the\nlink, CNES stores information in the memory to avoid redundant calculations.\nBesides, unlike the existing memory-based dynamic graph learning method that\nstores node hidden states, we introduce a hashtable-based memory to compress\nthe adjacency matrix for efficient structure feature construction and updating\nwith vector computation in parallel. Furthermore, CNES introduces a\nTemporal-Diverse Memory to generate long-term and short-term structure encoding\nfor neighbors with different structural information. A dynamic graph learning\nframework, Co-Neighbor Encoding Network (CNE-N), is proposed using the\naforementioned techniques. Extensive experiments on thirteen public datasets\nverify the effectiveness and efficiency of the proposed method.", "arxiv_id": "http://arxiv.org/abs/2407.20871v1", "pdf_url": "http://arxiv.org/pdf/2407.20871v1", "primary_category": "cs.LG", "preferences": "I'm intersted in LLMs", "response": "UNRELATED"}
