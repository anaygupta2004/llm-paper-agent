[
  {
    "title": "Generalized Out-of-Distribution Detection and Beyond in Vision Language Model Era: A Survey",
    "authors": "Atsuyuki Miyai, Jingkang Yang, Jingyang Zhang, Yifei Ming, Yueqian Lin, Qing Yu, Go Irie, Shafiq Joty, Yixuan Li, Hai Li, Ziwei Liu, Toshihiko Yamasaki, Kiyoharu Aizawa",
    "abstract": "Detecting out-of-distribution (OOD) samples is crucial for ensuring the\nsafety of machine learning systems and has shaped the field of OOD detection.\nMeanwhile, several other problems are closely related to OOD detection,\nincluding anomaly detection (AD), novelty detection (ND), open set recognition\n(OSR), and outlier detection (OD). To unify these problems, a generalized OOD\ndetection framework was proposed, taxonomically categorizing these five\nproblems. However, Vision Language Models (VLMs) such as CLIP have\nsignificantly changed the paradigm and blurred the boundaries between these\nfields, again confusing researchers. In this survey, we first present a\ngeneralized OOD detection v2, encapsulating the evolution of AD, ND, OSR, OOD\ndetection, and OD in the VLM era. Our framework reveals that, with some field\ninactivity and integration, the demanding challenges have become OOD detection\nand AD. In addition, we also highlight the significant shift in the definition,\nproblem settings, and benchmarks; we thus feature a comprehensive review of the\nmethodology for OOD detection, including the discussion over other related\ntasks to clarify their relationship to OOD detection. Finally, we explore the\nadvancements in the emerging Large Vision Language Model (LVLM) era, such as\nGPT-4V. We conclude this survey with open challenges and future directions.",
    "arxiv_id": "http://arxiv.org/abs/2407.21794v1",
    "pdf_url": "http://arxiv.org/pdf/2407.21794v1",
    "primary_category": "cs.CV",
    "votes": 1,
    "prompt": "LLM",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Safetywashing: Do AI Safety Benchmarks Actually Measure Safety Progress?",
    "authors": "Richard Ren, Steven Basart, Adam Khoja, Alice Gatti, Long Phan, Xuwang Yin, Mantas Mazeika, Alexander Pan, Gabriel Mukobi, Ryan H. Kim, Stephen Fitz, Dan Hendrycks",
    "abstract": "As artificial intelligence systems grow more powerful, there has been\nincreasing interest in \"AI safety\" research to address emerging and future\nrisks. However, the field of AI safety remains poorly defined and\ninconsistently measured, leading to confusion about how researchers can\ncontribute. This lack of clarity is compounded by the unclear relationship\nbetween AI safety benchmarks and upstream general capabilities (e.g., general\nknowledge and reasoning). To address these issues, we conduct a comprehensive\nmeta-analysis of AI safety benchmarks, empirically analyzing their correlation\nwith general capabilities across dozens of models and providing a survey of\nexisting directions in AI safety. Our findings reveal that many safety\nbenchmarks highly correlate with upstream model capabilities, potentially\nenabling \"safetywashing\" -- where capability improvements are misrepresented as\nsafety advancements. Based on these findings, we propose an empirical\nfoundation for developing more meaningful safety metrics and define AI safety\nin a machine learning research context as a set of clearly delineated research\ngoals that are empirically separable from generic capabilities advancements. In\ndoing so, we aim to provide a more rigorous framework for AI safety research,\nadvancing the science of safety evaluations and clarifying the path towards\nmeasurable progress.",
    "arxiv_id": "http://arxiv.org/abs/2407.21792v1",
    "pdf_url": "http://arxiv.org/pdf/2407.21792v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "LLM",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Vision-Language Model Based Handwriting Verification",
    "authors": "Mihir Chauhan, Abhishek Satbhai, Mohammad Abuzar Hashemi, Mir Basheer Ali, Bina Ramamurthy, Mingchen Gao, Siwei Lyu, Sargur Srihari",
    "abstract": "Handwriting Verification is a critical in document forensics. Deep learning\nbased approaches often face skepticism from forensic document examiners due to\ntheir lack of explainability and reliance on extensive training data and\nhandcrafted features. This paper explores using Vision Language Models (VLMs),\nsuch as OpenAI's GPT-4o and Google's PaliGemma, to address these challenges. By\nleveraging their Visual Question Answering capabilities and 0-shot\nChain-of-Thought (CoT) reasoning, our goal is to provide clear,\nhuman-understandable explanations for model decisions. Our experiments on the\nCEDAR handwriting dataset demonstrate that VLMs offer enhanced\ninterpretability, reduce the need for large training datasets, and adapt better\nto diverse handwriting styles. However, results show that the CNN-based\nResNet-18 architecture outperforms the 0-shot CoT prompt engineering approach\nwith GPT-4o (Accuracy: 70%) and supervised fine-tuned PaliGemma (Accuracy:\n71%), achieving an accuracy of 84% on the CEDAR AND dataset. These findings\nhighlight the potential of VLMs in generating human-interpretable decisions\nwhile underscoring the need for further advancements to match the performance\nof specialized deep learning models.",
    "arxiv_id": "http://arxiv.org/abs/2407.21788v1",
    "pdf_url": "http://arxiv.org/pdf/2407.21788v1",
    "primary_category": "cs.CV",
    "votes": 1,
    "prompt": "LLM",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Large Language Monkeys: Scaling Inference Compute with Repeated Sampling",
    "authors": "Bradley Brown, Jordan Juravsky, Ryan Ehrlich, Ronald Clark, Quoc V. Le, Christopher R\u00e9, Azalia Mirhoseini",
    "abstract": "Scaling the amount of compute used to train language models has dramatically\nimproved their capabilities. However, when it comes to inference, we often\nlimit the amount of compute to only one attempt per problem. Here, we explore\ninference compute as another axis for scaling by increasing the number of\ngenerated samples. Across multiple tasks and models, we observe that coverage -\nthe fraction of problems solved by any attempt - scales with the number of\nsamples over four orders of magnitude. In domains like coding and formal\nproofs, where all answers can be automatically verified, these increases in\ncoverage directly translate into improved performance. When we apply repeated\nsampling to SWE-bench Lite, the fraction of issues solved with\nDeepSeek-V2-Coder-Instruct increases from 15.9% with one sample to 56% with 250\nsamples, outperforming the single-attempt state-of-the-art of 43% which uses\nmore capable frontier models. Moreover, using current API pricing, amplifying\nthe cheaper DeepSeek model with five samples is more cost-effective and solves\nmore issues than paying a premium for one sample from GPT-4o or Claude 3.5\nSonnet. Interestingly, the relationship between coverage and the number of\nsamples is often log-linear and can be modelled with an exponentiated power\nlaw, suggesting the existence of inference-time scaling laws. Finally, we find\nthat identifying correct samples out of many generations remains an important\ndirection for future research in domains without automatic verifiers. When\nsolving math word problems from GSM8K and MATH, coverage with Llama-3 models\ngrows to over 95% with 10,000 samples. However, common methods to pick correct\nsolutions from a sample collection, such as majority voting or reward models,\nplateau beyond several hundred samples and fail to fully scale with the sample\nbudget.",
    "arxiv_id": "http://arxiv.org/abs/2407.21787v1",
    "pdf_url": "http://arxiv.org/pdf/2407.21787v1",
    "primary_category": "cs.LG",
    "votes": 1,
    "prompt": "LLM",
    "model": "gpt-4-turbo"
  },
  {
    "title": "ShieldGemma: Generative AI Content Moderation Based on Gemma",
    "authors": "Wenjun Zeng, Yuchi Liu, Ryan Mullins, Ludovic Peran, Joe Fernandez, Hamza Harkous, Karthik Narasimhan, Drew Proud, Piyush Kumar, Bhaktipriya Radharapu, Olivia Sturman, Oscar Wahltinez",
    "abstract": "We present ShieldGemma, a comprehensive suite of LLM-based safety content\nmoderation models built upon Gemma2. These models provide robust,\nstate-of-the-art predictions of safety risks across key harm types (sexually\nexplicit, dangerous content, harassment, hate speech) in both user input and\nLLM-generated output. By evaluating on both public and internal benchmarks, we\ndemonstrate superior performance compared to existing models, such as Llama\nGuard (+10.8\\% AU-PRC on public benchmarks) and WildCard (+4.3\\%).\nAdditionally, we present a novel LLM-based data curation pipeline, adaptable to\na variety of safety-related tasks and beyond. We have shown strong\ngeneralization performance for model trained mainly on synthetic data. By\nreleasing ShieldGemma, we provide a valuable resource to the research\ncommunity, advancing LLM safety and enabling the creation of more effective\ncontent moderation solutions for developers.",
    "arxiv_id": "http://arxiv.org/abs/2407.21772v1",
    "pdf_url": "http://arxiv.org/pdf/2407.21772v1",
    "primary_category": "cs.CL",
    "votes": 1,
    "prompt": "LLM",
    "model": "gpt-4-turbo"
  },
  {
    "title": "MoMa: Efficient Early-Fusion Pre-training with Mixture of Modality-Aware Experts",
    "authors": "Xi Victoria Lin, Akshat Shrivastava, Liang Luo, Srinivasan Iyer, Mike Lewis, Gargi Gosh, Luke Zettlemoyer, Armen Aghajanyan",
    "abstract": "We introduce MoMa, a novel modality-aware mixture-of-experts (MoE)\narchitecture designed for pre-training mixed-modal, early-fusion language\nmodels. MoMa processes images and text in arbitrary sequences by dividing\nexpert modules into modality-specific groups. These groups exclusively process\ndesignated tokens while employing learned routing within each group to maintain\nsemantically informed adaptivity. Our empirical results reveal substantial\npre-training efficiency gains through this modality-specific parameter\nallocation. Under a 1-trillion-token training budget, the MoMa 1.4B model,\nfeaturing 4 text experts and 4 image experts, achieves impressive FLOPs\nsavings: 3.7x overall, with 2.6x for text and 5.2x for image processing\ncompared to a compute-equivalent dense baseline, measured by pre-training loss.\nThis outperforms the standard expert-choice MoE with 8 mixed-modal experts,\nwhich achieves 3x overall FLOPs savings (3x for text, 2.8x for image).\nCombining MoMa with mixture-of-depths (MoD) further improves pre-training FLOPs\nsavings to 4.2x overall (text: 3.4x, image: 5.3x), although this combination\nhurts performance in causal inference due to increased sensitivity to router\naccuracy. These results demonstrate MoMa's potential to significantly advance\nthe efficiency of mixed-modal, early-fusion language model pre-training, paving\nthe way for more resource-efficient and capable multimodal AI systems.",
    "arxiv_id": "http://arxiv.org/abs/2407.21770v1",
    "pdf_url": "http://arxiv.org/pdf/2407.21770v1",
    "primary_category": "cs.AI",
    "votes": -1,
    "prompt": "LLM",
    "model": "gpt-4-turbo"
  },
  {
    "title": "HGOE: Hybrid External and Internal Graph Outlier Exposure for Graph Out-of-Distribution Detection",
    "authors": "Junwei He, Qianqian Xu, Yangbangyan Jiang, Zitai Wang, Yuchen Sun, Qingming Huang",
    "abstract": "With the progressive advancements in deep graph learning, out-of-distribution\n(OOD) detection for graph data has emerged as a critical challenge. While the\nefficacy of auxiliary datasets in enhancing OOD detection has been extensively\nstudied for image and text data, such approaches have not yet been explored for\ngraph data. Unlike Euclidean data, graph data exhibits greater diversity but\nlower robustness to perturbations, complicating the integration of outliers. To\ntackle these challenges, we propose the introduction of \\textbf{H}ybrid\nExternal and Internal \\textbf{G}raph \\textbf{O}utlier \\textbf{E}xposure (HGOE)\nto improve graph OOD detection performance. Our framework involves using\nrealistic external graph data from various domains and synthesizing internal\noutliers within ID subgroups to address the poor robustness and presence of OOD\nsamples within the ID class. Furthermore, we develop a boundary-aware OE loss\nthat adaptively assigns weights to outliers, maximizing the use of high-quality\nOOD samples while minimizing the impact of low-quality ones. Our proposed HGOE\nframework is model-agnostic and designed to enhance the effectiveness of\nexisting graph OOD detection models. Experimental results demonstrate that our\nHGOE framework can significantly improve the performance of existing OOD\ndetection models across all 8 real datasets.",
    "arxiv_id": "http://arxiv.org/abs/2407.21742v1",
    "pdf_url": "http://arxiv.org/pdf/2407.21742v1",
    "primary_category": "cs.LG",
    "votes": 1,
    "prompt": "LLM",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Contrastive Factor Analysis",
    "authors": "Zhibin Duan, Tiansheng Wen, Yifei Wang, Chen Zhu, Bo Chen, Mingyuan Zhou",
    "abstract": "Factor analysis, often regarded as a Bayesian variant of matrix\nfactorization, offers superior capabilities in capturing uncertainty, modeling\ncomplex dependencies, and ensuring robustness. As the deep learning era\narrives, factor analysis is receiving less and less attention due to their\nlimited expressive ability. On the contrary, contrastive learning has emerged\nas a potent technique with demonstrated efficacy in unsupervised\nrepresentational learning. While the two methods are different paradigms,\nrecent theoretical analysis has revealed the mathematical equivalence between\ncontrastive learning and matrix factorization, providing a potential\npossibility for factor analysis combined with contrastive learning. Motivated\nby the interconnectedness of contrastive learning, matrix factorization, and\nfactor analysis, this paper introduces a novel Contrastive Factor Analysis\nframework, aiming to leverage factor analysis's advantageous properties within\nthe realm of contrastive learning. To further leverage the interpretability\nproperties of non-negative factor analysis, which can learn disentangled\nrepresentations, contrastive factor analysis is extended to a non-negative\nversion. Finally, extensive experimental validation showcases the efficacy of\nthe proposed contrastive (non-negative) factor analysis methodology across\nmultiple key properties, including expressiveness, robustness,\ninterpretability, and accurate uncertainty estimation.",
    "arxiv_id": "http://arxiv.org/abs/2407.21740v1",
    "pdf_url": "http://arxiv.org/pdf/2407.21740v1",
    "primary_category": "cs.LG",
    "votes": 1,
    "prompt": "LLM",
    "model": "gpt-4-turbo"
  },
  {
    "title": "A Federated Learning-Friendly Approach for Parameter-Efficient Fine-Tuning of SAM in 3D Segmentation",
    "authors": "Mothilal Asokan, Joseph Geo Benjamin, Mohammad Yaqub, Karthik Nandakumar",
    "abstract": "Adapting foundation models for medical image analysis requires finetuning\nthem on a considerable amount of data because of extreme distribution shifts\nbetween natural (source) data used for pretraining and medical (target) data.\nHowever, collecting task-specific medical data for such finetuning at a central\nlocation raises many privacy concerns. Although Federated learning (FL)\nprovides an effective means for training on private decentralized data,\ncommunication costs in federating large foundation models can quickly become a\nsignificant bottleneck, impacting the solution's scalability. In this work, we\naddress this problem of efficient communication while ensuring effective\nlearning in FL by combining the strengths of Parameter-Efficient Fine-tuning\n(PEFT) with FL. Specifically, we study plug-and-play Low-Rank Adapters (LoRA)\nin a federated manner to adapt the Segment Anything Model (SAM) for 3D medical\nimage segmentation. Unlike prior works that utilize LoRA and finetune the\nentire decoder, we critically analyze the contribution of each granular\ncomponent of SAM on finetuning performance. Thus, we identify specific layers\nto be federated that are very efficient in terms of communication cost while\nproducing on-par accuracy. Our experiments show that retaining the parameters\nof the SAM model (including most of the decoder) in their original state during\nadaptation is beneficial because fine-tuning on small datasets tends to distort\nthe inherent capabilities of the underlying foundation model. On Fed-KiTS, our\napproach decreases communication cost (~48x) compared to full fine-tuning while\nincreasing performance (~6% Dice score) in 3D segmentation tasks. Our approach\nperforms similar to SAMed while achieving ~2.8x reduction in communication and\nparameters to be finetuned. We further validate our approach with experiments\non Fed-IXI and Prostate MRI datasets.",
    "arxiv_id": "http://arxiv.org/abs/2407.21739v1",
    "pdf_url": "http://arxiv.org/pdf/2407.21739v1",
    "primary_category": "cs.CV",
    "votes": 1,
    "prompt": "LLM",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Leveraging Self-Supervised Learning for Fetal Cardiac Planes Classification using Ultrasound Scan Videos",
    "authors": "Joseph Geo Benjamin, Mothilal Asokan, Amna Alhosani, Hussain Alasmawi, Werner Gerhard Diehl, Leanne Bricker, Karthik Nandakumar, Mohammad Yaqub",
    "abstract": "Self-supervised learning (SSL) methods are popular since they can address\nsituations with limited annotated data by directly utilising the underlying\ndata distribution. However, the adoption of such methods is not explored enough\nin ultrasound (US) imaging, especially for fetal assessment. We investigate the\npotential of dual-encoder SSL in utilizing unlabelled US video data to improve\nthe performance of challenging downstream Standard Fetal Cardiac Planes (SFCP)\nclassification using limited labelled 2D US images. We study 7 SSL approaches\nbased on reconstruction, contrastive loss, distillation, and information theory\nand evaluate them extensively on a large private US dataset. Our observations\nand findings are consolidated from more than 500 downstream training\nexperiments under different settings. Our primary observation shows that for\nSSL training, the variance of the dataset is more crucial than its size because\nit allows the model to learn generalisable representations, which improve the\nperformance of downstream tasks. Overall, the BarlowTwins method shows robust\nperformance, irrespective of the training settings and data variations, when\nused as an initialisation for downstream tasks. Notably, full fine-tuning with\n1% of labelled data outperforms ImageNet initialisation by 12% in F1-score and\noutperforms other SSL initialisations by at least 4% in F1-score, thus making\nit a promising candidate for transfer learning from US video to image data.",
    "arxiv_id": "http://arxiv.org/abs/2407.21738v1",
    "pdf_url": "http://arxiv.org/pdf/2407.21738v1",
    "primary_category": "eess.IV",
    "votes": 1,
    "prompt": "LLM",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Social Learning through Interactions with Other Agents: A Survey",
    "authors": "Dylan hillier, Cheston Tan, Jing Jiang",
    "abstract": "Social learning plays an important role in the development of human\nintelligence. As children, we imitate our parents' speech patterns until we are\nable to produce sounds; we learn from them praising us and scolding us; and as\nadults, we learn by working with others. In this work, we survey the degree to\nwhich this paradigm -- social learning -- has been mirrored in machine\nlearning. In particular, since learning socially requires interacting with\nothers, we are interested in how embodied agents can and have utilised these\ntechniques. This is especially in light of the degree to which recent advances\nin natural language processing (NLP) enable us to perform new forms of social\nlearning. We look at how behavioural cloning and next-token prediction mirror\nhuman imitation, how learning from human feedback mirrors human education, and\nhow we can go further to enable fully communicative agents that learn from each\nother. We find that while individual social learning techniques have been used\nsuccessfully, there has been little unifying work showing how to bring them\ntogether into socially embodied agents.",
    "arxiv_id": "http://arxiv.org/abs/2407.21713v1",
    "pdf_url": "http://arxiv.org/pdf/2407.21713v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "LLM",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Universal Approximation Theory: Foundations for Parallelism in Neural Networks",
    "authors": "Wei Wang, Qing Li",
    "abstract": "Neural networks are increasingly evolving towards training large models with\nbig data, a method that has demonstrated superior performance across many\ntasks. However, this approach introduces an urgent problem: current deep\nlearning models are predominantly serial, meaning that as the number of network\nlayers increases, so do the training and inference times. This is unacceptable\nif deep learning is to continue advancing. Therefore, this paper proposes a\ndeep learning parallelization strategy based on the Universal Approximation\nTheorem (UAT). From this foundation, we designed a parallel network called\nPara-Former to test our theory. Unlike traditional serial models, the inference\ntime of Para-Former does not increase with the number of layers, significantly\naccelerating the inference speed of multi-layer networks. Experimental results\nvalidate the effectiveness of this network.",
    "arxiv_id": "http://arxiv.org/abs/2407.21670v1",
    "pdf_url": "http://arxiv.org/pdf/2407.21670v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "LLM",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Synth-Empathy: Towards High-Quality Synthetic Empathy Data",
    "authors": "Hao Liang, Linzhuang Sun, Jingxuan Wei, Xijie Huang, Linkun Sun, Bihui Yu, Conghui He, Wentao Zhang",
    "abstract": "In recent years, with the rapid advancements in large language models (LLMs),\nachieving excellent empathetic response capabilities has become a crucial\nprerequisite. Consequently, managing and understanding empathetic datasets have\ngained increasing significance. However, empathetic data are typically\nhuman-labeled, leading to insufficient datasets and wasted human labor. In this\nwork, we present Synth-Empathy, an LLM-based data generation and quality and\ndiversity selection pipeline that automatically generates high-quality\nempathetic data while discarding low-quality data. With the data generated from\na low empathetic model, we are able to further improve empathetic response\nperformance and achieve state-of-the-art (SoTA) results across multiple\nbenchmarks. Moreover, our model achieves SoTA performance on various human\nevaluation benchmarks, demonstrating its effectiveness and robustness in\nreal-world applications. Furthermore, we show the trade-off between data\nquantity and quality, providing insights into empathetic data generation and\nselection.",
    "arxiv_id": "http://arxiv.org/abs/2407.21669v1",
    "pdf_url": "http://arxiv.org/pdf/2407.21669v1",
    "primary_category": "cs.CL",
    "votes": 1,
    "prompt": "LLM",
    "model": "gpt-4-turbo"
  },
  {
    "title": "An Explainable Vision Transformer with Transfer Learning Combined with Support Vector Machine Based Efficient Drought Stress Identification",
    "authors": "Aswini Kumar Patra, Ankit Varshney, Lingaraj Sahoo",
    "abstract": "Early detection of drought stress is critical for taking timely measures for\nreducing crop loss before the drought impact becomes irreversible. The subtle\nphenotypical and physiological changes in response to drought stress are\ncaptured by non-invasive imaging techniques and these imaging data serve as\nvaluable resource for machine learning methods to identify drought stress.\nWhile convolutional neural networks (CNNs) are in wide use, vision transformers\n(ViTs) present a promising alternative in capturing long-range dependencies and\nintricate spatial relationships, thereby enhancing the detection of subtle\nindicators of drought stress. We propose an explainable deep learning pipeline\nthat leverages the power of ViTs for drought stress detection in potato crops\nusing aerial imagery. We applied two distinct approaches: a synergistic\ncombination of ViT and support vector machine (SVM), where ViT extracts\nintricate spatial features from aerial images, and SVM classifies the crops as\nstressed or healthy and an end-to-end approach using a dedicated classification\nlayer within ViT to directly detect drought stress. Our key findings explain\nthe ViT model's decision-making process by visualizing attention maps. These\nmaps highlight the specific spatial features within the aerial images that the\nViT model focuses as the drought stress signature. Our findings demonstrate\nthat the proposed methods not only achieve high accuracy in drought stress\nidentification but also shedding light on the diverse subtle plant features\nassociated with drought stress. This offers a robust and interpretable solution\nfor drought stress monitoring for farmers to undertake informed decisions for\nimproved crop management.",
    "arxiv_id": "http://arxiv.org/abs/2407.21666v1",
    "pdf_url": "http://arxiv.org/pdf/2407.21666v1",
    "primary_category": "cs.CV",
    "votes": 1,
    "prompt": "LLM",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Comgra: A Tool for Analyzing and Debugging Neural Networks",
    "authors": "Florian Dietz, Sophie Fellenz, Dietrich Klakow, Marius Kloft",
    "abstract": "Neural Networks are notoriously difficult to inspect. We introduce comgra, an\nopen source python library for use with PyTorch. Comgra extracts data about the\ninternal activations of a model and organizes it in a GUI (graphical user\ninterface). It can show both summary statistics and individual data points,\ncompare early and late stages of training, focus on individual samples of\ninterest, and visualize the flow of the gradient through the network. This\nmakes it possible to inspect the model's behavior from many different angles\nand save time by rapidly testing different hypotheses without having to rerun\nit. Comgra has applications for debugging, neural architecture design, and\nmechanistic interpretability. We publish our library through Python Package\nIndex (PyPI) and provide code, documentation, and tutorials at\nhttps://github.com/FlorianDietz/comgra.",
    "arxiv_id": "http://arxiv.org/abs/2407.21656v1",
    "pdf_url": "http://arxiv.org/pdf/2407.21656v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "LLM",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Spatial Transformer Network YOLO Model for Agricultural Object Detection",
    "authors": "Yash Zambre, Ekdev Rajkitkul, Akshatha Mohan, Joshua Peeples",
    "abstract": "Object detection plays a crucial role in the field of computer vision by\nautonomously identifying and locating objects of interest. The You Only Look\nOnce (YOLO) model is an effective single-shot detector. However, YOLO faces\nchallenges in cluttered or partially occluded scenes and can struggle with\nsmall, low-contrast objects. We propose a new method that integrates spatial\ntransformer networks (STNs) into YOLO to improve performance. The proposed\nSTN-YOLO aims to enhance the model's effectiveness by focusing on important\nareas of the image and improving the spatial invariance of the model before the\ndetection process. Our proposed method improved object detection performance\nboth qualitatively and quantitatively. We explore the impact of different\nlocalization networks within the STN module as well as the robustness of the\nmodel across different spatial transformations. We apply the STN-YOLO on\nbenchmark datasets for Agricultural object detection as well as a new dataset\nfrom a state-of-the-art plant phenotyping greenhouse facility. Our code and\ndataset are publicly available.",
    "arxiv_id": "http://arxiv.org/abs/2407.21652v1",
    "pdf_url": "http://arxiv.org/pdf/2407.21652v1",
    "primary_category": "cs.CV",
    "votes": 1,
    "prompt": "LLM",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Lyapunov weights to convey the meaning of time in physics-informed neural networks",
    "authors": "Gabriel Turinici",
    "abstract": "Time is not a dimension as the others. In Physics-Informed Neural Networks\n(PINN) several proposals attempted to adapt the time sampling or time weighting\nto take into account the specifics of this special dimension. But these\nproposals are not principled and need guidance to be used. We explain here\ntheoretically why the Lyapunov exponents give actionable insights and propose a\nweighting scheme to automatically adapt to chaotic, periodic or stable\ndynamics. We characterize theoretically the best weighting scheme under\ncomputational constraints as a cumulative exponential integral of the local\nLyapunov exponent estimators and show that it performs well in practice under\nthe regimes mentioned above.",
    "arxiv_id": "http://arxiv.org/abs/2407.21642v1",
    "pdf_url": "http://arxiv.org/pdf/2407.21642v1",
    "primary_category": "cs.LG",
    "votes": 1,
    "prompt": "LLM",
    "model": "gpt-4-turbo"
  },
  {
    "title": "MART: MultiscAle Relational Transformer Networks for Multi-agent Trajectory Prediction",
    "authors": "Seongju Lee, Junseok Lee, Yeonguk Yu, Taeri Kim, Kyoobin Lee",
    "abstract": "Multi-agent trajectory prediction is crucial to autonomous driving and\nunderstanding the surrounding environment. Learning-based approaches for\nmulti-agent trajectory prediction, such as primarily relying on graph neural\nnetworks, graph transformers, and hypergraph neural networks, have demonstrated\noutstanding performance on real-world datasets in recent years. However, the\nhypergraph transformer-based method for trajectory prediction is yet to be\nexplored. Therefore, we present a MultiscAle Relational Transformer (MART)\nnetwork for multi-agent trajectory prediction. MART is a hypergraph transformer\narchitecture to consider individual and group behaviors in transformer\nmachinery. The core module of MART is the encoder, which comprises a Pair-wise\nRelational Transformer (PRT) and a Hyper Relational Transformer (HRT). The\nencoder extends the capabilities of a relational transformer by introducing\nHRT, which integrates hyperedge features into the transformer mechanism,\npromoting attention weights to focus on group-wise relations. In addition, we\npropose an Adaptive Group Estimator (AGE) designed to infer complex group\nrelations in real-world environments. Extensive experiments on three real-world\ndatasets (NBA, SDD, and ETH-UCY) demonstrate that our method achieves\nstate-of-the-art performance, enhancing ADE/FDE by 3.9%/11.8% on the NBA\ndataset. Code is available at https://github.com/gist-ailab/MART.",
    "arxiv_id": "http://arxiv.org/abs/2407.21635v1",
    "pdf_url": "http://arxiv.org/pdf/2407.21635v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "LLM",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Ironing the Graphs: Toward a Correct Geometric Analysis of Large-Scale Graphs",
    "authors": "Saloua Naama, Kav\u00e9 Salamatian, Francesco Bronzino",
    "abstract": "Graph embedding approaches attempt to project graphs into geometric entities,\ni.e, manifolds. The idea is that the geometric properties of the projected\nmanifolds are helpful in the inference of graph properties. However, if the\nchoice of the embedding manifold is incorrectly performed, it can lead to\nincorrect geometric inference. In this paper, we argue that the classical\nembedding techniques cannot lead to correct geometric interpretation as they\nmiss the curvature at each point, of manifold. We advocate that for doing\ncorrect geometric interpretation the embedding of graph should be done over\nregular constant curvature manifolds. To this end, we present an embedding\napproach, the discrete Ricci flow graph embedding (dRfge) based on the discrete\nRicci flow that adapts the distance between nodes in a graph so that the graph\ncan be embedded onto a constant curvature manifold that is homogeneous and\nisotropic, i.e., all directions are equivalent and distances comparable,\nresulting in correct geometric interpretations. A major contribution of this\npaper is that for the first time, we prove the convergence of discrete Ricci\nflow to a constant curvature and stable distance metrics over the edges. A\ndrawback of using the discrete Ricci flow is the high computational complexity\nthat prevented its usage in large-scale graph analysis. Another contribution of\nthis paper is a new algorithmic solution that makes it feasible to calculate\nthe Ricci flow for graphs of up to 50k nodes, and beyond. The intuitions behind\nthe discrete Ricci flow make it possible to obtain new insights into the\nstructure of large-scale graphs. We demonstrate this through a case study on\nanalyzing the internet connectivity structure between countries at the BGP\nlevel.",
    "arxiv_id": "http://arxiv.org/abs/2407.21609v1",
    "pdf_url": "http://arxiv.org/pdf/2407.21609v1",
    "primary_category": "cs.CG",
    "votes": -1,
    "prompt": "LLM",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Higher order quantum reservoir computing for non-intrusive reduced-order models",
    "authors": "Vinamr Jain, Romit Maulik",
    "abstract": "Forecasting dynamical systems is of importance to numerous real-world\napplications. When possible, dynamical systems forecasts are constructed based\non first-principles-based models such as through the use of differential\nequations. When these equations are unknown, non-intrusive techniques must be\nutilized to build predictive models from data alone. Machine learning (ML)\nmethods have recently been used for such tasks. Moreover, ML methods provide\nthe added advantage of significant reductions in time-to-solution for\npredictions in contrast with first-principle based models. However, many\nstate-of-the-art ML-based methods for forecasting rely on neural networks,\nwhich may be expensive to train and necessitate requirements for large amounts\nof memory. In this work, we propose a quantum mechanics inspired ML modeling\nstrategy for learning nonlinear dynamical systems that provides data-driven\nforecasts for complex dynamical systems with reduced training time and memory\ncosts. This approach, denoted the quantum reservoir computing technique (QRC),\nis a hybrid quantum-classical framework employing an ensemble of interconnected\nsmall quantum systems via classical linear feedback connections. By mapping the\ndynamical state to a suitable quantum representation amenable to unitary\noperations, QRC is able to predict complex nonlinear dynamical systems in a\nstable and accurate manner. We demonstrate the efficacy of this framework\nthrough benchmark forecasts of the NOAA Optimal Interpolation Sea Surface\nTemperature dataset and compare the performance of QRC to other ML methods.",
    "arxiv_id": "http://arxiv.org/abs/2407.21602v1",
    "pdf_url": "http://arxiv.org/pdf/2407.21602v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "LLM",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Measuring What Matters: Intrinsic Distance Preservation as a Robust Metric for Embedding Quality",
    "authors": "Steven N. Hart, Thomas E. Tavolara",
    "abstract": "Unsupervised embeddings are fundamental to numerous machine learning\napplications, yet their evaluation remains a challenging task. Traditional\nassessment methods often rely on extrinsic variables, such as performance in\ndownstream tasks, which can introduce confounding factors and mask the true\nquality of embeddings. This paper introduces the Intrinsic Distance\nPreservation Evaluation (IDPE) method, a novel approach for assessing embedding\nquality based on the preservation of Mahalanobis distances between data points\nin the original and embedded spaces. We demonstrate the limitations of\nextrinsic evaluation methods through a simple example, highlighting how they\ncan lead to misleading conclusions about embedding quality. IDPE addresses\nthese issues by providing a task-independent measure of how well embeddings\npreserve the intrinsic structure of the original data. Our method leverages\nefficient similarity search techniques to make it applicable to large-scale\ndatasets. We compare IDPE with established intrinsic metrics like\ntrustworthiness and continuity, as well as extrinsic metrics such as Average\nRank and Mean Reciprocal Rank. Our results show that IDPE offers a more\ncomprehensive and reliable assessment of embedding quality across various\nscenarios. We evaluate PCA and t-SNE embeddings using IDPE, revealing insights\ninto their performance that are not captured by traditional metrics. This work\ncontributes to the field by providing a robust, efficient, and interpretable\nmethod for embedding evaluation. IDPE's focus on intrinsic properties offers a\nvaluable tool for researchers and practitioners seeking to develop and assess\nhigh-quality embeddings for diverse machine learning applications.",
    "arxiv_id": "http://arxiv.org/abs/2407.21590v1",
    "pdf_url": "http://arxiv.org/pdf/2407.21590v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "LLM",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Multi-agent reinforcement learning for the control of three-dimensional Rayleigh-B\u00e9nard convection",
    "authors": "Joel Vasanth, Jean Rabault, Francisco Alc\u00e1ntara-\u00c1vila, Mikael Mortensen, Ricardo Vinuesa",
    "abstract": "Deep reinforcement learning (DRL) has found application in numerous use-cases\npertaining to flow control. Multi-agent RL (MARL), a variant of DRL, has shown\nto be more effective than single-agent RL in controlling flows exhibiting\nlocality and translational invariance. We present, for the first time, an\nimplementation of MARL-based control of three-dimensional Rayleigh-B\\'enard\nconvection (RBC). Control is executed by modifying the temperature distribution\nalong the bottom wall divided into multiple control segments, each of which\nacts as an independent agent. Two regimes of RBC are considered at Rayleigh\nnumbers $\\mathrm{Ra}=500$ and $750$. Evaluation of the learned control policy\nreveals a reduction in convection intensity by $23.5\\%$ and $8.7\\%$ at\n$\\mathrm{Ra}=500$ and $750$, respectively. The MARL controller converts\nirregularly shaped convective patterns to regular straight rolls with lower\nconvection that resemble flow in a relatively more stable regime. We draw\ncomparisons with proportional control at both $\\mathrm{Ra}$ and show that MARL\nis able to outperform the proportional controller. The learned control strategy\nis complex, featuring different non-linear segment-wise actuator delays and\nactuation magnitudes. We also perform successful evaluations on a larger domain\nthan used for training, demonstrating that the invariant property of MARL\nallows direct transfer of the learnt policy.",
    "arxiv_id": "http://arxiv.org/abs/2407.21565v1",
    "pdf_url": "http://arxiv.org/pdf/2407.21565v1",
    "primary_category": "physics.flu-dyn",
    "votes": 0,
    "prompt": "LLM",
    "model": "gpt-4-turbo"
  },
  {
    "title": "CXSimulator: A User Behavior Simulation using LLM Embeddings for Web-Marketing Campaign Assessment",
    "authors": "Akira Kasuga, Ryo Yonetani",
    "abstract": "This paper presents the Customer Experience (CX) Simulator, a novel framework\ndesigned to assess the effects of untested web-marketing campaigns through user\nbehavior simulations. The proposed framework leverages large language models\n(LLMs) to represent various events in a user's behavioral history, such as\nviewing an item, applying a coupon, or purchasing an item, as semantic\nembedding vectors. We train a model to predict transitions between events from\ntheir LLM embeddings, which can even generalize to unseen events by learning\nfrom diverse training data. In web-marketing applications, we leverage this\ntransition prediction model to simulate how users might react differently when\nnew campaigns or products are presented to them. This allows us to eliminate\nthe need for costly online testing and enhance the marketers' abilities to\nreveal insights. Our numerical evaluation and user study, utilizing BigQuery\nPublic Datasets from the Google Merchandise Store, demonstrate the\neffectiveness of our framework.",
    "arxiv_id": "http://arxiv.org/abs/2407.21553v1",
    "pdf_url": "http://arxiv.org/pdf/2407.21553v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "LLM",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Black box meta-learning intrinsic rewards for sparse-reward environments",
    "authors": "Octavio Pappalardo, Rodrigo Ramele, Juan Miguel Santos",
    "abstract": "Despite the successes and progress of deep reinforcement learning over the\nlast decade, several challenges remain that hinder its broader application.\nSome fundamental aspects to improve include data efficiency, generalization\ncapability, and ability to learn in sparse-reward environments, which often\nrequire human-designed dense rewards. Meta-learning has emerged as a promising\napproach to address these issues by optimizing components of the learning\nalgorithm to meet desired characteristics. Additionally, a different line of\nwork has extensively studied the use of intrinsic rewards to enhance the\nexploration capabilities of algorithms. This work investigates how\nmeta-learning can improve the training signal received by RL agents. The focus\nis on meta-learning intrinsic rewards under a framework that doesn't rely on\nthe use of meta-gradients. We analyze and compare this approach to the use of\nextrinsic rewards and a meta-learned advantage function. The developed\nalgorithms are evaluated on distributions of continuous control tasks with both\nparametric and non-parametric variations, and with only sparse rewards\naccessible for the evaluation tasks.",
    "arxiv_id": "http://arxiv.org/abs/2407.21546v1",
    "pdf_url": "http://arxiv.org/pdf/2407.21546v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "LLM",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Probabilistic Scoring Lists for Interpretable Machine Learning",
    "authors": "Jonas Hanselle, Stefan Heid, Johannes F\u00fcrnkranz, Eyke H\u00fcllermeier",
    "abstract": "A scoring system is a simple decision model that checks a set of features,\nadds a certain number of points to a total score for each feature that is\nsatisfied, and finally makes a decision by comparing the total score to a\nthreshold. Scoring systems have a long history of active use in safety-critical\ndomains such as healthcare and justice, where they provide guidance for making\nobjective and accurate decisions. Given their genuine interpretability, the\nidea of learning scoring systems from data is obviously appealing from the\nperspective of explainable AI. In this paper, we propose a practically\nmotivated extension of scoring systems called probabilistic scoring lists\n(PSL), as well as a method for learning PSLs from data. Instead of making a\ndeterministic decision, a PSL represents uncertainty in the form of probability\ndistributions, or, more generally, probability intervals. Moreover, in the\nspirit of decision lists, a PSL evaluates features one by one and stops as soon\nas a decision can be made with enough confidence. To evaluate our approach, we\nconduct a case study in the medical domain.",
    "arxiv_id": "http://arxiv.org/abs/2407.21535v1",
    "pdf_url": "http://arxiv.org/pdf/2407.21535v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "LLM",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Data Contamination Report from the 2024 CONDA Shared Task",
    "authors": "Oscar Sainz, Iker Garc\u00eda-Ferrero, Alon Jacovi, Jon Ander Campos, Yanai Elazar, Eneko Agirre, Yoav Goldberg, Wei-Lin Chen, Jenny Chim, Leshem Choshen, Luca D'Amico-Wong, Melissa Dell, Run-Ze Fan, Shahriar Golchin, Yucheng Li, Pengfei Liu, Bhavish Pahwa, Ameya Prabhu, Suryansh Sharma, Emily Silcock, Kateryna Solonko, David Stap, Mihai Surdeanu, Yu-Min Tseng, Vishaal Udandarao, Zengzhi Wang, Ruijie Xu, Jinglin Yang",
    "abstract": "The 1st Workshop on Data Contamination (CONDA 2024) focuses on all relevant\naspects of data contamination in natural language processing, where data\ncontamination is understood as situations where evaluation data is included in\npre-training corpora used to train large scale models, compromising evaluation\nresults. The workshop fostered a shared task to collect evidence on data\ncontamination in current available datasets and models. The goal of the shared\ntask and associated database is to assist the community in understanding the\nextent of the problem and to assist researchers in avoiding reporting\nevaluation results on known contaminated resources. The shared task provides a\nstructured, centralized public database for the collection of contamination\nevidence, open to contributions from the community via GitHub pool requests.\nThis first compilation paper is based on 566 reported entries over 91\ncontaminated sources from a total of 23 contributors. The details of the\nindividual contamination events are available in the platform. The platform\ncontinues to be online, open to contributions from the community.",
    "arxiv_id": "http://arxiv.org/abs/2407.21530v1",
    "pdf_url": "http://arxiv.org/pdf/2407.21530v1",
    "primary_category": "cs.CL",
    "votes": 0,
    "prompt": "LLM",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Tabular Data Augmentation for Machine Learning: Progress and Prospects of Embracing Generative AI",
    "authors": "Lingxi Cui, Huan Li, Ke Chen, Lidan Shou, Gang Chen",
    "abstract": "Machine learning (ML) on tabular data is ubiquitous, yet obtaining abundant\nhigh-quality tabular data for model training remains a significant obstacle.\nNumerous works have focused on tabular data augmentation (TDA) to enhance the\noriginal table with additional data, thereby improving downstream ML tasks.\nRecently, there has been a growing interest in leveraging the capabilities of\ngenerative AI for TDA. Therefore, we believe it is time to provide a\ncomprehensive review of the progress and future prospects of TDA, with a\nparticular emphasis on the trending generative AI. Specifically, we present an\narchitectural view of the TDA pipeline, comprising three main procedures:\npre-augmentation, augmentation, and post-augmentation. Pre-augmentation\nencompasses preparation tasks that facilitate subsequent TDA, including error\nhandling, table annotation, table simplification, table representation, table\nindexing, table navigation, schema matching, and entity matching. Augmentation\nsystematically analyzes current TDA methods, categorized into retrieval-based\nmethods, which retrieve external data, and generation-based methods, which\ngenerate synthetic data. We further subdivide these methods based on the\ngranularity of the augmentation process at the row, column, cell, and table\nlevels. Post-augmentation focuses on the datasets, evaluation and optimization\naspects of TDA. We also summarize current trends and future directions for TDA,\nhighlighting promising opportunities in the era of generative AI. In addition,\nthe accompanying papers and related resources are continuously updated and\nmaintained in the GitHub repository at\nhttps://github.com/SuDIS-ZJU/awesome-tabular-data-augmentation to reflect\nongoing advancements in the field.",
    "arxiv_id": "http://arxiv.org/abs/2407.21523v1",
    "pdf_url": "http://arxiv.org/pdf/2407.21523v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "LLM",
    "model": "gpt-4-turbo"
  },
  {
    "title": "On the Problem of Text-To-Speech Model Selection for Synthetic Data Generation in Automatic Speech Recognition",
    "authors": "Nick Rossenbach, Ralf Schl\u00fcter, Sakriani Sakti",
    "abstract": "The rapid development of neural text-to-speech (TTS) systems enabled its\nusage in other areas of natural language processing such as automatic speech\nrecognition (ASR) or spoken language translation (SLT). Due to the large number\nof different TTS architectures and their extensions, selecting which TTS\nsystems to use for synthetic data creation is not an easy task. We use the\ncomparison of five different TTS decoder architectures in the scope of\nsynthetic data generation to show the impact on CTC-based speech recognition\ntraining. We compare the recognition results to computable metrics like NISQA\nMOS and intelligibility, finding that there are no clear relations to the ASR\nperformance. We also observe that for data generation auto-regressive decoding\nperforms better than non-autoregressive decoding, and propose an approach to\nquantify TTS generalization capabilities.",
    "arxiv_id": "http://arxiv.org/abs/2407.21476v1",
    "pdf_url": "http://arxiv.org/pdf/2407.21476v1",
    "primary_category": "cs.CL",
    "votes": 0,
    "prompt": "LLM",
    "model": "gpt-4-turbo"
  },
  {
    "title": "MLLM Is a Strong Reranker: Advancing Multimodal Retrieval-augmented Generation via Knowledge-enhanced Reranking and Noise-injected Training",
    "authors": "Zhanpeng Chen, Chengjin Xu, Yiyan Qi, Jian Guo",
    "abstract": "Multimodal Large Language Models (MLLMs) have demonstrated remarkable\ncapabilities in processing and generating content across multiple data\nmodalities, including text, images, audio, and video. However, a significant\ndrawback of MLLMs is their reliance on static training data, leading to\noutdated information and limited contextual awareness. This static nature\nhampers their ability to provide accurate, up-to-date responses, particularly\nin dynamic or rapidly evolving contexts. Integrating Multimodal\nRetrieval-augmented Generation (Multimodal RAG) offers a promising solution,\nbut the system would inevitably encounter the multi-granularity noisy\ncorrespondence (MNC) problem, which involves two types of noise: coarse-grained\n(query-caption) and fine-grained (query-image). This noise hinders accurate\nretrieval and generation. In this work, we propose \\textbf{RagLLaVA}, a novel\nframework with knowledge-enhanced reranking and noise-injected training, to\naddress these limitations. We instruction-tune the MLLM with a simple yet\neffective instruction template to induce its ranking ability and serve it as a\nreranker to precisely filter the top-k retrieved images. For generation, we\ninject visual noise during training at the data and token levels to enhance the\ngenerator's robustness. Extensive experiments are conducted on the subsets of\ntwo datasets that require retrieving and reasoning over images to answer a\ngiven query. Our results demonstrate the superiority of RagLLaVA in retrieving\naccurately and generating robustly. Code and models are available at\nhttps://github.com/IDEA-FinAI/RagLLaVA.",
    "arxiv_id": "http://arxiv.org/abs/2407.21439v1",
    "pdf_url": "http://arxiv.org/pdf/2407.21439v1",
    "primary_category": "cs.AI",
    "votes": 0,
    "prompt": "LLM",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Cost-Effective Hallucination Detection for LLMs",
    "authors": "Simon Valentin, Jinmiao Fu, Gianluca Detommaso, Shaoyuan Xu, Giovanni Zappella, Bryan Wang",
    "abstract": "Large language models (LLMs) can be prone to hallucinations - generating\nunreliable outputs that are unfaithful to their inputs, external facts or\ninternally inconsistent. In this work, we address several challenges for\npost-hoc hallucination detection in production settings. Our pipeline for\nhallucination detection entails: first, producing a confidence score\nrepresenting the likelihood that a generated answer is a hallucination; second,\ncalibrating the score conditional on attributes of the inputs and candidate\nresponse; finally, performing detection by thresholding the calibrated score.\nWe benchmark a variety of state-of-the-art scoring methods on different\ndatasets, encompassing question answering, fact checking, and summarization\ntasks. We employ diverse LLMs to ensure a comprehensive assessment of\nperformance. We show that calibrating individual scoring methods is critical\nfor ensuring risk-aware downstream decision making. Based on findings that no\nindividual score performs best in all situations, we propose a multi-scoring\nframework, which combines different scores and achieves top performance across\nall datasets. We further introduce cost-effective multi-scoring, which can\nmatch or even outperform more expensive detection methods, while significantly\nreducing computational overhead.",
    "arxiv_id": "http://arxiv.org/abs/2407.21424v1",
    "pdf_url": "http://arxiv.org/pdf/2407.21424v1",
    "primary_category": "cs.CL",
    "votes": 0,
    "prompt": "LLM",
    "model": "gpt-4-turbo"
  },
  {
    "title": "FTuner: A Fast Dynamic Shape Tensors Program Auto-Tuner for Deep Learning Compilers",
    "authors": "Pengyu Mu, Linquan Wei, Yi Liu, Rui Wang",
    "abstract": "Many artificial intelligence models process input data of different lengths\nand resolutions, making the shape of the tensors dynamic. The performance of\nthese models depends on the shape of the tensors, which makes it difficult to\noptimize the tensors before the model runs. There are two common solutions to\nthis problem. The first is to add useless data to the input to match a\npre-optimized tensor library. The second is to use small basic tensors to\ncreate a tensor that is closest in size to the input data and then tune it to\nminimize padding. However, this second solution can be time-consuming.\n  This paper proposes a new technique for deep learning compilers called\nFTuner. Instead of using a large design space or training a cost model, we use\nan abstract computational unit called the uKernel to patch together small,\nvarious-sized tensors to match the shape of the input tensor. We determine the\nshape of the uKernel using an analytic hardware information model. Experiments\nshow that the FTuner can achieve comparable operators and end-to-end\nperformance to vendor libraries and achieves 3\\% speedup on existing auto-tuner\nwith the model-training compiler while reducing tuning time by two orders of\nmagnitude.",
    "arxiv_id": "http://arxiv.org/abs/2407.21418v1",
    "pdf_url": "http://arxiv.org/pdf/2407.21418v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "LLM",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Deep Fr\u00e9chet Regression",
    "authors": "Su I Iao, Yidong Zhou, Hans-Georg M\u00fcller",
    "abstract": "Advancements in modern science have led to the increasing availability of\nnon-Euclidean data in metric spaces. This paper addresses the challenge of\nmodeling relationships between non-Euclidean responses and multivariate\nEuclidean predictors. We propose a flexible regression model capable of\nhandling high-dimensional predictors without imposing parametric assumptions.\nTwo primary challenges are addressed: the curse of dimensionality in\nnonparametric regression and the absence of linear structure in general metric\nspaces. The former is tackled using deep neural networks, while for the latter\nwe demonstrate the feasibility of mapping the metric space where responses\nreside to a low-dimensional Euclidean space using manifold learning. We\nintroduce a reverse mapping approach, employing local Fr\\'echet regression, to\nmap the low-dimensional manifold representations back to objects in the\noriginal metric space. We develop a theoretical framework, investigating the\nconvergence rate of deep neural networks under dependent sub-Gaussian noise\nwith bias. The convergence rate of the proposed regression model is then\nobtained by expanding the scope of local Fr\\'echet regression to accommodate\nmultivariate predictors in the presence of errors in predictors. Simulations\nand case studies show that the proposed model outperforms existing methods for\nnon-Euclidean responses, focusing on the special cases of probability measures\nand networks.",
    "arxiv_id": "http://arxiv.org/abs/2407.21407v1",
    "pdf_url": "http://arxiv.org/pdf/2407.21407v1",
    "primary_category": "stat.ME",
    "votes": 0,
    "prompt": "LLM",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Two Completely Parameter-Free Alternating Gradient Projection Algorithms for Nonconvex-(strongly) Concave Minimax Problems",
    "authors": "Junnan Yang, Huiling Zhang, Zi Xu",
    "abstract": "Due to their importance in various emerging applications, efficient\nalgorithms for solving minimax problems have recently received increasing\nattention. However, many existing algorithms require prior knowledge of the\nproblem parameters in order to achieve optimal iteration complexity. In this\npaper, we propose a completely parameter-free alternating gradient projection\n(PF-AGP) algorithm to solve the smooth nonconvex-(strongly) concave minimax\nproblems using a backtracking strategy, which does not require prior knowledge\nof parameters such as the Lipschtiz constant $L$ or the strongly concave\nconstant $\\mu$. The PF-AGP algorithm utilizes a parameter-free gradient\nprojection step to alternately update the outer and inner variables in each\niteration. We show that the total number of gradient calls of the PF-AGP\nalgorithm to obtain an $\\varepsilon$-stationary point for nonconvex-strongly\nconcave minimax problems is upper bounded by $\\mathcal{O}\\left(\nL\\kappa^3\\varepsilon^{-2} \\right)$ where $\\kappa$ is the condition number,\nwhile the total number of gradient calls to obtain an $\\varepsilon$-stationary\npoint for nonconvex-concave minimax problems is upper bounded by\n$\\mathcal{O}\\left( L^4\\varepsilon^{-4} \\right)$. As far as we know, this is the\nfirst completely parameter-free algorithm for solving nonconvex-strongly\nconcave minimax problems, and it is also the completely parameter-free\nalgorithm which achieves the best iteration complexity in single loop method\nfor solving nonconvex-concave minimax problems. Numerical results validate the\nefficiency of the proposed PF-AGP algorithm.",
    "arxiv_id": "http://arxiv.org/abs/2407.21372v1",
    "pdf_url": "http://arxiv.org/pdf/2407.21372v1",
    "primary_category": "math.OC",
    "votes": 0,
    "prompt": "LLM",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Prompting Medical Large Vision-Language Models to Diagnose Pathologies by Visual Question Answering",
    "authors": "Danfeng Guo, Demetri Terzopoulos",
    "abstract": "Large Vision-Language Models (LVLMs) have achieved significant success in\nrecent years, and they have been extended to the medical domain. Although\ndemonstrating satisfactory performance on medical Visual Question Answering\n(VQA) tasks, Medical LVLMs (MLVLMs) suffer from the hallucination problem,\nwhich makes them fail to diagnose complex pathologies. Moreover, they readily\nfail to learn minority pathologies due to imbalanced training data. We propose\ntwo prompting strategies for MLVLMs that reduce hallucination and improve VQA\nperformance. In the first strategy, we provide a detailed explanation of the\nqueried pathology. In the second strategy, we fine-tune a cheap, weak learner\nto achieve high performance on a specific metric, and textually provide its\njudgment to the MLVLM. Tested on the MIMIC-CXR-JPG and Chexpert datasets, our\nmethods significantly improve the diagnostic F1 score, with the highest\nincrease being 0.27. We also demonstrate that our prompting strategies can be\nextended to general LVLM domains. Based on POPE metrics, it effectively\nsuppresses the false negative predictions of existing LVLMs and improves Recall\nby approximately 0.07.",
    "arxiv_id": "http://arxiv.org/abs/2407.21368v1",
    "pdf_url": "http://arxiv.org/pdf/2407.21368v1",
    "primary_category": "cs.CV",
    "votes": 0,
    "prompt": "LLM",
    "model": "gpt-4-turbo"
  },
  {
    "title": "ProSpec RL: Plan Ahead, then Execute",
    "authors": "Liangliang Liu, Yi Guan, BoRan Wang, Rujia Shen, Yi Lin, Chaoran Kong, Lian Yan, Jingchi Jiang",
    "abstract": "Imagining potential outcomes of actions before execution helps agents make\nmore informed decisions, a prospective thinking ability fundamental to human\ncognition. However, mainstream model-free Reinforcement Learning (RL) methods\nlack the ability to proactively envision future scenarios, plan, and guide\nstrategies. These methods typically rely on trial and error to adjust policy\nfunctions, aiming to maximize cumulative rewards or long-term value, even if\nsuch high-reward decisions place the environment in extremely dangerous states.\nTo address this, we propose the Prospective (ProSpec) RL method, which makes\nhigher-value, lower-risk optimal decisions by imagining future n-stream\ntrajectories. Specifically, ProSpec employs a dynamic model to predict future\nstates (termed \"imagined states\") based on the current state and a series of\nsampled actions. Furthermore, we integrate the concept of Model Predictive\nControl and introduce a cycle consistency constraint that allows the agent to\nevaluate and select the optimal actions from these trajectories. Moreover,\nProSpec employs cycle consistency to mitigate two fundamental issues in RL:\naugmenting state reversibility to avoid irreversible events (low risk) and\naugmenting actions to generate numerous virtual trajectories, thereby improving\ndata efficiency. We validated the effectiveness of our method on the DMControl\nbenchmarks, where our approach achieved significant performance improvements.\nCode will be open-sourced upon acceptance.",
    "arxiv_id": "http://arxiv.org/abs/2407.21359v1",
    "pdf_url": "http://arxiv.org/pdf/2407.21359v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "LLM",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Differentially Private Block-wise Gradient Shuffle for Deep Learning",
    "authors": "David Zagardo",
    "abstract": "Traditional Differentially Private Stochastic Gradient Descent (DP-SGD)\nintroduces statistical noise on top of gradients drawn from a Gaussian\ndistribution to ensure privacy. This paper introduces the novel Differentially\nPrivate Block-wise Gradient Shuffle (DP-BloGS) algorithm for deep learning.\nBloGS builds off of existing private deep learning literature, but makes a\ndefinitive shift by taking a probabilistic approach to gradient noise\nintroduction through shuffling modeled after information theoretic privacy\nanalyses. The theoretical results presented in this paper show that the\ncombination of shuffling, parameter-specific block size selection, batch layer\nclipping, and gradient accumulation allows DP-BloGS to achieve training times\nclose to that of non-private training while maintaining similar privacy and\nutility guarantees to DP-SGD. DP-BloGS is found to be significantly more\nresistant to data extraction attempts than DP-SGD. The theoretical results are\nvalidated by the experimental findings.",
    "arxiv_id": "http://arxiv.org/abs/2407.21347v1",
    "pdf_url": "http://arxiv.org/pdf/2407.21347v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "LLM",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Big Cooperative Learning",
    "authors": "Yulai Cong",
    "abstract": "Cooperation plays a pivotal role in the evolution of human intelligence;\nmoreover, it also underlies the recent revolutionary advancement of artificial\nintelligence (AI) that is driven by foundation models. Specifically, we reveal\nthat the training of foundation models can be interpreted as a form of big\ncooperative learning (\\textit{abbr.} big learning), where massive learning\nindividuals/tasks \\emph{cooperate} to approach the unique essence of data from\ndiverse perspectives of data prediction, leveraging a universal model. The\npresented big learning therefore unifies most training objectives of foundation\nmodels within a consistent framework, where their underlying assumptions are\nexposed simultaneously. We design tailored simulations to demonstrate the\nprinciple of big learning, based on which we provide learning-perspective\njustifications for the successes of foundation models, with interesting\nside-products. Furthermore, we reveal that big learning is a new dimension for\nupgrading conventional machine learning paradigms, valuable for endowing\nreinvigorations to associated applications; as an illustrative example, we\npropose the BigLearn-GAN, which is a novel adversarially-trained foundation\nmodel with versatile data sampling capabilities. Code is available at\n\\texttt{https://github.com/YulaiCong/BigCooperativeLearning}.",
    "arxiv_id": "http://arxiv.org/abs/2407.21319v1",
    "pdf_url": "http://arxiv.org/pdf/2407.21319v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "LLM",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Diff-Cleanse: Identifying and Mitigating Backdoor Attacks in Diffusion Models",
    "authors": "Jiang Hao, Xiao Jin, Hu Xiaoguang, Chen Tianyou",
    "abstract": "Diffusion models (DM) represent one of the most advanced generative models\ntoday, yet recent studies suggest that DMs are vulnerable to backdoor attacks.\nBackdoor attacks establish hidden associations between particular input\npatterns and model behaviors, compromising model integrity by triggering\nundesirable actions with manipulated input data. This vulnerability poses\nsubstantial risks, including reputational damage to model owners and the\ndissemination of harmful content. To mitigate the threat of backdoor attacks,\nthere have been some investigations on backdoor detection and model repair.\nHowever, previous work fails to purify the backdoored DMs created by\nstate-of-the-art attacks, rendering the field much underexplored. To bridge\nthis gap, we introduce \\textbf{Diff-Cleanse}, a novel two-stage backdoor\ndefense framework specifically designed for DMs. The first stage employs a\ninnovative trigger inversion technique to detect the backdoor and reconstruct\nthe trigger, and the second stage utilizes a structural pruning method to\neliminate the backdoor. We evaluate our framework on hundreds of DMs attacked\nby 3 existing backdoor attack methods. Extensive experiments demonstrate that\nDiff-Cleanse achieves nearly 100\\% detection accuracy and effectively mitigates\nbackdoor impacts, preserving the model's benign performance with minimal\ncompromise. Our code is avaliable at https://github.com/shymuel/diff-cleanse.",
    "arxiv_id": "http://arxiv.org/abs/2407.21316v1",
    "pdf_url": "http://arxiv.org/pdf/2407.21316v1",
    "primary_category": "cs.CR",
    "votes": 0,
    "prompt": "LLM",
    "model": "gpt-4-turbo"
  },
  {
    "title": "State-observation augmented diffusion model for nonlinear assimilation",
    "authors": "Zhuoyuan Li, Bin Dong, Pingwen Zhang",
    "abstract": "Data assimilation has become a crucial technique aiming to combine physical\nmodels with observational data to estimate state variables. Traditional\nassimilation algorithms often face challenges of high nonlinearity brought by\nboth the physical and observational models. In this work, we propose a novel\ndata-driven assimilation algorithm based on generative models to address such\nconcerns. Our State-Observation Augmented Diffusion (SOAD) model is designed to\nhandle nonlinear physical and observational models more effectively. The\nmarginal posterior associated with SOAD has been derived and then proved to\nmatch the real posterior under mild assumptions, which shows theoretical\nsuperiority over previous score-based assimilation works. Experimental results\nalso indicate that our SOAD model may offer improved accuracy over existing\ndata-driven methods.",
    "arxiv_id": "http://arxiv.org/abs/2407.21314v1",
    "pdf_url": "http://arxiv.org/pdf/2407.21314v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "LLM",
    "model": "gpt-4-turbo"
  }
]