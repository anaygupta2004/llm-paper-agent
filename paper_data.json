[
  {
    "title": "Mission Impossible: A Statistical Perspective on Jailbreaking LLMs",
    "authors": "Jingtong Su, Julia Kempe, Karen Ullrich",
    "abstract": "Large language models (LLMs) are trained on a deluge of text data with\nlimited quality control. As a result, LLMs can exhibit unintended or even\nharmful behaviours, such as leaking information, fake news or hate speech.\nCountermeasures, commonly referred to as preference alignment, include\nfine-tuning the pretrained LLMs with carefully crafted text examples of desired\nbehaviour. Even then, empirical evidence shows preference aligned LLMs can be\nenticed to harmful behaviour. This so called jailbreaking of LLMs is typically\nachieved by adversarially modifying the input prompt to the LLM. Our paper\nprovides theoretical insights into the phenomenon of preference alignment and\njailbreaking from a statistical perspective. Under our framework, we first show\nthat pretrained LLMs will mimic harmful behaviour if present in the training\ncorpus. Under that same framework, we then introduce a statistical notion of\nalignment, and lower-bound the jailbreaking probability, showing that it is\nunpreventable under reasonable assumptions. Based on our insights, we propose\nan alteration to the currently prevalent alignment strategy RLHF. Specifically,\nwe introduce a simple modification to the RLHF objective, we call E-RLHF, that\naims to increase the likelihood of safe responses. E-RLHF brings no additional\ntraining cost, and is compatible with other methods. Empirically, we\ndemonstrate that E-RLHF outperforms RLHF on all alignment problems put forward\nby the AdvBench and HarmBench project without sacrificing model performance as\nmeasured by the MT-Bench project.",
    "arxiv_id": "http://arxiv.org/abs/2408.01420v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01420v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Talk Less, Interact Better: Evaluating In-context Conversational Adaptation in Multimodal LLMs",
    "authors": "Yilun Hua, Yoav Artzi",
    "abstract": "Humans spontaneously use increasingly efficient language as interactions\nprogress, by adapting and forming ad-hoc conventions. This phenomenon has been\nstudied extensively using reference games, showing properties of human language\nthat go beyond relaying intents. It remains unexplored whether multimodal large\nlanguage models (MLLMs) similarly increase communication efficiency during\ninteractions, and what mechanisms they may adopt for this purpose. We introduce\nICCA, an automated framework to evaluate such conversational adaptation as an\nin-context behavior in MLLMs. We evaluate several state-of-the-art MLLMs, and\nobserve that while they may understand the increasingly efficient language of\ntheir interlocutor, they do not spontaneously make their own language more\nefficient over time. This latter ability can only be elicited in some models\n(e.g., GPT-4) with heavy-handed prompting. This shows that this property of\nlinguistic interaction does not arise from current training regimes, even\nthough it is a common hallmark of human language. ICCA is available at\nhttps://github.com/lil-lab/ICCA.",
    "arxiv_id": "http://arxiv.org/abs/2408.01417v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01417v1",
    "primary_category": "cs.CL",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Conditional LoRA Parameter Generation",
    "authors": "Xiaolong Jin, Kai Wang, Dongwen Tang, Wangbo Zhao, Yukun Zhou, Junshu Tang, Yang You",
    "abstract": "Generative models have achieved remarkable success in image, video, and text\ndomains. Inspired by this, researchers have explored utilizing generative\nmodels to generate neural network parameters. However, these efforts have been\nlimited by the parameter size and the practicality of generating\nhigh-performance parameters. In this paper, we propose COND P-DIFF, a novel\napproach that demonstrates the feasibility of controllable high-performance\nparameter generation, particularly for LoRA (Low-Rank Adaptation) weights,\nduring the fine-tuning process. Specifically, we employ an autoencoder to\nextract efficient latent representations for parameters. We then train a\nconditional latent diffusion model to synthesize high-performing model\nparameters from random noise based on specific task conditions. Experimental\nresults in both computer vision and natural language processing domains\nconsistently demonstrate that COND P-DIFF can generate high-performance\nparameters conditioned on the given task. Moreover, we observe that the\nparameter distribution generated by COND P-DIFF exhibits differences compared\nto the distribution obtained through normal optimization methods, indicating a\ncertain level of generalization capability. Our work paves the way for further\nexploration of condition-driven parameter generation, offering a promising\ndirection for task-specific adaptation of neural networks.",
    "arxiv_id": "http://arxiv.org/abs/2408.01415v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01415v1",
    "primary_category": "cs.AI",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Pre-trained Language Models Improve the Few-shot Prompt Ability of Decision Transformer",
    "authors": "Yu Yang, Pan Xu",
    "abstract": "Decision Transformer (DT) has emerged as a promising class of algorithms in\noffline reinforcement learning (RL) tasks, leveraging pre-collected datasets\nand Transformer's capability to model long sequences. Recent works have\ndemonstrated that using parts of trajectories from training tasks as prompts in\nDT enhances its performance on unseen tasks, giving rise to Prompt-DT methods.\nHowever, collecting data from specific environments can be both costly and\nunsafe in many scenarios, leading to suboptimal performance and limited\nfew-shot prompt abilities due to the data-hungry nature of Transformer-based\nmodels. Additionally, the limited datasets used in pre-training make it\nchallenging for Prompt-DT type of methods to distinguish between various RL\ntasks through prompts alone. To address these challenges, we introduce the\nLanguage model-initialized Prompt Decision Transformer (LPDT), which leverages\npre-trained language models for meta-RL tasks and fine-tunes the model using\nLow-rank Adaptation (LoRA). We further incorporate prompt regularization to\neffectively differentiate between tasks based on prompt feature\nrepresentations. Our approach integrates pre-trained language model and RL\ntasks seamlessly. Extensive empirical studies demonstrate that initializing\nwith a pre-trained language model significantly enhances the performance of\nPrompt-DT on unseen tasks compared to baseline methods.",
    "arxiv_id": "http://arxiv.org/abs/2408.01402v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01402v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "The Impact of Hyperparameters on Large Language Model Inference Performance: An Evaluation of vLLM and HuggingFace Pipelines",
    "authors": "Matias Martinez",
    "abstract": "The recent surge of open-source large language models (LLMs) enables\ndevelopers to create AI-based solutions while maintaining control over aspects\nsuch as privacy and compliance, thereby providing governance and ownership of\nthe model deployment process. To utilize these LLMs, inference engines are\nneeded. These engines load the model's weights onto available resources, such\nas GPUs, and process queries to generate responses. The speed of inference, or\nperformance, of the LLM, is critical for real-time applications, as it computes\nmillions or billions of floating point operations per inference. Recently,\nadvanced inference engines such as vLLM have emerged, incorporating novel\nmechanisms such as efficient memory management to achieve state-of-the-art\nperformance. In this paper, we analyze the performance, particularly the\nthroughput (tokens generated per unit of time), of 20 LLMs using two inference\nlibraries: vLLM and HuggingFace's pipelines. We investigate how various\nhyperparameters, which developers must configure, influence inference\nperformance. Our results reveal that throughput landscapes are irregular, with\ndistinct peaks, highlighting the importance of hyperparameter optimization to\nachieve maximum performance. We also show that applying hyperparameter\noptimization when upgrading or downgrading the GPU model used for inference can\nimprove throughput from HuggingFace pipelines by an average of 9.16% and 13.7%,\nrespectively.",
    "arxiv_id": "http://arxiv.org/abs/2408.01050v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01050v1",
    "primary_category": "cs.SE",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Tensor Train Low-rank Approximation (TT-LoRA): Democratizing AI with Accelerated LLMs",
    "authors": "Afia Anjum, Maksim E. Eren, Ismael Boureima, Boian Alexandrov, Manish Bhattarai",
    "abstract": "In recent years, Large Language Models (LLMs) have demonstrated remarkable\ncapabilities across a wide range of natural language processing (NLP) tasks,\nsuch as question-answering, sentiment analysis, text summarization, and machine\ntranslation. However, the ever-growing complexity of LLMs demands immense\ncomputational resources, hindering the broader research and application of\nthese models. To address this, various parameter-efficient fine-tuning\nstrategies, such as Low-Rank Approximation (LoRA) and Adapters, have been\ndeveloped. Despite their potential, these methods often face limitations in\ncompressibility. Specifically, LoRA struggles to scale effectively with the\nincreasing number of trainable parameters in modern large scale LLMs.\nAdditionally, Low-Rank Economic Tensor-Train Adaptation (LoRETTA), which\nutilizes tensor train decomposition, has not yet achieved the level of\ncompression necessary for fine-tuning very large scale models with limited\nresources. This paper introduces Tensor Train Low-Rank Approximation (TT-LoRA),\na novel parameter-efficient fine-tuning (PEFT) approach that extends LoRETTA\nwith optimized tensor train (TT) decomposition integration. By eliminating\nAdapters and traditional LoRA-based structures, TT-LoRA achieves greater model\ncompression without compromising downstream task performance, along with\nreduced inference latency and computational overhead. We conduct an exhaustive\nparameter search to establish benchmarks that highlight the trade-off between\nmodel compression and performance. Our results demonstrate significant\ncompression of LLMs while maintaining comparable performance to larger models,\nfacilitating their deployment on resource-constraint platforms.",
    "arxiv_id": "http://arxiv.org/abs/2408.01008v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01008v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "AgentGen: Enhancing Planning Abilities for Large Language Model based Agent via Environment and Task Generation",
    "authors": "Mengkang Hu, Pu Zhao, Can Xu, Qingfeng Sun, Jianguang Lou, Qingwei Lin, Ping Luo, Saravan Rajmohan, Dongmei Zhang",
    "abstract": "Large Language Model (LLM) based agents have garnered significant attention\nand are becoming increasingly popular. Furthermore, planning ability is a\ncrucial component of an LLM-based agent, involving interaction with the\nenvironment and executing actions to complete a planning task, which generally\nentails achieving a desired goal from an initial state. This paper investigates\nenhancing the planning abilities of LLMs through instruction tuning, referred\nto as agent training. Recent studies have demonstrated that utilizing\nexpert-level trajectory for instruction-tuning LLMs effectively enhances their\nplanning capabilities. However, existing work primarily focuses on synthesizing\ntrajectories from manually designed planning tasks and environments. The\nlabor-intensive nature of creating these environments and tasks impedes the\ngeneration of sufficiently varied and extensive trajectories. To address this\nlimitation, this paper explores the automated synthesis of diverse environments\nand a gradual range of planning tasks, from easy to difficult. We introduce a\nframework, AgentGen, that leverages LLMs first to generate environments and\nsubsequently generate planning tasks conditioned on these environments.\nSpecifically, to improve environmental diversity, we propose using an\ninspiration corpus composed of various domain-specific text segments as the\ncontext for synthesizing environments. Moreover, to increase the difficulty\ndiversity of generated planning tasks, we propose a bidirectional evolution\nmethod, Bi-Evol, that evolves planning tasks from easier and harder directions\nto synthesize a task set with a smoother difficulty curve. The evaluation\nresults derived from AgentBoard show that AgentGen greatly improves LLMs'\nplanning ability, e.g., the AgentGen instruction-tuned Llama-3 8B surpasses\nGPT-3.5 in overall performance. Moreover, in certain tasks, it even outperforms\nGPT-4.",
    "arxiv_id": "http://arxiv.org/abs/2408.00764v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00764v1",
    "primary_category": "cs.CL",
    "votes": 1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "AutoM3L: An Automated Multimodal Machine Learning Framework with Large Language Models",
    "authors": "Daqin Luo, Chengjian Feng, Yuxuan Nong, Yiqing Shen",
    "abstract": "Automated Machine Learning (AutoML) offers a promising approach to streamline\nthe training of machine learning models. However, existing AutoML frameworks\nare often limited to unimodal scenarios and require extensive manual\nconfiguration. Recent advancements in Large Language Models (LLMs) have\nshowcased their exceptional abilities in reasoning, interaction, and code\ngeneration, presenting an opportunity to develop a more automated and\nuser-friendly framework. To this end, we introduce AutoM3L, an innovative\nAutomated Multimodal Machine Learning framework that leverages LLMs as\ncontrollers to automatically construct multimodal training pipelines. AutoM3L\ncomprehends data modalities and selects appropriate models based on user\nrequirements, providing automation and interactivity. By eliminating the need\nfor manual feature engineering and hyperparameter optimization, our framework\nsimplifies user engagement and enables customization through directives,\naddressing the limitations of previous rule-based AutoML approaches. We\nevaluate the performance of AutoM3L on six diverse multimodal datasets spanning\nclassification, regression, and retrieval tasks, as well as a comprehensive set\nof unimodal datasets. The results demonstrate that AutoM3L achieves competitive\nor superior performance compared to traditional rule-based AutoML methods.\nFurthermore, a user study highlights the user-friendliness and usability of our\nframework, compared to the rule-based AutoML methods.",
    "arxiv_id": "http://arxiv.org/abs/2408.00665v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00665v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Disentangling Dense Embeddings with Sparse Autoencoders",
    "authors": "Charles O'Neill, Christine Ye, Kartheik Iyer, John F. Wu",
    "abstract": "Sparse autoencoders (SAEs) have shown promise in extracting interpretable\nfeatures from complex neural networks. We present one of the first applications\nof SAEs to dense text embeddings from large language models, demonstrating\ntheir effectiveness in disentangling semantic concepts. By training SAEs on\nembeddings of over 420,000 scientific paper abstracts from computer science and\nastronomy, we show that the resulting sparse representations maintain semantic\nfidelity while offering interpretability. We analyse these learned features,\nexploring their behaviour across different model capacities and introducing a\nnovel method for identifying ``feature families'' that represent related\nconcepts at varying levels of abstraction. To demonstrate the practical utility\nof our approach, we show how these interpretable features can be used to\nprecisely steer semantic search, allowing for fine-grained control over query\nsemantics. This work bridges the gap between the semantic richness of dense\nembeddings and the interpretability of sparse representations. We open source\nour embeddings, trained sparse autoencoders, and interpreted features, as well\nas a web app for exploring them.",
    "arxiv_id": "http://arxiv.org/abs/2408.00657v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00657v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Mission Impossible: A Statistical Perspective on Jailbreaking LLMs",
    "authors": "Jingtong Su, Julia Kempe, Karen Ullrich",
    "abstract": "Large language models (LLMs) are trained on a deluge of text data with\nlimited quality control. As a result, LLMs can exhibit unintended or even\nharmful behaviours, such as leaking information, fake news or hate speech.\nCountermeasures, commonly referred to as preference alignment, include\nfine-tuning the pretrained LLMs with carefully crafted text examples of desired\nbehaviour. Even then, empirical evidence shows preference aligned LLMs can be\nenticed to harmful behaviour. This so called jailbreaking of LLMs is typically\nachieved by adversarially modifying the input prompt to the LLM. Our paper\nprovides theoretical insights into the phenomenon of preference alignment and\njailbreaking from a statistical perspective. Under our framework, we first show\nthat pretrained LLMs will mimic harmful behaviour if present in the training\ncorpus. Under that same framework, we then introduce a statistical notion of\nalignment, and lower-bound the jailbreaking probability, showing that it is\nunpreventable under reasonable assumptions. Based on our insights, we propose\nan alteration to the currently prevalent alignment strategy RLHF. Specifically,\nwe introduce a simple modification to the RLHF objective, we call E-RLHF, that\naims to increase the likelihood of safe responses. E-RLHF brings no additional\ntraining cost, and is compatible with other methods. Empirically, we\ndemonstrate that E-RLHF outperforms RLHF on all alignment problems put forward\nby the AdvBench and HarmBench project without sacrificing model performance as\nmeasured by the MT-Bench project.",
    "arxiv_id": "http://arxiv.org/abs/2408.01420v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01420v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Talk Less, Interact Better: Evaluating In-context Conversational Adaptation in Multimodal LLMs",
    "authors": "Yilun Hua, Yoav Artzi",
    "abstract": "Humans spontaneously use increasingly efficient language as interactions\nprogress, by adapting and forming ad-hoc conventions. This phenomenon has been\nstudied extensively using reference games, showing properties of human language\nthat go beyond relaying intents. It remains unexplored whether multimodal large\nlanguage models (MLLMs) similarly increase communication efficiency during\ninteractions, and what mechanisms they may adopt for this purpose. We introduce\nICCA, an automated framework to evaluate such conversational adaptation as an\nin-context behavior in MLLMs. We evaluate several state-of-the-art MLLMs, and\nobserve that while they may understand the increasingly efficient language of\ntheir interlocutor, they do not spontaneously make their own language more\nefficient over time. This latter ability can only be elicited in some models\n(e.g., GPT-4) with heavy-handed prompting. This shows that this property of\nlinguistic interaction does not arise from current training regimes, even\nthough it is a common hallmark of human language. ICCA is available at\nhttps://github.com/lil-lab/ICCA.",
    "arxiv_id": "http://arxiv.org/abs/2408.01417v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01417v1",
    "primary_category": "cs.CL",
    "votes": 0,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "The Quest for the Right Mediator: A History, Survey, and Theoretical Grounding of Causal Interpretability",
    "authors": "Aaron Mueller, Jannik Brinkmann, Millicent Li, Samuel Marks, Koyena Pal, Nikhil Prakash, Can Rager, Aruna Sankaranarayanan, Arnab Sen Sharma, Jiuding Sun, Eric Todd, David Bau, Yonatan Belinkov",
    "abstract": "Interpretability provides a toolset for understanding how and why neural\nnetworks behave in certain ways. However, there is little unity in the field:\nmost studies employ ad-hoc evaluations and do not share theoretical\nfoundations, making it difficult to measure progress and compare the pros and\ncons of different techniques. Furthermore, while mechanistic understanding is\nfrequently discussed, the basic causal units underlying these mechanisms are\noften not explicitly defined. In this paper, we propose a perspective on\ninterpretability research grounded in causal mediation analysis. Specifically,\nwe describe the history and current state of interpretability taxonomized\naccording to the types of causal units (mediators) employed, as well as methods\nused to search over mediators. We discuss the pros and cons of each mediator,\nproviding insights as to when particular kinds of mediators and search methods\nare most appropriate depending on the goals of a given study. We argue that\nthis framing yields a more cohesive narrative of the field, as well as\nactionable insights for future work. Specifically, we recommend a focus on\ndiscovering new mediators with better trade-offs between human-interpretability\nand compute-efficiency, and which can uncover more sophisticated abstractions\nfrom neural networks than the primarily linear mediators employed in current\nwork. We also argue for more standardized evaluations that enable principled\ncomparisons across mediator types, such that we can better understand when\nparticular causal units are better suited to particular use cases.",
    "arxiv_id": "http://arxiv.org/abs/2408.01416v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01416v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Conditional LoRA Parameter Generation",
    "authors": "Xiaolong Jin, Kai Wang, Dongwen Tang, Wangbo Zhao, Yukun Zhou, Junshu Tang, Yang You",
    "abstract": "Generative models have achieved remarkable success in image, video, and text\ndomains. Inspired by this, researchers have explored utilizing generative\nmodels to generate neural network parameters. However, these efforts have been\nlimited by the parameter size and the practicality of generating\nhigh-performance parameters. In this paper, we propose COND P-DIFF, a novel\napproach that demonstrates the feasibility of controllable high-performance\nparameter generation, particularly for LoRA (Low-Rank Adaptation) weights,\nduring the fine-tuning process. Specifically, we employ an autoencoder to\nextract efficient latent representations for parameters. We then train a\nconditional latent diffusion model to synthesize high-performing model\nparameters from random noise based on specific task conditions. Experimental\nresults in both computer vision and natural language processing domains\nconsistently demonstrate that COND P-DIFF can generate high-performance\nparameters conditioned on the given task. Moreover, we observe that the\nparameter distribution generated by COND P-DIFF exhibits differences compared\nto the distribution obtained through normal optimization methods, indicating a\ncertain level of generalization capability. Our work paves the way for further\nexploration of condition-driven parameter generation, offering a promising\ndirection for task-specific adaptation of neural networks.",
    "arxiv_id": "http://arxiv.org/abs/2408.01415v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01415v1",
    "primary_category": "cs.AI",
    "votes": 0,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Derivation of Back-propagation for Graph Convolutional Networks using Matrix Calculus and its Application to Explainable Artificial Intelligence",
    "authors": "Yen-Che Hsiao, Rongting Yue, Abhishek Dutta",
    "abstract": "This paper provides a comprehensive and detailed derivation of the\nbackpropagation algorithm for graph convolutional neural networks using matrix\ncalculus. The derivation is extended to include arbitrary element-wise\nactivation functions and an arbitrary number of layers. The study addresses two\nfundamental problems, namely node classification and link prediction. To\nvalidate our method, we compare it with reverse-mode automatic differentiation.\nThe experimental results demonstrate that the median sum of squared errors of\nthe updated weight matrices, when comparing our method to the approach using\nreverse-mode automatic differentiation, falls within the range of $10^{-18}$ to\n$10^{-14}$. These outcomes are obtained from conducting experiments on a\nfive-layer graph convolutional network, applied to a node classification\nproblem on Zachary's karate club social network and a link prediction problem\non a drug-drug interaction network. Finally, we show how the derived\nclosed-form solution can facilitate the development of explainable AI and\nsensitivity analysis.",
    "arxiv_id": "http://arxiv.org/abs/2408.01408v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01408v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Pre-trained Language Models Improve the Few-shot Prompt Ability of Decision Transformer",
    "authors": "Yu Yang, Pan Xu",
    "abstract": "Decision Transformer (DT) has emerged as a promising class of algorithms in\noffline reinforcement learning (RL) tasks, leveraging pre-collected datasets\nand Transformer's capability to model long sequences. Recent works have\ndemonstrated that using parts of trajectories from training tasks as prompts in\nDT enhances its performance on unseen tasks, giving rise to Prompt-DT methods.\nHowever, collecting data from specific environments can be both costly and\nunsafe in many scenarios, leading to suboptimal performance and limited\nfew-shot prompt abilities due to the data-hungry nature of Transformer-based\nmodels. Additionally, the limited datasets used in pre-training make it\nchallenging for Prompt-DT type of methods to distinguish between various RL\ntasks through prompts alone. To address these challenges, we introduce the\nLanguage model-initialized Prompt Decision Transformer (LPDT), which leverages\npre-trained language models for meta-RL tasks and fine-tunes the model using\nLow-rank Adaptation (LoRA). We further incorporate prompt regularization to\neffectively differentiate between tasks based on prompt feature\nrepresentations. Our approach integrates pre-trained language model and RL\ntasks seamlessly. Extensive empirical studies demonstrate that initializing\nwith a pre-trained language model significantly enhances the performance of\nPrompt-DT on unseen tasks compared to baseline methods.",
    "arxiv_id": "http://arxiv.org/abs/2408.01402v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01402v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "FT K-Means: A High-Performance K-Means on GPU with Fault Tolerance",
    "authors": "Shixun Wu, Yitong Ding, Yujia Zhai, Jinyang Liu, Jiajun Huang, Zizhe Jian, Huangliang Dai, Sheng Di, Bryan M. Wong, Zizhong Chen, Franck Cappello",
    "abstract": "K-Means is a widely used algorithm in clustering, however, its efficiency is\nprimarily constrained by the computational cost of distance computing. Existing\nimplementations suffer from suboptimal utilization of computational units and\nlack resilience against soft errors. To address these challenges, we introduce\nFT K-Means, a high-performance GPU-accelerated implementation of K-Means with\nonline fault tolerance. We first present a stepwise optimization strategy that\nachieves competitive performance compared to NVIDIA's cuML library. We further\nimprove FT K-Means with a template-based code generation framework that\nsupports different data types and adapts to different input shapes. A novel\nwarp-level tensor-core error correction scheme is proposed to address the\nfailure of existing fault tolerance methods due to memory asynchronization\nduring copy operations. Our experimental evaluations on NVIDIA T4 GPU and A100\nGPU demonstrate that FT K-Means without fault tolerance outperforms cuML's\nK-Means implementation, showing a performance increase of 10\\%-300\\% in\nscenarios involving irregular data shapes. Moreover, the fault tolerance\nfeature of FT K-Means introduces only an overhead of 11\\%, maintaining robust\nperformance even with tens of errors injected per second.",
    "arxiv_id": "http://arxiv.org/abs/2408.01391v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01391v1",
    "primary_category": "cs.DC",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "NeuralBeta: Estimating Beta Using Deep Learning",
    "authors": "Yuxin Liu, Jimin Lin, Achintya Gopal",
    "abstract": "Traditional approaches to estimating beta in finance often involve rigid\nassumptions and fail to adequately capture beta dynamics, limiting their\neffectiveness in use cases like hedging. To address these limitations, we have\ndeveloped a novel method using neural networks called NeuralBeta, which is\ncapable of handling both univariate and multivariate scenarios and tracking the\ndynamic behavior of beta. To address the issue of interpretability, we\nintroduce a new output layer inspired by regularized weighted linear\nregression, which provides transparency into the model's decision-making\nprocess. We conducted extensive experiments on both synthetic and market data,\ndemonstrating NeuralBeta's superior performance compared to benchmark methods\nacross various scenarios, especially instances where beta is highly\ntime-varying, e.g., during regime shifts in the market. This model not only\nrepresents an advancement in the field of beta estimation, but also shows\npotential for applications in other financial contexts that assume linear\nrelationships.",
    "arxiv_id": "http://arxiv.org/abs/2408.01387v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01387v1",
    "primary_category": "q-fin.ST",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Explaining a probabilistic prediction on the simplex with Shapley compositions",
    "authors": "Paul-Gauthier No\u00e9, Miquel Perell\u00f3-Nieto, Jean-Fran\u00e7ois Bonastre, Peter Flach",
    "abstract": "Originating in game theory, Shapley values are widely used for explaining a\nmachine learning model's prediction by quantifying the contribution of each\nfeature's value to the prediction. This requires a scalar prediction as in\nbinary classification, whereas a multiclass probabilistic prediction is a\ndiscrete probability distribution, living on a multidimensional simplex. In\nsuch a multiclass setting the Shapley values are typically computed separately\non each class in a one-vs-rest manner, ignoring the compositional nature of the\noutput distribution. In this paper, we introduce Shapley compositions as a\nwell-founded way to properly explain a multiclass probabilistic prediction,\nusing the Aitchison geometry from compositional data analysis. We prove that\nthe Shapley composition is the unique quantity satisfying linearity, symmetry\nand efficiency on the Aitchison simplex, extending the corresponding axiomatic\nproperties of the standard Shapley value. We demonstrate this proper multiclass\ntreatment in a range of scenarios.",
    "arxiv_id": "http://arxiv.org/abs/2408.01382v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01382v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Resampling and averaging coordinates on data",
    "authors": "Andrew J. Blumberg, Mathieu Carriere, Jun Hou Fung, Michael A. Mandell",
    "abstract": "We introduce algorithms for robustly computing intrinsic coordinates on point\nclouds. Our approach relies on generating many candidate coordinates by\nsubsampling the data and varying hyperparameters of the embedding algorithm\n(e.g., manifold learning). We then identify a subset of representative\nembeddings by clustering the collection of candidate coordinates and using\nshape descriptors from topological data analysis. The final output is the\nembedding obtained as an average of the representative embeddings using\ngeneralized Procrustes analysis. We validate our algorithm on both synthetic\ndata and experimental measurements from genomics, demonstrating robustness to\nnoise and outliers.",
    "arxiv_id": "http://arxiv.org/abs/2408.01379v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01379v1",
    "primary_category": "stat.ML",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Adaptive Recruitment Resource Allocation to Improve Cohort Representativeness in Participatory Biomedical Datasets",
    "authors": "Victor Borza, Andrew Estornell, Ellen Wright Clayton, Chien-Ju Ho, Russell Rothman, Yevgeniy Vorobeychik, Bradley Malin",
    "abstract": "Large participatory biomedical studies, studies that recruit individuals to\njoin a dataset, are gaining popularity and investment, especially for analysis\nby modern AI methods. Because they purposively recruit participants, these\nstudies are uniquely able to address a lack of historical representation, an\nissue that has affected many biomedical datasets. In this work, we define\nrepresentativeness as the similarity to a target population distribution of a\nset of attributes and our goal is to mirror the U.S. population across\ndistributions of age, gender, race, and ethnicity. Many participatory studies\nrecruit at several institutions, so we introduce a computational approach to\nadaptively allocate recruitment resources among sites to improve\nrepresentativeness. In simulated recruitment of 10,000-participant cohorts from\nmedical centers in the STAR Clinical Research Network, we show that our\napproach yields a more representative cohort than existing baselines. Thus, we\nhighlight the value of computational modeling in guiding recruitment efforts.",
    "arxiv_id": "http://arxiv.org/abs/2408.01375v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01375v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Hybrid Coordinate Descent for Efficient Neural Network Learning Using Line Search and Gradient Descent",
    "authors": "Yen-Che Hsiao, Abhishek Dutta",
    "abstract": "This paper presents a novel coordinate descent algorithm leveraging a\ncombination of one-directional line search and gradient information for\nparameter updates for a squared error loss function. Each parameter undergoes\nupdates determined by either the line search or gradient method, contingent\nupon whether the modulus of the gradient of the loss with respect to that\nparameter surpasses a predefined threshold. Notably, a larger threshold value\nenhances algorithmic efficiency. Despite the potentially slower nature of the\nline search method relative to gradient descent, its parallelizability\nfacilitates computational time reduction. Experimental validation conducted on\na 2-layer Rectified Linear Unit network with synthetic data elucidates the\nimpact of hyperparameters on convergence rates and computational efficiency.",
    "arxiv_id": "http://arxiv.org/abs/2408.01374v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01374v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Data Debugging is NP-hard for Classifiers Trained with SGD",
    "authors": "Zizheng Guo, Pengyu Chen, Yanzhang Fu, Dongjing Miao",
    "abstract": "Data debugging is to find a subset of the training data such that the model\nobtained by retraining on the subset has a better accuracy. A bunch of\nheuristic approaches are proposed, however, none of them are guaranteed to\nsolve this problem effectively. This leaves an open issue whether there exists\nan efficient algorithm to find the subset such that the model obtained by\nretraining on it has a better accuracy. To answer this open question and\nprovide theoretical basis for further study on developing better algorithms for\ndata debugging, we investigate the computational complexity of the problem\nnamed Debuggable. Given a machine learning model $\\mathcal{M}$ obtained by\ntraining on dataset $D$ and a test instance\n$(\\mathbf{x}_\\text{test},y_\\text{test})$ where\n$\\mathcal{M}(\\mathbf{x}_\\text{test})\\neq y_\\text{test}$, Debuggable is to\ndetermine whether there exists a subset $D^\\prime$ of $D$ such that the model\n$\\mathcal{M}^\\prime$ obtained by retraining on $D^\\prime$ satisfies\n$\\mathcal{M}^\\prime(\\mathbf{x}_\\text{test})=y_\\text{test}$. To cover a wide\nrange of commonly used models, we take SGD-trained linear classifier as the\nmodel and derive the following main results. (1) If the loss function and the\ndimension of the model are not fixed, Debuggable is NP-complete regardless of\nthe training order in which all the training samples are processed during SGD.\n(2) For hinge-like loss functions, a comprehensive analysis on the\ncomputational complexity of Debuggable is provided; (3) If the loss function is\na linear function, Debuggable can be solved in linear time, that is, data\ndebugging can be solved easily in this case. These results not only highlight\nthe limitations of current approaches but also offer new insights into data\ndebugging.",
    "arxiv_id": "http://arxiv.org/abs/2408.01365v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01365v1",
    "primary_category": "cs.CC",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Autoencoders in Function Space",
    "authors": "Justin Bunker, Mark Girolami, Hefin Lambley, Andrew M. Stuart, T. J. Sullivan",
    "abstract": "Autoencoders have found widespread application, in both their original\ndeterministic form and in their variational formulation (VAEs). In scientific\napplications it is often of interest to consider data that are comprised of\nfunctions; the same perspective is useful in image processing. In practice,\ndiscretisation (of differential equations arising in the sciences) or\npixellation (of images) renders problems finite dimensional, but conceiving\nfirst of algorithms that operate on functions, and only then discretising or\npixellating, leads to better algorithms that smoothly operate between different\nlevels of discretisation or pixellation. In this paper function-space versions\nof the autoencoder (FAE) and variational autoencoder (FVAE) are introduced,\nanalysed, and deployed. Well-definedness of the objective function governing\nVAEs is a subtle issue, even in finite dimension, and more so on function\nspace. The FVAE objective is well defined whenever the data distribution is\ncompatible with the chosen generative model; this happens, for example, when\nthe data arise from a stochastic differential equation. The FAE objective is\nvalid much more broadly, and can be straightforwardly applied to data governed\nby differential equations. Pairing these objectives with neural operator\narchitectures, which can thus be evaluated on any mesh, enables new\napplications of autoencoders to inpainting, superresolution, and generative\nmodelling of scientific data.",
    "arxiv_id": "http://arxiv.org/abs/2408.01362v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01362v1",
    "primary_category": "stat.ML",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "PC$^2$: Pseudo-Classification Based Pseudo-Captioning for Noisy Correspondence Learning in Cross-Modal Retrieval",
    "authors": "Yue Duan, Zhangxuan Gu, Zhenzhe Ying, Lei Qi, Changhua Meng, Yinghuan Shi",
    "abstract": "In the realm of cross-modal retrieval, seamlessly integrating diverse\nmodalities within multimedia remains a formidable challenge, especially given\nthe complexities introduced by noisy correspondence learning (NCL). Such noise\noften stems from mismatched data pairs, which is a significant obstacle\ndistinct from traditional noisy labels. This paper introduces\nPseudo-Classification based Pseudo-Captioning (PC$^2$) framework to address\nthis challenge. PC$^2$ offers a threefold strategy: firstly, it establishes an\nauxiliary \"pseudo-classification\" task that interprets captions as categorical\nlabels, steering the model to learn image-text semantic similarity through a\nnon-contrastive mechanism. Secondly, unlike prevailing margin-based techniques,\ncapitalizing on PC$^2$'s pseudo-classification capability, we generate\npseudo-captions to provide more informative and tangible supervision for each\nmismatched pair. Thirdly, the oscillation of pseudo-classification is borrowed\nto assistant the correction of correspondence. In addition to technical\ncontributions, we develop a realistic NCL dataset called Noise of Web (NoW),\nwhich could be a new powerful NCL benchmark where noise exists naturally.\nEmpirical evaluations of PC$^2$ showcase marked improvements over existing\nstate-of-the-art robust cross-modal retrieval techniques on both simulated and\nrealistic datasets with various NCL settings. The contributed dataset and\nsource code are released at https://github.com/alipay/PC2-NoiseofWeb.",
    "arxiv_id": "http://arxiv.org/abs/2408.01349v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01349v1",
    "primary_category": "cs.MM",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "StitchFusion: Weaving Any Visual Modalities to Enhance Multimodal Semantic Segmentation",
    "authors": "Bingyu Li, Da Zhang, Zhiyuan Zhao, Junyu Gao, Xuelong Li",
    "abstract": "Multimodal semantic segmentation shows significant potential for enhancing\nsegmentation accuracy in complex scenes. However, current methods often\nincorporate specialized feature fusion modules tailored to specific modalities,\nthereby restricting input flexibility and increasing the number of training\nparameters. To address these challenges, we propose StitchFusion, a\nstraightforward yet effective modal fusion framework that integrates\nlarge-scale pre-trained models directly as encoders and feature fusers. This\napproach facilitates comprehensive multi-modal and multi-scale feature fusion,\naccommodating any visual modal inputs. Specifically, Our framework achieves\nmodal integration during encoding by sharing multi-modal visual information. To\nenhance information exchange across modalities, we introduce a\nmulti-directional adapter module (MultiAdapter) to enable cross-modal\ninformation transfer during encoding. By leveraging MultiAdapter to propagate\nmulti-scale information across pre-trained encoders during the encoding\nprocess, StitchFusion achieves multi-modal visual information integration\nduring encoding. Extensive comparative experiments demonstrate that our model\nachieves state-of-the-art performance on four multi-modal segmentation datasets\nwith minimal additional parameters. Furthermore, the experimental integration\nof MultiAdapter with existing Feature Fusion Modules (FFMs) highlights their\ncomplementary nature. Our code is available at StitchFusion_repo.",
    "arxiv_id": "http://arxiv.org/abs/2408.01343v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01343v1",
    "primary_category": "cs.CV",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "MuChoMusic: Evaluating Music Understanding in Multimodal Audio-Language Models",
    "authors": "Benno Weck, Ilaria Manco, Emmanouil Benetos, Elio Quinton, George Fazekas, Dmitry Bogdanov",
    "abstract": "Multimodal models that jointly process audio and language hold great promise\nin audio understanding and are increasingly being adopted in the music domain.\nBy allowing users to query via text and obtain information about a given audio\ninput, these models have the potential to enable a variety of music\nunderstanding tasks via language-based interfaces. However, their evaluation\nposes considerable challenges, and it remains unclear how to effectively assess\ntheir ability to correctly interpret music-related inputs with current methods.\nMotivated by this, we introduce MuChoMusic, a benchmark for evaluating music\nunderstanding in multimodal language models focused on audio. MuChoMusic\ncomprises 1,187 multiple-choice questions, all validated by human annotators,\non 644 music tracks sourced from two publicly available music datasets, and\ncovering a wide variety of genres. Questions in the benchmark are crafted to\nassess knowledge and reasoning abilities across several dimensions that cover\nfundamental musical concepts and their relation to cultural and functional\ncontexts. Through the holistic analysis afforded by the benchmark, we evaluate\nfive open-source models and identify several pitfalls, including an\nover-reliance on the language modality, pointing to a need for better\nmultimodal integration. Data and code are open-sourced.",
    "arxiv_id": "http://arxiv.org/abs/2408.01337v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01337v1",
    "primary_category": "cs.SD",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Sparse Linear Regression when Noises and Covariates are Heavy-Tailed and Contaminated by Outliers",
    "authors": "Takeyuki Sasai, Hironori Fujisawa",
    "abstract": "We investigate a problem estimating coefficients of linear regression under\nsparsity assumption when covariates and noises are sampled from heavy tailed\ndistributions. Additionally, we consider the situation where not only\ncovariates and noises are sampled from heavy tailed distributions but also\ncontaminated by outliers. Our estimators can be computed efficiently, and\nexhibit sharp error bounds.",
    "arxiv_id": "http://arxiv.org/abs/2408.01336v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01336v1",
    "primary_category": "stat.ML",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "HMDN: Hierarchical Multi-Distribution Network for Click-Through Rate Prediction",
    "authors": "Xingyu Lou, Yu Yang, Kuiyao Dong, Heyuan Huang, Wenyi Yu, Ping Wang, Xiu Li, Jun Wang",
    "abstract": "As the recommendation service needs to address increasingly diverse\ndistributions, such as multi-population, multi-scenario, multitarget, and\nmulti-interest, more and more recent works have focused on multi-distribution\nmodeling and achieved great progress. However, most of them only consider\nmodeling in a single multi-distribution manner, ignoring that mixed\nmulti-distributions often coexist and form hierarchical relationships. To\naddress these challenges, we propose a flexible modeling paradigm, named\nHierarchical Multi-Distribution Network (HMDN), which efficiently models these\nhierarchical relationships and can seamlessly integrate with existing\nmulti-distribution methods, such as Mixture of-Experts (MoE) and Dynamic-Weight\n(DW) models. Specifically, we first design a hierarchical multi-distribution\nrepresentation refinement module, employing a multi-level residual quantization\nto obtain fine-grained hierarchical representation. Then, the refined\nhierarchical representation is integrated into the existing single\nmulti-distribution models, seamlessly expanding them into mixed\nmulti-distribution models. Experimental results on both public and industrial\ndatasets validate the effectiveness and flexibility of HMDN.",
    "arxiv_id": "http://arxiv.org/abs/2408.01332v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01332v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "UnifiedNN: Efficient Neural Network Training on the Cloud",
    "authors": "Sifat Ut Taki, Spyridon Mastorakis, Arthi Padmanabhan",
    "abstract": "Nowadays, cloud-based services are widely favored over the traditional\napproach of locally training a Neural Network (NN) model. Oftentimes, a cloud\nservice processes multiple requests from users--thus training multiple NN\nmodels concurrently. However, training NN models concurrently is a challenging\nprocess, which typically requires significant amounts of available computing\nresources and takes a long time to complete. In this paper, we present\nUnifiedNN to effectively train multiple NN models concurrently on the cloud.\nUnifiedNN effectively \"combines\" multiple NN models and features several memory\nand time conservation mechanisms to train multiple NN models simultaneously\nwithout impacting the accuracy of the training process. Specifically, UnifiedNN\nmerges multiple NN models and creates a large singular unified model in order\nto efficiently train all models at once. We have implemented a prototype of\nUnifiedNN in PyTorch and we have compared its performance with relevant\nstate-of-the-art frameworks. Our experimental results demonstrate that\nUnifiedNN can reduce memory consumption by up to 53% and training time by up to\n81% when compared with vanilla PyTorch without impacting the model training and\ntesting accuracy. Finally, our results indicate that UnifiedNN can reduce\nmemory consumption by up to 52% and training time by up to 41% when compared to\nstate-of-the-art frameworks when training multiple models concurrently.",
    "arxiv_id": "http://arxiv.org/abs/2408.01331v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01331v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Point Prediction for Streaming Data",
    "authors": "Aleena Chanda, N. V. Vinodchandran, Bertrand Clarke",
    "abstract": "We present two new approaches for point prediction with streaming data. One\nis based on the Count-Min sketch (CMS) and the other is based on Gaussian\nprocess priors with a random bias. These methods are intended for the most\ngeneral predictive problems where no true model can be usefully formulated for\nthe data stream. In statistical contexts, this is often called the\n$\\mathcal{M}$-open problem class. Under the assumption that the data consists\nof i.i.d samples from a fixed distribution function $F$, we show that the\nCMS-based estimates of the distribution function are consistent.\n  We compare our new methods with two established predictors in terms of\ncumulative $L^1$ error. One is based on the Shtarkov solution (often called the\nnormalized maximum likelihood) in the normal experts setting and the other is\nbased on Dirichlet process priors. These comparisons are for two cases. The\nfirst is one-pass meaning that the updating of the predictors is done using the\nfact that the CMS is a sketch. For predictors that are not one-pass, we use\nstreaming $K$-means to give a representative subset of fixed size that can be\nupdated as data accumulate.\n  Preliminary computational work suggests that the one-pass median version of\nthe CMS method is rarely outperformed by the other methods for sufficiently\ncomplex data. We also find that predictors based on Gaussian process priors\nwith random biases perform well. The Shtarkov predictors we use here did not\nperform as well probably because we were only using the simplest example. The\nother predictors seemed to perform well mainly when the data did not look like\nthey came from an M-open data generator.",
    "arxiv_id": "http://arxiv.org/abs/2408.01318v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01318v1",
    "primary_category": "stat.ML",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Decentralized Smoothing ADMM for Quantile Regression with Non-Convex Sparse Penalties",
    "authors": "Reza Mirzaeifard, Diyako Ghaderyan, Stefan Werner",
    "abstract": "In the rapidly evolving internet-of-things (IoT) ecosystem, effective data\nanalysis techniques are crucial for handling distributed data generated by\nsensors. Addressing the limitations of existing methods, such as the\nsub-gradient approach, which fails to distinguish between active and non-active\ncoefficients effectively, this paper introduces the decentralized smoothing\nalternating direction method of multipliers (DSAD) for penalized quantile\nregression. Our method leverages non-convex sparse penalties like the minimax\nconcave penalty (MCP) and smoothly clipped absolute deviation (SCAD), improving\nthe identification and retention of significant predictors. DSAD incorporates a\ntotal variation norm within a smoothing ADMM framework, achieving consensus\namong distributed nodes and ensuring uniform model performance across disparate\ndata sources. This approach overcomes traditional convergence challenges\nassociated with non-convex penalties in decentralized settings. We present\ntheoretical proofs and extensive simulation results to validate the\neffectiveness of the DSAD, demonstrating its superiority in achieving reliable\nconvergence and enhancing estimation accuracy compared with prior methods.",
    "arxiv_id": "http://arxiv.org/abs/2408.01307v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01307v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "A Decision-driven Methodology for Designing Uncertainty-aware AI Self-Assessment",
    "authors": "Gregory Canal, Vladimir Leung, Philip Sage, Eric Heim, I-Jeng Wang",
    "abstract": "Artificial intelligence (AI) has revolutionized decision-making processes and\nsystems throughout society and, in particular, has emerged as a significant\ntechnology in high-impact scenarios of national interest. Yet, despite AI's\nimpressive predictive capabilities in controlled settings, it still suffers\nfrom a range of practical setbacks preventing its widespread use in various\ncritical scenarios. In particular, it is generally unclear if a given AI\nsystem's predictions can be trusted by decision-makers in downstream\napplications. To address the need for more transparent, robust, and trustworthy\nAI systems, a suite of tools has been developed to quantify the uncertainty of\nAI predictions and, more generally, enable AI to \"self-assess\" the reliability\nof its predictions. In this manuscript, we categorize methods for AI\nself-assessment along several key dimensions and provide guidelines for\nselecting and designing the appropriate method for a practitioner's needs. In\nparticular, we focus on uncertainty estimation techniques that consider the\nimpact of self-assessment on the choices made by downstream decision-makers and\non the resulting costs and benefits of decision outcomes. To demonstrate the\nutility of our methodology for self-assessment design, we illustrate its use\nfor two realistic national-interest scenarios. This manuscript is a practical\nguide for machine learning engineers and AI system users to select the ideal\nself-assessment techniques for each problem.",
    "arxiv_id": "http://arxiv.org/abs/2408.01301v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01301v1",
    "primary_category": "stat.ML",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Assessing Robustness of Machine Learning Models using Covariate Perturbations",
    "authors": "Arun Prakash R, Anwesha Bhattacharyya, Joel Vaughan, Vijayan N. Nair",
    "abstract": "As machine learning models become increasingly prevalent in critical\ndecision-making models and systems in fields like finance, healthcare, etc.,\nensuring their robustness against adversarial attacks and changes in the input\ndata is paramount, especially in cases where models potentially overfit. This\npaper proposes a comprehensive framework for assessing the robustness of\nmachine learning models through covariate perturbation techniques. We explore\nvarious perturbation strategies to assess robustness and examine their impact\non model predictions, including separate strategies for numeric and non-numeric\nvariables, summaries of perturbations to assess and compare model robustness\nacross different scenarios, and local robustness diagnosis to identify any\nregions in the data where a model is particularly unstable. Through empirical\nstudies on real world dataset, we demonstrate the effectiveness of our approach\nin comparing robustness across models, identifying the instabilities in the\nmodel, and enhancing model robustness.",
    "arxiv_id": "http://arxiv.org/abs/2408.01300v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01300v1",
    "primary_category": "stat.ML",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Optimal Mixed Integer Linear Optimization Trained Multivariate Classification Trees",
    "authors": "Brandon Alston, Illya V. Hicks",
    "abstract": "Multivariate decision trees are powerful machine learning tools for\nclassification and regression that attract many researchers and industry\nprofessionals. An optimal binary tree has two types of vertices, (i) branching\nvertices which have exactly two children and where datapoints are assessed on a\nset of discrete features and (ii) leaf vertices at which datapoints are given a\nprediction, and can be obtained by solving a biobjective optimization problem\nthat seeks to (i) maximize the number of correctly classified datapoints and\n(ii) minimize the number of branching vertices. Branching vertices are linear\ncombinations of training features and therefore can be thought of as\nhyperplanes. In this paper, we propose two cut-based mixed integer linear\noptimization (MILO) formulations for designing optimal binary classification\ntrees (leaf vertices assign discrete classes). Our models leverage on-the-fly\nidentification of minimal infeasible subsystems (MISs) from which we derive\ncutting planes that hold the form of packing constraints. We show theoretical\nimprovements on the strongest flow-based MILO formulation currently in the\nliterature and conduct experiments on publicly available datasets to show our\nmodels' ability to scale, strength against traditional branch and bound\napproaches, and robustness in out-of-sample test performance. Our code and data\nare available on GitHub.",
    "arxiv_id": "http://arxiv.org/abs/2408.01297v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01297v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Feature Clock: High-Dimensional Effects in Two-Dimensional Plots",
    "authors": "Olga Ovcharenko, Rita Sevastjanova, Valentina Boeva",
    "abstract": "Humans struggle to perceive and interpret high-dimensional data. Therefore,\nhigh-dimensional data are often projected into two dimensions for\nvisualization. Many applications benefit from complex nonlinear dimensionality\nreduction techniques, but the effects of individual high-dimensional features\nare hard to explain in the two-dimensional space. Most visualization solutions\nuse multiple two-dimensional plots, each showing the effect of one\nhigh-dimensional feature in two dimensions; this approach creates a need for a\nvisual inspection of k plots for a k-dimensional input space. Our solution,\nFeature Clock, provides a novel approach that eliminates the need to inspect\nthese k plots to grasp the influence of original features on the data structure\ndepicted in two dimensions. Feature Clock enhances the explainability and\ncompactness of visualizations of embedded data and is available in an\nopen-source Python library.",
    "arxiv_id": "http://arxiv.org/abs/2408.01294v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01294v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "A Tiny Supervised ODL Core with Auto Data Pruning for Human Activity Recognition",
    "authors": "Hiroki Matsutani, Radu Marculescu",
    "abstract": "In this paper, we introduce a low-cost and low-power tiny supervised\non-device learning (ODL) core that can address the distributional shift of\ninput data for human activity recognition. Although ODL for resource-limited\nedge devices has been studied recently, how exactly to provide the training\nlabels to these devices at runtime remains an open-issue. To address this\nproblem, we propose to combine an automatic data pruning with supervised ODL to\nreduce the number queries needed to acquire predicted labels from a nearby\nteacher device and thus save power consumption during model retraining. The\ndata pruning threshold is automatically tuned, eliminating a manual threshold\ntuning. As a tinyML solution at a few mW for the human activity recognition, we\ndesign a supervised ODL core that supports our automatic data pruning using a\n45nm CMOS process technology. We show that the required memory size for the\ncore is smaller than the same-shaped multilayer perceptron (MLP) and the power\nconsumption is only 3.39mW. Experiments using a human activity recognition\ndataset show that the proposed automatic data pruning reduces the communication\nvolume by 55.7% and power consumption accordingly with only 0.9% accuracy loss.",
    "arxiv_id": "http://arxiv.org/abs/2408.01283v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01283v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Certified Robust Invariant Polytope Training in Neural Controlled ODEs",
    "authors": "Akash Harapanahalli, Samuel Coogan",
    "abstract": "We consider a nonlinear control system modeled as an ordinary differential\nequation subject to disturbance, with a state feedback controller parameterized\nas a feedforward neural network. We propose a framework for training\ncontrollers with certified robust forward invariant polytopes, where any\ntrajectory initialized inside the polytope remains within the polytope,\nregardless of the disturbance. First, we parameterize a family of lifted\ncontrol systems in a higher dimensional space, where the original neural\ncontrolled system evolves on an invariant subspace of each lifted system. We\nuse interval analysis and neural network verifiers to further construct a\nfamily of lifted embedding systems, carefully capturing the knowledge of this\ninvariant subspace. If the vector field of any lifted embedding system\nsatisfies a sign constraint at a single point, then a certain convex polytope\nof the original system is robustly forward invariant. Treating the neural\nnetwork controller and the lifted system parameters as variables, we propose an\nalgorithm to train controllers with certified forward invariant polytopes in\nthe closed-loop control system. Through two examples, we demonstrate how the\nsimplicity of the sign constraint allows our approach to scale with system\ndimension to over $50$ states, and outperform state-of-the-art Lyapunov-based\nsampling approaches in runtime.",
    "arxiv_id": "http://arxiv.org/abs/2408.01273v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01273v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Detection and Characterization of Coordinated Online Behavior: A Survey",
    "authors": "Lorenzo Mannocci, Michele Mazza, Anna Monreale, Maurizio Tesconi, Stefano Cresci",
    "abstract": "Coordination is a fundamental aspect of life. The advent of social media has\nmade it integral also to online human interactions, such as those that\ncharacterize thriving online communities and social movements. At the same\ntime, coordination is also core to effective disinformation, manipulation, and\nhate campaigns. This survey collects, categorizes, and critically discusses the\nbody of work produced as a result of the growing interest on coordinated online\nbehavior. We reconcile industry and academic definitions, propose a\ncomprehensive framework to study coordinated online behavior, and review and\ncritically discuss the existing detection and characterization methods. Our\nanalysis identifies open challenges and promising directions of research,\nserving as a guide for scholars, practitioners, and policymakers in\nunderstanding and addressing the complexities inherent to online coordination.",
    "arxiv_id": "http://arxiv.org/abs/2408.01257v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01257v1",
    "primary_category": "cs.SI",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Deep progressive reinforcement learning-based flexible resource scheduling framework for IRS and UAV-assisted MEC system",
    "authors": "Li Dong, Feibo Jiang, Minjie Wang, Yubo Peng, Xiaolong Li",
    "abstract": "The intelligent reflection surface (IRS) and unmanned aerial vehicle\n(UAV)-assisted mobile edge computing (MEC) system is widely used in temporary\nand emergency scenarios. Our goal is to minimize the energy consumption of the\nMEC system by jointly optimizing UAV locations, IRS phase shift, task\noffloading, and resource allocation with a variable number of UAVs. To this\nend, we propose a Flexible REsource Scheduling (FRES) framework by employing a\nnovel deep progressive reinforcement learning which includes the following\ninnovations: Firstly, a novel multi-task agent is presented to deal with the\nmixed integer nonlinear programming (MINLP) problem. The multi-task agent has\ntwo output heads designed for different tasks, in which a classified head is\nemployed to make offloading decisions with integer variables while a fitting\nhead is applied to solve resource allocation with continuous variables.\nSecondly, a progressive scheduler is introduced to adapt the agent to the\nvarying number of UAVs by progressively adjusting a part of neurons in the\nagent. This structure can naturally accumulate experiences and be immune to\ncatastrophic forgetting. Finally, a light taboo search (LTS) is introduced to\nenhance the global search of the FRES. The numerical results demonstrate the\nsuperiority of the FRES framework which can make real-time and optimal resource\nscheduling even in dynamic MEC systems.",
    "arxiv_id": "http://arxiv.org/abs/2408.01248v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01248v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Automated Classification of Dry Bean Varieties Using XGBoost and SVM Models",
    "authors": "Ramtin Ardeshirifar",
    "abstract": "This paper presents a comparative study on the automated classification of\nseven different varieties of dry beans using machine learning models.\nLeveraging a dataset of 12,909 dry bean samples, reduced from an initial 13,611\nthrough outlier removal and feature extraction, we applied Principal Component\nAnalysis (PCA) for dimensionality reduction and trained two multiclass\nclassifiers: XGBoost and Support Vector Machine (SVM). The models were\nevaluated using nested cross-validation to ensure robust performance assessment\nand hyperparameter tuning. The XGBoost and SVM models achieved overall correct\nclassification rates of 94.00% and 94.39%, respectively. The results underscore\nthe efficacy of these machine learning approaches in agricultural applications,\nparticularly in enhancing the uniformity and efficiency of seed classification.\nThis study contributes to the growing body of work on precision agriculture,\ndemonstrating that automated systems can significantly support seed quality\ncontrol and crop yield optimization. Future work will explore incorporating\nmore diverse datasets and advanced algorithms to further improve classification\naccuracy.",
    "arxiv_id": "http://arxiv.org/abs/2408.01244v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01244v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Tailoring Graph Neural Network-based Flow-guided Localization to Individual Bloodstreams and Activities",
    "authors": "Pablo Galv\u00e1n, Filip Lemic, Gerard Calvo Bartra, Sergi Abadal, Xavier Costa P\u00e9rez",
    "abstract": "Flow-guided localization using in-body nanodevices in the bloodstream is\nexpected to be beneficial for early disease detection, continuous monitoring of\nbiological conditions, and targeted treatment. The nanodevices face size and\npower constraints that produce erroneous raw data for localization purposes.\nOn-body anchors receive this data, and use it to derive the locations of\ndiagnostic events of interest. Different Machine Learning (ML) approaches have\nbeen recently proposed for this task, yet they are currently restricted to a\nreference bloodstream of a resting patient. As such, they are unable to deal\nwith the physical diversity of patients' bloodstreams and cannot provide\ncontinuous monitoring due to changes in individual patient's activities. Toward\naddressing these issues for the current State-of-the-Art (SotA) flow-guided\nlocalization approach based on Graph Neural Networks (GNNs), we propose a\npipeline for GNN adaptation based on individual physiological indicators\nincluding height, weight, and heart rate. Our results indicate that the\nproposed adaptions are beneficial in reconciling the individual differences\nbetween bloodstreams and activities.",
    "arxiv_id": "http://arxiv.org/abs/2408.01239v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01239v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "HeteroMorpheus: Universal Control Based on Morphological Heterogeneity Modeling",
    "authors": "YiFan Hao, Yang Yang, Junru Song, Wei Peng, Weien Zhou, Tingsong Jiang, Wen Yao",
    "abstract": "In the field of robotic control, designing individual controllers for each\nrobot leads to high computational costs. Universal control policies, applicable\nacross diverse robot morphologies, promise to mitigate this challenge.\nPredominantly, models based on Graph Neural Networks (GNN) and Transformers are\nemployed, owing to their effectiveness in capturing relational dynamics across\na robot's limbs. However, these models typically employ homogeneous graph\nstructures that overlook the functional diversity of different limbs. To bridge\nthis gap, we introduce HeteroMorpheus, a novel method based on heterogeneous\ngraph Transformer. This method uniquely addresses limb heterogeneity, fostering\nbetter representation of robot dynamics of various morphologies. Through\nextensive experiments we demonstrate the superiority of HeteroMorpheus against\nstate-of-the-art methods in the capability of policy generalization, including\nzero-shot generalization and sample-efficient transfer to unfamiliar robot\nmorphologies.",
    "arxiv_id": "http://arxiv.org/abs/2408.01230v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01230v1",
    "primary_category": "cs.RO",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "ZNorm: Z-Score Gradient Normalization for Accelerating Neural Network Training",
    "authors": "Juyoung Yun, Hoyoung Kim, Suin Cho, Hangil Kang",
    "abstract": "The rapid advancements in deep learning necessitate efficient training\nmethods for deep neural networks (DNNs). As models grow in complexity,\nvanishing and exploding gradients impede convergence and performance. We\npropose Z-Score Normalization for Gradient Descent (ZNorm), an innovative\ntechnique that adjusts only the gradients to enhance training efficiency and\nimprove model performance. ZNorm normalizes the overall gradients, providing\nconsistent gradient scaling across layers, thereby reducing the risks of\nvanishing and exploding gradients. Our extensive experiments on CIFAR-10 and\nmedical datasets demonstrate that ZNorm not only accelerates convergence but\nalso enhances performance metrics. ZNorm consistently outperforms existing\nmethods, achieving superior results using the same computational settings. In\nmedical imaging applications, ZNorm improves tumor prediction and segmentation\nperformances, underscoring its practical utility. These findings highlight\nZNorm's potential as a robust and versatile tool for improving the efficiency\nand effectiveness of deep neural network training across a wide range of\narchitectures and applications.",
    "arxiv_id": "http://arxiv.org/abs/2408.01215v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01215v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Certifiably Robust Encoding Schemes",
    "authors": "Aman Saxena, Tom Wollschl\u00e4ger, Nicola Franco, Jeanette Miriam Lorenz, Stephan G\u00fcnnemann",
    "abstract": "Quantum machine learning uses principles from quantum mechanics to process\ndata, offering potential advances in speed and performance. However, previous\nwork has shown that these models are susceptible to attacks that manipulate\ninput data or exploit noise in quantum circuits. Following this, various\nstudies have explored the robustness of these models. These works focus on the\nrobustness certification of manipulations of the quantum states. We extend this\nline of research by investigating the robustness against perturbations in the\nclassical data for a general class of data encoding schemes. We show that for\nsuch schemes, the addition of suitable noise channels is equivalent to\nevaluating the mean value of the noiseless classifier at the smoothed data,\nakin to Randomized Smoothing from classical machine learning. Using our general\nframework, we show that suitable additions of phase-damping noise channels\nimprove empirical and provable robustness for the considered class of encoding\nschemes.",
    "arxiv_id": "http://arxiv.org/abs/2408.01200v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01200v1",
    "primary_category": "quant-ph",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Optimizing Variational Quantum Circuits Using Metaheuristic Strategies in Reinforcement Learning",
    "authors": "Michael K\u00f6lle, Daniel Seidl, Maximilian Zorn, Philipp Altmann, Jonas Stein, Thomas Gabor",
    "abstract": "Quantum Reinforcement Learning (QRL) offers potential advantages over\nclassical Reinforcement Learning, such as compact state space representation\nand faster convergence in certain scenarios. However, practical benefits\nrequire further validation. QRL faces challenges like flat solution landscapes,\nwhere traditional gradient-based methods are inefficient, necessitating the use\nof gradient-free algorithms. This work explores the integration of\nmetaheuristic algorithms -- Particle Swarm Optimization, Ant Colony\nOptimization, Tabu Search, Genetic Algorithm, Simulated Annealing, and Harmony\nSearch -- into QRL. These algorithms provide flexibility and efficiency in\nparameter optimization. Evaluations in $5\\times5$ MiniGrid Reinforcement\nLearning environments show that, all algorithms yield near-optimal results,\nwith Simulated Annealing and Particle Swarm Optimization performing best. In\nthe Cart Pole environment, Simulated Annealing, Genetic Algorithms, and\nParticle Swarm Optimization achieve optimal results, while the others perform\nslightly better than random action selection. These findings demonstrate the\npotential of Particle Swarm Optimization and Simulated Annealing for efficient\nQRL learning, emphasizing the need for careful algorithm selection and\nadaptation.",
    "arxiv_id": "http://arxiv.org/abs/2408.01187v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01187v1",
    "primary_category": "quant-ph",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Nested Music Transformer: Sequentially Decoding Compound Tokens in Symbolic Music and Audio Generation",
    "authors": "Jiwoo Ryu, Hao-Wen Dong, Jongmin Jung, Dasaem Jeong",
    "abstract": "Representing symbolic music with compound tokens, where each token consists\nof several different sub-tokens representing a distinct musical feature or\nattribute, offers the advantage of reducing sequence length. While previous\nresearch has validated the efficacy of compound tokens in music sequence\nmodeling, predicting all sub-tokens simultaneously can lead to suboptimal\nresults as it may not fully capture the interdependencies between them. We\nintroduce the Nested Music Transformer (NMT), an architecture tailored for\ndecoding compound tokens autoregressively, similar to processing flattened\ntokens, but with low memory usage. The NMT consists of two transformers: the\nmain decoder that models a sequence of compound tokens and the sub-decoder for\nmodeling sub-tokens of each compound token. The experiment results showed that\napplying the NMT to compound tokens can enhance the performance in terms of\nbetter perplexity in processing various symbolic music datasets and discrete\naudio tokens from the MAESTRO dataset.",
    "arxiv_id": "http://arxiv.org/abs/2408.01180v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01180v1",
    "primary_category": "cs.SD",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Sustainable Diffusion-based Incentive Mechanism for Generative AI-driven Digital Twins in Industrial Cyber-Physical Systems",
    "authors": "Jinbo Wen, Jiawen Kang, Dusit Niyato, Yang Zhang, Shiwen Mao",
    "abstract": "Industrial Cyber-Physical Systems (ICPSs) are an integral component of modern\nmanufacturing and industries. By digitizing data throughout the product life\ncycle, Digital Twins (DTs) in ICPSs enable a shift from current industrial\ninfrastructures to intelligent and adaptive infrastructures. Thanks to data\nprocess capability, Generative Artificial Intelligence (GAI) can drive the\nconstruction and update of DTs to improve predictive accuracy and prepare for\ndiverse smart manufacturing. However, mechanisms that leverage sensing\nIndustrial Internet of Things (IIoT) devices to share data for the construction\nof DTs are susceptible to adverse selection problems. In this paper, we first\ndevelop a GAI-driven DT architecture for ICPSs. To address the adverse\nselection problem caused by information asymmetry, we propose a contract theory\nmodel and develop the sustainable diffusion-based soft actor-critic algorithm\nto identify the optimal feasible contract. Specifically, we leverage the\ndynamic structured pruning technique to reduce parameter numbers of actor\nnetworks, allowing sustainability and efficient implementation of the proposed\nalgorithm. Finally, numerical results demonstrate the effectiveness of the\nproposed scheme.",
    "arxiv_id": "http://arxiv.org/abs/2408.01173v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01173v1",
    "primary_category": "cs.NI",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Domain Adaptation-Enhanced Searchlight: Enabling brain decoding from visual perception to mental imagery",
    "authors": "Alexander Olza, David Soto, Roberto Santana",
    "abstract": "In cognitive neuroscience and brain-computer interface research, accurately\npredicting imagined stimuli is crucial. This study investigates the\neffectiveness of Domain Adaptation (DA) in enhancing imagery prediction using\nprimarily visual data from fMRI scans of 18 subjects. Initially, we train a\nbaseline model on visual stimuli to predict imagined stimuli, utilizing data\nfrom 14 brain regions. We then develop several models to improve imagery\nprediction, comparing different DA methods. Our results demonstrate that DA\nsignificantly enhances imagery prediction, especially with the Regular Transfer\napproach. We then conduct a DA-enhanced searchlight analysis using Regular\nTransfer, followed by permutation-based statistical tests to identify brain\nregions where imagery decoding is consistently above chance across subjects.\nOur DA-enhanced searchlight predicts imagery contents in a highly distributed\nset of brain regions, including the visual cortex and the frontoparietal\ncortex, thereby outperforming standard cross-domain classification methods. The\ncomplete code and data for this paper have been made openly available for the\nuse of the scientific community.",
    "arxiv_id": "http://arxiv.org/abs/2408.01163v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01163v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "TCR-GPT: Integrating Autoregressive Model and Reinforcement Learning for T-Cell Receptor Repertoires Generation",
    "authors": "Yicheng Lin, Dandan Zhang, Yun Liu",
    "abstract": "T-cell receptors (TCRs) play a crucial role in the immune system by\nrecognizing and binding to specific antigens presented by infected or cancerous\ncells. Understanding the sequence patterns of TCRs is essential for developing\ntargeted immune therapies and designing effective vaccines. Language models,\nsuch as auto-regressive transformers, offer a powerful solution to this problem\nby learning the probability distributions of TCR repertoires, enabling the\ngeneration of new TCR sequences that inherit the underlying patterns of the\nrepertoire. We introduce TCR-GPT, a probabilistic model built on a decoder-only\ntransformer architecture, designed to uncover and replicate sequence patterns\nin TCR repertoires. TCR-GPT demonstrates an accuracy of 0.953 in inferring\nsequence probability distributions measured by Pearson correlation coefficient.\nFurthermore, by leveraging Reinforcement Learning(RL), we adapted the\ndistribution of TCR sequences to generate TCRs capable of recognizing specific\npeptides, offering significant potential for advancing targeted immune\ntherapies and vaccine development. With the efficacy of RL, fine-tuned\npretrained TCR-GPT models demonstrated the ability to produce TCR repertoires\nlikely to bind specific peptides, illustrating RL's efficiency in enhancing the\nmodel's adaptability to the probability distributions of biologically relevant\nTCR sequences.",
    "arxiv_id": "http://arxiv.org/abs/2408.01156v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01156v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Enhanced Prediction of Ventilator-Associated Pneumonia in Patients with Traumatic Brain Injury Using Advanced Machine Learning Techniques",
    "authors": "Negin Ashrafi, Armin Abdollahi, Maryam Pishgar",
    "abstract": "Background: Ventilator-associated pneumonia (VAP) in traumatic brain injury\n(TBI) patients poses a significant mortality risk and imposes a considerable\nfinancial burden on patients and healthcare systems. Timely detection and\nprognostication of VAP in TBI patients are crucial to improve patient outcomes\nand alleviate the strain on healthcare resources.\n  Methods: We implemented six machine learning models using the MIMIC-III\ndatabase. Our methodology included preprocessing steps, such as feature\nselection with CatBoost and expert opinion, addressing class imbalance with the\nSynthetic Minority Oversampling Technique (SMOTE), and rigorous model tuning\nthrough 5-fold cross-validation to optimize hyperparameters. Key models\nevaluated included SVM, Logistic Regression, Random Forest, XGBoost, ANN, and\nAdaBoost. Additionally, we conducted SHAP analysis to determine feature\nimportance and performed an ablation study to assess feature impacts on model\nperformance.\n  Results: XGBoost outperformed the baseline models and the best existing\nliterature. We used metrics, including AUC, Accuracy, Specificity, Sensitivity,\nF1 Score, PPV, and NPV. XGBoost demonstrated the highest performance with an\nAUC of 0.940 and an Accuracy of 0.875, which are 23.4% and 23.5% higher than\nthe best results in the existing literature, with an AUC of 0.706 and an\nAccuracy of 0.640, respectively. This enhanced performance underscores the\nmodels' effectiveness in clinical settings.\n  Conclusions: This study enhances the predictive modeling of VAP in TBI\npatients, improving early detection and intervention potential. Refined feature\nselection and advanced ensemble techniques significantly boosted model accuracy\nand reliability, offering promising directions for future clinical applications\nand medical diagnostics research.",
    "arxiv_id": "http://arxiv.org/abs/2408.01144v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01144v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Machine learning topological energy braiding of non-Bloch bands",
    "authors": "Shuwei Shi, Shibing Chu, Yuee Xie, Yuanping Chen",
    "abstract": "Machine learning has been used to identify phase transitions in a variety of\nphysical systems. However, there is still a lack of relevant research on\nnon-Bloch energy braiding in non-Hermitian systems. In this work, we study\nnon-Bloch energy braiding in one-dimensional non-Hermitian systems using\nunsupervised and supervised methods. In unsupervised learning, we use diffusion\nmaps to successfully identify non-Bloch energy braiding without any prior\nknowledge and combine it with k-means to cluster different topological elements\ninto clusters, such as Unlink and Hopf link. In supervised learning, we train a\nConvolutional Neural Network (CNN) based on Bloch energy data to predict not\nonly Bloch energy braiding but also non-Bloch energy braiding with an accuracy\napproaching 100%. By analysing the CNN, we can ascertain that the network has\nsuccessfully acquired the ability to recognise the braiding topology of the\nenergy bands. The present study demonstrates the considerable potential of\nmachine learning in the identification of non-Hermitian topological phases and\nenergy braiding.",
    "arxiv_id": "http://arxiv.org/abs/2408.01141v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01141v1",
    "primary_category": "cond-mat.mes-hall",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "A Survey of Mamba",
    "authors": "Haohao Qu, Liangbo Ning, Rui An, Wenqi Fan, Tyler Derr, Xin Xu, Qing Li",
    "abstract": "Deep learning, as a vital technique, has sparked a notable revolution in\nartificial intelligence. As the most representative architecture, Transformers\nhave empowered numerous advanced models, especially the large language models\nthat comprise billions of parameters, becoming a cornerstone in deep learning.\nDespite the impressive achievements, Transformers still face inherent\nlimitations, particularly the time-consuming inference resulting from the\nquadratic computation complexity of attention calculation. Recently, a novel\narchitecture named Mamba, drawing inspiration from classical state space\nmodels, has emerged as a promising alternative for building foundation models,\ndelivering comparable modeling abilities to Transformers while preserving\nnear-linear scalability concerning sequence length. This has sparked an\nincreasing number of studies actively exploring Mamba's potential to achieve\nimpressive performance across diverse domains. Given such rapid evolution,\nthere is a critical need for a systematic review that consolidates existing\nMamba-empowered models, offering a comprehensive understanding of this emerging\nmodel architecture. In this survey, we therefore conduct an in-depth\ninvestigation of recent Mamba-associated studies, covering from three main\naspects: the advancements of Mamba-based models, the techniques of adapting\nMamba to diverse data, and the applications where Mamba can excel.\nSpecifically, we first recall the foundational knowledge of various\nrepresentative deep learning models and the details of Mamba as preliminaries.\nThen, to showcase the significance of Mamba, we comprehensively review the\nrelated studies focusing on Mamba models' architecture design, data\nadaptability, and applications. Finally, we present an discussion of current\nlimitations and explore various promising research directions to provide deeper\ninsights for future investigations.",
    "arxiv_id": "http://arxiv.org/abs/2408.01129v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01129v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "An Encoding--Searching Separation Perspective on Bi-Encoder Neural Search",
    "authors": "Hung-Nghiep Tran, Akiko Aizawa, Atsuhiro Takasu",
    "abstract": "This paper reviews, analyzes, and proposes a new perspective on the\nbi-encoder architecture for neural search. While the bi-encoder architecture is\nwidely used due to its simplicity and scalability at test time, it has some\nnotable issues such as low performance on seen datasets and weak zero-shot\nperformance on new datasets. In this paper, we analyze these issues and\nsummarize two main critiques: the encoding information bottleneck problem and\nlimitations of the basic assumption of embedding search. We then construct a\nthought experiment to logically analyze the encoding and searching operations\nand challenge the basic assumption of embedding search. Building on these\nobservations, we propose a new perspective on the bi-encoder architecture\ncalled the \\textit{encoding--searching separation} perspective, which\nconceptually and practically separates the encoding and searching operations.\nThis new perspective is applied to explain the root cause of the identified\nissues and discuss ways to mitigate the problems. Finally, we discuss the\nimplications of the ideas underlying the new perspective, the design surface\nthat it exposes and the potential research directions arising from it.",
    "arxiv_id": "http://arxiv.org/abs/2408.01094v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01094v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Universality of kernel random matrices and kernel regression in the quadratic regime",
    "authors": "Parthe Pandit, Zhichao Wang, Yizhe Zhu",
    "abstract": "Kernel ridge regression (KRR) is a popular class of machine learning models\nthat has become an important tool for understanding deep learning. Much of the\nfocus has been on studying the proportional asymptotic regime, $n \\asymp d$,\nwhere $n$ is the number of training samples and $d$ is the dimension of the\ndataset. In this regime, under certain conditions on the data distribution, the\nkernel random matrix involved in KRR exhibits behavior akin to that of a linear\nkernel. In this work, we extend the study of kernel regression to the quadratic\nasymptotic regime, where $n \\asymp d^2$. In this regime, we demonstrate that a\nbroad class of inner-product kernels exhibit behavior similar to a quadratic\nkernel. Specifically, we establish an operator norm approximation bound for the\ndifference between the original kernel random matrix and a quadratic kernel\nrandom matrix with additional correction terms compared to the Taylor expansion\nof the kernel functions. The approximation works for general data distributions\nunder a Gaussian-moment-matching assumption with a covariance structure. This\nnew approximation is utilized to obtain a limiting spectral distribution of the\noriginal kernel matrix and characterize the precise asymptotic training and\ngeneralization errors for KRR in the quadratic regime when $n/d^2$ converges to\na non-zero constant. The generalization errors are obtained for both\ndeterministic and random teacher models. Our proof techniques combine moment\nmethods, Wick's formula, orthogonal polynomials, and resolvent analysis of\nrandom matrices with correlated entries.",
    "arxiv_id": "http://arxiv.org/abs/2408.01062v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01062v1",
    "primary_category": "stat.ML",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "The Impact of Hyperparameters on Large Language Model Inference Performance: An Evaluation of vLLM and HuggingFace Pipelines",
    "authors": "Matias Martinez",
    "abstract": "The recent surge of open-source large language models (LLMs) enables\ndevelopers to create AI-based solutions while maintaining control over aspects\nsuch as privacy and compliance, thereby providing governance and ownership of\nthe model deployment process. To utilize these LLMs, inference engines are\nneeded. These engines load the model's weights onto available resources, such\nas GPUs, and process queries to generate responses. The speed of inference, or\nperformance, of the LLM, is critical for real-time applications, as it computes\nmillions or billions of floating point operations per inference. Recently,\nadvanced inference engines such as vLLM have emerged, incorporating novel\nmechanisms such as efficient memory management to achieve state-of-the-art\nperformance. In this paper, we analyze the performance, particularly the\nthroughput (tokens generated per unit of time), of 20 LLMs using two inference\nlibraries: vLLM and HuggingFace's pipelines. We investigate how various\nhyperparameters, which developers must configure, influence inference\nperformance. Our results reveal that throughput landscapes are irregular, with\ndistinct peaks, highlighting the importance of hyperparameter optimization to\nachieve maximum performance. We also show that applying hyperparameter\noptimization when upgrading or downgrading the GPU model used for inference can\nimprove throughput from HuggingFace pipelines by an average of 9.16% and 13.7%,\nrespectively.",
    "arxiv_id": "http://arxiv.org/abs/2408.01050v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01050v1",
    "primary_category": "cs.SE",
    "votes": 0,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Privacy-Preserving Split Learning with Vision Transformers using Patch-Wise Random and Noisy CutMix",
    "authors": "Seungeun Oh, Sihun Baek, Jihong Park, Hyelin Nam, Praneeth Vepakomma, Ramesh Raskar, Mehdi Bennis, Seong-Lyun Kim",
    "abstract": "In computer vision, the vision transformer (ViT) has increasingly superseded\nthe convolutional neural network (CNN) for improved accuracy and robustness.\nHowever, ViT's large model sizes and high sample complexity make it difficult\nto train on resource-constrained edge devices. Split learning (SL) emerges as a\nviable solution, leveraging server-side resources to train ViTs while utilizing\nprivate data from distributed devices. However, SL requires additional\ninformation exchange for weight updates between the device and the server,\nwhich can be exposed to various attacks on private training data. To mitigate\nthe risk of data breaches in classification tasks, inspired from the CutMix\nregularization, we propose a novel privacy-preserving SL framework that injects\nGaussian noise into smashed data and mixes randomly chosen patches of smashed\ndata across clients, coined DP-CutMixSL. Our analysis demonstrates that\nDP-CutMixSL is a differentially private (DP) mechanism that strengthens privacy\nprotection against membership inference attacks during forward propagation.\nThrough simulations, we show that DP-CutMixSL improves privacy protection\nagainst membership inference attacks, reconstruction attacks, and label\ninference attacks, while also improving accuracy compared to DP-SL and\nDP-MixSL.",
    "arxiv_id": "http://arxiv.org/abs/2408.01040v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01040v1",
    "primary_category": "cs.DC",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Distilling interpretable causal trees from causal forests",
    "authors": "Patrick Rehill",
    "abstract": "Machine learning methods for estimating treatment effect heterogeneity\npromise greater flexibility than existing methods that test a few pre-specified\nhypotheses. However, one problem these methods can have is that it can be\nchallenging to extract insights from complicated machine learning models. A\nhigh-dimensional distribution of conditional average treatment effects may give\naccurate, individual-level estimates, but it can be hard to understand the\nunderlying patterns; hard to know what the implications of the analysis are.\nThis paper proposes the Distilled Causal Tree, a method for distilling a\nsingle, interpretable causal tree from a causal forest. This compares well to\nexisting methods of extracting a single tree, particularly in noisy data or\nhigh-dimensional data where there are many correlated features. Here it even\noutperforms the base causal forest in most simulations. Its estimates are\ndoubly robust and asymptotically normal just as those of the causal forest are.",
    "arxiv_id": "http://arxiv.org/abs/2408.01023v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01023v1",
    "primary_category": "econ.EM",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "A Family of Distributions of Random Subsets for Controlling Positive and Negative Dependence",
    "authors": "Takahiro Kawashima, Hideitsu Hino",
    "abstract": "Positive and negative dependence are fundamental concepts that characterize\nthe attractive and repulsive behavior of random subsets. Although some\nprobabilistic models are known to exhibit positive or negative dependence, it\nis challenging to seamlessly bridge them with a practicable probabilistic\nmodel. In this study, we introduce a new family of distributions, named the\ndiscrete kernel point process (DKPP), which includes determinantal point\nprocesses and parts of Boltzmann machines. We also develop some computational\nmethods for probabilistic operations and inference with DKPPs, such as\ncalculating marginal and conditional probabilities and learning the parameters.\nOur numerical experiments demonstrate the controllability of positive and\nnegative dependence and the effectiveness of the computational methods for\nDKPPs.",
    "arxiv_id": "http://arxiv.org/abs/2408.01022v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01022v1",
    "primary_category": "stat.ML",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "GNN-MolKAN: Harnessing the Power of KAN to Advance Molecular Representation Learning with GNNs",
    "authors": "Ruifeng Li",
    "abstract": "Effective molecular representation learning is crucial for molecular property\nprediction and drug design. However, existing approaches struggle with\nlimitations in insufficient annotations and suboptimal architecture design. For\ninstance, Graph Neural Networks (GNNs) suffer from over-squashing, causing the\nloss of important structural details in molecules, thus impairing molecular\nrepresentations. In this work, we propose a new class of GNNs, GNN-MolKAN and\nits augmented variant, GNN-MolKAN+, that integrate the Kolmogorov-Arnold\nNetworks (KAN) architecture from AI + Science into GNNs to address these\nchallenges. Additionally, we introduce Adaptive FastKAN (AdFastKAN), an\nadvanced KAN that offers increased stability and speed, further enhancing the\nperformance of standard GNNs. Notably, our approach holds three key benefits:\n1) Superior Performance: GNN-MolKAN and GNN-MolKAN+ demonstrate superior\nprediction ability, robust generalization to unseen scaffolds, and versatile\ntransferability across different GNN architectures. 2) Efficiency: These models\nrequire less computational time and fewer parameters while matching or\nsurpassing the state-of-the-art (SOTA) self-supervised methods. 3) Few-shot\nLearning Ability: GNN-MolKAN demonstrates great potential in few-shot learning\nscenarios, achieving an average improvement of 6.97% across few-shot\nbenchmarks. Overall, we validate our architecture on 6 classification datasets,\n6 regression datasets, and 4 few-shot learning datasets, consistently achieving\nhighly competitive results across all of them.",
    "arxiv_id": "http://arxiv.org/abs/2408.01018v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01018v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "IBB Traffic Graph Data: Benchmarking and Road Traffic Prediction Model",
    "authors": "Eren Olug, Kiymet Kaya, Resul Tugay, Sule Gunduz Oguducu",
    "abstract": "Road traffic congestion prediction is a crucial component of intelligent\ntransportation systems, since it enables proactive traffic management, enhances\nsuburban experience, reduces environmental impact, and improves overall safety\nand efficiency. Although there are several public datasets, especially for\nmetropolitan areas, these datasets may not be applicable to practical scenarios\ndue to insufficiency in the scale of data (i.e. number of sensors and road\nlinks) and several external factors like different characteristics of the\ntarget area such as urban, highways and the data collection location. To\naddress this, this paper introduces a novel IBB Traffic graph dataset as an\nalternative benchmark dataset to mitigate these limitations and enrich the\nliterature with new geographical characteristics. IBB Traffic graph dataset\ncovers the sensor data collected at 2451 distinct locations. Moreover, we\npropose a novel Road Traffic Prediction Model that strengthens temporal links\nthrough feature engineering, node embedding with GLEE to represent\ninter-related relationships within the traffic network, and traffic prediction\nwith ExtraTrees. The results indicate that the proposed model consistently\noutperforms the baseline models, demonstrating an average accuracy improvement\nof 4%.",
    "arxiv_id": "http://arxiv.org/abs/2408.01016v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01016v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Tensor Train Low-rank Approximation (TT-LoRA): Democratizing AI with Accelerated LLMs",
    "authors": "Afia Anjum, Maksim E. Eren, Ismael Boureima, Boian Alexandrov, Manish Bhattarai",
    "abstract": "In recent years, Large Language Models (LLMs) have demonstrated remarkable\ncapabilities across a wide range of natural language processing (NLP) tasks,\nsuch as question-answering, sentiment analysis, text summarization, and machine\ntranslation. However, the ever-growing complexity of LLMs demands immense\ncomputational resources, hindering the broader research and application of\nthese models. To address this, various parameter-efficient fine-tuning\nstrategies, such as Low-Rank Approximation (LoRA) and Adapters, have been\ndeveloped. Despite their potential, these methods often face limitations in\ncompressibility. Specifically, LoRA struggles to scale effectively with the\nincreasing number of trainable parameters in modern large scale LLMs.\nAdditionally, Low-Rank Economic Tensor-Train Adaptation (LoRETTA), which\nutilizes tensor train decomposition, has not yet achieved the level of\ncompression necessary for fine-tuning very large scale models with limited\nresources. This paper introduces Tensor Train Low-Rank Approximation (TT-LoRA),\na novel parameter-efficient fine-tuning (PEFT) approach that extends LoRETTA\nwith optimized tensor train (TT) decomposition integration. By eliminating\nAdapters and traditional LoRA-based structures, TT-LoRA achieves greater model\ncompression without compromising downstream task performance, along with\nreduced inference latency and computational overhead. We conduct an exhaustive\nparameter search to establish benchmarks that highlight the trade-off between\nmodel compression and performance. Our results demonstrate significant\ncompression of LLMs while maintaining comparable performance to larger models,\nfacilitating their deployment on resource-constraint platforms.",
    "arxiv_id": "http://arxiv.org/abs/2408.01008v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01008v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Enhancing Financial Market Predictions: Causality-Driven Feature Selection",
    "authors": "Wenhao Liang, Zhengyang Li, Weitong Chen",
    "abstract": "This paper introduces the FinSen dataset that revolutionizes financial market\nanalysis by integrating economic and financial news articles from 197 countries\nwith stock market data. The dataset's extensive coverage spans 15 years from\n2007 to 2023 with temporal information, offering a rich, global perspective\nwith 160,000 records on financial market news. Our study leverages causally\nvalidated sentiment scores and LSTM models to enhance market forecast accuracy\nand reliability. Utilizing the FinSen dataset, we introduce an innovative Focal\nCalibration Loss, reducing Expected Calibration Error (ECE) to 3.34 percent\nwith the DAN 3 model. This not only improves prediction accuracy but also\naligns probabilistic forecasts closely with real outcomes, crucial for the\nfinancial sector where predicted probability is paramount. Our approach\ndemonstrates the effectiveness of combining sentiment analysis with precise\ncalibration techniques for trustworthy financial forecasting where the cost of\nmisinterpretation can be high. Finsen Data can be found at [this github\nURL](https://github.com/EagleAdelaide/FinSen_Dataset.git).",
    "arxiv_id": "http://arxiv.org/abs/2408.01005v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01005v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Adaptive Two-Stage Cloud Resource Scaling via Hierarchical Multi-Indicator Forecasting and Bayesian Decision-Making",
    "authors": "Yang Luo, Shiyu Wang, Zhemeng Yu, Wei Lu, Xiaofeng Gao, Lintao Ma, Guihai Chen",
    "abstract": "The surging demand for cloud computing resources, driven by the rapid growth\nof sophisticated large-scale models and data centers, underscores the critical\nimportance of efficient and adaptive resource allocation. As major tech\nenterprises deploy massive infrastructures with thousands of GPUs, existing\ncloud platforms still struggle with low resource utilization due to key\nchallenges: capturing hierarchical indicator structures, modeling non-Gaussian\ndistributions, and decision-making under uncertainty. To address these\nchallenges, we propose HRAMONY, an adaptive Hierarchical Attention-based\nResource Modeling and Decision-Making System. HARMONY combines hierarchical\nmulti-indicator distribution forecasting and uncertainty-aware Bayesian\ndecision-making. It introduces a novel hierarchical attention mechanism that\ncomprehensively models complex inter-indicator dependencies, enabling accurate\npredictions that can adapt to evolving environment states. By transforming\nGaussian projections into adaptive non-Gaussian distributions via Normalizing\nFlows. Crucially, HARMONY leverages the full predictive distributions in an\nadaptive Bayesian process, proactively incorporating uncertainties to optimize\nresource allocation while robustly meeting SLA constraints under varying\nconditions. Extensive evaluations across four large-scale cloud datasets\ndemonstrate HARMONY's state-of-the-art performance, significantly outperforming\nnine established methods. A month-long real-world deployment validated\nHARMONY's substantial practical impact, realizing over 35,000 GPU hours in\nsavings and translating to $100K+ in cost reduction, showcasing its remarkable\neconomic value through adaptive, uncertainty-aware scaling. Our code is\navailable at https://github.com/Floating-LY/HARMONY1.",
    "arxiv_id": "http://arxiv.org/abs/2408.01000v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01000v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "IncidentNet: Traffic Incident Detection, Localization and Severity Estimation with Sparse Sensing",
    "authors": "Sai Shashank Peddiraju, Kaustubh Harapanahalli, Edward Andert, Aviral Shrivastava",
    "abstract": "Prior art in traffic incident detection relies on high sensor coverage and is\nprimarily based on decision-tree and random forest models that have limited\nrepresentation capacity and, as a result, cannot detect incidents with high\naccuracy. This paper presents IncidentNet - a novel approach for classifying,\nlocalizing, and estimating the severity of traffic incidents using deep\nlearning models trained on data captured from sparsely placed sensors in urban\nenvironments. Our model works on microscopic traffic data that can be collected\nusing cameras installed at traffic intersections. Due to the unavailability of\ndatasets that provide microscopic traffic details and traffic incident details\nsimultaneously, we also present a methodology to generate a synthetic\nmicroscopic traffic dataset that matches given macroscopic traffic data.\nIncidentNet achieves a traffic incident detection rate of 98%, with false alarm\nrates of less than 7% in 197 seconds on average in urban environments with\ncameras on less than 20% of the traffic intersections.",
    "arxiv_id": "http://arxiv.org/abs/2408.00996v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00996v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Fairness in Large Language Models in Three Hour",
    "authors": "Thang Doan Viet, Zichong Wang, Minh Nhat Nguyen, Wenbin Zhang",
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable success across\nvarious domains but often lack fairness considerations, potentially leading to\ndiscriminatory outcomes against marginalized populations. Unlike fairness in\ntraditional machine learning, fairness in LLMs involves unique backgrounds,\ntaxonomies, and fulfillment techniques. This tutorial provides a systematic\noverview of recent advances in the literature concerning fair LLMs, beginning\nwith real-world case studies to introduce LLMs, followed by an analysis of bias\ncauses therein. The concept of fairness in LLMs is then explored, summarizing\nthe strategies for evaluating bias and the algorithms designed to promote\nfairness. Additionally, resources for assessing bias in LLMs, including\ntoolkits and datasets, are compiled, and current research challenges and open\nquestions in the field are discussed. The repository is available at\n\\url{https://github.com/LavinWong/Fairness-in-Large-Language-Models}.",
    "arxiv_id": "http://arxiv.org/abs/2408.00992v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00992v1",
    "primary_category": "cs.CL",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Reconstructing Richtmyer-Meshkov instabilities from noisy radiographs using low dimensional features and attention-based neural networks",
    "authors": "Daniel A. Serino, Marc L. Klasky, Balasubramanya T. Nadiga, Xiaojian Xu, Trevor Wilcox",
    "abstract": "A trained attention-based transformer network can robustly recover the\ncomplex topologies given by the Richtmyer-Meshkoff instability from a sequence\nof hydrodynamic features derived from radiographic images corrupted with blur,\nscatter, and noise. This approach is demonstrated on ICF-like double shell\nhydrodynamic simulations. The key component of this network is a transformer\nencoder that acts on a sequence of features extracted from noisy radiographs.\nThis encoder includes numerous self-attention layers that act to learn temporal\ndependencies in the input sequences and increase the expressiveness of the\nmodel. This approach is demonstrated to exhibit an excellent ability to\naccurately recover the Richtmyer-Meshkov instability growth rates, even despite\nthe gas-metal interface being greatly obscured by radiographic noise.",
    "arxiv_id": "http://arxiv.org/abs/2408.00985v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00985v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "META-ANOVA: Screening interactions for interpretable machine learning",
    "authors": "Yongchan Choi, Seokhun Park, Chanmoo Park, Dongha Kim, Yongdai Kim",
    "abstract": "There are two things to be considered when we evaluate predictive models. One\nis prediction accuracy,and the other is interpretability. Over the recent\ndecades, many prediction models of high performance, such as ensemble-based\nmodels and deep neural networks, have been developed. However, these models are\noften too complex, making it difficult to intuitively interpret their\npredictions. This complexity in interpretation limits their use in many\nreal-world fields that require accountability, such as medicine, finance, and\ncollege admissions. In this study, we develop a novel method called Meta-ANOVA\nto provide an interpretable model for any given prediction model. The basic\nidea of Meta-ANOVA is to transform a given black-box prediction model to the\nfunctional ANOVA model. A novel technical contribution of Meta-ANOVA is a\nprocedure of screening out unnecessary interaction before transforming a given\nblack-box model to the functional ANOVA model. This screening procedure allows\nthe inclusion of higher order interactions in the transformed functional ANOVA\nmodel without computational difficulties. We prove that the screening procedure\nis asymptotically consistent. Through various experiments with synthetic and\nreal-world datasets, we empirically demonstrate the superiority of Meta-ANOVA",
    "arxiv_id": "http://arxiv.org/abs/2408.00973v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00973v1",
    "primary_category": "stat.ML",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "MIS-ME: A Multi-modal Framework for Soil Moisture Estimation",
    "authors": "Mohammed Rakib, Adil Aman Mohammed, Cole Diggins, Sumit Sharma, Jeff Michael Sadler, Tyson Ochsner, Arun Bagavathi",
    "abstract": "Soil moisture estimation is an important task to enable precision agriculture\nin creating optimal plans for irrigation, fertilization, and harvest. It is\ncommon to utilize statistical and machine learning models to estimate soil\nmoisture from traditional data sources such as weather forecasts, soil\nproperties, and crop properties. However, there is a growing interest in\nutilizing aerial and geospatial imagery to estimate soil moisture. Although\nthese images capture high-resolution crop details, they are expensive to curate\nand challenging to interpret. Imagine, an AI-enhanced software tool that\npredicts soil moisture using visual cues captured by smartphones and\nstatistical data given by weather forecasts. This work is a first step towards\nthat goal of developing a multi-modal approach for soil moisture estimation. In\nparticular, we curate a dataset consisting of real-world images taken from\nground stations and their corresponding weather data. We also propose MIS-ME -\nMeteorological & Image based Soil Moisture Estimator, a multi-modal framework\nfor soil moisture estimation. Our extensive analysis shows that MIS-ME achieves\na MAPE of 10.79%, outperforming traditional unimodal approaches with a\nreduction of 2.6% in MAPE for meteorological data and 1.5% in MAPE for image\ndata, highlighting the effectiveness of tailored multi-modal approaches.",
    "arxiv_id": "http://arxiv.org/abs/2408.00963v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00963v1",
    "primary_category": "cs.CV",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Aggregation Models with Optimal Weights for Distributed Gaussian Processes",
    "authors": "Haoyuan Chen, Rui Tuo",
    "abstract": "Gaussian process (GP) models have received increasingly attentions in recent\nyears due to their superb prediction accuracy and modeling flexibility. To\naddress the computational burdens of GP models for large-scale datasets,\ndistributed learning for GPs are often adopted. Current aggregation models for\ndistributed GPs are not time-efficient when incorporating correlations between\nGP experts. In this work, we propose a novel approach for aggregated prediction\nin distributed GPs. The technique is suitable for both the exact and sparse\nvariational GPs. The proposed method incorporates correlations among experts,\nleading to better prediction accuracy with manageable computational\nrequirements. As demonstrated by empirical studies, the proposed approach\nresults in more stable predictions in less time than state-of-the-art\nconsistent aggregation models.",
    "arxiv_id": "http://arxiv.org/abs/2408.00955v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00955v1",
    "primary_category": "stat.ML",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Equivariant neural networks and piecewise linear representation theory",
    "authors": "Joel Gibson, Daniel Tubbenhauer, Geordie Williamson",
    "abstract": "Equivariant neural networks are neural networks with symmetry. Motivated by\nthe theory of group representations, we decompose the layers of an equivariant\nneural network into simple representations. The nonlinear activation functions\nlead to interesting nonlinear equivariant maps between simple representations.\nFor example, the rectified linear unit (ReLU) gives rise to piecewise linear\nmaps. We show that these considerations lead to a filtration of equivariant\nneural networks, generalizing Fourier series. This observation might provide a\nuseful tool for interpreting equivariant neural networks.",
    "arxiv_id": "http://arxiv.org/abs/2408.00949v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00949v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Generalisation of Total Uncertainty in AI: A Theoretical Study",
    "authors": "Keivan Shariatmadar",
    "abstract": "AI has been dealing with uncertainty to have highly accurate results. This\nbecomes even worse with reasonably small data sets or a variation in the data\nsets. This has far-reaching effects on decision-making, forecasting and\nlearning mechanisms. This study seeks to unpack the nature of uncertainty that\nexists within AI by drawing ideas from established works, the latest\ndevelopments and practical applications and provide a novel total uncertainty\ndefinition in AI.\n  From inception theories up to current methodologies, this paper provides an\nintegrated view of dealing with better total uncertainty as well as\ncomplexities of uncertainty in AI that help us understand its meaning and value\nacross different domains.",
    "arxiv_id": "http://arxiv.org/abs/2408.00946v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00946v1",
    "primary_category": "cs.AI",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Enabling High Data Throughput Reinforcement Learning on GPUs: A Domain Agnostic Framework for Data-Driven Scientific Research",
    "authors": "Tian Lan, Huan Wang, Caiming Xiong, Silvio Savarese",
    "abstract": "We introduce WarpSci, a domain agnostic framework designed to overcome\ncrucial system bottlenecks encountered in the application of reinforcement\nlearning to intricate environments with vast datasets featuring\nhigh-dimensional observation or action spaces. Notably, our framework\neliminates the need for data transfer between the CPU and GPU, enabling the\nconcurrent execution of thousands of simulations on a single or multiple GPUs.\nThis high data throughput architecture proves particularly advantageous for\ndata-driven scientific research, where intricate environment models are\ncommonly essential.",
    "arxiv_id": "http://arxiv.org/abs/2408.00930v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00930v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Verification of Machine Unlearning is Fragile",
    "authors": "Binchi Zhang, Zihan Chen, Cong Shen, Jundong Li",
    "abstract": "As privacy concerns escalate in the realm of machine learning, data owners\nnow have the option to utilize machine unlearning to remove their data from\nmachine learning models, following recent legislation. To enhance transparency\nin machine unlearning and avoid potential dishonesty by model providers,\nvarious verification strategies have been proposed. These strategies enable\ndata owners to ascertain whether their target data has been effectively\nunlearned from the model. However, our understanding of the safety issues of\nmachine unlearning verification remains nascent. In this paper, we explore the\nnovel research question of whether model providers can circumvent verification\nstrategies while retaining the information of data supposedly unlearned. Our\ninvestigation leads to a pessimistic answer: \\textit{the verification of\nmachine unlearning is fragile}. Specifically, we categorize the current\nverification strategies regarding potential dishonesty among model providers\ninto two types. Subsequently, we introduce two novel adversarial unlearning\nprocesses capable of circumventing both types. We validate the efficacy of our\nmethods through theoretical analysis and empirical experiments using real-world\ndatasets. This study highlights the vulnerabilities and limitations in machine\nunlearning verification, paving the way for further research into the safety of\nmachine unlearning.",
    "arxiv_id": "http://arxiv.org/abs/2408.00929v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00929v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Automatic Pull Request Description Generation Using LLMs: A T5 Model Approach",
    "authors": "Md Nazmus Sakib, Md Athikul Islam, Md Mashrur Arifin",
    "abstract": "Developers create pull request (PR) descriptions to provide an overview of\ntheir changes and explain the motivations behind them. These descriptions help\nreviewers and fellow developers quickly understand the updates. Despite their\nimportance, some developers omit these descriptions. To tackle this problem, we\npropose an automated method for generating PR descriptions based on commit\nmessages and source code comments. This method frames the task as a text\nsummarization problem, for which we utilized the T5 text-to-text transfer\nmodel. We fine-tuned a pre-trained T5 model using a dataset containing 33,466\nPRs. The model's effectiveness was assessed using ROUGE metrics, which are\nrecognized for their strong alignment with human evaluations. Our findings\nreveal that the T5 model significantly outperforms LexRank, which served as our\nbaseline for comparison.",
    "arxiv_id": "http://arxiv.org/abs/2408.00921v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00921v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Towards Certified Unlearning for Deep Neural Networks",
    "authors": "Binchi Zhang, Yushun Dong, Tianhao Wang, Jundong Li",
    "abstract": "In the field of machine unlearning, certified unlearning has been extensively\nstudied in convex machine learning models due to its high efficiency and strong\ntheoretical guarantees. However, its application to deep neural networks\n(DNNs), known for their highly nonconvex nature, still poses challenges. To\nbridge the gap between certified unlearning and DNNs, we propose several simple\ntechniques to extend certified unlearning methods to nonconvex objectives. To\nreduce the time complexity, we develop an efficient computation method by\ninverse Hessian approximation without compromising certification guarantees. In\naddition, we extend our discussion of certification to nonconvergence training\nand sequential unlearning, considering that real-world users can send\nunlearning requests at different time points. Extensive experiments on three\nreal-world datasets demonstrate the efficacy of our method and the advantages\nof certified unlearning in DNNs.",
    "arxiv_id": "http://arxiv.org/abs/2408.00920v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00920v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Distance-Preserving Generative Modeling of Spatial Transcriptomics",
    "authors": "Wenbin Zhou, Jin-Hong Du",
    "abstract": "Spatial transcriptomics data is invaluable for understanding the spatial\norganization of gene expression in tissues. There have been consistent efforts\nin studying how to effectively utilize the associated spatial information for\nrefining gene expression modeling. We introduce a class of distance-preserving\ngenerative models for spatial transcriptomics, which utilizes the provided\nspatial information to regularize the learned representation space of gene\nexpressions to have a similar pair-wise distance structure. This helps the\nlatent space to capture meaningful encodings of genes in spatial proximity. We\ncarry out theoretical analysis over a tractable loss function for this purpose\nand formalize the overall learning objective as a regularized evidence lower\nbound. Our framework grants compatibility with any variational-inference-based\ngenerative models for gene expression modeling. Empirically, we validate our\nproposed method on the mouse brain tissues Visium dataset and observe improved\nperformance with variational autoencoders and scVI used as backbone models.",
    "arxiv_id": "http://arxiv.org/abs/2408.00911v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00911v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Early Stopping Based on Repeated Significance",
    "authors": "Eric Bax, Arundhyoti Sarkar, Alex Shtoff",
    "abstract": "For a bucket test with a single criterion for success and a fixed number of\nsamples or testing period, requiring a $p$-value less than a specified value of\n$\\alpha$ for the success criterion produces statistical confidence at level $1\n- \\alpha$. For multiple criteria, a Bonferroni correction that partitions\n$\\alpha$ among the criteria produces statistical confidence, at the cost of\nrequiring lower $p$-values for each criterion. The same concept can be applied\nto decisions about early stopping, but that can lead to strict requirements for\n$p$-values. We show how to address that challenge by requiring criteria to be\nsuccessful at multiple decision points.",
    "arxiv_id": "http://arxiv.org/abs/2408.00908v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00908v1",
    "primary_category": "stat.ME",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Parkinson's Disease Detection from Resting State EEG using Multi-Head Graph Structure Learning with Gradient Weighted Graph Attention Explanations",
    "authors": "Christopher Neves, Yong Zeng, Yiming Xiao",
    "abstract": "Parkinson's disease (PD) is a debilitating neurodegenerative disease that has\nsevere impacts on an individual's quality of life. Compared with structural and\nfunctional MRI-based biomarkers for the disease, electroencephalography (EEG)\ncan provide more accessible alternatives for clinical insights. While deep\nlearning (DL) techniques have provided excellent outcomes, many techniques fail\nto model spatial information and dynamic brain connectivity, and face\nchallenges in robust feature learning, limited data sizes, and poor\nexplainability. To address these issues, we proposed a novel graph neural\nnetwork (GNN) technique for explainable PD detection using resting state EEG.\nSpecifically, we employ structured global convolutions with contrastive\nlearning to better model complex features with limited data, a novel multi-head\ngraph structure learner to capture the non-Euclidean structure of EEG data, and\na head-wise gradient-weighted graph attention explainer to offer neural\nconnectivity insights. We developed and evaluated our method using the UC San\nDiego Parkinson's disease EEG dataset, and achieved 69.40% detection accuracy\nin subject-wise leave-one-out cross-validation while generating intuitive\nexplanations for the learnt graph topology.",
    "arxiv_id": "http://arxiv.org/abs/2408.00906v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00906v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Discrete Randomized Smoothing Meets Quantum Computing",
    "authors": "Tom Wollschl\u00e4ger, Aman Saxena, Nicola Franco, Jeanette Miriam Lorenz, Stephan G\u00fcnnemann",
    "abstract": "Breakthroughs in machine learning (ML) and advances in quantum computing (QC)\ndrive the interdisciplinary field of quantum machine learning to new levels.\nHowever, due to the susceptibility of ML models to adversarial attacks,\npractical use raises safety-critical concerns. Existing Randomized Smoothing\n(RS) certification methods for classical machine learning models are\ncomputationally intensive. In this paper, we propose the combination of QC and\nthe concept of discrete randomized smoothing to speed up the stochastic\ncertification of ML models for discrete data. We show how to encode all the\nperturbations of the input binary data in superposition and use Quantum\nAmplitude Estimation (QAE) to obtain a quadratic reduction in the number of\ncalls to the model that are required compared to traditional randomized\nsmoothing techniques. In addition, we propose a new binary threat model to\nallow for an extensive evaluation of our approach on images, graphs, and text.",
    "arxiv_id": "http://arxiv.org/abs/2408.00895v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00895v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Peptide Sequencing Via Protein Language Models",
    "authors": "Thuong Le Hoai Pham, Jillur Rahman Saurav, Aisosa A. Omere, Calvin J. Heyl, Mohammad Sadegh Nasr, Cody Tyler Reynolds, Jai Prakash Yadav Veerla, Helen H Shang, Justyn Jaworski, Alison Ravenscraft, Joseph Anthony Buonomo, Jacob M. Luber",
    "abstract": "We introduce a protein language model for determining the complete sequence\nof a peptide based on measurement of a limited set of amino acids. To date,\nprotein sequencing relies on mass spectrometry, with some novel edman\ndegregation based platforms able to sequence non-native peptides. Current\nprotein sequencing techniques face limitations in accurately identifying all\namino acids, hindering comprehensive proteome analysis. Our method simulates\npartial sequencing data by selectively masking amino acids that are\nexperimentally difficult to identify in protein sequences from the UniRef\ndatabase. This targeted masking mimics real-world sequencing limitations. We\nthen modify and finetune a ProtBert derived transformer-based model, for a new\ndownstream task predicting these masked residues, providing an approximation of\nthe complete sequence. Evaluating on three bacterial Escherichia species, we\nachieve per-amino-acid accuracy up to 90.5% when only four amino acids ([KCYM])\nare known. Structural assessment using AlphaFold and TM-score validates the\nbiological relevance of our predictions. The model also demonstrates potential\nfor evolutionary analysis through cross-species performance. This integration\nof simulated experimental constraints with computational predictions offers a\npromising avenue for enhancing protein sequence analysis, potentially\naccelerating advancements in proteomics and structural biology by providing a\nprobabilistic reconstruction of the complete protein sequence from limited\nexperimental data.",
    "arxiv_id": "http://arxiv.org/abs/2408.00892v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00892v1",
    "primary_category": "q-bio.BM",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "On the Relationship Between Monotone and Squared Probabilistic Circuits",
    "authors": "Benjie Wang, Guy Van den Broeck",
    "abstract": "Probabilistic circuits are a unifying representation of functions as\ncomputation graphs of weighted sums and products. Their primary application is\nin probabilistic modeling, where circuits with non-negative weights (monotone\ncircuits) can be used to represent and learn density/mass functions, with\ntractable marginal inference. Recently, it was proposed to instead represent\ndensities as the square of the circuit function (squared circuits); this allows\nthe use of negative weights while retaining tractability, and can be\nexponentially more compact than monotone circuits. Unfortunately, we show the\nreverse also holds, meaning that monotone circuits and squared circuits are\nincomparable in general. This raises the question of whether we can reconcile,\nand indeed improve upon the two modeling approaches. We answer in the positive\nby proposing InceptionPCs, a novel type of circuit that naturally encompasses\nboth monotone circuits and squared circuits as special cases, and employs\ncomplex parameters. Empirically, we validate that InceptionPCs can outperform\nboth monotone and squared circuits on image datasets.",
    "arxiv_id": "http://arxiv.org/abs/2408.00876v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00876v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Online Detection of Anomalies in Temporal Knowledge Graphs with Interpretability",
    "authors": "Jiasheng Zhang, Jie Shao, Rex Ying",
    "abstract": "Temporal knowledge graphs (TKGs) are valuable resources for capturing\nevolving relationships among entities, yet they are often plagued by noise,\nnecessitating robust anomaly detection mechanisms. Existing dynamic graph\nanomaly detection approaches struggle to capture the rich semantics introduced\nby node and edge categories within TKGs, while TKG embedding methods lack\ninterpretability, undermining the credibility of anomaly detection. Moreover,\nthese methods falter in adapting to pattern changes and semantic drifts\nresulting from knowledge updates. To tackle these challenges, we introduce\nAnoT, an efficient TKG summarization method tailored for interpretable online\nanomaly detection in TKGs. AnoT begins by summarizing a TKG into a novel rule\ngraph, enabling flexible inference of complex patterns in TKGs. When new\nknowledge emerges, AnoT maps it onto a node in the rule graph and traverses the\nrule graph recursively to derive the anomaly score of the knowledge. The\ntraversal yields reachable nodes that furnish interpretable evidence for the\nvalidity or the anomalous of the new knowledge. Overall, AnoT embodies a\ndetector-updater-monitor architecture, encompassing a detector for offline TKG\nsummarization and online scoring, an updater for real-time rule graph updates\nbased on emerging knowledge, and a monitor for estimating the approximation\nerror of the rule graph. Experimental results on four real-world datasets\ndemonstrate that AnoT surpasses existing methods significantly in terms of\naccuracy and interoperability. All of the raw datasets and the implementation\nof AnoT are provided in https://github.com/zjs123/ANoT.",
    "arxiv_id": "http://arxiv.org/abs/2408.00872v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00872v1",
    "primary_category": "cs.AI",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "UniMoT: Unified Molecule-Text Language Model with Discrete Token Representation",
    "authors": "Juzheng Zhang, Yatao Bian, Yongqiang Chen, Quanming Yao",
    "abstract": "The remarkable success of Large Language Models (LLMs) across diverse tasks\nhas driven the research community to extend their capabilities to molecular\napplications. However, most molecular LLMs employ adapter-based architectures\nthat do not treat molecule and text modalities equally and lack a supervision\nsignal for the molecule modality. To address these issues, we introduce UniMoT,\na Unified Molecule-Text LLM adopting a tokenizer-based architecture that\nexpands the vocabulary of LLM with molecule tokens. Specifically, we introduce\na Vector Quantization-driven tokenizer that incorporates a Q-Former to bridge\nthe modality gap between molecule and text. This tokenizer transforms molecules\ninto sequences of molecule tokens with causal dependency, encapsulating\nhigh-level molecular and textual information. Equipped with this tokenizer,\nUniMoT can unify molecule and text modalities under a shared token\nrepresentation and an autoregressive training paradigm, enabling it to\ninterpret molecules as a foreign language and generate them as text. Following\na four-stage training scheme, UniMoT emerges as a multi-modal generalist\ncapable of performing both molecule-to-text and text-to-molecule tasks.\nExtensive experiments demonstrate that UniMoT achieves state-of-the-art\nperformance across a wide range of molecule comprehension and generation tasks.",
    "arxiv_id": "http://arxiv.org/abs/2408.00863v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00863v1",
    "primary_category": "cs.CL",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Deep Learning Approach for Changepoint Detection: Penalty Parameter Optimization",
    "authors": "Tung L Nguyen, Toby Dylan Hocking",
    "abstract": "Changepoint detection, a technique for identifying significant shifts within\ndata sequences, is crucial in various fields such as finance, genomics,\nmedicine, etc. Dynamic programming changepoint detection algorithms are\nemployed to identify the locations of changepoints within a sequence, which\nrely on a penalty parameter to regulate the number of changepoints. To estimate\nthis penalty parameter, previous work uses simple models such as linear models\nor decision trees. This study introduces a novel deep learning method for\npredicting penalty parameters, leading to demonstrably improved changepoint\ndetection accuracy on large benchmark supervised labeled datasets compared to\nprevious methods.",
    "arxiv_id": "http://arxiv.org/abs/2408.00856v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00856v1",
    "primary_category": "stat.ML",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "A Novel Use of Pseudospectra in Mathematical Biology: Understanding HPA Axis Sensitivity",
    "authors": "Catherine Drysdale, Matthew J. Colbrook",
    "abstract": "The Hypothalamic-Pituitary-Adrenal (HPA) axis is a major neuroendocrine\nsystem, and its dysregulation is implicated in various diseases. This system\nalso presents interesting mathematical challenges for modeling. We consider a\nnonlinear delay differential equation model and calculate pseudospectra of\nthree different linearizations: a time-dependent Jacobian, linearization around\nthe limit cycle, and dynamic mode decomposition (DMD) analysis of Koopman\noperators (global linearization). The time-dependent Jacobian provided insight\ninto experimental phenomena, explaining why rats respond differently to\nperturbations during corticosterone secretion's upward versus downward slopes.\nWe developed new mathematical techniques for the other two linearizations to\ncalculate pseudospectra on Banach spaces and apply DMD to delay differential\nequations, respectively. These methods helped establish local and global limit\ncycle stability and study transients. Additionally, we discuss using\npseudospectra to substantiate the model in experimental contexts and establish\nbio-variability via data-driven methods. This work is the first to utilize\npseudospectra to explore the HPA axis.",
    "arxiv_id": "http://arxiv.org/abs/2408.00845v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00845v1",
    "primary_category": "math.SP",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Calibrating Bayesian Generative Machine Learning for Bayesiamplification",
    "authors": "Sebastian Bieringer, Sascha Diefenbacher, Gregor Kasieczka, Mathias Trabs",
    "abstract": "Recently, combinations of generative and Bayesian machine learning have been\nintroduced in particle physics for both fast detector simulation and inference\ntasks. These neural networks aim to quantify the uncertainty on the generated\ndistribution originating from limited training statistics. The interpretation\nof a distribution-wide uncertainty however remains ill-defined. We show a clear\nscheme for quantifying the calibration of Bayesian generative machine learning\nmodels. For a Continuous Normalizing Flow applied to a low-dimensional toy\nexample, we evaluate the calibration of Bayesian uncertainties from either a\nmean-field Gaussian weight posterior, or Monte Carlo sampling network weights,\nto gauge their behaviour on unsteady distribution edges. Well calibrated\nuncertainties can then be used to roughly estimate the number of uncorrelated\ntruth samples that are equivalent to the generated sample and clearly indicate\ndata amplification for smooth features of the distribution.",
    "arxiv_id": "http://arxiv.org/abs/2408.00838v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00838v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "AgentGen: Enhancing Planning Abilities for Large Language Model based Agent via Environment and Task Generation",
    "authors": "Mengkang Hu, Pu Zhao, Can Xu, Qingfeng Sun, Jianguang Lou, Qingwei Lin, Ping Luo, Saravan Rajmohan, Dongmei Zhang",
    "abstract": "Large Language Model (LLM) based agents have garnered significant attention\nand are becoming increasingly popular. Furthermore, planning ability is a\ncrucial component of an LLM-based agent, involving interaction with the\nenvironment and executing actions to complete a planning task, which generally\nentails achieving a desired goal from an initial state. This paper investigates\nenhancing the planning abilities of LLMs through instruction tuning, referred\nto as agent training. Recent studies have demonstrated that utilizing\nexpert-level trajectory for instruction-tuning LLMs effectively enhances their\nplanning capabilities. However, existing work primarily focuses on synthesizing\ntrajectories from manually designed planning tasks and environments. The\nlabor-intensive nature of creating these environments and tasks impedes the\ngeneration of sufficiently varied and extensive trajectories. To address this\nlimitation, this paper explores the automated synthesis of diverse environments\nand a gradual range of planning tasks, from easy to difficult. We introduce a\nframework, AgentGen, that leverages LLMs first to generate environments and\nsubsequently generate planning tasks conditioned on these environments.\nSpecifically, to improve environmental diversity, we propose using an\ninspiration corpus composed of various domain-specific text segments as the\ncontext for synthesizing environments. Moreover, to increase the difficulty\ndiversity of generated planning tasks, we propose a bidirectional evolution\nmethod, Bi-Evol, that evolves planning tasks from easier and harder directions\nto synthesize a task set with a smoother difficulty curve. The evaluation\nresults derived from AgentBoard show that AgentGen greatly improves LLMs'\nplanning ability, e.g., the AgentGen instruction-tuned Llama-3 8B surpasses\nGPT-3.5 in overall performance. Moreover, in certain tasks, it even outperforms\nGPT-4.",
    "arxiv_id": "http://arxiv.org/abs/2408.00764v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00764v1",
    "primary_category": "cs.CL",
    "votes": 0,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Tamper-Resistant Safeguards for Open-Weight LLMs",
    "authors": "Rishub Tamirisa, Bhrugu Bharathi, Long Phan, Andy Zhou, Alice Gatti, Tarun Suresh, Maxwell Lin, Justin Wang, Rowan Wang, Ron Arel, Andy Zou, Dawn Song, Bo Li, Dan Hendrycks, Mantas Mazeika",
    "abstract": "Rapid advances in the capabilities of large language models (LLMs) have\nraised widespread concerns regarding their potential for malicious use.\nOpen-weight LLMs present unique challenges, as existing safeguards lack\nrobustness to tampering attacks that modify model weights. For example, recent\nworks have demonstrated that refusal and unlearning safeguards can be trivially\nremoved with a few steps of fine-tuning. These vulnerabilities necessitate new\napproaches for enabling the safe release of open-weight LLMs. We develop a\nmethod, called TAR, for building tamper-resistant safeguards into open-weight\nLLMs such that adversaries cannot remove the safeguards even after thousands of\nsteps of fine-tuning. In extensive evaluations and red teaming analyses, we\nfind that our method greatly improves tamper-resistance while preserving benign\ncapabilities. Our results demonstrate that tamper-resistance is a tractable\nproblem, opening up a promising new avenue to improve the safety and security\nof open-weight LLMs.",
    "arxiv_id": "http://arxiv.org/abs/2408.00761v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00761v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Smoothed Energy Guidance: Guiding Diffusion Models with Reduced Energy Curvature of Attention",
    "authors": "Susung Hong",
    "abstract": "Conditional diffusion models have shown remarkable success in visual content\ngeneration, producing high-quality samples across various domains, largely due\nto classifier-free guidance (CFG). Recent attempts to extend guidance to\nunconditional models have relied on heuristic techniques, resulting in\nsuboptimal generation quality and unintended effects. In this work, we propose\nSmoothed Energy Guidance (SEG), a novel training- and condition-free approach\nthat leverages the energy-based perspective of the self-attention mechanism to\nenhance image generation. By defining the energy of self-attention, we\nintroduce a method to reduce the curvature of the energy landscape of attention\nand use the output as the unconditional prediction. Practically, we control the\ncurvature of the energy landscape by adjusting the Gaussian kernel parameter\nwhile keeping the guidance scale parameter fixed. Additionally, we present a\nquery blurring method that is equivalent to blurring the entire attention\nweights without incurring quadratic complexity in the number of tokens. In our\nexperiments, SEG achieves a Pareto improvement in both quality and the\nreduction of side effects. The code is available at\n\\url{https://github.com/SusungHong/SEG-SDXL}.",
    "arxiv_id": "http://arxiv.org/abs/2408.00760v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00760v1",
    "primary_category": "cs.CV",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Coarse Correspondence Elicit 3D Spacetime Understanding in Multimodal Language Model",
    "authors": "Benlin Liu, Yuhao Dong, Yiqin Wang, Yongming Rao, Yansong Tang, Wei-Chiu Ma, Ranjay Krishna",
    "abstract": "Multimodal language models (MLLMs) are increasingly being implemented in\nreal-world environments, necessitating their ability to interpret 3D spaces and\ncomprehend temporal dynamics. Despite their potential, current top models\nwithin our community still fall short in adequately understanding spatial and\ntemporal dimensions. We introduce Coarse Correspondence, a simple,\ntraining-free, effective, and general-purpose visual prompting method to elicit\n3D and temporal understanding in multimodal LLMs. Our method uses a lightweight\ntracking model to find object correspondences between frames in a video or\nbetween sets of image viewpoints. It selects the most frequent object instances\nand visualizes them with markers with unique IDs in the image. With this simple\napproach, we achieve state-of-the-art results on 3D understanding benchmarks\nincluding ScanQA (+20.5\\%) and a subset of OpenEQA (+9.7\\%), and on long-form\nvideo benchmarks such as EgoSchema (+6.0\\%). We also curate a small diagnostic\ndataset to evaluate whether MLLMs can reason about space from a described\nviewpoint other than the camera viewpoint. Again, Coarse Correspondence\nimproves spatial perspective-taking abilities but we highlight that MLLMs\nstruggle with this task. Together, we demonstrate that our simple prompting\nmethod can significantly aid downstream tasks that require 3D or temporal\nreasoning.",
    "arxiv_id": "http://arxiv.org/abs/2408.00754v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00754v1",
    "primary_category": "cs.CV",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "A Policy-Gradient Approach to Solving Imperfect-Information Games with Iterate Convergence",
    "authors": "Mingyang Liu, Gabriele Farina, Asuman Ozdaglar",
    "abstract": "Policy gradient methods have become a staple of any single-agent\nreinforcement learning toolbox, due to their combination of desirable\nproperties: iterate convergence, efficient use of stochastic trajectory\nfeedback, and theoretically-sound avoidance of importance sampling corrections.\nIn multi-agent imperfect-information settings (extensive-form games), however,\nit is still unknown whether the same desiderata can be guaranteed while\nretaining theoretical guarantees. Instead, sound methods for extensive-form\ngames rely on approximating counterfactual values (as opposed to Q values),\nwhich are incompatible with policy gradient methodologies. In this paper, we\ninvestigate whether policy gradient can be safely used in two-player zero-sum\nimperfect-information extensive-form games (EFGs). We establish positive\nresults, showing for the first time that a policy gradient method leads to\nprovable best-iterate convergence to a regularized Nash equilibrium in\nself-play.",
    "arxiv_id": "http://arxiv.org/abs/2408.00751v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00751v1",
    "primary_category": "cs.GT",
    "votes": 1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Leaf Angle Estimation using Mask R-CNN and LETR Vision Transformer",
    "authors": "Venkat Margapuri, Prapti Thapaliya, Trevor Rife",
    "abstract": "Modern day studies show a high degree of correlation between high yielding\ncrop varieties and plants with upright leaf angles. It is observed that plants\nwith upright leaf angles intercept more light than those without upright leaf\nangles, leading to a higher rate of photosynthesis. Plant scientists and\nbreeders benefit from tools that can directly measure plant parameters in the\nfield i.e. on-site phenotyping. The estimation of leaf angles by manual means\nin a field setting is tedious and cumbersome. We mitigate the tedium using a\ncombination of the Mask R-CNN instance segmentation neural network, and Line\nSegment Transformer (LETR), a vision transformer. The proposed Computer Vision\n(CV) pipeline is applied on two image datasets, Summer 2015-Ames ULA and Summer\n2015- Ames MLA, with a combined total of 1,827 plant images collected in the\nfield using FieldBook, an Android application aimed at on-site phenotyping. The\nleaf angles estimated by the proposed pipeline on the image datasets are\ncompared to two independent manual measurements using ImageJ, a Java-based\nimage processing program developed at the National Institutes of Health and the\nLaboratory for Optical and Computational Instrumentation. The results, when\ncompared for similarity using the Cosine Similarity measure, exhibit 0.98\nsimilarity scores on both independent measurements of Summer 2015-Ames ULA and\nSummer 2015-Ames MLA image datasets, demonstrating the feasibility of the\nproposed pipeline for on-site measurement of leaf angles.",
    "arxiv_id": "http://arxiv.org/abs/2408.00749v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00749v1",
    "primary_category": "cs.CV",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "CERT-ED: Certifiably Robust Text Classification for Edit Distance",
    "authors": "Zhuoqun Huang, Neil G Marchant, Olga Ohrimenko, Benjamin I. P. Rubinstein",
    "abstract": "With the growing integration of AI in daily life, ensuring the robustness of\nsystems to inference-time attacks is crucial. Among the approaches for\ncertifying robustness to such adversarial examples, randomized smoothing has\nemerged as highly promising due to its nature as a wrapper around arbitrary\nblack-box models. Previous work on randomized smoothing in natural language\nprocessing has primarily focused on specific subsets of edit distance\noperations, such as synonym substitution or word insertion, without exploring\nthe certification of all edit operations. In this paper, we adapt Randomized\nDeletion (Huang et al., 2023) and propose, CERTified Edit Distance defense\n(CERT-ED) for natural language classification. Through comprehensive\nexperiments, we demonstrate that CERT-ED outperforms the existing Hamming\ndistance method RanMASK (Zeng et al., 2023) in 4 out of 5 datasets in terms of\nboth accuracy and the cardinality of the certificate. By covering various\nthreat models, including 5 direct and 5 transfer attacks, our method improves\nempirical robustness in 38 out of 50 settings.",
    "arxiv_id": "http://arxiv.org/abs/2408.00728v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00728v1",
    "primary_category": "cs.CL",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "A Natural Language Processing Framework for Hotel Recommendation Based on Users' Text Reviews",
    "authors": "Lavrentia Aravani, Emmanuel Pintelas, Christos Pierrakeas, Panagiotis Pintelas",
    "abstract": "Recently, the application of Artificial Intelligence algorithms in hotel\nrecommendation systems has become an increasingly popular topic. One such\nmethod that has proven to be effective in this field is Deep Learning,\nespecially Natural Language processing models, which are able to extract\nsemantic knowledge from user's text reviews to create more efficient\nrecommendation systems. This can lead to the development of intelligent models\nthat can classify a user's preferences and emotions based on their feedback in\nthe form of text reviews about their hotel stay experience. In this study, we\npropose a Natural Language Processing framework that utilizes customer text\nreviews to provide personalized recommendations for the most appropriate hotel\nbased on their preferences. The framework is based on Bidirectional Encoder\nRepresentations from Transformers (BERT) and a fine-tuning/validation pipeline\nthat categorizes customer hotel review texts into \"Bad,\" \"Good,\" or \"Excellent\"\nrecommended hotels. Our findings indicate that the hotel recommendation system\nwe propose can significantly enhance the user experience of booking\naccommodations by providing personalized recommendations based on user\npreferences and previous booking history.",
    "arxiv_id": "http://arxiv.org/abs/2408.00716v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00716v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "SAM 2: Segment Anything in Images and Videos",
    "authors": "Nikhila Ravi, Valentin Gabeur, Yuan-Ting Hu, Ronghang Hu, Chaitanya Ryali, Tengyu Ma, Haitham Khedr, Roman R\u00e4dle, Chloe Rolland, Laura Gustafson, Eric Mintun, Junting Pan, Kalyan Vasudev Alwala, Nicolas Carion, Chao-Yuan Wu, Ross Girshick, Piotr Doll\u00e1r, Christoph Feichtenhofer",
    "abstract": "We present Segment Anything Model 2 (SAM 2), a foundation model towards\nsolving promptable visual segmentation in images and videos. We build a data\nengine, which improves model and data via user interaction, to collect the\nlargest video segmentation dataset to date. Our model is a simple transformer\narchitecture with streaming memory for real-time video processing. SAM 2\ntrained on our data provides strong performance across a wide range of tasks.\nIn video segmentation, we observe better accuracy, using 3x fewer interactions\nthan prior approaches. In image segmentation, our model is more accurate and 6x\nfaster than the Segment Anything Model (SAM). We believe that our data, model,\nand insights will serve as a significant milestone for video segmentation and\nrelated perception tasks. We are releasing a version of our model, the dataset\nand an interactive demo.",
    "arxiv_id": "http://arxiv.org/abs/2408.00714v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00714v1",
    "primary_category": "cs.CV",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Reinforcement Learning applied to Insurance Portfolio Pursuit",
    "authors": "Edward James Young, Alistair Rogers, Elliott Tong, James Jordon",
    "abstract": "When faced with a new customer, many factors contribute to an insurance\nfirm's decision of what offer to make to that customer. In addition to the\nexpected cost of providing the insurance, the firm must consider the other\noffers likely to be made to the customer, and how sensitive the customer is to\ndifferences in price. Moreover, firms often target a specific portfolio of\ncustomers that could depend on, e.g., age, location, and occupation. Given such\na target portfolio, firms may choose to modulate an individual customer's offer\nbased on whether the firm desires the customer within their portfolio. We term\nthe problem of modulating offers to achieve a desired target portfolio the\nportfolio pursuit problem. Having formulated the portfolio pursuit problem as a\nsequential decision making problem, we devise a novel reinforcement learning\nalgorithm for its solution. We test our method on a complex synthetic market\nenvironment, and demonstrate that it outperforms a baseline method which mimics\ncurrent industry approaches to portfolio pursuit.",
    "arxiv_id": "http://arxiv.org/abs/2408.00713v2",
    "pdf_url": "http://arxiv.org/pdf/2408.00713v2",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Synthetic dual image generation for reduction of labeling efforts in semantic segmentation of micrographs with a customized metric function",
    "authors": "Matias Oscar Volman Stern, Dominic Hohs, Andreas Jansche, Timo Bernthaler, Gerhard Schneider",
    "abstract": "Training of semantic segmentation models for material analysis requires\nmicrographs and their corresponding masks. It is quite unlikely that perfect\nmasks will be drawn, especially at the edges of objects, and sometimes the\namount of data that can be obtained is small, since only a few samples are\navailable. These aspects make it very problematic to train a robust model. We\ndemonstrate a workflow for the improvement of semantic segmentation models of\nmicrographs through the generation of synthetic microstructural images in\nconjunction with masks. The workflow only requires joining a few micrographs\nwith their respective masks to create the input for a Vector\nQuantised-Variational AutoEncoder model that includes an embedding space, which\nis trained such that a generative model (PixelCNN) learns the distribution of\neach input, transformed into discrete codes, and can be used to sample new\ncodes. The latter will eventually be decoded by VQ-VAE to generate images\nalongside corresponding masks for semantic segmentation. To evaluate the\nsynthetic data, we have trained U-Net models with different amounts of these\nsynthetic data in conjunction with real data. These models were then evaluated\nusing non-synthetic images only. Additionally, we introduce a customized metric\nderived from the mean Intersection over Union (mIoU). The proposed metric\nprevents a few falsely predicted pixels from greatly reducing the value of the\nmIoU. We have achieved a reduction in sample preparation and acquisition times,\nas well as the efforts, needed for image processing and labeling tasks, are\nless when it comes to training semantic segmentation model. The approach could\nbe generalized to various types of image data such that it serves as a\nuser-friendly solution for training models with a small number of real images.",
    "arxiv_id": "http://arxiv.org/abs/2408.00707v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00707v1",
    "primary_category": "cs.CV",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Point-supervised Brain Tumor Segmentation with Box-prompted MedSAM",
    "authors": "Xiaofeng Liu, Jonghye Woo, Chao Ma, Jinsong Ouyang, Georges El Fakhri",
    "abstract": "Delineating lesions and anatomical structure is important for image-guided\ninterventions. Point-supervised medical image segmentation (PSS) has great\npotential to alleviate costly expert delineation labeling. However, due to the\nlack of precise size and boundary guidance, the effectiveness of PSS often\nfalls short of expectations. Although recent vision foundational models, such\nas the medical segment anything model (MedSAM), have made significant\nadvancements in bounding-box-prompted segmentation, it is not straightforward\nto utilize point annotation, and is prone to semantic ambiguity. In this\npreliminary study, we introduce an iterative framework to facilitate\nsemantic-aware point-supervised MedSAM. Specifically, the semantic box-prompt\ngenerator (SBPG) module has the capacity to convert the point input into\npotential pseudo bounding box suggestions, which are explicitly refined by the\nprototype-based semantic similarity. This is then succeeded by a prompt-guided\nspatial refinement (PGSR) module that harnesses the exceptional\ngeneralizability of MedSAM to infer the segmentation mask, which also updates\nthe box proposal seed in SBPG. Performance can be progressively improved with\nadequate iterations. We conducted an evaluation on BraTS2018 for the\nsegmentation of whole brain tumors and demonstrated its superior performance\ncompared to traditional PSS methods and on par with box-supervised methods.",
    "arxiv_id": "http://arxiv.org/abs/2408.00706v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00706v1",
    "primary_category": "cs.CV",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "You Can't Ignore Either: Unifying Structure and Feature Denoising for Robust Graph Learning",
    "authors": "Tianmeng Yang, Jiahao Meng, Min Zhou, Yaming Yang, Yujing Wang, Xiangtai Li, Yunhai Tong",
    "abstract": "Recent research on the robustness of Graph Neural Networks (GNNs) under\nnoises or attacks has attracted great attention due to its importance in\nreal-world applications. Most previous methods explore a single noise source,\nrecovering corrupt node embedding by reliable structures bias or developing\nstructure learning with reliable node features. However, the noises and attacks\nmay come from both structures and features in graphs, making the graph\ndenoising a dilemma and challenging problem. In this paper, we develop a\nunified graph denoising (UGD) framework to unravel the deadlock between\nstructure and feature denoising. Specifically, a high-order neighborhood\nproximity evaluation method is proposed to recognize noisy edges, considering\nfeatures may be perturbed simultaneously. Moreover, we propose to refine noisy\nfeatures with reconstruction based on a graph auto-encoder. An iterative\nupdating algorithm is further designed to optimize the framework and acquire a\nclean graph, thus enabling robust graph learning for downstream tasks. Our UGD\nframework is self-supervised and can be easily implemented as a plug-and-play\nmodule. We carry out extensive experiments, which proves the effectiveness and\nadvantages of our method. Code is avalaible at\nhttps://github.com/YoungTimmy/UGD.",
    "arxiv_id": "http://arxiv.org/abs/2408.00700v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00700v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Granular-Balls based Fuzzy Twin Support Vector Machine for Classification",
    "authors": "Lixi Zhao, Weiping Ding, Duoqian Miao, Guangming Lang",
    "abstract": "The twin support vector machine (TWSVM) classifier has attracted increasing\nattention because of its low computational complexity. However, its performance\ntends to degrade when samples are affected by noise. The granular-ball fuzzy\nsupport vector machine (GBFSVM) classifier partly alleviates the adverse\neffects of noise, but it relies solely on the distance between the\ngranular-ball's center and the class center to design the granular-ball\nmembership function. In this paper, we first introduce the granular-ball twin\nsupport vector machine (GBTWSVM) classifier, which integrates granular-ball\ncomputing (GBC) with the twin support vector machine (TWSVM) classifier. By\nreplacing traditional point inputs with granular-balls, we demonstrate how to\nderive a pair of non-parallel hyperplanes for the GBTWSVM classifier by solving\na quadratic programming problem. Subsequently, we design the membership and\nnon-membership functions of granular-balls using Pythagorean fuzzy sets to\ndifferentiate the contributions of granular-balls in various regions.\nAdditionally, we develop the granular-ball fuzzy twin support vector machine\n(GBFTSVM) classifier by incorporating GBC with the fuzzy twin support vector\nmachine (FTSVM) classifier. We demonstrate how to derive a pair of non-parallel\nhyperplanes for the GBFTSVM classifier by solving a quadratic programming\nproblem. We also design algorithms for the GBTSVM classifier and the GBFTSVM\nclassifier. Finally, the superior classification performance of the GBTWSVM\nclassifier and the GBFTSVM classifier on 20 benchmark datasets underscores\ntheir scalability, efficiency, and robustness in tackling classification tasks.",
    "arxiv_id": "http://arxiv.org/abs/2408.00699v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00699v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Accelerating Full Waveform Inversion By Transfer Learning",
    "authors": "Divya Shyam Singh, Leon Herrmann, Qing Sun, Tim B\u00fcrchner, Felix Dietrich, Stefan Kollmannsberger",
    "abstract": "Full waveform inversion (FWI) is a powerful tool for reconstructing material\nfields based on sparsely measured data obtained by wave propagation. For\nspecific problems, discretizing the material field with a neural network (NN)\nimproves the robustness and reconstruction quality of the corresponding\noptimization problem. We call this method NN-based FWI. Starting from an\ninitial guess, the weights of the NN are iteratively updated to fit the\nsimulated wave signals to the sparsely measured data set. For gradient-based\noptimization, a suitable choice of the initial guess, i.e., a suitable NN\nweight initialization, is crucial for fast and robust convergence.\n  In this paper, we introduce a novel transfer learning approach to further\nimprove NN-based FWI. This approach leverages supervised pretraining to provide\na better NN weight initialization, leading to faster convergence of the\nsubsequent optimization problem. Moreover, the inversions yield physically more\nmeaningful local minima. The network is pretrained to predict the unknown\nmaterial field using the gradient information from the first iteration of\nconventional FWI. In our computational experiments on two-dimensional domains,\nthe training data set consists of reference simulations with arbitrarily\npositioned elliptical voids of different shapes and orientations. We compare\nthe performance of the proposed transfer learning NN-based FWI with three other\nmethods: conventional FWI, NN-based FWI without pretraining and conventional\nFWI with an initial guess predicted from the pretrained NN. Our results show\nthat transfer learning NN-based FWI outperforms the other methods in terms of\nconvergence speed and reconstruction quality.",
    "arxiv_id": "http://arxiv.org/abs/2408.00695v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00695v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Alpha-VI DeepONet: A prior-robust variational Bayesian approach for enhancing DeepONets with uncertainty quantification",
    "authors": "Soban Nasir Lone, Subhayan De, Rajdip Nayek",
    "abstract": "We introduce a novel deep operator network (DeepONet) framework that\nincorporates generalised variational inference (GVI) using R\\'enyi's\n$\\alpha$-divergence to learn complex operators while quantifying uncertainty.\nBy incorporating Bayesian neural networks as the building blocks for the branch\nand trunk networks, our framework endows DeepONet with uncertainty\nquantification. The use of R\\'enyi's $\\alpha$-divergence, instead of the\nKullback-Leibler divergence (KLD), commonly used in standard variational\ninference, mitigates issues related to prior misspecification that are\nprevalent in Variational Bayesian DeepONets. This approach offers enhanced\nflexibility and robustness. We demonstrate that modifying the variational\nobjective function yields superior results in terms of minimising the mean\nsquared error and improving the negative log-likelihood on the test set. Our\nframework's efficacy is validated across various mechanical systems, where it\noutperforms both deterministic and standard KLD-based VI DeepONets in\npredictive accuracy and uncertainty quantification. The hyperparameter\n$\\alpha$, which controls the degree of robustness, can be tuned to optimise\nperformance for specific problems. We apply this approach to a range of\nmechanics problems, including gravity pendulum, advection-diffusion, and\ndiffusion-reaction systems. Our findings underscore the potential of\n$\\alpha$-VI DeepONet to advance the field of data-driven operator learning and\nits applications in engineering and scientific domains.",
    "arxiv_id": "http://arxiv.org/abs/2408.00681v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00681v1",
    "primary_category": "stat.ML",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "An effect analysis of the balancing techniques on the counterfactual explanations of student success prediction models",
    "authors": "Mustafa Cavus, Jakub Kuzilek",
    "abstract": "In the past decade, we have experienced a massive boom in the usage of\ndigital solutions in higher education. Due to this boom, large amounts of data\nhave enabled advanced data analysis methods to support learners and examine\nlearning processes. One of the dominant research directions in learning\nanalytics is predictive modeling of learners' success using various machine\nlearning methods. To build learners' and teachers' trust in such methods and\nsystems, exploring the methods and methodologies that enable relevant\nstakeholders to deeply understand the underlying machine-learning models is\nnecessary. In this context, counterfactual explanations from explainable\nmachine learning tools are promising. Several counterfactual generation methods\nhold much promise, but the features must be actionable and causal to be\neffective. Thus, obtaining which counterfactual generation method suits the\nstudent success prediction models in terms of desiderata, stability, and\nrobustness is essential. Although a few studies have been published in recent\nyears on the use of counterfactual explanations in educational sciences, they\nhave yet to discuss which counterfactual generation method is more suitable for\nthis problem. This paper analyzed the effectiveness of commonly used\ncounterfactual generation methods, such as WhatIf Counterfactual Explanations,\nMulti-Objective Counterfactual Explanations, and Nearest Instance\nCounterfactual Explanations after balancing. This contribution presents a case\nstudy using the Open University Learning Analytics dataset to demonstrate the\npractical usefulness of counterfactual explanations. The results illustrate the\nmethod's effectiveness and describe concrete steps that could be taken to alter\nthe model's prediction.",
    "arxiv_id": "http://arxiv.org/abs/2408.00676v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00676v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "ChordSync: Conformer-Based Alignment of Chord Annotations to Music Audio",
    "authors": "Andrea Poltronieri, Valentina Presutti, Mart\u00edn Rocamora",
    "abstract": "In the Western music tradition, chords are the main constituent components of\nharmony, a fundamental dimension of music. Despite its relevance for several\nMusic Information Retrieval (MIR) tasks, chord-annotated audio datasets are\nlimited and need more diversity. One way to improve those resources is to\nleverage the large number of chord annotations available online, but this\nrequires aligning them with music audio. However, existing audio-to-score\nalignment techniques, which typically rely on Dynamic Time Warping (DTW), fail\nto address this challenge, as they require weakly aligned data for precise\nsynchronisation. In this paper, we introduce ChordSync, a novel conformer-based\nmodel designed to seamlessly align chord annotations with audio, eliminating\nthe need for weak alignment. We also provide a pre-trained model and a\nuser-friendly library, enabling users to synchronise chord annotations with\naudio tracks effortlessly. In this way, ChordSync creates opportunities for\nharnessing crowd-sourced chord data for MIR, especially in audio chord\nestimation, thereby facilitating the generation of novel datasets.\nAdditionally, our system extends its utility to music education, enhancing\nmusic learning experiences by providing accurately aligned annotations, thus\nenabling learners to engage in synchronised musical practices.",
    "arxiv_id": "http://arxiv.org/abs/2408.00674v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00674v1",
    "primary_category": "cs.SD",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "AutoM3L: An Automated Multimodal Machine Learning Framework with Large Language Models",
    "authors": "Daqin Luo, Chengjian Feng, Yuxuan Nong, Yiqing Shen",
    "abstract": "Automated Machine Learning (AutoML) offers a promising approach to streamline\nthe training of machine learning models. However, existing AutoML frameworks\nare often limited to unimodal scenarios and require extensive manual\nconfiguration. Recent advancements in Large Language Models (LLMs) have\nshowcased their exceptional abilities in reasoning, interaction, and code\ngeneration, presenting an opportunity to develop a more automated and\nuser-friendly framework. To this end, we introduce AutoM3L, an innovative\nAutomated Multimodal Machine Learning framework that leverages LLMs as\ncontrollers to automatically construct multimodal training pipelines. AutoM3L\ncomprehends data modalities and selects appropriate models based on user\nrequirements, providing automation and interactivity. By eliminating the need\nfor manual feature engineering and hyperparameter optimization, our framework\nsimplifies user engagement and enables customization through directives,\naddressing the limitations of previous rule-based AutoML approaches. We\nevaluate the performance of AutoM3L on six diverse multimodal datasets spanning\nclassification, regression, and retrieval tasks, as well as a comprehensive set\nof unimodal datasets. The results demonstrate that AutoM3L achieves competitive\nor superior performance compared to traditional rule-based AutoML methods.\nFurthermore, a user study highlights the user-friendliness and usability of our\nframework, compared to the rule-based AutoML methods.",
    "arxiv_id": "http://arxiv.org/abs/2408.00665v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00665v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Aligning Multiple Knowledge Graphs in a Single Pass",
    "authors": "Yaming Yang, Zhe Wang, Ziyu Guan, Wei Zhao, Weigang Lu, Xinyan Huang",
    "abstract": "Entity alignment (EA) is to identify equivalent entities across different\nknowledge graphs (KGs), which can help fuse these KGs into a more comprehensive\none. Previous EA methods mainly focus on aligning a pair of KGs, and to the\nbest of our knowledge, no existing EA method considers aligning multiple (more\nthan two) KGs. To fill this research gap, in this work, we study a novel\nproblem of aligning multiple KGs and propose an effective framework named\nMultiEA to solve the problem. First, we embed the entities of all the candidate\nKGs into a common feature space by a shared KG encoder. Then, we explore three\nalignment strategies to minimize the distances among pre-aligned entities. In\nparticular, we propose an innovative inference enhancement technique to improve\nthe alignment performance by incorporating high-order similarities. Finally, to\nverify the effectiveness of MultiEA, we construct two new real-world benchmark\ndatasets and conduct extensive experiments on them. The results show that our\nMultiEA can effectively and efficiently align multiple KGs in a single pass.",
    "arxiv_id": "http://arxiv.org/abs/2408.00662v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00662v1",
    "primary_category": "cs.CL",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Disentangling Dense Embeddings with Sparse Autoencoders",
    "authors": "Charles O'Neill, Christine Ye, Kartheik Iyer, John F. Wu",
    "abstract": "Sparse autoencoders (SAEs) have shown promise in extracting interpretable\nfeatures from complex neural networks. We present one of the first applications\nof SAEs to dense text embeddings from large language models, demonstrating\ntheir effectiveness in disentangling semantic concepts. By training SAEs on\nembeddings of over 420,000 scientific paper abstracts from computer science and\nastronomy, we show that the resulting sparse representations maintain semantic\nfidelity while offering interpretability. We analyse these learned features,\nexploring their behaviour across different model capacities and introducing a\nnovel method for identifying ``feature families'' that represent related\nconcepts at varying levels of abstraction. To demonstrate the practical utility\nof our approach, we show how these interpretable features can be used to\nprecisely steer semantic search, allowing for fine-grained control over query\nsemantics. This work bridges the gap between the semantic richness of dense\nembeddings and the interpretability of sparse representations. We open source\nour embeddings, trained sparse autoencoders, and interpreted features, as well\nas a web app for exploring them.",
    "arxiv_id": "http://arxiv.org/abs/2408.00657v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00657v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Enhancing Multistep Prediction of Multivariate Market Indices Using Weighted Optical Reservoir Computing",
    "authors": "Fang Wang, Ting Bu, Yuping Huang",
    "abstract": "We propose and experimentally demonstrate an innovative stock index\nprediction method using a weighted optical reservoir computing system. We\nconstruct fundamental market data combined with macroeconomic data and\ntechnical indicators to capture the broader behavior of the stock market. Our\napproach shows significant higher performance than state-of-the-art methods\nsuch as linear regression, decision trees, and neural network architectures\nincluding long short-term memory. It captures well the market's high volatility\nand nonlinear behaviors despite limited data, demonstrating great potential for\nreal-time, parallel, multi-dimensional data processing and predictions.",
    "arxiv_id": "http://arxiv.org/abs/2408.00652v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00652v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Enhancing Ethereum Fraud Detection via Generative and Contrastive Self-supervision",
    "authors": "Chenxiang Jin, Jiajun Zhou, Chenxuan Xie, Shanqing Yu, Qi Xuan, Xiaoniu Yang",
    "abstract": "The rampant fraudulent activities on Ethereum hinder the healthy development\nof the blockchain ecosystem, necessitating the reinforcement of regulations.\nHowever, multiple imbalances involving account interaction frequencies and\ninteraction types in the Ethereum transaction environment pose significant\nchallenges to data mining-based fraud detection research. To address this, we\nfirst propose the concept of meta-interactions to refine interaction behaviors\nin Ethereum, and based on this, we present a dual self-supervision enhanced\nEthereum fraud detection framework, named Meta-IFD. This framework initially\nintroduces a generative self-supervision mechanism to augment the interaction\nfeatures of accounts, followed by a contrastive self-supervision mechanism to\ndifferentiate various behavior patterns, and ultimately characterizes the\nbehavioral representations of accounts and mines potential fraud risks through\nmulti-view interaction feature learning. Extensive experiments on real Ethereum\ndatasets demonstrate the effectiveness and superiority of our framework in\ndetecting common Ethereum fraud behaviors such as Ponzi schemes and phishing\nscams. Additionally, the generative module can effectively alleviate the\ninteraction distribution imbalance in Ethereum data, while the contrastive\nmodule significantly enhances the framework's ability to distinguish different\nbehavior patterns. The source code will be released on GitHub soon.",
    "arxiv_id": "http://arxiv.org/abs/2408.00641v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00641v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I'm interested in papers about LLM reasoning and scaling laws.",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters",
    "authors": "Charlie Snell, Jaehoon Lee, Kelvin Xu, Aviral Kumar",
    "abstract": "Enabling LLMs to improve their outputs by using more test-time computation is\na critical step towards building generally self-improving agents that can\noperate on open-ended natural language. In this paper, we study the scaling of\ninference-time computation in LLMs, with a focus on answering the question: if\nan LLM is allowed to use a fixed but non-trivial amount of inference-time\ncompute, how much can it improve its performance on a challenging prompt?\nAnswering this question has implications not only on the achievable performance\nof LLMs, but also on the future of LLM pretraining and how one should tradeoff\ninference-time and pre-training compute. Despite its importance, little\nresearch attempted to understand the scaling behaviors of various test-time\ninference methods. Moreover, current work largely provides negative results for\na number of these strategies. In this work, we analyze two primary mechanisms\nto scale test-time computation: (1) searching against dense, process-based\nverifier reward models; and (2) updating the model's distribution over a\nresponse adaptively, given the prompt at test time. We find that in both cases,\nthe effectiveness of different approaches to scaling test-time compute\ncritically varies depending on the difficulty of the prompt. This observation\nmotivates applying a \"compute-optimal\" scaling strategy, which acts to most\neffectively allocate test-time compute adaptively per prompt. Using this\ncompute-optimal strategy, we can improve the efficiency of test-time compute\nscaling by more than 4x compared to a best-of-N baseline. Additionally, in a\nFLOPs-matched evaluation, we find that on problems where a smaller base model\nattains somewhat non-trivial success rates, test-time compute can be used to\noutperform a 14x larger model.",
    "arxiv_id": "http://arxiv.org/abs/2408.03314v1",
    "pdf_url": "http://arxiv.org/pdf/2408.03314v1",
    "primary_category": "cs.LG",
    "votes": 1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Pre-training and in-context learning IS Bayesian inference a la De Finetti",
    "authors": "Naimeng Ye, Hanming Yang, Andrew Siah, Hongseok Namkoong",
    "abstract": "Accurately gauging uncertainty on the underlying environment is a\nlongstanding goal of intelligent systems. We characterize which latent concepts\npre-trained sequence models are naturally able to reason with. We go back to De\nFinetti's predictive view of Bayesian reasoning: instead of modeling latent\nparameters through priors and likelihoods like topic models do, De Finetti has\nlong advocated for modeling exchangeable (permutation invariant) sequences of\nobservables. According to this view, pre-training autoregressive models\nformulates informed beliefs based on prior observations (\"empirical Bayes\"),\nand forward generation is a simulated instantiation of an environment\n(\"posterior inference\"). This connection allows extending in-context learning\n(ICL) beyond predictive settings, highlighting sequence models' ability to\nperform explicit statistical inference. In particular, we show the sequence\nprediction loss over exchangeable documents controls performance on downstream\ntasks where uncertainty quantification is key. Empirically, we propose and\ndemonstrate several approaches for encoding exchangeability in sequence model\narchitectures: data augmentation, regularization, and causal masking.",
    "arxiv_id": "http://arxiv.org/abs/2408.03307v1",
    "pdf_url": "http://arxiv.org/pdf/2408.03307v1",
    "primary_category": "stat.ML",
    "votes": 1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "SARA: Singular-Value Based Adaptive Low-Rank Adaption",
    "authors": "Jihao Gu, Shuai Chen, Zelin Wang, Yibo Zhang, Ping Gong",
    "abstract": "With the increasing number of parameters in large pre-trained models, LoRA as\na parameter-efficient fine-tuning(PEFT) method is widely used for not adding\ninference overhead. The LoRA method assumes that weight changes during\nfine-tuning can be approximated by low-rank matrices. However, the rank values\nneed to be manually verified to match different downstream tasks, and they\ncannot accommodate the varying importance of different layers in the model. In\nthis work, we first analyze the relationship between the performance of\ndifferent layers and their ranks using SVD. Based on this, we design the\nSingular-Value Based Adaptive Low-Rank Adaption(SARA), which adaptively finds\nthe rank during initialization by performing SVD on the pre-trained weights.\nAdditionally, we explore the Mixture-of-SARA(Mo-SARA), which significantly\nreduces the number of parameters by fine-tuning only multiple parallel sets of\nsingular values controlled by a router. Extensive experiments on various\ncomplex tasks demonstrate the simplicity and parameter efficiency of our\nmethods. They can effectively and adaptively find the most suitable rank for\neach layer of each model.",
    "arxiv_id": "http://arxiv.org/abs/2408.03290v1",
    "pdf_url": "http://arxiv.org/pdf/2408.03290v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "StructEval: Deepen and Broaden Large Language Model Assessment via Structured Evaluation",
    "authors": "Boxi Cao, Mengjie Ren, Hongyu Lin, Xianpei Han, Feng Zhang, Junfeng Zhan, Le Sun",
    "abstract": "Evaluation is the baton for the development of large language models. Current\nevaluations typically employ a single-item assessment paradigm for each atomic\ntest objective, which struggles to discern whether a model genuinely possesses\nthe required capabilities or merely memorizes/guesses the answers to specific\nquestions. To this end, we propose a novel evaluation framework referred to as\nStructEval. Starting from an atomic test objective, StructEval deepens and\nbroadens the evaluation by conducting a structured assessment across multiple\ncognitive levels and critical concepts, and therefore offers a comprehensive,\nrobust and consistent evaluation for LLMs. Experiments on three widely-used\nbenchmarks demonstrate that StructEval serves as a reliable tool for resisting\nthe risk of data contamination and reducing the interference of potential\nbiases, thereby providing more reliable and consistent conclusions regarding\nmodel capabilities. Our framework also sheds light on the design of future\nprincipled and trustworthy LLM evaluation protocols.",
    "arxiv_id": "http://arxiv.org/abs/2408.03281v1",
    "pdf_url": "http://arxiv.org/pdf/2408.03281v1",
    "primary_category": "cs.CL",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Learning to Learn without Forgetting using Attention",
    "authors": "Anna Vettoruzzo, Joaquin Vanschoren, Mohamed-Rafik Bouguelia, Thorsteinn R\u00f6gnvaldsson",
    "abstract": "Continual learning (CL) refers to the ability to continually learn over time\nby accommodating new knowledge while retaining previously learned experience.\nWhile this concept is inherent in human learning, current machine learning\nmethods are highly prone to overwrite previously learned patterns and thus\nforget past experience. Instead, model parameters should be updated selectively\nand carefully, avoiding unnecessary forgetting while optimally leveraging\npreviously learned patterns to accelerate future learning. Since hand-crafting\neffective update mechanisms is difficult, we propose meta-learning a\ntransformer-based optimizer to enhance CL. This meta-learned optimizer uses\nattention to learn the complex relationships between model parameters across a\nstream of tasks, and is designed to generate effective weight updates for the\ncurrent task while preventing catastrophic forgetting on previously encountered\ntasks. Evaluations on benchmark datasets like SplitMNIST, RotatedMNIST, and\nSplitCIFAR-100 affirm the efficacy of the proposed approach in terms of both\nforward and backward transfer, even on small sets of labeled data, highlighting\nthe advantages of integrating a meta-learned optimizer within the continual\nlearning framework.",
    "arxiv_id": "http://arxiv.org/abs/2408.03219v1",
    "pdf_url": "http://arxiv.org/pdf/2408.03219v1",
    "primary_category": "cs.LG",
    "votes": 1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "RELIEF: Reinforcement Learning Empowered Graph Feature Prompt Tuning",
    "authors": "Jiapeng Zhu, Zichen Ding, Jianxiang Yu, Jiaqi Tan, Xiang Li, Weining Qian",
    "abstract": "The advent of the \"pre-train, prompt\" paradigm has recently extended its\ngeneralization ability and data efficiency to graph representation learning,\nfollowing its achievements in Natural Language Processing (NLP). Initial graph\nprompt tuning approaches tailored specialized prompting functions for Graph\nNeural Network (GNN) models pre-trained with specific strategies, such as edge\nprediction, thus limiting their applicability. In contrast, another pioneering\nline of research has explored universal prompting via adding prompts to the\ninput graph's feature space, thereby removing the reliance on specific\npre-training strategies. However, the necessity to add feature prompts to all\nnodes remains an open question. Motivated by findings from prompt tuning\nresearch in the NLP domain, which suggest that highly capable pre-trained\nmodels need less conditioning signal to achieve desired behaviors, we advocate\nfor strategically incorporating necessary and lightweight feature prompts to\ncertain graph nodes to enhance downstream task performance. This introduces a\ncombinatorial optimization problem, requiring a policy to decide 1) which nodes\nto prompt and 2) what specific feature prompts to attach. We then address the\nproblem by framing the prompt incorporation process as a sequential\ndecision-making problem and propose our method, RELIEF, which employs\nReinforcement Learning (RL) to optimize it. At each step, the RL agent selects\na node (discrete action) and determines the prompt content (continuous action),\naiming to maximize cumulative performance gain. Extensive experiments on graph\nand node-level tasks with various pre-training strategies in few-shot scenarios\ndemonstrate that our RELIEF outperforms fine-tuning and other prompt-based\napproaches in classification performance and data efficiency.",
    "arxiv_id": "http://arxiv.org/abs/2408.03195v1",
    "pdf_url": "http://arxiv.org/pdf/2408.03195v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Highly Efficient Self-Adaptive Reward Shaping for Reinforcement Learning",
    "authors": "Haozhe Ma, Zhengding Luo, Thanh Vinh Vo, Kuankuan Sima, Tze-Yun Leong",
    "abstract": "Reward shaping addresses the challenge of sparse rewards in reinforcement\nlearning by constructing denser and more informative reward signals. To achieve\nself-adaptive and highly efficient reward shaping, we propose a novel method\nthat incorporates success rates derived from historical experiences into shaped\nrewards. Our approach utilizes success rates sampled from Beta distributions,\nwhich dynamically evolve from uncertain to reliable values as more data is\ncollected. Initially, the self-adaptive success rates exhibit more randomness\nto encourage exploration. Over time, they become more certain to enhance\nexploitation, thus achieving a better balance between exploration and\nexploitation. We employ Kernel Density Estimation (KDE) combined with Random\nFourier Features (RFF) to derive the Beta distributions, resulting in a\ncomputationally efficient implementation in high-dimensional continuous state\nspaces. This method provides a non-parametric and learning-free approach. The\nproposed method is evaluated on a wide range of continuous control tasks with\nsparse and delayed rewards, demonstrating significant improvements in sample\nefficiency and convergence stability compared to several baselines.",
    "arxiv_id": "http://arxiv.org/abs/2408.03029v1",
    "pdf_url": "http://arxiv.org/pdf/2408.03029v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Scaling Laws for Data Poisoning in LLMs",
    "authors": "Dillon Bowen, Brendan Murphy, Will Cai, David Khachaturov, Adam Gleave, Kellin Pelrine",
    "abstract": "Recent work shows that LLMs are vulnerable to data poisoning, in which they\nare trained on partially corrupted or harmful data. Poisoned data is hard to\ndetect, breaks guardrails, and leads to undesirable and harmful behavior. Given\nthe intense efforts by leading labs to train and deploy increasingly larger and\nmore capable LLMs, it is critical to ask if the risk of data poisoning will be\nnaturally mitigated by scale, or if it is an increasing threat. We consider\nthree threat models by which data poisoning can occur: malicious fine-tuning,\nimperfect data curation, and intentional data contamination. Our experiments\nevaluate the effects of data poisoning on 23 frontier LLMs ranging from 1.5-72\nbillion parameters on three datasets which speak to each of our threat models.\nWe find that larger LLMs are increasingly vulnerable, learning harmful behavior\n-- including sleeper agent behavior -- significantly more quickly than smaller\nLLMs with even minimal data poisoning. These results underscore the need for\nrobust safeguards against data poisoning in larger LLMs.",
    "arxiv_id": "http://arxiv.org/abs/2408.02946v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02946v1",
    "primary_category": "cs.CR",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "The Need for a Big World Simulator: A Scientific Challenge for Continual Learning",
    "authors": "Saurabh Kumar, Hong Jun Jeon, Alex Lewandowski, Benjamin Van Roy",
    "abstract": "The \"small agent, big world\" frame offers a conceptual view that motivates\nthe need for continual learning. The idea is that a small agent operating in a\nmuch bigger world cannot store all information that the world has to offer. To\nperform well, the agent must be carefully designed to ingest, retain, and eject\nthe right information. To enable the development of performant continual\nlearning agents, a number of synthetic environments have been proposed.\nHowever, these benchmarks suffer from limitations, including unnatural\ndistribution shifts and a lack of fidelity to the \"small agent, big world\"\nframing. This paper aims to formalize two desiderata for the design of future\nsimulated environments. These two criteria aim to reflect the objectives and\ncomplexity of continual learning in practical settings while enabling rapid\nprototyping of algorithms on a smaller scale.",
    "arxiv_id": "http://arxiv.org/abs/2408.02930v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02930v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "HARMONIC: Harnessing LLMs for Tabular Data Synthesis and Privacy Protection",
    "authors": "Yuxin Wang, Duanyu Feng, Yongfu Dai, Zhengyu Chen, Jimin Huang, Sophia Ananiadou, Qianqian Xie, Hao Wang",
    "abstract": "Data serves as the fundamental foundation for advancing deep learning,\nparticularly tabular data presented in a structured format, which is highly\nconducive to modeling. However, even in the era of LLM, obtaining tabular data\nfrom sensitive domains remains a challenge due to privacy or copyright\nconcerns. Hence, exploring how to effectively use models like LLMs to generate\nrealistic and privacy-preserving synthetic tabular data is urgent. In this\npaper, we take a step forward to explore LLMs for tabular data synthesis and\nprivacy protection, by introducing a new framework HARMONIC for tabular data\ngeneration and evaluation. In the tabular data generation of our framework,\nunlike previous small-scale LLM-based methods that rely on continued\npre-training, we explore the larger-scale LLMs with fine-tuning to generate\ntabular data and enhance privacy. Based on idea of the k-nearest neighbors\nalgorithm, an instruction fine-tuning dataset is constructed to inspire LLMs to\ndiscover inter-row relationships. Then, with fine-tuning, LLMs are trained to\nremember the format and connections of the data rather than the data itself,\nwhich reduces the risk of privacy leakage. In the evaluation part of our\nframework, we develop specific privacy risk metrics DLT for LLM synthetic data\ngeneration, as well as performance evaluation metrics LLE for downstream LLM\ntasks. Our experiments find that this tabular data generation framework\nachieves equivalent performance to existing methods with better privacy, which\nalso demonstrates our evaluation framework for the effectiveness of synthetic\ndata and privacy risks in LLM scenarios.",
    "arxiv_id": "http://arxiv.org/abs/2408.02927v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02927v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "A Metric Driven Approach to Mixed Precision Training",
    "authors": "Mitchelle Rasquinha, Gil Tabak",
    "abstract": "As deep learning methodologies have developed, it has been generally agreed\nthat increasing neural network size improves model quality. However, this is at\nthe expense of memory and compute requirements, which also need to be\nincreased. Various efficiency techniques have been proposed to rein in hardware\ncosts, one being the use of low precision numerics. Recent accelerators have\nintroduced several different 8-bit data types to help accommodate DNNs in terms\nof numerics. In this paper, we identify a metric driven methodology to aid in\nthe choice of numerics. We demonstrate how such a methodology can help scale\ntraining of a language representation model. The technique can be generalized\nto other model architectures.",
    "arxiv_id": "http://arxiv.org/abs/2408.02897v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02897v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Compromising Embodied Agents with Contextual Backdoor Attacks",
    "authors": "Aishan Liu, Yuguang Zhou, Xianglong Liu, Tianyuan Zhang, Siyuan Liang, Jiakai Wang, Yanjun Pu, Tianlin Li, Junqi Zhang, Wenbo Zhou, Qing Guo, Dacheng Tao",
    "abstract": "Large language models (LLMs) have transformed the development of embodied\nintelligence. By providing a few contextual demonstrations, developers can\nutilize the extensive internal knowledge of LLMs to effortlessly translate\ncomplex tasks described in abstract language into sequences of code snippets,\nwhich will serve as the execution logic for embodied agents. However, this\npaper uncovers a significant backdoor security threat within this process and\nintroduces a novel method called \\method{}. By poisoning just a few contextual\ndemonstrations, attackers can covertly compromise the contextual environment of\na black-box LLM, prompting it to generate programs with context-dependent\ndefects. These programs appear logically sound but contain defects that can\nactivate and induce unintended behaviors when the operational agent encounters\nspecific triggers in its interactive environment. To compromise the LLM's\ncontextual environment, we employ adversarial in-context generation to optimize\npoisoned demonstrations, where an LLM judge evaluates these poisoned prompts,\nreporting to an additional LLM that iteratively optimizes the demonstration in\na two-player adversarial game using chain-of-thought reasoning. To enable\ncontext-dependent behaviors in downstream agents, we implement a dual-modality\nactivation strategy that controls both the generation and execution of program\ndefects through textual and visual triggers. We expand the scope of our attack\nby developing five program defect modes that compromise key aspects of\nconfidentiality, integrity, and availability in embodied agents. To validate\nthe effectiveness of our approach, we conducted extensive experiments across\nvarious tasks, including robot planning, robot manipulation, and compositional\nvisual reasoning. Additionally, we demonstrate the potential impact of our\napproach by successfully attacking real-world autonomous driving systems.",
    "arxiv_id": "http://arxiv.org/abs/2408.02882v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02882v1",
    "primary_category": "cs.AI",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "A Framework for Fine-Tuning LLMs using Heterogeneous Feedback",
    "authors": "Ryan Aponte, Ryan A. Rossi, Shunan Guo, Franck Dernoncourt, Tong Yu, Xiang Chen, Subrata Mitra, Nedim Lipka",
    "abstract": "Large language models (LLMs) have been applied to a wide range of tasks,\nincluding text summarization, web navigation, and chatbots. They have\nbenefitted from supervised fine-tuning (SFT) and reinforcement learning from\nhuman feedback (RLHF) following an unsupervised pretraining. These datasets can\nbe difficult to collect, limited in scope, and vary in sample quality.\nAdditionally, datasets can vary extensively in supervision format, from\nnumerical to binary as well as multi-dimensional with many different values. We\npresent a framework for fine-tuning LLMs using heterogeneous feedback, which\nhas two main components. First, we combine the heterogeneous feedback data into\na single supervision format, compatible with methods like SFT and RLHF. Next,\ngiven this unified feedback dataset, we extract a high-quality and diverse\nsubset to obtain performance increases potentially exceeding the full dataset.\nWe conduct extensive experiments to understand the effectiveness of these\ntechniques for incorporating heterogeneous feedback, and demonstrate\nimprovements from using a high-quality and diverse subset of the data. We find\nthat our framework is able to improve models in multiple areas simultaneously,\nsuch as in instruction following and bias reduction.",
    "arxiv_id": "http://arxiv.org/abs/2408.02861v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02861v1",
    "primary_category": "cs.CL",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "RAG Foundry: A Framework for Enhancing LLMs for Retrieval Augmented Generation",
    "authors": "Daniel Fleischer, Moshe Berchansky, Moshe Wasserblat, Peter Izsak",
    "abstract": "Implementing Retrieval-Augmented Generation (RAG) systems is inherently\ncomplex, requiring deep understanding of data, use cases, and intricate design\ndecisions. Additionally, evaluating these systems presents significant\nchallenges, necessitating assessment of both retrieval accuracy and generative\nquality through a multi-faceted approach. We introduce RAG Foundry, an\nopen-source framework for augmenting large language models for RAG use cases.\nRAG Foundry integrates data creation, training, inference and evaluation into a\nsingle workflow, facilitating the creation of data-augmented datasets for\ntraining and evaluating large language models in RAG settings. This integration\nenables rapid prototyping and experimentation with various RAG techniques,\nallowing users to easily generate datasets and train RAG models using internal\nor specialized knowledge sources. We demonstrate the framework effectiveness by\naugmenting and fine-tuning Llama-3 and Phi-3 models with diverse RAG\nconfigurations, showcasing consistent improvements across three\nknowledge-intensive datasets. Code is released as open-source in\nhttps://github.com/IntelLabs/RAGFoundry.",
    "arxiv_id": "http://arxiv.org/abs/2408.02545v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02545v1",
    "primary_category": "cs.CL",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "MDM: Advancing Multi-Domain Distribution Matching for Automatic Modulation Recognition Dataset Synthesis",
    "authors": "Dongwei Xu, Jiajun Chen, Yao Lu, Tianhao Xia, Qi Xuan, Wei Wang, Yun Lin, Xiaoniu Yang",
    "abstract": "Recently, deep learning technology has been successfully introduced into\nAutomatic Modulation Recognition (AMR) tasks. However, the success of deep\nlearning is all attributed to the training on large-scale datasets. Such a\nlarge amount of data brings huge pressure on storage, transmission and model\ntraining. In order to solve the problem of large amount of data, some\nresearchers put forward the method of data distillation, which aims to compress\nlarge training data into smaller synthetic datasets to maintain its\nperformance. While numerous data distillation techniques have been developed\nwithin the realm of image processing, the unique characteristics of signals set\nthem apart. Signals exhibit distinct features across various domains,\nnecessitating specialized approaches for their analysis and processing. To this\nend, a novel dataset distillation method--Multi-domain Distribution Matching\n(MDM) is proposed. MDM employs the Discrete Fourier Transform (DFT) to\ntranslate timedomain signals into the frequency domain, and then uses a model\nto compute distribution matching losses between the synthetic and real\ndatasets, considering both the time and frequency domains. Ultimately, these\ntwo losses are integrated to update the synthetic dataset. We conduct extensive\nexperiments on three AMR datasets. Experimental results show that, compared\nwith baseline methods, our method achieves better performance under the same\ncompression ratio. Furthermore, we conduct crossarchitecture generalization\nexperiments on several models, and the experimental results show that our\nsynthetic datasets can generalize well on other unseen models.",
    "arxiv_id": "http://arxiv.org/abs/2408.02714v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02714v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Dialogue Ontology Relation Extraction via Constrained Chain-of-Thought Decoding",
    "authors": "Renato Vukovic, David Arps, Carel van Niekerk, Benjamin Matthias Ruppik, Hsien-Chin Lin, Michael Heck, Milica Ga\u0161i\u0107",
    "abstract": "State-of-the-art task-oriented dialogue systems typically rely on\ntask-specific ontologies for fulfilling user queries. The majority of\ntask-oriented dialogue data, such as customer service recordings, comes without\nontology and annotation. Such ontologies are normally built manually, limiting\nthe application of specialised systems. Dialogue ontology construction is an\napproach for automating that process and typically consists of two steps: term\nextraction and relation extraction. In this work, we focus on relation\nextraction in a transfer learning set-up. To improve the generalisation, we\npropose an extension to the decoding mechanism of large language models. We\nadapt Chain-of-Thought (CoT) decoding, recently developed for reasoning\nproblems, to generative relation extraction. Here, we generate multiple\nbranches in the decoding space and select the relations based on a confidence\nthreshold. By constraining the decoding to ontology terms and relations, we aim\nto decrease the risk of hallucination. We conduct extensive experimentation on\ntwo widely used datasets and find improvements in performance on target\nontology for source fine-tuned and one-shot prompted large language models.",
    "arxiv_id": "http://arxiv.org/abs/2408.02361v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02361v1",
    "primary_category": "cs.CL",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "On the consistent reasoning paradox of intelligence and optimal trust in AI: The power of 'I don't know'",
    "authors": "Alexander Bastounis, Paolo Campodonico, Mihaela van der Schaar, Ben Adcock, Anders C. Hansen",
    "abstract": "We introduce the Consistent Reasoning Paradox (CRP). Consistent reasoning,\nwhich lies at the core of human intelligence, is the ability to handle tasks\nthat are equivalent, yet described by different sentences ('Tell me the time!'\nand 'What is the time?'). The CRP asserts that consistent reasoning implies\nfallibility -- in particular, human-like intelligence in AI necessarily comes\nwith human-like fallibility. Specifically, it states that there are problems,\ne.g. in basic arithmetic, where any AI that always answers and strives to mimic\nhuman intelligence by reasoning consistently will hallucinate (produce wrong,\nyet plausible answers) infinitely often. The paradox is that there exists a\nnon-consistently reasoning AI (which therefore cannot be on the level of human\nintelligence) that will be correct on the same set of problems. The CRP also\nshows that detecting these hallucinations, even in a probabilistic sense, is\nstrictly harder than solving the original problems, and that there are problems\nthat an AI may answer correctly, but it cannot provide a correct logical\nexplanation for how it arrived at the answer. Therefore, the CRP implies that\nany trustworthy AI (i.e., an AI that never answers incorrectly) that also\nreasons consistently must be able to say 'I don't know'. Moreover, this can\nonly be done by implicitly computing a new concept that we introduce, termed\nthe 'I don't know' function -- something currently lacking in modern AI. In\nview of these insights, the CRP also provides a glimpse into the behaviour of\nArtificial General Intelligence (AGI). An AGI cannot be 'almost sure', nor can\nit always explain itself, and therefore to be trustworthy it must be able to\nsay 'I don't know'.",
    "arxiv_id": "http://arxiv.org/abs/2408.02357v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02357v1",
    "primary_category": "cs.AI",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Generalized Gaussian Temporal Difference Error For Uncertainty-aware Reinforcement Learning",
    "authors": "Seyeon Kim, Joonhun Lee, Namhoon Cho, Sungjun Han, Seungeon Baek",
    "abstract": "Conventional uncertainty-aware temporal difference (TD) learning methods\noften rely on simplistic assumptions, typically including a zero-mean Gaussian\ndistribution for TD errors. Such oversimplification can lead to inaccurate\nerror representations and compromised uncertainty estimation. In this paper, we\nintroduce a novel framework for generalized Gaussian error modeling in deep\nreinforcement learning, applicable to both discrete and continuous control\nsettings. Our framework enhances the flexibility of error distribution modeling\nby incorporating higher-order moments, particularly kurtosis, thereby improving\nthe estimation and mitigation of data-dependent noise, i.e., aleatoric\nuncertainty. We examine the influence of the shape parameter of the generalized\nGaussian distribution (GGD) on aleatoric uncertainty and provide a closed-form\nexpression that demonstrates an inverse relationship between uncertainty and\nthe shape parameter. Additionally, we propose a theoretically grounded\nweighting scheme to fully leverage the GGD. To address epistemic uncertainty,\nwe enhance the batch inverse variance weighting by incorporating bias reduction\nand kurtosis considerations, resulting in improved robustness. Extensive\nexperimental evaluations using policy gradient algorithms demonstrate the\nconsistent efficacy of our method, showcasing significant performance\nimprovements.",
    "arxiv_id": "http://arxiv.org/abs/2408.02295v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02295v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "One-Shot Collaborative Data Distillation",
    "authors": "Rayne Holland, Chandra Thapa, Sarah Ali Siddiqui, Wei Shao, Seyit Camtepe",
    "abstract": "Large machine-learning training datasets can be distilled into small\ncollections of informative synthetic data samples. These synthetic sets support\nefficient model learning and reduce the communication cost of data sharing.\nThus, high-fidelity distilled data can support the efficient deployment of\nmachine learning applications in distributed network environments. A naive way\nto construct a synthetic set in a distributed environment is to allow each\nclient to perform local data distillation and to merge local distillations at a\ncentral server. However, the quality of the resulting set is impaired by\nheterogeneity in the distributions of the local data held by clients. To\novercome this challenge, we introduce the first collaborative data distillation\ntechnique, called CollabDM, which captures the global distribution of the data\nand requires only a single round of communication between client and server.\nOur method outperforms the state-of-the-art one-shot learning method on skewed\ndata in distributed learning environments. We also show the promising practical\nbenefits of our method when applied to attack detection in 5G networks.",
    "arxiv_id": "http://arxiv.org/abs/2408.02266v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02266v1",
    "primary_category": "cs.LG",
    "votes": 1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "CodeACT: Code Adaptive Compute-efficient Tuning Framework for Code LLMs",
    "authors": "Weijie Lv, Xuan Xia, Sheng-Jun Huang",
    "abstract": "Large language models (LLMs) have shown great potential in code-related\ntasks, yet open-source models lag behind their closed-source counterparts. To\nbridge this performance gap, existing methods generate vast amounts of\nsynthetic data for fine-tuning, leading to inefficiencies in training.\nMotivated by the need for more effective and efficient training, we propose the\nCode Adaptive Compute-efficient Tuning (CodeACT) framework. CodeACT introduces\nthe Complexity and Diversity Aware Sampling (CDAS) method to select\nhigh-quality training data based on complexity and diversity, and the Dynamic\nPack padding strategy to reduce computational resource usage by minimizing\npadding tokens during training. Experimental results demonstrate that\nCodeACT-DeepSeek-Coder-6.7B, fine-tuned on only 40% of the EVOL-Instruct data,\nachieves an 8.6% performance increase on HumanEval, reduces training time by\n78%, and decreases peak GPU memory usage by 27%. These findings underscore\nCodeACT's ability to enhance the performance and efficiency of open-source\nmodels. By optimizing both the data selection and training processes, CodeACT\noffers a comprehensive approach to improving the capabilities of open-source\nLLMs while significantly reducing computational requirements, addressing the\ndual challenges of data quality and training efficiency, and paving the way for\nmore resource-efficient and performant models.",
    "arxiv_id": "http://arxiv.org/abs/2408.02193v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02193v1",
    "primary_category": "cs.CL",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "ARVO: Atlas of Reproducible Vulnerabilities for Open Source Software",
    "authors": "Xiang Mei, Pulkit Singh Singaria, Jordi Del Castillo, Haoran Xi, Abdelouahab, Benchikh, Tiffany Bao, Ruoyu Wang, Yan Shoshitaishvili, Adam Doup\u00e9, Hammond Pearce, Brendan Dolan-Gavitt",
    "abstract": "High-quality datasets of real-world vulnerabilities are enormously valuable\nfor downstream research in software security, but existing datasets are\ntypically small, require extensive manual effort to update, and are missing\ncrucial features that such research needs. In this paper, we introduce ARVO: an\nAtlas of Reproducible Vulnerabilities in Open-source software. By sourcing\nvulnerabilities from C/C++ projects that Google's OSS-Fuzz discovered and\nimplementing a reliable re-compilation system, we successfully reproduce more\nthan 5,000 memory vulnerabilities across over 250 projects, each with a\ntriggering input, the canonical developer-written patch for fixing the\nvulnerability, and the ability to automatically rebuild the project from source\nand run it at its vulnerable and patched revisions. Moreover, our dataset can\nbe automatically updated as OSS-Fuzz finds new vulnerabilities, allowing it to\ngrow over time. We provide a thorough characterization of the ARVO dataset,\nshow that it can locate fixes more accurately than Google's own OSV\nreproduction effort, and demonstrate its value for future research through two\ncase studies: firstly evaluating real-world LLM-based vulnerability repair, and\nsecondly identifying over 300 falsely patched (still-active) zero-day\nvulnerabilities from projects improperly labeled by OSS-Fuzz.",
    "arxiv_id": "http://arxiv.org/abs/2408.02153v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02153v1",
    "primary_category": "cs.CR",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Generative Retrieval with Few-shot Indexing",
    "authors": "Arian Askari, Chuan Meng, Mohammad Aliannejadi, Zhaochun Ren, Evangelos Kanoulas, Suzan Verberne",
    "abstract": "Existing generative retrieval (GR) approaches rely on training-based\nindexing, i.e., fine-tuning a model to memorise the associations between a\nquery and the document identifier (docid) of a relevant document.\nTraining-based indexing has three limitations: high training overhead,\nunder-utilization of the pre-trained knowledge of large language models (LLMs),\nand challenges in adapting to a dynamic document corpus. To address the above\nissues, we propose a novel few-shot indexing-based GR framework (Few-Shot GR).\nIt has a novel few-shot indexing process, where we prompt an LLM to generate\ndocids for all documents in a corpus, ultimately creating a docid bank for the\nentire corpus. During retrieval, we feed a query to the same LLM and constrain\nit to generate a docid within the docid bank created during indexing, and then\nmap the generated docid back to its corresponding document. Few-Shot GR relies\nsolely on prompting an LLM without requiring any training, making it more\nefficient. Moreover, we devise few-shot indexing with one-to-many mapping to\nfurther enhance Few-Shot GR. Experiments show that Few-Shot GR achieves\nsuperior performance to state-of-the-art GR methods that require heavy\ntraining.",
    "arxiv_id": "http://arxiv.org/abs/2408.02152v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02152v1",
    "primary_category": "cs.IR",
    "votes": 1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "VidModEx: Interpretable and Efficient Black Box Model Extraction for High-Dimensional Spaces",
    "authors": "Somnath Sendhil Kumar, Yuvaraj Govindarajulu, Pavan Kulkarni, Manojkumar Parmar",
    "abstract": "In the domain of black-box model extraction, conventional methods reliant on\nsoft labels or surrogate datasets struggle with scaling to high-dimensional\ninput spaces and managing the complexity of an extensive array of interrelated\nclasses. In this work, we present a novel approach that utilizes SHAP (SHapley\nAdditive exPlanations) to enhance synthetic data generation. SHAP quantifies\nthe individual contributions of each input feature towards the victim model's\noutput, facilitating the optimization of an energy-based GAN towards a\ndesirable output. This method significantly boosts performance, achieving a\n16.45% increase in the accuracy of image classification models and extending to\nvideo classification models with an average improvement of 26.11% and a maximum\nof 33.36% on challenging datasets such as UCF11, UCF101, Kinetics 400, Kinetics\n600, and Something-Something V2. We further demonstrate the effectiveness and\npractical utility of our method under various scenarios, including the\navailability of top-k prediction probabilities, top-k prediction labels, and\ntop-1 labels.",
    "arxiv_id": "http://arxiv.org/abs/2408.02140v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02140v1",
    "primary_category": "cs.CV",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "MedSyn: LLM-based Synthetic Medical Text Generation Framework",
    "authors": "Gleb Kumichev, Pavel Blinov, Yulia Kuzkina, Vasily Goncharov, Galina Zubkova, Nikolai Zenovkin, Aleksei Goncharov, Andrey Savchenko",
    "abstract": "Generating synthetic text addresses the challenge of data availability in\nprivacy-sensitive domains such as healthcare. This study explores the\napplicability of synthetic data in real-world medical settings. We introduce\nMedSyn, a novel medical text generation framework that integrates large\nlanguage models with a Medical Knowledge Graph (MKG). We use MKG to sample\nprior medical information for the prompt and generate synthetic clinical notes\nwith GPT-4 and fine-tuned LLaMA models. We assess the benefit of synthetic data\nthrough application in the ICD code prediction task. Our research indicates\nthat synthetic data can increase the classification accuracy of vital and\nchallenging codes by up to 17.8% compared to settings without synthetic data.\nFurthermore, to provide new data for further research in the healthcare domain,\nwe present the largest open-source synthetic dataset of clinical notes for the\nRussian language, comprising over 41k samples covering 219 ICD-10 codes.",
    "arxiv_id": "http://arxiv.org/abs/2408.02056v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02056v1",
    "primary_category": "cs.CL",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Walk Wisely on Graph: Knowledge Graph Reasoning with Dual Agents via Efficient Guidance-Exploration",
    "authors": "Zijian Wang, Bin Wang, Haifeng Jing, Huayu Li, Hongbo Dou",
    "abstract": "Recent years, multi-hop reasoning has been widely studied for knowledge graph\n(KG) reasoning due to its efficacy and interpretability. However, previous\nmulti-hop reasoning approaches are subject to two primary shortcomings. First,\nagents struggle to learn effective and robust policies at the early phase due\nto sparse rewards. Second, these approaches often falter on specific datasets\nlike sparse knowledge graphs, where agents are required to traverse lengthy\nreasoning paths. To address these problems, we propose a multi-hop reasoning\nmodel with dual agents based on hierarchical reinforcement learning (HRL),\nwhich is named FULORA. FULORA tackles the above reasoning challenges by\neFficient GUidance-ExpLORAtion between dual agents. The high-level agent walks\non the simplified knowledge graph to provide stage-wise hints for the low-level\nagent walking on the original knowledge graph. In this framework, the low-level\nagent optimizes a value function that balances two objectives: (1) maximizing\nreturn, and (2) integrating efficient guidance from the high-level agent.\nExperiments conducted on three real-word knowledge graph datasets demonstrate\nthat FULORA outperforms RL-based baselines, especially in the case of\nlong-distance reasoning.",
    "arxiv_id": "http://arxiv.org/abs/2408.01880v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01880v1",
    "primary_category": "cs.AI",
    "votes": 1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "MALADE: Orchestration of LLM-powered Agents with Retrieval Augmented Generation for Pharmacovigilance",
    "authors": "Jihye Choi, Nils Palumbo, Prasad Chalasani, Matthew M. Engelhard, Somesh Jha, Anivarya Kumar, David Page",
    "abstract": "In the era of Large Language Models (LLMs), given their remarkable text\nunderstanding and generation abilities, there is an unprecedented opportunity\nto develop new, LLM-based methods for trustworthy medical knowledge synthesis,\nextraction and summarization. This paper focuses on the problem of\nPharmacovigilance (PhV), where the significance and challenges lie in\nidentifying Adverse Drug Events (ADEs) from diverse text sources, such as\nmedical literature, clinical notes, and drug labels. Unfortunately, this task\nis hindered by factors including variations in the terminologies of drugs and\noutcomes, and ADE descriptions often being buried in large amounts of narrative\ntext. We present MALADE, the first effective collaborative multi-agent system\npowered by LLM with Retrieval Augmented Generation for ADE extraction from drug\nlabel data. This technique involves augmenting a query to an LLM with relevant\ninformation extracted from text resources, and instructing the LLM to compose a\nresponse consistent with the augmented data. MALADE is a general LLM-agnostic\narchitecture, and its unique capabilities are: (1) leveraging a variety of\nexternal sources, such as medical literature, drug labels, and FDA tools (e.g.,\nOpenFDA drug information API), (2) extracting drug-outcome association in a\nstructured format along with the strength of the association, and (3) providing\nexplanations for established associations. Instantiated with GPT-4 Turbo or\nGPT-4o, and FDA drug label data, MALADE demonstrates its efficacy with an Area\nUnder ROC Curve of 0.90 against the OMOP Ground Truth table of ADEs. Our\nimplementation leverages the Langroid multi-agent LLM framework and can be\nfound at https://github.com/jihyechoi77/malade.",
    "arxiv_id": "http://arxiv.org/abs/2408.01869v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01869v1",
    "primary_category": "cs.CL",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Efficient Solutions For An Intriguing Failure of LLMs: Long Context Window Does Not Mean LLMs Can Analyze Long Sequences Flawlessly",
    "authors": "Peyman Hosseini, Ignacio Castro, Iacopo Ghinassi, Matthew Purver",
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\ncomprehending and analyzing lengthy sequential inputs, owing to their extensive\ncontext windows that allow processing millions of tokens in a single forward\npass. However, this paper uncovers a surprising limitation: LLMs fall short\nwhen handling long input sequences. We investigate this issue using three\ndatasets and two tasks (sentiment analysis and news categorization) across\nvarious LLMs, including Claude 3, Gemini Pro, GPT 3.5 Turbo, Llama 3 Instruct,\nand Mistral Instruct models. To address this limitation, we propose and\nevaluate ad-hoc solutions that substantially enhance LLMs' performance on long\ninput sequences by up to 50%, while reducing API cost and latency by up to 93%\nand 50%, respectively.",
    "arxiv_id": "http://arxiv.org/abs/2408.01866v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01866v1",
    "primary_category": "cs.CL",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "STBLLM: Breaking the 1-Bit Barrier with Structured Binary LLMs",
    "authors": "Peijie Dong, Lujun Li, Dayou Du, Yuhan Chen, Zhenheng Tang, Qiang Wang, Wei Xue, Wenhan Luo, Qifeng Liu, Yike Guo, Xiaowen Chu",
    "abstract": "In this paper, we present STBLLM, the first structural binarization framework\nfor compressing Large Language Models (LLMs) to less than 1-bit precision. LLMs\nhave achieved remarkable performance, but their heavy memory requirements have\nhindered widespread adoption, particularly on resource-constrained devices.\nBinarization, which quantifies weights to a mere 1-bit, achieves a milestone in\nincreasing computational efficiency. However, we observe that some weights in\nbinarized LLMs can be randomly flipped without significant performance\ndegradation, indicating the potential for further compression. To exploit this,\nour STBLLM employs an N:M sparsity to perform structural binarization of the\nweights. First, we introduce a new Standardized Importance (SI) metric that\nconsiders weight magnitude and input feature norm to better evaluate weight\nsignificance. Then, we propose a layer-wise approach where different layers of\nthe LLM can be sparsified with varying N:M ratios, balancing compression and\naccuracy. Finally, we use residual approximation with double binarization to\npreserve information for salient weights. In addition, we utilize a\nfine-grained grouping strategy for less important weights that applies\ndifferent quantization schemes to sparse, intermediate, and dense regions. We\nconduct extensive experiments on various language models, including the\nLLaMA-1/2/3, OPT family, and Mistral, to evaluate the effectiveness of STBLLM.\nThe results demonstrate that our approach performs better than other compressed\nbinarization LLM methods while significantly reducing memory requirements.",
    "arxiv_id": "http://arxiv.org/abs/2408.01803v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01803v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Can LLMs predict the convergence of Stochastic Gradient Descent?",
    "authors": "Oussama Zekri, Abdelhakim Benechehab, Ievgen Redko",
    "abstract": "Large-language models are notoriously famous for their impressive performance\nacross a wide range of tasks. One surprising example of such impressive\nperformance is a recently identified capacity of LLMs to understand the\ngoverning principles of dynamical systems satisfying the Markovian property. In\nthis paper, we seek to explore this direction further by studying the dynamics\nof stochastic gradient descent in convex and non-convex optimization. By\nleveraging the theoretical link between the SGD and Markov chains, we show a\nremarkable zero-shot performance of LLMs in predicting the local minima to\nwhich SGD converges for previously unseen starting points. On a more general\nlevel, we inquire about the possibility of using LLMs to perform zero-shot\nrandomized trials for larger deep learning models used in practice.",
    "arxiv_id": "http://arxiv.org/abs/2408.01736v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01736v1",
    "primary_category": "cs.LG",
    "votes": 1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Mission Impossible: A Statistical Perspective on Jailbreaking LLMs",
    "authors": "Jingtong Su, Julia Kempe, Karen Ullrich",
    "abstract": "Large language models (LLMs) are trained on a deluge of text data with\nlimited quality control. As a result, LLMs can exhibit unintended or even\nharmful behaviours, such as leaking information, fake news or hate speech.\nCountermeasures, commonly referred to as preference alignment, include\nfine-tuning the pretrained LLMs with carefully crafted text examples of desired\nbehaviour. Even then, empirical evidence shows preference aligned LLMs can be\nenticed to harmful behaviour. This so called jailbreaking of LLMs is typically\nachieved by adversarially modifying the input prompt to the LLM. Our paper\nprovides theoretical insights into the phenomenon of preference alignment and\njailbreaking from a statistical perspective. Under our framework, we first show\nthat pretrained LLMs will mimic harmful behaviour if present in the training\ncorpus. Under that same framework, we then introduce a statistical notion of\nalignment, and lower-bound the jailbreaking probability, showing that it is\nunpreventable under reasonable assumptions. Based on our insights, we propose\nan alteration to the currently prevalent alignment strategy RLHF. Specifically,\nwe introduce a simple modification to the RLHF objective, we call E-RLHF, that\naims to increase the likelihood of safe responses. E-RLHF brings no additional\ntraining cost, and is compatible with other methods. Empirically, we\ndemonstrate that E-RLHF outperforms RLHF on all alignment problems put forward\nby the AdvBench and HarmBench project without sacrificing model performance as\nmeasured by the MT-Bench project.",
    "arxiv_id": "http://arxiv.org/abs/2408.01420v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01420v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Talk Less, Interact Better: Evaluating In-context Conversational Adaptation in Multimodal LLMs",
    "authors": "Yilun Hua, Yoav Artzi",
    "abstract": "Humans spontaneously use increasingly efficient language as interactions\nprogress, by adapting and forming ad-hoc conventions. This phenomenon has been\nstudied extensively using reference games, showing properties of human language\nthat go beyond relaying intents. It remains unexplored whether multimodal large\nlanguage models (MLLMs) similarly increase communication efficiency during\ninteractions, and what mechanisms they may adopt for this purpose. We introduce\nICCA, an automated framework to evaluate such conversational adaptation as an\nin-context behavior in MLLMs. We evaluate several state-of-the-art MLLMs, and\nobserve that while they may understand the increasingly efficient language of\ntheir interlocutor, they do not spontaneously make their own language more\nefficient over time. This latter ability can only be elicited in some models\n(e.g., GPT-4) with heavy-handed prompting. This shows that this property of\nlinguistic interaction does not arise from current training regimes, even\nthough it is a common hallmark of human language. ICCA is available at\nhttps://github.com/lil-lab/ICCA.",
    "arxiv_id": "http://arxiv.org/abs/2408.01417v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01417v1",
    "primary_category": "cs.CL",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Conditional LoRA Parameter Generation",
    "authors": "Xiaolong Jin, Kai Wang, Dongwen Tang, Wangbo Zhao, Yukun Zhou, Junshu Tang, Yang You",
    "abstract": "Generative models have achieved remarkable success in image, video, and text\ndomains. Inspired by this, researchers have explored utilizing generative\nmodels to generate neural network parameters. However, these efforts have been\nlimited by the parameter size and the practicality of generating\nhigh-performance parameters. In this paper, we propose COND P-DIFF, a novel\napproach that demonstrates the feasibility of controllable high-performance\nparameter generation, particularly for LoRA (Low-Rank Adaptation) weights,\nduring the fine-tuning process. Specifically, we employ an autoencoder to\nextract efficient latent representations for parameters. We then train a\nconditional latent diffusion model to synthesize high-performing model\nparameters from random noise based on specific task conditions. Experimental\nresults in both computer vision and natural language processing domains\nconsistently demonstrate that COND P-DIFF can generate high-performance\nparameters conditioned on the given task. Moreover, we observe that the\nparameter distribution generated by COND P-DIFF exhibits differences compared\nto the distribution obtained through normal optimization methods, indicating a\ncertain level of generalization capability. Our work paves the way for further\nexploration of condition-driven parameter generation, offering a promising\ndirection for task-specific adaptation of neural networks.",
    "arxiv_id": "http://arxiv.org/abs/2408.01415v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01415v1",
    "primary_category": "cs.AI",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Pre-trained Language Models Improve the Few-shot Prompt Ability of Decision Transformer",
    "authors": "Yu Yang, Pan Xu",
    "abstract": "Decision Transformer (DT) has emerged as a promising class of algorithms in\noffline reinforcement learning (RL) tasks, leveraging pre-collected datasets\nand Transformer's capability to model long sequences. Recent works have\ndemonstrated that using parts of trajectories from training tasks as prompts in\nDT enhances its performance on unseen tasks, giving rise to Prompt-DT methods.\nHowever, collecting data from specific environments can be both costly and\nunsafe in many scenarios, leading to suboptimal performance and limited\nfew-shot prompt abilities due to the data-hungry nature of Transformer-based\nmodels. Additionally, the limited datasets used in pre-training make it\nchallenging for Prompt-DT type of methods to distinguish between various RL\ntasks through prompts alone. To address these challenges, we introduce the\nLanguage model-initialized Prompt Decision Transformer (LPDT), which leverages\npre-trained language models for meta-RL tasks and fine-tunes the model using\nLow-rank Adaptation (LoRA). We further incorporate prompt regularization to\neffectively differentiate between tasks based on prompt feature\nrepresentations. Our approach integrates pre-trained language model and RL\ntasks seamlessly. Extensive empirical studies demonstrate that initializing\nwith a pre-trained language model significantly enhances the performance of\nPrompt-DT on unseen tasks compared to baseline methods.",
    "arxiv_id": "http://arxiv.org/abs/2408.01402v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01402v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "TCR-GPT: Integrating Autoregressive Model and Reinforcement Learning for T-Cell Receptor Repertoires Generation",
    "authors": "Yicheng Lin, Dandan Zhang, Yun Liu",
    "abstract": "T-cell receptors (TCRs) play a crucial role in the immune system by\nrecognizing and binding to specific antigens presented by infected or cancerous\ncells. Understanding the sequence patterns of TCRs is essential for developing\ntargeted immune therapies and designing effective vaccines. Language models,\nsuch as auto-regressive transformers, offer a powerful solution to this problem\nby learning the probability distributions of TCR repertoires, enabling the\ngeneration of new TCR sequences that inherit the underlying patterns of the\nrepertoire. We introduce TCR-GPT, a probabilistic model built on a decoder-only\ntransformer architecture, designed to uncover and replicate sequence patterns\nin TCR repertoires. TCR-GPT demonstrates an accuracy of 0.953 in inferring\nsequence probability distributions measured by Pearson correlation coefficient.\nFurthermore, by leveraging Reinforcement Learning(RL), we adapted the\ndistribution of TCR sequences to generate TCRs capable of recognizing specific\npeptides, offering significant potential for advancing targeted immune\ntherapies and vaccine development. With the efficacy of RL, fine-tuned\npretrained TCR-GPT models demonstrated the ability to produce TCR repertoires\nlikely to bind specific peptides, illustrating RL's efficiency in enhancing the\nmodel's adaptability to the probability distributions of biologically relevant\nTCR sequences.",
    "arxiv_id": "http://arxiv.org/abs/2408.01156v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01156v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Tensor Train Low-rank Approximation (TT-LoRA): Democratizing AI with Accelerated LLMs",
    "authors": "Afia Anjum, Maksim E. Eren, Ismael Boureima, Boian Alexandrov, Manish Bhattarai",
    "abstract": "In recent years, Large Language Models (LLMs) have demonstrated remarkable\ncapabilities across a wide range of natural language processing (NLP) tasks,\nsuch as question-answering, sentiment analysis, text summarization, and machine\ntranslation. However, the ever-growing complexity of LLMs demands immense\ncomputational resources, hindering the broader research and application of\nthese models. To address this, various parameter-efficient fine-tuning\nstrategies, such as Low-Rank Approximation (LoRA) and Adapters, have been\ndeveloped. Despite their potential, these methods often face limitations in\ncompressibility. Specifically, LoRA struggles to scale effectively with the\nincreasing number of trainable parameters in modern large scale LLMs.\nAdditionally, Low-Rank Economic Tensor-Train Adaptation (LoRETTA), which\nutilizes tensor train decomposition, has not yet achieved the level of\ncompression necessary for fine-tuning very large scale models with limited\nresources. This paper introduces Tensor Train Low-Rank Approximation (TT-LoRA),\na novel parameter-efficient fine-tuning (PEFT) approach that extends LoRETTA\nwith optimized tensor train (TT) decomposition integration. By eliminating\nAdapters and traditional LoRA-based structures, TT-LoRA achieves greater model\ncompression without compromising downstream task performance, along with\nreduced inference latency and computational overhead. We conduct an exhaustive\nparameter search to establish benchmarks that highlight the trade-off between\nmodel compression and performance. Our results demonstrate significant\ncompression of LLMs while maintaining comparable performance to larger models,\nfacilitating their deployment on resource-constraint platforms.",
    "arxiv_id": "http://arxiv.org/abs/2408.01008v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01008v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "AgentGen: Enhancing Planning Abilities for Large Language Model based Agent via Environment and Task Generation",
    "authors": "Mengkang Hu, Pu Zhao, Can Xu, Qingfeng Sun, Jianguang Lou, Qingwei Lin, Ping Luo, Saravan Rajmohan, Dongmei Zhang",
    "abstract": "Large Language Model (LLM) based agents have garnered significant attention\nand are becoming increasingly popular. Furthermore, planning ability is a\ncrucial component of an LLM-based agent, involving interaction with the\nenvironment and executing actions to complete a planning task, which generally\nentails achieving a desired goal from an initial state. This paper investigates\nenhancing the planning abilities of LLMs through instruction tuning, referred\nto as agent training. Recent studies have demonstrated that utilizing\nexpert-level trajectory for instruction-tuning LLMs effectively enhances their\nplanning capabilities. However, existing work primarily focuses on synthesizing\ntrajectories from manually designed planning tasks and environments. The\nlabor-intensive nature of creating these environments and tasks impedes the\ngeneration of sufficiently varied and extensive trajectories. To address this\nlimitation, this paper explores the automated synthesis of diverse environments\nand a gradual range of planning tasks, from easy to difficult. We introduce a\nframework, AgentGen, that leverages LLMs first to generate environments and\nsubsequently generate planning tasks conditioned on these environments.\nSpecifically, to improve environmental diversity, we propose using an\ninspiration corpus composed of various domain-specific text segments as the\ncontext for synthesizing environments. Moreover, to increase the difficulty\ndiversity of generated planning tasks, we propose a bidirectional evolution\nmethod, Bi-Evol, that evolves planning tasks from easier and harder directions\nto synthesize a task set with a smoother difficulty curve. The evaluation\nresults derived from AgentBoard show that AgentGen greatly improves LLMs'\nplanning ability, e.g., the AgentGen instruction-tuned Llama-3 8B surpasses\nGPT-3.5 in overall performance. Moreover, in certain tasks, it even outperforms\nGPT-4.",
    "arxiv_id": "http://arxiv.org/abs/2408.00764v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00764v1",
    "primary_category": "cs.CL",
    "votes": 1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters",
    "authors": "Charlie Snell, Jaehoon Lee, Kelvin Xu, Aviral Kumar",
    "abstract": "Enabling LLMs to improve their outputs by using more test-time computation is\na critical step towards building generally self-improving agents that can\noperate on open-ended natural language. In this paper, we study the scaling of\ninference-time computation in LLMs, with a focus on answering the question: if\nan LLM is allowed to use a fixed but non-trivial amount of inference-time\ncompute, how much can it improve its performance on a challenging prompt?\nAnswering this question has implications not only on the achievable performance\nof LLMs, but also on the future of LLM pretraining and how one should tradeoff\ninference-time and pre-training compute. Despite its importance, little\nresearch attempted to understand the scaling behaviors of various test-time\ninference methods. Moreover, current work largely provides negative results for\na number of these strategies. In this work, we analyze two primary mechanisms\nto scale test-time computation: (1) searching against dense, process-based\nverifier reward models; and (2) updating the model's distribution over a\nresponse adaptively, given the prompt at test time. We find that in both cases,\nthe effectiveness of different approaches to scaling test-time compute\ncritically varies depending on the difficulty of the prompt. This observation\nmotivates applying a \"compute-optimal\" scaling strategy, which acts to most\neffectively allocate test-time compute adaptively per prompt. Using this\ncompute-optimal strategy, we can improve the efficiency of test-time compute\nscaling by more than 4x compared to a best-of-N baseline. Additionally, in a\nFLOPs-matched evaluation, we find that on problems where a smaller base model\nattains somewhat non-trivial success rates, test-time compute can be used to\noutperform a 14x larger model.",
    "arxiv_id": "http://arxiv.org/abs/2408.03314v1",
    "pdf_url": "http://arxiv.org/pdf/2408.03314v1",
    "primary_category": "cs.LG",
    "votes": 1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Pre-training and in-context learning IS Bayesian inference a la De Finetti",
    "authors": "Naimeng Ye, Hanming Yang, Andrew Siah, Hongseok Namkoong",
    "abstract": "Accurately gauging uncertainty on the underlying environment is a\nlongstanding goal of intelligent systems. We characterize which latent concepts\npre-trained sequence models are naturally able to reason with. We go back to De\nFinetti's predictive view of Bayesian reasoning: instead of modeling latent\nparameters through priors and likelihoods like topic models do, De Finetti has\nlong advocated for modeling exchangeable (permutation invariant) sequences of\nobservables. According to this view, pre-training autoregressive models\nformulates informed beliefs based on prior observations (\"empirical Bayes\"),\nand forward generation is a simulated instantiation of an environment\n(\"posterior inference\"). This connection allows extending in-context learning\n(ICL) beyond predictive settings, highlighting sequence models' ability to\nperform explicit statistical inference. In particular, we show the sequence\nprediction loss over exchangeable documents controls performance on downstream\ntasks where uncertainty quantification is key. Empirically, we propose and\ndemonstrate several approaches for encoding exchangeability in sequence model\narchitectures: data augmentation, regularization, and causal masking.",
    "arxiv_id": "http://arxiv.org/abs/2408.03307v1",
    "pdf_url": "http://arxiv.org/pdf/2408.03307v1",
    "primary_category": "stat.ML",
    "votes": 1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "SARA: Singular-Value Based Adaptive Low-Rank Adaption",
    "authors": "Jihao Gu, Shuai Chen, Zelin Wang, Yibo Zhang, Ping Gong",
    "abstract": "With the increasing number of parameters in large pre-trained models, LoRA as\na parameter-efficient fine-tuning(PEFT) method is widely used for not adding\ninference overhead. The LoRA method assumes that weight changes during\nfine-tuning can be approximated by low-rank matrices. However, the rank values\nneed to be manually verified to match different downstream tasks, and they\ncannot accommodate the varying importance of different layers in the model. In\nthis work, we first analyze the relationship between the performance of\ndifferent layers and their ranks using SVD. Based on this, we design the\nSingular-Value Based Adaptive Low-Rank Adaption(SARA), which adaptively finds\nthe rank during initialization by performing SVD on the pre-trained weights.\nAdditionally, we explore the Mixture-of-SARA(Mo-SARA), which significantly\nreduces the number of parameters by fine-tuning only multiple parallel sets of\nsingular values controlled by a router. Extensive experiments on various\ncomplex tasks demonstrate the simplicity and parameter efficiency of our\nmethods. They can effectively and adaptively find the most suitable rank for\neach layer of each model.",
    "arxiv_id": "http://arxiv.org/abs/2408.03290v1",
    "pdf_url": "http://arxiv.org/pdf/2408.03290v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "StructEval: Deepen and Broaden Large Language Model Assessment via Structured Evaluation",
    "authors": "Boxi Cao, Mengjie Ren, Hongyu Lin, Xianpei Han, Feng Zhang, Junfeng Zhan, Le Sun",
    "abstract": "Evaluation is the baton for the development of large language models. Current\nevaluations typically employ a single-item assessment paradigm for each atomic\ntest objective, which struggles to discern whether a model genuinely possesses\nthe required capabilities or merely memorizes/guesses the answers to specific\nquestions. To this end, we propose a novel evaluation framework referred to as\nStructEval. Starting from an atomic test objective, StructEval deepens and\nbroadens the evaluation by conducting a structured assessment across multiple\ncognitive levels and critical concepts, and therefore offers a comprehensive,\nrobust and consistent evaluation for LLMs. Experiments on three widely-used\nbenchmarks demonstrate that StructEval serves as a reliable tool for resisting\nthe risk of data contamination and reducing the interference of potential\nbiases, thereby providing more reliable and consistent conclusions regarding\nmodel capabilities. Our framework also sheds light on the design of future\nprincipled and trustworthy LLM evaluation protocols.",
    "arxiv_id": "http://arxiv.org/abs/2408.03281v1",
    "pdf_url": "http://arxiv.org/pdf/2408.03281v1",
    "primary_category": "cs.CL",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Learning to Learn without Forgetting using Attention",
    "authors": "Anna Vettoruzzo, Joaquin Vanschoren, Mohamed-Rafik Bouguelia, Thorsteinn R\u00f6gnvaldsson",
    "abstract": "Continual learning (CL) refers to the ability to continually learn over time\nby accommodating new knowledge while retaining previously learned experience.\nWhile this concept is inherent in human learning, current machine learning\nmethods are highly prone to overwrite previously learned patterns and thus\nforget past experience. Instead, model parameters should be updated selectively\nand carefully, avoiding unnecessary forgetting while optimally leveraging\npreviously learned patterns to accelerate future learning. Since hand-crafting\neffective update mechanisms is difficult, we propose meta-learning a\ntransformer-based optimizer to enhance CL. This meta-learned optimizer uses\nattention to learn the complex relationships between model parameters across a\nstream of tasks, and is designed to generate effective weight updates for the\ncurrent task while preventing catastrophic forgetting on previously encountered\ntasks. Evaluations on benchmark datasets like SplitMNIST, RotatedMNIST, and\nSplitCIFAR-100 affirm the efficacy of the proposed approach in terms of both\nforward and backward transfer, even on small sets of labeled data, highlighting\nthe advantages of integrating a meta-learned optimizer within the continual\nlearning framework.",
    "arxiv_id": "http://arxiv.org/abs/2408.03219v1",
    "pdf_url": "http://arxiv.org/pdf/2408.03219v1",
    "primary_category": "cs.LG",
    "votes": 1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "RELIEF: Reinforcement Learning Empowered Graph Feature Prompt Tuning",
    "authors": "Jiapeng Zhu, Zichen Ding, Jianxiang Yu, Jiaqi Tan, Xiang Li, Weining Qian",
    "abstract": "The advent of the \"pre-train, prompt\" paradigm has recently extended its\ngeneralization ability and data efficiency to graph representation learning,\nfollowing its achievements in Natural Language Processing (NLP). Initial graph\nprompt tuning approaches tailored specialized prompting functions for Graph\nNeural Network (GNN) models pre-trained with specific strategies, such as edge\nprediction, thus limiting their applicability. In contrast, another pioneering\nline of research has explored universal prompting via adding prompts to the\ninput graph's feature space, thereby removing the reliance on specific\npre-training strategies. However, the necessity to add feature prompts to all\nnodes remains an open question. Motivated by findings from prompt tuning\nresearch in the NLP domain, which suggest that highly capable pre-trained\nmodels need less conditioning signal to achieve desired behaviors, we advocate\nfor strategically incorporating necessary and lightweight feature prompts to\ncertain graph nodes to enhance downstream task performance. This introduces a\ncombinatorial optimization problem, requiring a policy to decide 1) which nodes\nto prompt and 2) what specific feature prompts to attach. We then address the\nproblem by framing the prompt incorporation process as a sequential\ndecision-making problem and propose our method, RELIEF, which employs\nReinforcement Learning (RL) to optimize it. At each step, the RL agent selects\na node (discrete action) and determines the prompt content (continuous action),\naiming to maximize cumulative performance gain. Extensive experiments on graph\nand node-level tasks with various pre-training strategies in few-shot scenarios\ndemonstrate that our RELIEF outperforms fine-tuning and other prompt-based\napproaches in classification performance and data efficiency.",
    "arxiv_id": "http://arxiv.org/abs/2408.03195v1",
    "pdf_url": "http://arxiv.org/pdf/2408.03195v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Highly Efficient Self-Adaptive Reward Shaping for Reinforcement Learning",
    "authors": "Haozhe Ma, Zhengding Luo, Thanh Vinh Vo, Kuankuan Sima, Tze-Yun Leong",
    "abstract": "Reward shaping addresses the challenge of sparse rewards in reinforcement\nlearning by constructing denser and more informative reward signals. To achieve\nself-adaptive and highly efficient reward shaping, we propose a novel method\nthat incorporates success rates derived from historical experiences into shaped\nrewards. Our approach utilizes success rates sampled from Beta distributions,\nwhich dynamically evolve from uncertain to reliable values as more data is\ncollected. Initially, the self-adaptive success rates exhibit more randomness\nto encourage exploration. Over time, they become more certain to enhance\nexploitation, thus achieving a better balance between exploration and\nexploitation. We employ Kernel Density Estimation (KDE) combined with Random\nFourier Features (RFF) to derive the Beta distributions, resulting in a\ncomputationally efficient implementation in high-dimensional continuous state\nspaces. This method provides a non-parametric and learning-free approach. The\nproposed method is evaluated on a wide range of continuous control tasks with\nsparse and delayed rewards, demonstrating significant improvements in sample\nefficiency and convergence stability compared to several baselines.",
    "arxiv_id": "http://arxiv.org/abs/2408.03029v1",
    "pdf_url": "http://arxiv.org/pdf/2408.03029v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Scaling Laws for Data Poisoning in LLMs",
    "authors": "Dillon Bowen, Brendan Murphy, Will Cai, David Khachaturov, Adam Gleave, Kellin Pelrine",
    "abstract": "Recent work shows that LLMs are vulnerable to data poisoning, in which they\nare trained on partially corrupted or harmful data. Poisoned data is hard to\ndetect, breaks guardrails, and leads to undesirable and harmful behavior. Given\nthe intense efforts by leading labs to train and deploy increasingly larger and\nmore capable LLMs, it is critical to ask if the risk of data poisoning will be\nnaturally mitigated by scale, or if it is an increasing threat. We consider\nthree threat models by which data poisoning can occur: malicious fine-tuning,\nimperfect data curation, and intentional data contamination. Our experiments\nevaluate the effects of data poisoning on 23 frontier LLMs ranging from 1.5-72\nbillion parameters on three datasets which speak to each of our threat models.\nWe find that larger LLMs are increasingly vulnerable, learning harmful behavior\n-- including sleeper agent behavior -- significantly more quickly than smaller\nLLMs with even minimal data poisoning. These results underscore the need for\nrobust safeguards against data poisoning in larger LLMs.",
    "arxiv_id": "http://arxiv.org/abs/2408.02946v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02946v1",
    "primary_category": "cs.CR",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "The Need for a Big World Simulator: A Scientific Challenge for Continual Learning",
    "authors": "Saurabh Kumar, Hong Jun Jeon, Alex Lewandowski, Benjamin Van Roy",
    "abstract": "The \"small agent, big world\" frame offers a conceptual view that motivates\nthe need for continual learning. The idea is that a small agent operating in a\nmuch bigger world cannot store all information that the world has to offer. To\nperform well, the agent must be carefully designed to ingest, retain, and eject\nthe right information. To enable the development of performant continual\nlearning agents, a number of synthetic environments have been proposed.\nHowever, these benchmarks suffer from limitations, including unnatural\ndistribution shifts and a lack of fidelity to the \"small agent, big world\"\nframing. This paper aims to formalize two desiderata for the design of future\nsimulated environments. These two criteria aim to reflect the objectives and\ncomplexity of continual learning in practical settings while enabling rapid\nprototyping of algorithms on a smaller scale.",
    "arxiv_id": "http://arxiv.org/abs/2408.02930v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02930v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "HARMONIC: Harnessing LLMs for Tabular Data Synthesis and Privacy Protection",
    "authors": "Yuxin Wang, Duanyu Feng, Yongfu Dai, Zhengyu Chen, Jimin Huang, Sophia Ananiadou, Qianqian Xie, Hao Wang",
    "abstract": "Data serves as the fundamental foundation for advancing deep learning,\nparticularly tabular data presented in a structured format, which is highly\nconducive to modeling. However, even in the era of LLM, obtaining tabular data\nfrom sensitive domains remains a challenge due to privacy or copyright\nconcerns. Hence, exploring how to effectively use models like LLMs to generate\nrealistic and privacy-preserving synthetic tabular data is urgent. In this\npaper, we take a step forward to explore LLMs for tabular data synthesis and\nprivacy protection, by introducing a new framework HARMONIC for tabular data\ngeneration and evaluation. In the tabular data generation of our framework,\nunlike previous small-scale LLM-based methods that rely on continued\npre-training, we explore the larger-scale LLMs with fine-tuning to generate\ntabular data and enhance privacy. Based on idea of the k-nearest neighbors\nalgorithm, an instruction fine-tuning dataset is constructed to inspire LLMs to\ndiscover inter-row relationships. Then, with fine-tuning, LLMs are trained to\nremember the format and connections of the data rather than the data itself,\nwhich reduces the risk of privacy leakage. In the evaluation part of our\nframework, we develop specific privacy risk metrics DLT for LLM synthetic data\ngeneration, as well as performance evaluation metrics LLE for downstream LLM\ntasks. Our experiments find that this tabular data generation framework\nachieves equivalent performance to existing methods with better privacy, which\nalso demonstrates our evaluation framework for the effectiveness of synthetic\ndata and privacy risks in LLM scenarios.",
    "arxiv_id": "http://arxiv.org/abs/2408.02927v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02927v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "A Metric Driven Approach to Mixed Precision Training",
    "authors": "Mitchelle Rasquinha, Gil Tabak",
    "abstract": "As deep learning methodologies have developed, it has been generally agreed\nthat increasing neural network size improves model quality. However, this is at\nthe expense of memory and compute requirements, which also need to be\nincreased. Various efficiency techniques have been proposed to rein in hardware\ncosts, one being the use of low precision numerics. Recent accelerators have\nintroduced several different 8-bit data types to help accommodate DNNs in terms\nof numerics. In this paper, we identify a metric driven methodology to aid in\nthe choice of numerics. We demonstrate how such a methodology can help scale\ntraining of a language representation model. The technique can be generalized\nto other model architectures.",
    "arxiv_id": "http://arxiv.org/abs/2408.02897v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02897v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Compromising Embodied Agents with Contextual Backdoor Attacks",
    "authors": "Aishan Liu, Yuguang Zhou, Xianglong Liu, Tianyuan Zhang, Siyuan Liang, Jiakai Wang, Yanjun Pu, Tianlin Li, Junqi Zhang, Wenbo Zhou, Qing Guo, Dacheng Tao",
    "abstract": "Large language models (LLMs) have transformed the development of embodied\nintelligence. By providing a few contextual demonstrations, developers can\nutilize the extensive internal knowledge of LLMs to effortlessly translate\ncomplex tasks described in abstract language into sequences of code snippets,\nwhich will serve as the execution logic for embodied agents. However, this\npaper uncovers a significant backdoor security threat within this process and\nintroduces a novel method called \\method{}. By poisoning just a few contextual\ndemonstrations, attackers can covertly compromise the contextual environment of\na black-box LLM, prompting it to generate programs with context-dependent\ndefects. These programs appear logically sound but contain defects that can\nactivate and induce unintended behaviors when the operational agent encounters\nspecific triggers in its interactive environment. To compromise the LLM's\ncontextual environment, we employ adversarial in-context generation to optimize\npoisoned demonstrations, where an LLM judge evaluates these poisoned prompts,\nreporting to an additional LLM that iteratively optimizes the demonstration in\na two-player adversarial game using chain-of-thought reasoning. To enable\ncontext-dependent behaviors in downstream agents, we implement a dual-modality\nactivation strategy that controls both the generation and execution of program\ndefects through textual and visual triggers. We expand the scope of our attack\nby developing five program defect modes that compromise key aspects of\nconfidentiality, integrity, and availability in embodied agents. To validate\nthe effectiveness of our approach, we conducted extensive experiments across\nvarious tasks, including robot planning, robot manipulation, and compositional\nvisual reasoning. Additionally, we demonstrate the potential impact of our\napproach by successfully attacking real-world autonomous driving systems.",
    "arxiv_id": "http://arxiv.org/abs/2408.02882v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02882v1",
    "primary_category": "cs.AI",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "A Framework for Fine-Tuning LLMs using Heterogeneous Feedback",
    "authors": "Ryan Aponte, Ryan A. Rossi, Shunan Guo, Franck Dernoncourt, Tong Yu, Xiang Chen, Subrata Mitra, Nedim Lipka",
    "abstract": "Large language models (LLMs) have been applied to a wide range of tasks,\nincluding text summarization, web navigation, and chatbots. They have\nbenefitted from supervised fine-tuning (SFT) and reinforcement learning from\nhuman feedback (RLHF) following an unsupervised pretraining. These datasets can\nbe difficult to collect, limited in scope, and vary in sample quality.\nAdditionally, datasets can vary extensively in supervision format, from\nnumerical to binary as well as multi-dimensional with many different values. We\npresent a framework for fine-tuning LLMs using heterogeneous feedback, which\nhas two main components. First, we combine the heterogeneous feedback data into\na single supervision format, compatible with methods like SFT and RLHF. Next,\ngiven this unified feedback dataset, we extract a high-quality and diverse\nsubset to obtain performance increases potentially exceeding the full dataset.\nWe conduct extensive experiments to understand the effectiveness of these\ntechniques for incorporating heterogeneous feedback, and demonstrate\nimprovements from using a high-quality and diverse subset of the data. We find\nthat our framework is able to improve models in multiple areas simultaneously,\nsuch as in instruction following and bias reduction.",
    "arxiv_id": "http://arxiv.org/abs/2408.02861v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02861v1",
    "primary_category": "cs.CL",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "RAG Foundry: A Framework for Enhancing LLMs for Retrieval Augmented Generation",
    "authors": "Daniel Fleischer, Moshe Berchansky, Moshe Wasserblat, Peter Izsak",
    "abstract": "Implementing Retrieval-Augmented Generation (RAG) systems is inherently\ncomplex, requiring deep understanding of data, use cases, and intricate design\ndecisions. Additionally, evaluating these systems presents significant\nchallenges, necessitating assessment of both retrieval accuracy and generative\nquality through a multi-faceted approach. We introduce RAG Foundry, an\nopen-source framework for augmenting large language models for RAG use cases.\nRAG Foundry integrates data creation, training, inference and evaluation into a\nsingle workflow, facilitating the creation of data-augmented datasets for\ntraining and evaluating large language models in RAG settings. This integration\nenables rapid prototyping and experimentation with various RAG techniques,\nallowing users to easily generate datasets and train RAG models using internal\nor specialized knowledge sources. We demonstrate the framework effectiveness by\naugmenting and fine-tuning Llama-3 and Phi-3 models with diverse RAG\nconfigurations, showcasing consistent improvements across three\nknowledge-intensive datasets. Code is released as open-source in\nhttps://github.com/IntelLabs/RAGFoundry.",
    "arxiv_id": "http://arxiv.org/abs/2408.02545v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02545v1",
    "primary_category": "cs.CL",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "MDM: Advancing Multi-Domain Distribution Matching for Automatic Modulation Recognition Dataset Synthesis",
    "authors": "Dongwei Xu, Jiajun Chen, Yao Lu, Tianhao Xia, Qi Xuan, Wei Wang, Yun Lin, Xiaoniu Yang",
    "abstract": "Recently, deep learning technology has been successfully introduced into\nAutomatic Modulation Recognition (AMR) tasks. However, the success of deep\nlearning is all attributed to the training on large-scale datasets. Such a\nlarge amount of data brings huge pressure on storage, transmission and model\ntraining. In order to solve the problem of large amount of data, some\nresearchers put forward the method of data distillation, which aims to compress\nlarge training data into smaller synthetic datasets to maintain its\nperformance. While numerous data distillation techniques have been developed\nwithin the realm of image processing, the unique characteristics of signals set\nthem apart. Signals exhibit distinct features across various domains,\nnecessitating specialized approaches for their analysis and processing. To this\nend, a novel dataset distillation method--Multi-domain Distribution Matching\n(MDM) is proposed. MDM employs the Discrete Fourier Transform (DFT) to\ntranslate timedomain signals into the frequency domain, and then uses a model\nto compute distribution matching losses between the synthetic and real\ndatasets, considering both the time and frequency domains. Ultimately, these\ntwo losses are integrated to update the synthetic dataset. We conduct extensive\nexperiments on three AMR datasets. Experimental results show that, compared\nwith baseline methods, our method achieves better performance under the same\ncompression ratio. Furthermore, we conduct crossarchitecture generalization\nexperiments on several models, and the experimental results show that our\nsynthetic datasets can generalize well on other unseen models.",
    "arxiv_id": "http://arxiv.org/abs/2408.02714v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02714v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Dialogue Ontology Relation Extraction via Constrained Chain-of-Thought Decoding",
    "authors": "Renato Vukovic, David Arps, Carel van Niekerk, Benjamin Matthias Ruppik, Hsien-Chin Lin, Michael Heck, Milica Ga\u0161i\u0107",
    "abstract": "State-of-the-art task-oriented dialogue systems typically rely on\ntask-specific ontologies for fulfilling user queries. The majority of\ntask-oriented dialogue data, such as customer service recordings, comes without\nontology and annotation. Such ontologies are normally built manually, limiting\nthe application of specialised systems. Dialogue ontology construction is an\napproach for automating that process and typically consists of two steps: term\nextraction and relation extraction. In this work, we focus on relation\nextraction in a transfer learning set-up. To improve the generalisation, we\npropose an extension to the decoding mechanism of large language models. We\nadapt Chain-of-Thought (CoT) decoding, recently developed for reasoning\nproblems, to generative relation extraction. Here, we generate multiple\nbranches in the decoding space and select the relations based on a confidence\nthreshold. By constraining the decoding to ontology terms and relations, we aim\nto decrease the risk of hallucination. We conduct extensive experimentation on\ntwo widely used datasets and find improvements in performance on target\nontology for source fine-tuned and one-shot prompted large language models.",
    "arxiv_id": "http://arxiv.org/abs/2408.02361v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02361v1",
    "primary_category": "cs.CL",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "On the consistent reasoning paradox of intelligence and optimal trust in AI: The power of 'I don't know'",
    "authors": "Alexander Bastounis, Paolo Campodonico, Mihaela van der Schaar, Ben Adcock, Anders C. Hansen",
    "abstract": "We introduce the Consistent Reasoning Paradox (CRP). Consistent reasoning,\nwhich lies at the core of human intelligence, is the ability to handle tasks\nthat are equivalent, yet described by different sentences ('Tell me the time!'\nand 'What is the time?'). The CRP asserts that consistent reasoning implies\nfallibility -- in particular, human-like intelligence in AI necessarily comes\nwith human-like fallibility. Specifically, it states that there are problems,\ne.g. in basic arithmetic, where any AI that always answers and strives to mimic\nhuman intelligence by reasoning consistently will hallucinate (produce wrong,\nyet plausible answers) infinitely often. The paradox is that there exists a\nnon-consistently reasoning AI (which therefore cannot be on the level of human\nintelligence) that will be correct on the same set of problems. The CRP also\nshows that detecting these hallucinations, even in a probabilistic sense, is\nstrictly harder than solving the original problems, and that there are problems\nthat an AI may answer correctly, but it cannot provide a correct logical\nexplanation for how it arrived at the answer. Therefore, the CRP implies that\nany trustworthy AI (i.e., an AI that never answers incorrectly) that also\nreasons consistently must be able to say 'I don't know'. Moreover, this can\nonly be done by implicitly computing a new concept that we introduce, termed\nthe 'I don't know' function -- something currently lacking in modern AI. In\nview of these insights, the CRP also provides a glimpse into the behaviour of\nArtificial General Intelligence (AGI). An AGI cannot be 'almost sure', nor can\nit always explain itself, and therefore to be trustworthy it must be able to\nsay 'I don't know'.",
    "arxiv_id": "http://arxiv.org/abs/2408.02357v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02357v1",
    "primary_category": "cs.AI",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Generalized Gaussian Temporal Difference Error For Uncertainty-aware Reinforcement Learning",
    "authors": "Seyeon Kim, Joonhun Lee, Namhoon Cho, Sungjun Han, Seungeon Baek",
    "abstract": "Conventional uncertainty-aware temporal difference (TD) learning methods\noften rely on simplistic assumptions, typically including a zero-mean Gaussian\ndistribution for TD errors. Such oversimplification can lead to inaccurate\nerror representations and compromised uncertainty estimation. In this paper, we\nintroduce a novel framework for generalized Gaussian error modeling in deep\nreinforcement learning, applicable to both discrete and continuous control\nsettings. Our framework enhances the flexibility of error distribution modeling\nby incorporating higher-order moments, particularly kurtosis, thereby improving\nthe estimation and mitigation of data-dependent noise, i.e., aleatoric\nuncertainty. We examine the influence of the shape parameter of the generalized\nGaussian distribution (GGD) on aleatoric uncertainty and provide a closed-form\nexpression that demonstrates an inverse relationship between uncertainty and\nthe shape parameter. Additionally, we propose a theoretically grounded\nweighting scheme to fully leverage the GGD. To address epistemic uncertainty,\nwe enhance the batch inverse variance weighting by incorporating bias reduction\nand kurtosis considerations, resulting in improved robustness. Extensive\nexperimental evaluations using policy gradient algorithms demonstrate the\nconsistent efficacy of our method, showcasing significant performance\nimprovements.",
    "arxiv_id": "http://arxiv.org/abs/2408.02295v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02295v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "One-Shot Collaborative Data Distillation",
    "authors": "Rayne Holland, Chandra Thapa, Sarah Ali Siddiqui, Wei Shao, Seyit Camtepe",
    "abstract": "Large machine-learning training datasets can be distilled into small\ncollections of informative synthetic data samples. These synthetic sets support\nefficient model learning and reduce the communication cost of data sharing.\nThus, high-fidelity distilled data can support the efficient deployment of\nmachine learning applications in distributed network environments. A naive way\nto construct a synthetic set in a distributed environment is to allow each\nclient to perform local data distillation and to merge local distillations at a\ncentral server. However, the quality of the resulting set is impaired by\nheterogeneity in the distributions of the local data held by clients. To\novercome this challenge, we introduce the first collaborative data distillation\ntechnique, called CollabDM, which captures the global distribution of the data\nand requires only a single round of communication between client and server.\nOur method outperforms the state-of-the-art one-shot learning method on skewed\ndata in distributed learning environments. We also show the promising practical\nbenefits of our method when applied to attack detection in 5G networks.",
    "arxiv_id": "http://arxiv.org/abs/2408.02266v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02266v1",
    "primary_category": "cs.LG",
    "votes": 1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "CodeACT: Code Adaptive Compute-efficient Tuning Framework for Code LLMs",
    "authors": "Weijie Lv, Xuan Xia, Sheng-Jun Huang",
    "abstract": "Large language models (LLMs) have shown great potential in code-related\ntasks, yet open-source models lag behind their closed-source counterparts. To\nbridge this performance gap, existing methods generate vast amounts of\nsynthetic data for fine-tuning, leading to inefficiencies in training.\nMotivated by the need for more effective and efficient training, we propose the\nCode Adaptive Compute-efficient Tuning (CodeACT) framework. CodeACT introduces\nthe Complexity and Diversity Aware Sampling (CDAS) method to select\nhigh-quality training data based on complexity and diversity, and the Dynamic\nPack padding strategy to reduce computational resource usage by minimizing\npadding tokens during training. Experimental results demonstrate that\nCodeACT-DeepSeek-Coder-6.7B, fine-tuned on only 40% of the EVOL-Instruct data,\nachieves an 8.6% performance increase on HumanEval, reduces training time by\n78%, and decreases peak GPU memory usage by 27%. These findings underscore\nCodeACT's ability to enhance the performance and efficiency of open-source\nmodels. By optimizing both the data selection and training processes, CodeACT\noffers a comprehensive approach to improving the capabilities of open-source\nLLMs while significantly reducing computational requirements, addressing the\ndual challenges of data quality and training efficiency, and paving the way for\nmore resource-efficient and performant models.",
    "arxiv_id": "http://arxiv.org/abs/2408.02193v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02193v1",
    "primary_category": "cs.CL",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "ARVO: Atlas of Reproducible Vulnerabilities for Open Source Software",
    "authors": "Xiang Mei, Pulkit Singh Singaria, Jordi Del Castillo, Haoran Xi, Abdelouahab, Benchikh, Tiffany Bao, Ruoyu Wang, Yan Shoshitaishvili, Adam Doup\u00e9, Hammond Pearce, Brendan Dolan-Gavitt",
    "abstract": "High-quality datasets of real-world vulnerabilities are enormously valuable\nfor downstream research in software security, but existing datasets are\ntypically small, require extensive manual effort to update, and are missing\ncrucial features that such research needs. In this paper, we introduce ARVO: an\nAtlas of Reproducible Vulnerabilities in Open-source software. By sourcing\nvulnerabilities from C/C++ projects that Google's OSS-Fuzz discovered and\nimplementing a reliable re-compilation system, we successfully reproduce more\nthan 5,000 memory vulnerabilities across over 250 projects, each with a\ntriggering input, the canonical developer-written patch for fixing the\nvulnerability, and the ability to automatically rebuild the project from source\nand run it at its vulnerable and patched revisions. Moreover, our dataset can\nbe automatically updated as OSS-Fuzz finds new vulnerabilities, allowing it to\ngrow over time. We provide a thorough characterization of the ARVO dataset,\nshow that it can locate fixes more accurately than Google's own OSV\nreproduction effort, and demonstrate its value for future research through two\ncase studies: firstly evaluating real-world LLM-based vulnerability repair, and\nsecondly identifying over 300 falsely patched (still-active) zero-day\nvulnerabilities from projects improperly labeled by OSS-Fuzz.",
    "arxiv_id": "http://arxiv.org/abs/2408.02153v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02153v1",
    "primary_category": "cs.CR",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Generative Retrieval with Few-shot Indexing",
    "authors": "Arian Askari, Chuan Meng, Mohammad Aliannejadi, Zhaochun Ren, Evangelos Kanoulas, Suzan Verberne",
    "abstract": "Existing generative retrieval (GR) approaches rely on training-based\nindexing, i.e., fine-tuning a model to memorise the associations between a\nquery and the document identifier (docid) of a relevant document.\nTraining-based indexing has three limitations: high training overhead,\nunder-utilization of the pre-trained knowledge of large language models (LLMs),\nand challenges in adapting to a dynamic document corpus. To address the above\nissues, we propose a novel few-shot indexing-based GR framework (Few-Shot GR).\nIt has a novel few-shot indexing process, where we prompt an LLM to generate\ndocids for all documents in a corpus, ultimately creating a docid bank for the\nentire corpus. During retrieval, we feed a query to the same LLM and constrain\nit to generate a docid within the docid bank created during indexing, and then\nmap the generated docid back to its corresponding document. Few-Shot GR relies\nsolely on prompting an LLM without requiring any training, making it more\nefficient. Moreover, we devise few-shot indexing with one-to-many mapping to\nfurther enhance Few-Shot GR. Experiments show that Few-Shot GR achieves\nsuperior performance to state-of-the-art GR methods that require heavy\ntraining.",
    "arxiv_id": "http://arxiv.org/abs/2408.02152v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02152v1",
    "primary_category": "cs.IR",
    "votes": 1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "VidModEx: Interpretable and Efficient Black Box Model Extraction for High-Dimensional Spaces",
    "authors": "Somnath Sendhil Kumar, Yuvaraj Govindarajulu, Pavan Kulkarni, Manojkumar Parmar",
    "abstract": "In the domain of black-box model extraction, conventional methods reliant on\nsoft labels or surrogate datasets struggle with scaling to high-dimensional\ninput spaces and managing the complexity of an extensive array of interrelated\nclasses. In this work, we present a novel approach that utilizes SHAP (SHapley\nAdditive exPlanations) to enhance synthetic data generation. SHAP quantifies\nthe individual contributions of each input feature towards the victim model's\noutput, facilitating the optimization of an energy-based GAN towards a\ndesirable output. This method significantly boosts performance, achieving a\n16.45% increase in the accuracy of image classification models and extending to\nvideo classification models with an average improvement of 26.11% and a maximum\nof 33.36% on challenging datasets such as UCF11, UCF101, Kinetics 400, Kinetics\n600, and Something-Something V2. We further demonstrate the effectiveness and\npractical utility of our method under various scenarios, including the\navailability of top-k prediction probabilities, top-k prediction labels, and\ntop-1 labels.",
    "arxiv_id": "http://arxiv.org/abs/2408.02140v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02140v1",
    "primary_category": "cs.CV",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "MedSyn: LLM-based Synthetic Medical Text Generation Framework",
    "authors": "Gleb Kumichev, Pavel Blinov, Yulia Kuzkina, Vasily Goncharov, Galina Zubkova, Nikolai Zenovkin, Aleksei Goncharov, Andrey Savchenko",
    "abstract": "Generating synthetic text addresses the challenge of data availability in\nprivacy-sensitive domains such as healthcare. This study explores the\napplicability of synthetic data in real-world medical settings. We introduce\nMedSyn, a novel medical text generation framework that integrates large\nlanguage models with a Medical Knowledge Graph (MKG). We use MKG to sample\nprior medical information for the prompt and generate synthetic clinical notes\nwith GPT-4 and fine-tuned LLaMA models. We assess the benefit of synthetic data\nthrough application in the ICD code prediction task. Our research indicates\nthat synthetic data can increase the classification accuracy of vital and\nchallenging codes by up to 17.8% compared to settings without synthetic data.\nFurthermore, to provide new data for further research in the healthcare domain,\nwe present the largest open-source synthetic dataset of clinical notes for the\nRussian language, comprising over 41k samples covering 219 ICD-10 codes.",
    "arxiv_id": "http://arxiv.org/abs/2408.02056v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02056v1",
    "primary_category": "cs.CL",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Walk Wisely on Graph: Knowledge Graph Reasoning with Dual Agents via Efficient Guidance-Exploration",
    "authors": "Zijian Wang, Bin Wang, Haifeng Jing, Huayu Li, Hongbo Dou",
    "abstract": "Recent years, multi-hop reasoning has been widely studied for knowledge graph\n(KG) reasoning due to its efficacy and interpretability. However, previous\nmulti-hop reasoning approaches are subject to two primary shortcomings. First,\nagents struggle to learn effective and robust policies at the early phase due\nto sparse rewards. Second, these approaches often falter on specific datasets\nlike sparse knowledge graphs, where agents are required to traverse lengthy\nreasoning paths. To address these problems, we propose a multi-hop reasoning\nmodel with dual agents based on hierarchical reinforcement learning (HRL),\nwhich is named FULORA. FULORA tackles the above reasoning challenges by\neFficient GUidance-ExpLORAtion between dual agents. The high-level agent walks\non the simplified knowledge graph to provide stage-wise hints for the low-level\nagent walking on the original knowledge graph. In this framework, the low-level\nagent optimizes a value function that balances two objectives: (1) maximizing\nreturn, and (2) integrating efficient guidance from the high-level agent.\nExperiments conducted on three real-word knowledge graph datasets demonstrate\nthat FULORA outperforms RL-based baselines, especially in the case of\nlong-distance reasoning.",
    "arxiv_id": "http://arxiv.org/abs/2408.01880v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01880v1",
    "primary_category": "cs.AI",
    "votes": 1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "MALADE: Orchestration of LLM-powered Agents with Retrieval Augmented Generation for Pharmacovigilance",
    "authors": "Jihye Choi, Nils Palumbo, Prasad Chalasani, Matthew M. Engelhard, Somesh Jha, Anivarya Kumar, David Page",
    "abstract": "In the era of Large Language Models (LLMs), given their remarkable text\nunderstanding and generation abilities, there is an unprecedented opportunity\nto develop new, LLM-based methods for trustworthy medical knowledge synthesis,\nextraction and summarization. This paper focuses on the problem of\nPharmacovigilance (PhV), where the significance and challenges lie in\nidentifying Adverse Drug Events (ADEs) from diverse text sources, such as\nmedical literature, clinical notes, and drug labels. Unfortunately, this task\nis hindered by factors including variations in the terminologies of drugs and\noutcomes, and ADE descriptions often being buried in large amounts of narrative\ntext. We present MALADE, the first effective collaborative multi-agent system\npowered by LLM with Retrieval Augmented Generation for ADE extraction from drug\nlabel data. This technique involves augmenting a query to an LLM with relevant\ninformation extracted from text resources, and instructing the LLM to compose a\nresponse consistent with the augmented data. MALADE is a general LLM-agnostic\narchitecture, and its unique capabilities are: (1) leveraging a variety of\nexternal sources, such as medical literature, drug labels, and FDA tools (e.g.,\nOpenFDA drug information API), (2) extracting drug-outcome association in a\nstructured format along with the strength of the association, and (3) providing\nexplanations for established associations. Instantiated with GPT-4 Turbo or\nGPT-4o, and FDA drug label data, MALADE demonstrates its efficacy with an Area\nUnder ROC Curve of 0.90 against the OMOP Ground Truth table of ADEs. Our\nimplementation leverages the Langroid multi-agent LLM framework and can be\nfound at https://github.com/jihyechoi77/malade.",
    "arxiv_id": "http://arxiv.org/abs/2408.01869v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01869v1",
    "primary_category": "cs.CL",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Efficient Solutions For An Intriguing Failure of LLMs: Long Context Window Does Not Mean LLMs Can Analyze Long Sequences Flawlessly",
    "authors": "Peyman Hosseini, Ignacio Castro, Iacopo Ghinassi, Matthew Purver",
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\ncomprehending and analyzing lengthy sequential inputs, owing to their extensive\ncontext windows that allow processing millions of tokens in a single forward\npass. However, this paper uncovers a surprising limitation: LLMs fall short\nwhen handling long input sequences. We investigate this issue using three\ndatasets and two tasks (sentiment analysis and news categorization) across\nvarious LLMs, including Claude 3, Gemini Pro, GPT 3.5 Turbo, Llama 3 Instruct,\nand Mistral Instruct models. To address this limitation, we propose and\nevaluate ad-hoc solutions that substantially enhance LLMs' performance on long\ninput sequences by up to 50%, while reducing API cost and latency by up to 93%\nand 50%, respectively.",
    "arxiv_id": "http://arxiv.org/abs/2408.01866v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01866v1",
    "primary_category": "cs.CL",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "STBLLM: Breaking the 1-Bit Barrier with Structured Binary LLMs",
    "authors": "Peijie Dong, Lujun Li, Dayou Du, Yuhan Chen, Zhenheng Tang, Qiang Wang, Wei Xue, Wenhan Luo, Qifeng Liu, Yike Guo, Xiaowen Chu",
    "abstract": "In this paper, we present STBLLM, the first structural binarization framework\nfor compressing Large Language Models (LLMs) to less than 1-bit precision. LLMs\nhave achieved remarkable performance, but their heavy memory requirements have\nhindered widespread adoption, particularly on resource-constrained devices.\nBinarization, which quantifies weights to a mere 1-bit, achieves a milestone in\nincreasing computational efficiency. However, we observe that some weights in\nbinarized LLMs can be randomly flipped without significant performance\ndegradation, indicating the potential for further compression. To exploit this,\nour STBLLM employs an N:M sparsity to perform structural binarization of the\nweights. First, we introduce a new Standardized Importance (SI) metric that\nconsiders weight magnitude and input feature norm to better evaluate weight\nsignificance. Then, we propose a layer-wise approach where different layers of\nthe LLM can be sparsified with varying N:M ratios, balancing compression and\naccuracy. Finally, we use residual approximation with double binarization to\npreserve information for salient weights. In addition, we utilize a\nfine-grained grouping strategy for less important weights that applies\ndifferent quantization schemes to sparse, intermediate, and dense regions. We\nconduct extensive experiments on various language models, including the\nLLaMA-1/2/3, OPT family, and Mistral, to evaluate the effectiveness of STBLLM.\nThe results demonstrate that our approach performs better than other compressed\nbinarization LLM methods while significantly reducing memory requirements.",
    "arxiv_id": "http://arxiv.org/abs/2408.01803v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01803v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Can LLMs predict the convergence of Stochastic Gradient Descent?",
    "authors": "Oussama Zekri, Abdelhakim Benechehab, Ievgen Redko",
    "abstract": "Large-language models are notoriously famous for their impressive performance\nacross a wide range of tasks. One surprising example of such impressive\nperformance is a recently identified capacity of LLMs to understand the\ngoverning principles of dynamical systems satisfying the Markovian property. In\nthis paper, we seek to explore this direction further by studying the dynamics\nof stochastic gradient descent in convex and non-convex optimization. By\nleveraging the theoretical link between the SGD and Markov chains, we show a\nremarkable zero-shot performance of LLMs in predicting the local minima to\nwhich SGD converges for previously unseen starting points. On a more general\nlevel, we inquire about the possibility of using LLMs to perform zero-shot\nrandomized trials for larger deep learning models used in practice.",
    "arxiv_id": "http://arxiv.org/abs/2408.01736v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01736v1",
    "primary_category": "cs.LG",
    "votes": 1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Mission Impossible: A Statistical Perspective on Jailbreaking LLMs",
    "authors": "Jingtong Su, Julia Kempe, Karen Ullrich",
    "abstract": "Large language models (LLMs) are trained on a deluge of text data with\nlimited quality control. As a result, LLMs can exhibit unintended or even\nharmful behaviours, such as leaking information, fake news or hate speech.\nCountermeasures, commonly referred to as preference alignment, include\nfine-tuning the pretrained LLMs with carefully crafted text examples of desired\nbehaviour. Even then, empirical evidence shows preference aligned LLMs can be\nenticed to harmful behaviour. This so called jailbreaking of LLMs is typically\nachieved by adversarially modifying the input prompt to the LLM. Our paper\nprovides theoretical insights into the phenomenon of preference alignment and\njailbreaking from a statistical perspective. Under our framework, we first show\nthat pretrained LLMs will mimic harmful behaviour if present in the training\ncorpus. Under that same framework, we then introduce a statistical notion of\nalignment, and lower-bound the jailbreaking probability, showing that it is\nunpreventable under reasonable assumptions. Based on our insights, we propose\nan alteration to the currently prevalent alignment strategy RLHF. Specifically,\nwe introduce a simple modification to the RLHF objective, we call E-RLHF, that\naims to increase the likelihood of safe responses. E-RLHF brings no additional\ntraining cost, and is compatible with other methods. Empirically, we\ndemonstrate that E-RLHF outperforms RLHF on all alignment problems put forward\nby the AdvBench and HarmBench project without sacrificing model performance as\nmeasured by the MT-Bench project.",
    "arxiv_id": "http://arxiv.org/abs/2408.01420v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01420v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Talk Less, Interact Better: Evaluating In-context Conversational Adaptation in Multimodal LLMs",
    "authors": "Yilun Hua, Yoav Artzi",
    "abstract": "Humans spontaneously use increasingly efficient language as interactions\nprogress, by adapting and forming ad-hoc conventions. This phenomenon has been\nstudied extensively using reference games, showing properties of human language\nthat go beyond relaying intents. It remains unexplored whether multimodal large\nlanguage models (MLLMs) similarly increase communication efficiency during\ninteractions, and what mechanisms they may adopt for this purpose. We introduce\nICCA, an automated framework to evaluate such conversational adaptation as an\nin-context behavior in MLLMs. We evaluate several state-of-the-art MLLMs, and\nobserve that while they may understand the increasingly efficient language of\ntheir interlocutor, they do not spontaneously make their own language more\nefficient over time. This latter ability can only be elicited in some models\n(e.g., GPT-4) with heavy-handed prompting. This shows that this property of\nlinguistic interaction does not arise from current training regimes, even\nthough it is a common hallmark of human language. ICCA is available at\nhttps://github.com/lil-lab/ICCA.",
    "arxiv_id": "http://arxiv.org/abs/2408.01417v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01417v1",
    "primary_category": "cs.CL",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Conditional LoRA Parameter Generation",
    "authors": "Xiaolong Jin, Kai Wang, Dongwen Tang, Wangbo Zhao, Yukun Zhou, Junshu Tang, Yang You",
    "abstract": "Generative models have achieved remarkable success in image, video, and text\ndomains. Inspired by this, researchers have explored utilizing generative\nmodels to generate neural network parameters. However, these efforts have been\nlimited by the parameter size and the practicality of generating\nhigh-performance parameters. In this paper, we propose COND P-DIFF, a novel\napproach that demonstrates the feasibility of controllable high-performance\nparameter generation, particularly for LoRA (Low-Rank Adaptation) weights,\nduring the fine-tuning process. Specifically, we employ an autoencoder to\nextract efficient latent representations for parameters. We then train a\nconditional latent diffusion model to synthesize high-performing model\nparameters from random noise based on specific task conditions. Experimental\nresults in both computer vision and natural language processing domains\nconsistently demonstrate that COND P-DIFF can generate high-performance\nparameters conditioned on the given task. Moreover, we observe that the\nparameter distribution generated by COND P-DIFF exhibits differences compared\nto the distribution obtained through normal optimization methods, indicating a\ncertain level of generalization capability. Our work paves the way for further\nexploration of condition-driven parameter generation, offering a promising\ndirection for task-specific adaptation of neural networks.",
    "arxiv_id": "http://arxiv.org/abs/2408.01415v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01415v1",
    "primary_category": "cs.AI",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Pre-trained Language Models Improve the Few-shot Prompt Ability of Decision Transformer",
    "authors": "Yu Yang, Pan Xu",
    "abstract": "Decision Transformer (DT) has emerged as a promising class of algorithms in\noffline reinforcement learning (RL) tasks, leveraging pre-collected datasets\nand Transformer's capability to model long sequences. Recent works have\ndemonstrated that using parts of trajectories from training tasks as prompts in\nDT enhances its performance on unseen tasks, giving rise to Prompt-DT methods.\nHowever, collecting data from specific environments can be both costly and\nunsafe in many scenarios, leading to suboptimal performance and limited\nfew-shot prompt abilities due to the data-hungry nature of Transformer-based\nmodels. Additionally, the limited datasets used in pre-training make it\nchallenging for Prompt-DT type of methods to distinguish between various RL\ntasks through prompts alone. To address these challenges, we introduce the\nLanguage model-initialized Prompt Decision Transformer (LPDT), which leverages\npre-trained language models for meta-RL tasks and fine-tunes the model using\nLow-rank Adaptation (LoRA). We further incorporate prompt regularization to\neffectively differentiate between tasks based on prompt feature\nrepresentations. Our approach integrates pre-trained language model and RL\ntasks seamlessly. Extensive empirical studies demonstrate that initializing\nwith a pre-trained language model significantly enhances the performance of\nPrompt-DT on unseen tasks compared to baseline methods.",
    "arxiv_id": "http://arxiv.org/abs/2408.01402v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01402v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "TCR-GPT: Integrating Autoregressive Model and Reinforcement Learning for T-Cell Receptor Repertoires Generation",
    "authors": "Yicheng Lin, Dandan Zhang, Yun Liu",
    "abstract": "T-cell receptors (TCRs) play a crucial role in the immune system by\nrecognizing and binding to specific antigens presented by infected or cancerous\ncells. Understanding the sequence patterns of TCRs is essential for developing\ntargeted immune therapies and designing effective vaccines. Language models,\nsuch as auto-regressive transformers, offer a powerful solution to this problem\nby learning the probability distributions of TCR repertoires, enabling the\ngeneration of new TCR sequences that inherit the underlying patterns of the\nrepertoire. We introduce TCR-GPT, a probabilistic model built on a decoder-only\ntransformer architecture, designed to uncover and replicate sequence patterns\nin TCR repertoires. TCR-GPT demonstrates an accuracy of 0.953 in inferring\nsequence probability distributions measured by Pearson correlation coefficient.\nFurthermore, by leveraging Reinforcement Learning(RL), we adapted the\ndistribution of TCR sequences to generate TCRs capable of recognizing specific\npeptides, offering significant potential for advancing targeted immune\ntherapies and vaccine development. With the efficacy of RL, fine-tuned\npretrained TCR-GPT models demonstrated the ability to produce TCR repertoires\nlikely to bind specific peptides, illustrating RL's efficiency in enhancing the\nmodel's adaptability to the probability distributions of biologically relevant\nTCR sequences.",
    "arxiv_id": "http://arxiv.org/abs/2408.01156v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01156v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Tensor Train Low-rank Approximation (TT-LoRA): Democratizing AI with Accelerated LLMs",
    "authors": "Afia Anjum, Maksim E. Eren, Ismael Boureima, Boian Alexandrov, Manish Bhattarai",
    "abstract": "In recent years, Large Language Models (LLMs) have demonstrated remarkable\ncapabilities across a wide range of natural language processing (NLP) tasks,\nsuch as question-answering, sentiment analysis, text summarization, and machine\ntranslation. However, the ever-growing complexity of LLMs demands immense\ncomputational resources, hindering the broader research and application of\nthese models. To address this, various parameter-efficient fine-tuning\nstrategies, such as Low-Rank Approximation (LoRA) and Adapters, have been\ndeveloped. Despite their potential, these methods often face limitations in\ncompressibility. Specifically, LoRA struggles to scale effectively with the\nincreasing number of trainable parameters in modern large scale LLMs.\nAdditionally, Low-Rank Economic Tensor-Train Adaptation (LoRETTA), which\nutilizes tensor train decomposition, has not yet achieved the level of\ncompression necessary for fine-tuning very large scale models with limited\nresources. This paper introduces Tensor Train Low-Rank Approximation (TT-LoRA),\na novel parameter-efficient fine-tuning (PEFT) approach that extends LoRETTA\nwith optimized tensor train (TT) decomposition integration. By eliminating\nAdapters and traditional LoRA-based structures, TT-LoRA achieves greater model\ncompression without compromising downstream task performance, along with\nreduced inference latency and computational overhead. We conduct an exhaustive\nparameter search to establish benchmarks that highlight the trade-off between\nmodel compression and performance. Our results demonstrate significant\ncompression of LLMs while maintaining comparable performance to larger models,\nfacilitating their deployment on resource-constraint platforms.",
    "arxiv_id": "http://arxiv.org/abs/2408.01008v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01008v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "AgentGen: Enhancing Planning Abilities for Large Language Model based Agent via Environment and Task Generation",
    "authors": "Mengkang Hu, Pu Zhao, Can Xu, Qingfeng Sun, Jianguang Lou, Qingwei Lin, Ping Luo, Saravan Rajmohan, Dongmei Zhang",
    "abstract": "Large Language Model (LLM) based agents have garnered significant attention\nand are becoming increasingly popular. Furthermore, planning ability is a\ncrucial component of an LLM-based agent, involving interaction with the\nenvironment and executing actions to complete a planning task, which generally\nentails achieving a desired goal from an initial state. This paper investigates\nenhancing the planning abilities of LLMs through instruction tuning, referred\nto as agent training. Recent studies have demonstrated that utilizing\nexpert-level trajectory for instruction-tuning LLMs effectively enhances their\nplanning capabilities. However, existing work primarily focuses on synthesizing\ntrajectories from manually designed planning tasks and environments. The\nlabor-intensive nature of creating these environments and tasks impedes the\ngeneration of sufficiently varied and extensive trajectories. To address this\nlimitation, this paper explores the automated synthesis of diverse environments\nand a gradual range of planning tasks, from easy to difficult. We introduce a\nframework, AgentGen, that leverages LLMs first to generate environments and\nsubsequently generate planning tasks conditioned on these environments.\nSpecifically, to improve environmental diversity, we propose using an\ninspiration corpus composed of various domain-specific text segments as the\ncontext for synthesizing environments. Moreover, to increase the difficulty\ndiversity of generated planning tasks, we propose a bidirectional evolution\nmethod, Bi-Evol, that evolves planning tasks from easier and harder directions\nto synthesize a task set with a smoother difficulty curve. The evaluation\nresults derived from AgentBoard show that AgentGen greatly improves LLMs'\nplanning ability, e.g., the AgentGen instruction-tuned Llama-3 8B surpasses\nGPT-3.5 in overall performance. Moreover, in certain tasks, it even outperforms\nGPT-4.",
    "arxiv_id": "http://arxiv.org/abs/2408.00764v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00764v1",
    "primary_category": "cs.CL",
    "votes": 1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "ClassiFIM: An Unsupervised Method To Detect Phase Transitions",
    "authors": "Victor Kasatkin, Evgeny Mozgunov, Nicholas Ezzell, Utkarsh Mishra, Itay Hen, Daniel Lidar",
    "abstract": "Estimation of the Fisher Information Metric (FIM-estimation) is an important\ntask that arises in unsupervised learning of phase transitions, a problem\nproposed by physicists. This work completes the definition of the task by\ndefining rigorous evaluation metrics distMSE, distMSEPS, and distRE and\nintroduces ClassiFIM, a novel machine learning method designed to solve the\nFIM-estimation task. Unlike existing methods for unsupervised learning of phase\ntransitions, ClassiFIM directly estimates a well-defined quantity (the FIM),\nallowing it to be rigorously compared to any present and future other methods\nthat estimate the same. ClassiFIM transforms a dataset for the FIM-estimation\ntask into a dataset for an auxiliary binary classification task and involves\nselecting and training a model for the latter. We prove that the output of\nClassiFIM approaches the exact FIM in the limit of infinite dataset size and\nunder certain regularity conditions. We implement ClassiFIM on multiple\ndatasets, including datasets describing classical and quantum phase\ntransitions, and find that it achieves a good ground truth approximation with\nmodest computational resources. Furthermore, we independently implement two\nalternative state-of-the-art methods for unsupervised estimation of phase\ntransition locations on the same datasets and find that ClassiFIM predicts such\nlocations at least as well as these other methods. To emphasize the generality\nof our method, we also propose and generate the MNIST-CNN dataset, which\nconsists of the output of CNNs trained on MNIST for different hyperparameter\nchoices. Using ClassiFIM on this dataset suggests there is a phase transition\nin the distribution of image-prediction pairs for CNNs trained on MNIST,\ndemonstrating the broad scope of FIM-estimation beyond physics.",
    "arxiv_id": "http://arxiv.org/abs/2408.03323v1",
    "pdf_url": "http://arxiv.org/pdf/2408.03323v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Hedge Fund Portfolio Construction Using PolyModel Theory and iTransformer",
    "authors": "Siqiao Zhao, Zhikang Dong, Zeyu Cao, Raphael Douady",
    "abstract": "When constructing portfolios, a key problem is that a lot of financial time\nseries data are sparse, making it challenging to apply machine learning\nmethods. Polymodel theory can solve this issue and demonstrate superiority in\nportfolio construction from various aspects. To implement the PolyModel theory\nfor constructing a hedge fund portfolio, we begin by identifying an asset pool,\nutilizing over 10,000 hedge funds for the past 29 years' data. PolyModel theory\nalso involves choosing a wide-ranging set of risk factors, which includes\nvarious financial indices, currencies, and commodity prices. This comprehensive\nselection mirrors the complexities of the real-world environment. Leveraging on\nthe PolyModel theory, we create quantitative measures such as Long-term Alpha,\nLong-term Ratio, and SVaR. We also use more classical measures like the Sharpe\nratio or Morningstar's MRAR. To enhance the performance of the constructed\nportfolio, we also employ the latest deep learning techniques (iTransformer) to\ncapture the upward trend, while efficiently controlling the downside, using all\nthe features. The iTransformer model is specifically designed to address the\nchallenges in high-dimensional time series forecasting and could largely\nimprove our strategies. More precisely, our strategies achieve better Sharpe\nratio and annualized return. The above process enables us to create multiple\nportfolio strategies aiming for high returns and low risks when compared to\nvarious benchmarks.",
    "arxiv_id": "http://arxiv.org/abs/2408.03320v1",
    "pdf_url": "http://arxiv.org/pdf/2408.03320v1",
    "primary_category": "q-fin.PM",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters",
    "authors": "Charlie Snell, Jaehoon Lee, Kelvin Xu, Aviral Kumar",
    "abstract": "Enabling LLMs to improve their outputs by using more test-time computation is\na critical step towards building generally self-improving agents that can\noperate on open-ended natural language. In this paper, we study the scaling of\ninference-time computation in LLMs, with a focus on answering the question: if\nan LLM is allowed to use a fixed but non-trivial amount of inference-time\ncompute, how much can it improve its performance on a challenging prompt?\nAnswering this question has implications not only on the achievable performance\nof LLMs, but also on the future of LLM pretraining and how one should tradeoff\ninference-time and pre-training compute. Despite its importance, little\nresearch attempted to understand the scaling behaviors of various test-time\ninference methods. Moreover, current work largely provides negative results for\na number of these strategies. In this work, we analyze two primary mechanisms\nto scale test-time computation: (1) searching against dense, process-based\nverifier reward models; and (2) updating the model's distribution over a\nresponse adaptively, given the prompt at test time. We find that in both cases,\nthe effectiveness of different approaches to scaling test-time compute\ncritically varies depending on the difficulty of the prompt. This observation\nmotivates applying a \"compute-optimal\" scaling strategy, which acts to most\neffectively allocate test-time compute adaptively per prompt. Using this\ncompute-optimal strategy, we can improve the efficiency of test-time compute\nscaling by more than 4x compared to a best-of-N baseline. Additionally, in a\nFLOPs-matched evaluation, we find that on problems where a smaller base model\nattains somewhat non-trivial success rates, test-time compute can be used to\noutperform a 14x larger model.",
    "arxiv_id": "http://arxiv.org/abs/2408.03314v1",
    "pdf_url": "http://arxiv.org/pdf/2408.03314v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Pre-training and in-context learning IS Bayesian inference a la De Finetti",
    "authors": "Naimeng Ye, Hanming Yang, Andrew Siah, Hongseok Namkoong",
    "abstract": "Accurately gauging uncertainty on the underlying environment is a\nlongstanding goal of intelligent systems. We characterize which latent concepts\npre-trained sequence models are naturally able to reason with. We go back to De\nFinetti's predictive view of Bayesian reasoning: instead of modeling latent\nparameters through priors and likelihoods like topic models do, De Finetti has\nlong advocated for modeling exchangeable (permutation invariant) sequences of\nobservables. According to this view, pre-training autoregressive models\nformulates informed beliefs based on prior observations (\"empirical Bayes\"),\nand forward generation is a simulated instantiation of an environment\n(\"posterior inference\"). This connection allows extending in-context learning\n(ICL) beyond predictive settings, highlighting sequence models' ability to\nperform explicit statistical inference. In particular, we show the sequence\nprediction loss over exchangeable documents controls performance on downstream\ntasks where uncertainty quantification is key. Empirically, we propose and\ndemonstrate several approaches for encoding exchangeability in sequence model\narchitectures: data augmentation, regularization, and causal masking.",
    "arxiv_id": "http://arxiv.org/abs/2408.03307v1",
    "pdf_url": "http://arxiv.org/pdf/2408.03307v1",
    "primary_category": "stat.ML",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Fusing Forces: Deep-Human-Guided Refinement of Segmentation Masks",
    "authors": "Rafael Sterzinger, Christian Stippel, Robert Sablatnig",
    "abstract": "Etruscan mirrors constitute a significant category in Etruscan art,\ncharacterized by elaborate figurative illustrations featured on their backside.\nA laborious and costly aspect of their analysis and documentation is the task\nof manually tracing these illustrations. In previous work, a methodology has\nbeen proposed to automate this process, involving photometric-stereo scanning\nin combination with deep neural networks. While achieving quantitative\nperformance akin to an expert annotator, some results still lack qualitative\nprecision and, thus, require annotators for inspection and potential\ncorrection, maintaining resource intensity. In response, we propose a deep\nneural network trained to interactively refine existing annotations based on\nhuman guidance. Our human-in-the-loop approach streamlines annotation,\nachieving equal quality with up to 75% less manual input required. Moreover,\nduring the refinement process, the relative improvement of our methodology over\npure manual labeling reaches peak values of up to 26%, attaining drastically\nbetter quality quicker. By being tailored to the complex task of segmenting\nintricate lines, specifically distinguishing it from previous methods, our\napproach offers drastic improvements in efficacy, transferable to a broad\nspectrum of applications beyond Etruscan mirrors.",
    "arxiv_id": "http://arxiv.org/abs/2408.03304v1",
    "pdf_url": "http://arxiv.org/pdf/2408.03304v1",
    "primary_category": "cs.CV",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "SARA: Singular-Value Based Adaptive Low-Rank Adaption",
    "authors": "Jihao Gu, Shuai Chen, Zelin Wang, Yibo Zhang, Ping Gong",
    "abstract": "With the increasing number of parameters in large pre-trained models, LoRA as\na parameter-efficient fine-tuning(PEFT) method is widely used for not adding\ninference overhead. The LoRA method assumes that weight changes during\nfine-tuning can be approximated by low-rank matrices. However, the rank values\nneed to be manually verified to match different downstream tasks, and they\ncannot accommodate the varying importance of different layers in the model. In\nthis work, we first analyze the relationship between the performance of\ndifferent layers and their ranks using SVD. Based on this, we design the\nSingular-Value Based Adaptive Low-Rank Adaption(SARA), which adaptively finds\nthe rank during initialization by performing SVD on the pre-trained weights.\nAdditionally, we explore the Mixture-of-SARA(Mo-SARA), which significantly\nreduces the number of parameters by fine-tuning only multiple parallel sets of\nsingular values controlled by a router. Extensive experiments on various\ncomplex tasks demonstrate the simplicity and parameter efficiency of our\nmethods. They can effectively and adaptively find the most suitable rank for\neach layer of each model.",
    "arxiv_id": "http://arxiv.org/abs/2408.03290v1",
    "pdf_url": "http://arxiv.org/pdf/2408.03290v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Malicious Internet Entity Detection Using Local Graph Inference",
    "authors": "Simon Mandlik, Tomas Pevny, Vaclav Smidl, Lukas Bajer",
    "abstract": "Detection of malicious behavior in a large network is a challenging problem\nfor machine learning in computer security, since it requires a model with high\nexpressive power and scalable inference. Existing solutions struggle to achieve\nthis feat -- current cybersec-tailored approaches are still limited in\nexpressivity, and methods successful in other domains do not scale well for\nlarge volumes of data, rendering frequent retraining impossible. This work\nproposes a new perspective for learning from graph data that is modeling\nnetwork entity interactions as a large heterogeneous graph. High expressivity\nof the method is achieved with neural network architecture HMILnet that\nnaturally models this type of data and provides theoretical guarantees. The\nscalability is achieved by pursuing local graph inference, i.e., classifying\nindividual vertices and their neighborhood as independent samples. Our\nexperiments exhibit improvement over the state-of-the-art Probabilistic Threat\nPropagation (PTP) algorithm, show a further threefold accuracy improvement when\nadditional data is used, which is not possible with the PTP algorithm, and\ndemonstrate the generalization capabilities of the method to new, previously\nunseen entities.",
    "arxiv_id": "http://arxiv.org/abs/2408.03287v1",
    "pdf_url": "http://arxiv.org/pdf/2408.03287v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "StructEval: Deepen and Broaden Large Language Model Assessment via Structured Evaluation",
    "authors": "Boxi Cao, Mengjie Ren, Hongyu Lin, Xianpei Han, Feng Zhang, Junfeng Zhan, Le Sun",
    "abstract": "Evaluation is the baton for the development of large language models. Current\nevaluations typically employ a single-item assessment paradigm for each atomic\ntest objective, which struggles to discern whether a model genuinely possesses\nthe required capabilities or merely memorizes/guesses the answers to specific\nquestions. To this end, we propose a novel evaluation framework referred to as\nStructEval. Starting from an atomic test objective, StructEval deepens and\nbroadens the evaluation by conducting a structured assessment across multiple\ncognitive levels and critical concepts, and therefore offers a comprehensive,\nrobust and consistent evaluation for LLMs. Experiments on three widely-used\nbenchmarks demonstrate that StructEval serves as a reliable tool for resisting\nthe risk of data contamination and reducing the interference of potential\nbiases, thereby providing more reliable and consistent conclusions regarding\nmodel capabilities. Our framework also sheds light on the design of future\nprincipled and trustworthy LLM evaluation protocols.",
    "arxiv_id": "http://arxiv.org/abs/2408.03281v1",
    "pdf_url": "http://arxiv.org/pdf/2408.03281v1",
    "primary_category": "cs.CL",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Compress and Compare: Interactively Evaluating Efficiency and Behavior Across ML Model Compression Experiments",
    "authors": "Angie Boggust, Venkatesh Sivaraman, Yannick Assogba, Donghao Ren, Dominik Moritz, Fred Hohman",
    "abstract": "To deploy machine learning models on-device, practitioners use compression\nalgorithms to shrink and speed up models while maintaining their high-quality\noutput. A critical aspect of compression in practice is model comparison,\nincluding tracking many compression experiments, identifying subtle changes in\nmodel behavior, and negotiating complex accuracy-efficiency trade-offs.\nHowever, existing compression tools poorly support comparison, leading to\ntedious and, sometimes, incomplete analyses spread across disjoint tools. To\nsupport real-world comparative workflows, we develop an interactive visual\nsystem called Compress and Compare. Within a single interface, Compress and\nCompare surfaces promising compression strategies by visualizing provenance\nrelationships between compressed models and reveals compression-induced\nbehavior changes by comparing models' predictions, weights, and activations. We\ndemonstrate how Compress and Compare supports common compression analysis tasks\nthrough two case studies, debugging failed compression on generative language\nmodels and identifying compression artifacts in image classification models. We\nfurther evaluate Compress and Compare in a user study with eight compression\nexperts, illustrating its potential to provide structure to compression\nworkflows, help practitioners build intuition about compression, and encourage\nthorough analysis of compression's effect on model behavior. Through these\nevaluations, we identify compression-specific challenges that future visual\nanalytics tools should consider and Compress and Compare visualizations that\nmay generalize to broader model comparison tasks.",
    "arxiv_id": "http://arxiv.org/abs/2408.03274v1",
    "pdf_url": "http://arxiv.org/pdf/2408.03274v1",
    "primary_category": "cs.HC",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Analysis of Partially-Calibrated Sparse Subarrays for Direction Finding with Extended Degrees of Freedom",
    "authors": "W. S. Leite, R. C. de Lamare",
    "abstract": "This paper investigates the problem of direction-of-arrival (DOA) estimation\nusing multiple partially-calibrated sparse subarrays. In particular, we present\nthe Generalized Coarray Multiple Signal Classification (GCA-MUSIC) DOA\nestimation algorithm to scenarios with partially-calibrated sparse subarrays.\nThe proposed GCA-MUSIC algorithm exploits the difference coarray for each\nsubarray, followed by a specific pseudo-spectrum merging rule that is based on\nthe intersection of the signal subspaces associated to each subarray. This rule\nassumes that there is no a priori knowledge about the cross-covariance between\nsubarrays. In that way, only the second-order statistics of each subarray are\nused to estimate the directions with increased degrees of freedom, i.e., the\nestimation procedure preserves the coarray Multiple Signal Classification and\nsparse arrays properties to estimate more sources than the number of physical\nsensors in each subarray. Numerical simulations show that the proposed\nGCA-MUSIC has better performance than other similar strategies.",
    "arxiv_id": "http://arxiv.org/abs/2408.03236v1",
    "pdf_url": "http://arxiv.org/pdf/2408.03236v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Don't Think It Twice: Exploit Shift Invariance for Efficient Online Streaming Inference of CNNs",
    "authors": "Christodoulos Kechris, Jonathan Dan, Jose Miranda, David Atienza",
    "abstract": "Deep learning time-series processing often relies on convolutional neural\nnetworks with overlapping windows. This overlap allows the network to produce\nan output faster than the window length. However, it introduces additional\ncomputations. This work explores the potential to optimize computational\nefficiency during inference by exploiting convolution's shift-invariance\nproperties to skip the calculation of layer activations between successive\noverlapping windows. Although convolutions are shift-invariant, zero-padding\nand pooling operations, widely used in such networks, are not efficient and\ncomplicate efficient streaming inference. We introduce StreamiNNC, a strategy\nto deploy Convolutional Neural Networks for online streaming inference. We\nexplore the adverse effects of zero padding and pooling on the accuracy of\nstreaming inference, deriving theoretical error upper bounds for pooling during\nstreaming. We address these limitations by proposing signal padding and pooling\nalignment and provide guidelines for designing and deploying models for\nStreamiNNC. We validate our method in simulated data and on three real-world\nbiomedical signal processing applications. StreamiNNC achieves a low deviation\nbetween streaming output and normal inference for all three networks (2.03 -\n3.55% NRMSE). This work demonstrates that it is possible to linearly speed up\nthe inference of streaming CNNs processing overlapping windows, negating the\nadditional computation typically incurred by overlapping windows.",
    "arxiv_id": "http://arxiv.org/abs/2408.03223v1",
    "pdf_url": "http://arxiv.org/pdf/2408.03223v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Masked Random Noise for Communication Efficient Federaetd Learning",
    "authors": "Shiwei Li, Yingyi Cheng, Haozhao Wang, Xing Tang, Shijie Xu, Weihong Luo, Yuhua Li, Dugang Liu, Xiuqiang He, and Ruixuan Li",
    "abstract": "Federated learning is a promising distributed training paradigm that\neffectively safeguards data privacy. However, it may involve significant\ncommunication costs, which hinders training efficiency. In this paper, we aim\nto enhance communication efficiency from a new perspective. Specifically, we\nrequest the distributed clients to find optimal model updates relative to\nglobal model parameters within predefined random noise. For this purpose, we\npropose Federated Masked Random Noise (FedMRN), a novel framework that enables\nclients to learn a 1-bit mask for each model parameter and apply masked random\nnoise (i.e., the Hadamard product of random noise and masks) to represent model\nupdates. To make FedMRN feasible, we propose an advanced mask training\nstrategy, called progressive stochastic masking (PSM). After local training,\neach client only need to transmit local masks and a random seed to the server.\nAdditionally, we provide theoretical guarantees for the convergence of FedMRN\nunder both strongly convex and non-convex assumptions. Extensive experiments\nare conducted on four popular datasets. The results show that FedMRN exhibits\nsuperior convergence speed and test accuracy compared to relevant baselines,\nwhile attaining a similar level of accuracy as FedAvg.",
    "arxiv_id": "http://arxiv.org/abs/2408.03220v1",
    "pdf_url": "http://arxiv.org/pdf/2408.03220v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Learning to Learn without Forgetting using Attention",
    "authors": "Anna Vettoruzzo, Joaquin Vanschoren, Mohamed-Rafik Bouguelia, Thorsteinn R\u00f6gnvaldsson",
    "abstract": "Continual learning (CL) refers to the ability to continually learn over time\nby accommodating new knowledge while retaining previously learned experience.\nWhile this concept is inherent in human learning, current machine learning\nmethods are highly prone to overwrite previously learned patterns and thus\nforget past experience. Instead, model parameters should be updated selectively\nand carefully, avoiding unnecessary forgetting while optimally leveraging\npreviously learned patterns to accelerate future learning. Since hand-crafting\neffective update mechanisms is difficult, we propose meta-learning a\ntransformer-based optimizer to enhance CL. This meta-learned optimizer uses\nattention to learn the complex relationships between model parameters across a\nstream of tasks, and is designed to generate effective weight updates for the\ncurrent task while preventing catastrophic forgetting on previously encountered\ntasks. Evaluations on benchmark datasets like SplitMNIST, RotatedMNIST, and\nSplitCIFAR-100 affirm the efficacy of the proposed approach in terms of both\nforward and backward transfer, even on small sets of labeled data, highlighting\nthe advantages of integrating a meta-learned optimizer within the continual\nlearning framework.",
    "arxiv_id": "http://arxiv.org/abs/2408.03219v1",
    "pdf_url": "http://arxiv.org/pdf/2408.03219v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "FedBAT: Communication-Efficient Federated Learning via Learnable Binarization",
    "authors": "Shiwei Li, Wenchao Xu, Haozhao Wang, Xing Tang, Yining Qi, Shijie Xu, Weihong Luo, Yuhua Li, Xiuqiang He, Ruixuan Li",
    "abstract": "Federated learning is a promising distributed machine learning paradigm that\ncan effectively exploit large-scale data without exposing users' privacy.\nHowever, it may incur significant communication overhead, thereby potentially\nimpairing the training efficiency. To address this challenge, numerous studies\nsuggest binarizing the model updates. Nonetheless, traditional methods usually\nbinarize model updates in a post-training manner, resulting in significant\napproximation errors and consequent degradation in model accuracy. To this end,\nwe propose Federated Binarization-Aware Training (FedBAT), a novel framework\nthat directly learns binary model updates during the local training process,\nthus inherently reducing the approximation errors. FedBAT incorporates an\ninnovative binarization operator, along with meticulously designed derivatives\nto facilitate efficient learning. In addition, we establish theoretical\nguarantees regarding the convergence of FedBAT. Extensive experiments are\nconducted on four popular datasets. The results show that FedBAT significantly\naccelerates the convergence and exceeds the accuracy of baselines by up to 9\\%,\neven surpassing that of FedAvg in some cases.",
    "arxiv_id": "http://arxiv.org/abs/2408.03215v1",
    "pdf_url": "http://arxiv.org/pdf/2408.03215v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Convergence Conditions for Stochastic Line Search Based Optimization of Over-parametrized Models",
    "authors": "Matteo Lapucci, Davide Pucci",
    "abstract": "In this paper, we deal with algorithms to solve the finite-sum problems\nrelated to fitting over-parametrized models, that typically satisfy the\ninterpolation condition. In particular, we focus on approaches based on\nstochastic line searches and employing general search directions. We define\nconditions on the sequence of search directions that guarantee finite\ntermination and bounds for the backtracking procedure. Moreover, we shed light\non the additional property of directions needed to prove fast (linear)\nconvergence of the general class of algorithms when applied to PL functions in\nthe interpolation regime. From the point of view of algorithms design, the\nproposed analysis identifies safeguarding conditions that could be employed in\nrelevant algorithmic framework. In particular, it could be of interest to\nintegrate stochastic line searches within momentum, conjugate gradient or\nadaptive preconditioning methods.",
    "arxiv_id": "http://arxiv.org/abs/2408.03199v1",
    "pdf_url": "http://arxiv.org/pdf/2408.03199v1",
    "primary_category": "math.OC",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "RELIEF: Reinforcement Learning Empowered Graph Feature Prompt Tuning",
    "authors": "Jiapeng Zhu, Zichen Ding, Jianxiang Yu, Jiaqi Tan, Xiang Li, Weining Qian",
    "abstract": "The advent of the \"pre-train, prompt\" paradigm has recently extended its\ngeneralization ability and data efficiency to graph representation learning,\nfollowing its achievements in Natural Language Processing (NLP). Initial graph\nprompt tuning approaches tailored specialized prompting functions for Graph\nNeural Network (GNN) models pre-trained with specific strategies, such as edge\nprediction, thus limiting their applicability. In contrast, another pioneering\nline of research has explored universal prompting via adding prompts to the\ninput graph's feature space, thereby removing the reliance on specific\npre-training strategies. However, the necessity to add feature prompts to all\nnodes remains an open question. Motivated by findings from prompt tuning\nresearch in the NLP domain, which suggest that highly capable pre-trained\nmodels need less conditioning signal to achieve desired behaviors, we advocate\nfor strategically incorporating necessary and lightweight feature prompts to\ncertain graph nodes to enhance downstream task performance. This introduces a\ncombinatorial optimization problem, requiring a policy to decide 1) which nodes\nto prompt and 2) what specific feature prompts to attach. We then address the\nproblem by framing the prompt incorporation process as a sequential\ndecision-making problem and propose our method, RELIEF, which employs\nReinforcement Learning (RL) to optimize it. At each step, the RL agent selects\na node (discrete action) and determines the prompt content (continuous action),\naiming to maximize cumulative performance gain. Extensive experiments on graph\nand node-level tasks with various pre-training strategies in few-shot scenarios\ndemonstrate that our RELIEF outperforms fine-tuning and other prompt-based\napproaches in classification performance and data efficiency.",
    "arxiv_id": "http://arxiv.org/abs/2408.03195v1",
    "pdf_url": "http://arxiv.org/pdf/2408.03195v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "An Object is Worth 64x64 Pixels: Generating 3D Object via Image Diffusion",
    "authors": "Xingguang Yan, Han-Hung Lee, Ziyu Wan, Angel X. Chang",
    "abstract": "We introduce a new approach for generating realistic 3D models with UV maps\nthrough a representation termed \"Object Images.\" This approach encapsulates\nsurface geometry, appearance, and patch structures within a 64x64 pixel image,\neffectively converting complex 3D shapes into a more manageable 2D format. By\ndoing so, we address the challenges of both geometric and semantic irregularity\ninherent in polygonal meshes. This method allows us to use image generation\nmodels, such as Diffusion Transformers, directly for 3D shape generation.\nEvaluated on the ABO dataset, our generated shapes with patch structures\nachieve point cloud FID comparable to recent 3D generative models, while\nnaturally supporting PBR material generation.",
    "arxiv_id": "http://arxiv.org/abs/2408.03178v1",
    "pdf_url": "http://arxiv.org/pdf/2408.03178v1",
    "primary_category": "cs.CV",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Leveraging Parameter Efficient Training Methods for Low Resource Text Classification: A Case Study in Marathi",
    "authors": "Pranita Deshmukh, Nikita Kulkarni, Sanhita Kulkarni, Kareena Manghani, Raviraj Joshi",
    "abstract": "With the surge in digital content in low-resource languages, there is an\nescalating demand for advanced Natural Language Processing (NLP) techniques\ntailored to these languages. BERT (Bidirectional Encoder Representations from\nTransformers), serving as the foundational framework for numerous NLP\narchitectures and language models, is increasingly employed for the development\nof low-resource NLP models. Parameter Efficient Fine-Tuning (PEFT) is a method\nfor fine-tuning Large Language Models (LLMs) and reducing the training\nparameters to some extent to decrease the computational costs needed for\ntraining the model and achieve results comparable to a fully fine-tuned model.\nIn this work, we present a study of PEFT methods for the Indic low-resource\nlanguage Marathi. We conduct a comprehensive analysis of PEFT methods applied\nto various monolingual and multilingual Marathi BERT models. These approaches\nare evaluated on prominent text classification datasets like MahaSent,\nMahaHate, and MahaNews. The incorporation of PEFT techniques is demonstrated to\nsignificantly expedite the training speed of the models, addressing a critical\naspect of model development and deployment. In this study, we explore Low-Rank\nAdaptation of Large Language Models (LoRA) and adapter methods for low-resource\ntext classification. We show that these methods are competitive with full\nfine-tuning and can be used without loss in accuracy. This study contributes\nvaluable insights into the effectiveness of Marathi BERT models, offering a\nfoundation for the continued advancement of NLP capabilities in Marathi and\nsimilar Indic languages.",
    "arxiv_id": "http://arxiv.org/abs/2408.03172v1",
    "pdf_url": "http://arxiv.org/pdf/2408.03172v1",
    "primary_category": "cs.CL",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Iterative CT Reconstruction via Latent Variable Optimization of Shallow Diffusion Models",
    "authors": "Sho Ozaki, Shizuo Kaji, Toshikazu Imae, Kanabu Nawa, Hideomi Yamashita, Keiichi Nakagawa",
    "abstract": "Image generative AI has garnered significant attention in recent years. In\nparticular, the diffusion model, a core component of recent generative AI,\nproduces high-quality images with rich diversity. In this study, we propose a\nnovel CT reconstruction method by combining the denoising diffusion\nprobabilistic model with iterative CT reconstruction. In sharp contrast to\nprevious studies, we optimize the fidelity loss of CT reconstruction with\nrespect to the latent variable of the diffusion model, instead of the image and\nmodel parameters. To suppress anatomical structure changes produced by the\ndiffusion model, we shallow the diffusion and reverse processes, and fix a set\nof added noises in the reverse process to make it deterministic during\ninference. We demonstrate the effectiveness of the proposed method through\nsparse view CT reconstruction of 1/10 view projection data. Despite the\nsimplicity of the implementation, the proposed method shows the capability of\nreconstructing high-quality images while preserving the patient's anatomical\nstructure, and outperforms existing methods including iterative reconstruction,\niterative reconstruction with total variation, and the diffusion model alone in\nterms of quantitative indices such as SSIM and PSNR. We also explore further\nsparse view CT using 1/20 view projection data with the same trained diffusion\nmodel. As the number of iterations increases, image quality improvement\ncomparable to that of 1/10 sparse view CT reconstruction is achieved. In\nprinciple, the proposed method can be widely applied not only to CT but also to\nother imaging modalities such as MRI, PET, and SPECT.",
    "arxiv_id": "http://arxiv.org/abs/2408.03156v1",
    "pdf_url": "http://arxiv.org/pdf/2408.03156v1",
    "primary_category": "cs.CV",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "TSC: A Simple Two-Sided Constraint against Over-Smoothing",
    "authors": "Furong Peng, Kang Liu, Xuan Lu, Yuhua Qian, Hongren Yan, Chao Ma",
    "abstract": "Graph Convolutional Neural Network (GCN), a widely adopted method for\nanalyzing relational data, enhances node discriminability through the\naggregation of neighboring information. Usually, stacking multiple layers can\nimprove the performance of GCN by leveraging information from high-order\nneighbors. However, the increase of the network depth will induce the\nover-smoothing problem, which can be attributed to the quality and quantity of\nneighbors changing: (a) neighbor quality, node's neighbors become overlapping\nin high order, leading to aggregated information becoming indistinguishable,\n(b) neighbor quantity, the exponentially growing aggregated neighbors submerges\nthe node's initial feature by recursively aggregating operations. Current\nsolutions mainly focus on one of the above causes and seldom consider both at\nonce.\n  Aiming at tackling both causes of over-smoothing in one shot, we introduce a\nsimple Two-Sided Constraint (TSC) for GCNs, comprising two straightforward yet\npotent techniques: random masking and contrastive constraint. The random\nmasking acts on the representation matrix's columns to regulate the degree of\ninformation aggregation from neighbors, thus preventing the convergence of node\nrepresentations. Meanwhile, the contrastive constraint, applied to the\nrepresentation matrix's rows, enhances the discriminability of the nodes.\nDesigned as a plug-in module, TSC can be easily coupled with GCN or SGC\narchitectures. Experimental analyses on diverse real-world graph datasets\nverify that our approach markedly reduces the convergence of node's\nrepresentation and the performance degradation in deeper GCN.",
    "arxiv_id": "http://arxiv.org/abs/2408.03152v1",
    "pdf_url": "http://arxiv.org/pdf/2408.03152v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Conditioning LLMs with Emotion in Neural Machine Translation",
    "authors": "Charles Brazier, Jean-Luc Rouas",
    "abstract": "Large Language Models (LLMs) have shown remarkable performance in Natural\nLanguage Processing tasks, including Machine Translation (MT). In this work, we\npropose a novel MT pipeline that integrates emotion information extracted from\na Speech Emotion Recognition (SER) model into LLMs to enhance translation\nquality. We first fine-tune five existing LLMs on the Libri-trans dataset and\nselect the most performant model. Subsequently, we augment LLM prompts with\ndifferent dimensional emotions and train the selected LLM under these different\nconfigurations. Our experiments reveal that integrating emotion information,\nespecially arousal, into LLM prompts leads to notable improvements in\ntranslation quality.",
    "arxiv_id": "http://arxiv.org/abs/2408.03150v1",
    "pdf_url": "http://arxiv.org/pdf/2408.03150v1",
    "primary_category": "cs.CL",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Active Learning for Level Set Estimation Using Randomized Straddle Algorithms",
    "authors": "Yu Inatsu, Shion Takeno, Kentaro Kutsukake, Ichiro Takeuchi",
    "abstract": "Level set estimation (LSE), the problem of identifying the set of input\npoints where a function takes value above (or below) a given threshold, is\nimportant in practical applications. When the function is expensive-to-evaluate\nand black-box, the \\textit{straddle} algorithm, which is a representative\nheuristic for LSE based on Gaussian process models, and its extensions having\ntheoretical guarantees have been developed. However, many of existing methods\ninclude a confidence parameter $\\beta^{1/2}_t$ that must be specified by the\nuser, and methods that choose $\\beta^{1/2}_t$ heuristically do not provide\ntheoretical guarantees. In contrast, theoretically guaranteed values of\n$\\beta^{1/2}_t$ need to be increased depending on the number of iterations and\ncandidate points, and are conservative and not good for practical performance.\nIn this study, we propose a novel method, the \\textit{randomized straddle}\nalgorithm, in which $\\beta_t$ in the straddle algorithm is replaced by a random\nsample from the chi-squared distribution with two degrees of freedom. The\nconfidence parameter in the proposed method has the advantages of not needing\nadjustment, not depending on the number of iterations and candidate points, and\nnot being conservative. Furthermore, we show that the proposed method has\ntheoretical guarantees that depend on the sample complexity and the number of\niterations. Finally, we confirm the usefulness of the proposed method through\nnumerical experiments using synthetic and real data.",
    "arxiv_id": "http://arxiv.org/abs/2408.03144v1",
    "pdf_url": "http://arxiv.org/pdf/2408.03144v1",
    "primary_category": "stat.ML",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Topic Modeling with Fine-tuning LLMs and Bag of Sentences",
    "authors": "Johannes Schneider",
    "abstract": "Large language models (LLM)'s are increasingly used for topic modeling\noutperforming classical topic models such as LDA. Commonly, pre-trained LLM\nencoders such as BERT are used out-of-the-box despite the fact that fine-tuning\nis known to improve LLMs considerably. The challenge lies in obtaining a\nsuitable (labeled) dataset for fine-tuning. In this paper, we use the recent\nidea to use bag of sentences as the elementary unit in computing topics. In\nturn, we derive an approach FT-Topic to perform unsupervised fine-tuning\nrelying primarily on two steps for constructing a training dataset in an\nautomatic fashion. First, a heuristic method to identifies pairs of sentence\ngroups that are either assumed to be of the same or different topics. Second,\nwe remove sentence pairs that are likely labeled incorrectly. The dataset is\nthen used to fine-tune an encoder LLM, which can be leveraged by any topic\nmodeling approach using embeddings. However, in this work, we demonstrate its\neffectiveness by deriving a novel state-of-the-art topic modeling method called\nSenClu, which achieves fast inference through an expectation-maximization\nalgorithm and hard assignments of sentence groups to a single topic, while\ngiving users the possibility to encode prior knowledge on the topic-document\ndistribution. Code is at \\url{https://github.com/JohnTailor/FT-Topic}",
    "arxiv_id": "http://arxiv.org/abs/2408.03099v1",
    "pdf_url": "http://arxiv.org/pdf/2408.03099v1",
    "primary_category": "cs.CL",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Learning Provably Robust Policies in Uncertain Parametric Environments",
    "authors": "Yannik Schnitzer, Alessandro Abate, David Parker",
    "abstract": "We present a data-driven approach for learning MDP policies that are robust\nacross stochastic environments whose transition probabilities are defined by\nparameters with an unknown distribution. We produce probably approximately\ncorrect (PAC) guarantees for the performance of these learned policies in a\nnew, unseen environment over the unknown distribution. Our approach is based on\nfinite samples of the MDP environments, for each of which we build an\napproximation of the model as an interval MDP, by exploring a set of generated\ntrajectories. We use the built approximations to synthesise a single policy\nthat performs well (meets given requirements) across the sampled environments,\nand furthermore bound its risk (of not meeting the given requirements) when\ndeployed in an unseen environment. Our procedure offers a trade-off between the\nguaranteed performance of the learned policy and the risk of not meeting the\nguarantee in an unseen environment. Our approach exploits knowledge of the\nenvironment's state space and graph structure, and we show how additional\nknowledge of its parametric structure can be leveraged to optimize learning and\nto obtain tighter guarantees from less samples. We evaluate our approach on a\ndiverse range of established benchmarks, demonstrating that we can generate\nhighly performing and robust policies, along with guarantees that tightly\nquantify their performance and the associated risk.",
    "arxiv_id": "http://arxiv.org/abs/2408.03093v1",
    "pdf_url": "http://arxiv.org/pdf/2408.03093v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "QADQN: Quantum Attention Deep Q-Network for Financial Market Prediction",
    "authors": "Siddhant Dutta, Nouhaila Innan, Alberto Marchisio, Sadok Ben Yahia, Muhammad Shafique",
    "abstract": "Financial market prediction and optimal trading strategy development remain\nchallenging due to market complexity and volatility. Our research in quantum\nfinance and reinforcement learning for decision-making demonstrates the\napproach of quantum-classical hybrid algorithms to tackling real-world\nfinancial challenges. In this respect, we corroborate the concept with rigorous\nbacktesting and validate the framework's performance under realistic market\nconditions, by including fixed transaction cost per trade. This paper\nintroduces a Quantum Attention Deep Q-Network (QADQN) approach to address these\nchallenges through quantum-enhanced reinforcement learning. Our QADQN\narchitecture uses a variational quantum circuit inside a traditional deep\nQ-learning framework to take advantage of possible quantum advantages in\ndecision-making. We gauge the QADQN agent's performance on historical data from\nmajor market indices, including the S&P 500. We evaluate the agent's learning\nprocess by examining its reward accumulation and the effectiveness of its\nexperience replay mechanism. Our empirical results demonstrate the QADQN's\nsuperior performance, achieving better risk-adjusted returns with Sortino\nratios of 1.28 and 1.19 for non-overlapping and overlapping test periods\nrespectively, indicating effective downside risk management.",
    "arxiv_id": "http://arxiv.org/abs/2408.03088v1",
    "pdf_url": "http://arxiv.org/pdf/2408.03088v1",
    "primary_category": "quant-ph",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Matrix Multiplication on Quantum Computer",
    "authors": "Jiaqi Yao, Ding Liu",
    "abstract": "This paper introduces an innovative and practical approach to universal\nquantum matrix multiplication. We designed optimized quantum adders and\nmultipliers based on Quantum Fourier Transform (QFT), which significantly\nreduced the number of gates used compared to classical adders and multipliers.\nSubsequently, we construct a basic universal quantum matrix multiplication and\nextend it to the Strassen algorithm. We conduct comparative experiments to\nanalyze the performance of the quantum matrix multiplication and evaluate the\nacceleration provided by the optimized quantum adder and multiplier.\nFurthermore, we investigate the advantages and disadvantages of the quantum\nStrassen algorithm compared to basic quantum matrix multiplication.",
    "arxiv_id": "http://arxiv.org/abs/2408.03085v1",
    "pdf_url": "http://arxiv.org/pdf/2408.03085v1",
    "primary_category": "quant-ph",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Research on Autonomous Driving Decision-making Strategies based Deep Reinforcement Learning",
    "authors": "Zixiang Wang, Hao Yan, Changsong Wei, Junyu Wang, Shi Bo, Minheng Xiao",
    "abstract": "The behavior decision-making subsystem is a key component of the autonomous\ndriving system, which reflects the decision-making ability of the vehicle and\nthe driver, and is an important symbol of the high-level intelligence of the\nvehicle. However, the existing rule-based decision-making schemes are limited\nby the prior knowledge of designers, and it is difficult to cope with complex\nand changeable traffic scenarios. In this work, an advanced deep reinforcement\nlearning model is adopted, which can autonomously learn and optimize driving\nstrategies in a complex and changeable traffic environment by modeling the\ndriving decision-making process as a reinforcement learning problem.\nSpecifically, we used Deep Q-Network (DQN) and Proximal Policy Optimization\n(PPO) for comparative experiments. DQN guides the agent to choose the best\naction by approximating the state-action value function, while PPO improves the\ndecision-making quality by optimizing the policy function. We also introduce\nimprovements in the design of the reward function to promote the robustness and\nadaptability of the model in real-world driving situations. Experimental\nresults show that the decision-making strategy based on deep reinforcement\nlearning has better performance than the traditional rule-based method in a\nvariety of driving tasks.",
    "arxiv_id": "http://arxiv.org/abs/2408.03084v1",
    "pdf_url": "http://arxiv.org/pdf/2408.03084v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Highly Efficient Self-Adaptive Reward Shaping for Reinforcement Learning",
    "authors": "Haozhe Ma, Zhengding Luo, Thanh Vinh Vo, Kuankuan Sima, Tze-Yun Leong",
    "abstract": "Reward shaping addresses the challenge of sparse rewards in reinforcement\nlearning by constructing denser and more informative reward signals. To achieve\nself-adaptive and highly efficient reward shaping, we propose a novel method\nthat incorporates success rates derived from historical experiences into shaped\nrewards. Our approach utilizes success rates sampled from Beta distributions,\nwhich dynamically evolve from uncertain to reliable values as more data is\ncollected. Initially, the self-adaptive success rates exhibit more randomness\nto encourage exploration. Over time, they become more certain to enhance\nexploitation, thus achieving a better balance between exploration and\nexploitation. We employ Kernel Density Estimation (KDE) combined with Random\nFourier Features (RFF) to derive the Beta distributions, resulting in a\ncomputationally efficient implementation in high-dimensional continuous state\nspaces. This method provides a non-parametric and learning-free approach. The\nproposed method is evaluated on a wide range of continuous control tasks with\nsparse and delayed rewards, demonstrating significant improvements in sample\nefficiency and convergence stability compared to several baselines.",
    "arxiv_id": "http://arxiv.org/abs/2408.03029v1",
    "pdf_url": "http://arxiv.org/pdf/2408.03029v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "NeurDB: On the Design and Implementation of an AI-powered Autonomous Database",
    "authors": "Zhanhao Zhao, Shaofeng Cai, Haotian Gao, Hexiang Pan, Siqi Xiang, Naili Xing, Gang Chen, Beng Chin Ooi, Yanyan Shen, Yuncheng Wu, Meihui Zhang",
    "abstract": "Databases are increasingly embracing AI to provide autonomous system\noptimization and intelligent in-database analytics, aiming to relieve end-user\nburdens across various industry sectors. Nonetheless, most existing approaches\nfail to account for the dynamic nature of databases, which renders them\nineffective for real-world applications characterized by evolving data and\nworkloads. This paper introduces NeurDB, an AI-powered autonomous database that\ndeepens the fusion of AI and databases with adaptability to data and workload\ndrift. NeurDB establishes a new in-database AI ecosystem that seamlessly\nintegrates AI workflows within the database. This integration enables efficient\nand effective in-database AI analytics and fast-adaptive learned system\ncomponents. Empirical evaluations demonstrate that NeurDB substantially\noutperforms existing solutions in managing AI analytics tasks, with the\nproposed learned components more effectively handling environmental dynamism\nthan state-of-the-art approaches.",
    "arxiv_id": "http://arxiv.org/abs/2408.03013v1",
    "pdf_url": "http://arxiv.org/pdf/2408.03013v1",
    "primary_category": "cs.DB",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Federated Learning Architectures: A Performance Evaluation with Crop Yield Prediction Application",
    "authors": "Anwesha Mukherjee, Rajkumar Buyya",
    "abstract": "Federated learning has become an emerging technology for data analysis for\nIoT applications. This paper implements centralized and decentralized federated\nlearning frameworks for crop yield prediction based on Long Short-Term Memory\nNetwork. For centralized federated learning, multiple clients and one server is\nconsidered, where the clients exchange their model updates with the server that\nworks as the aggregator to build the global model. For the decentralized\nframework, a collaborative network is formed among the devices either using\nring topology or using mesh topology. In this network, each device receives\nmodel updates from the neighbour devices, and performs aggregation to build the\nupgraded model. The performance of the centralized and decentralized federated\nlearning frameworks are evaluated in terms of prediction accuracy, precision,\nrecall, F1-Score, and training time. The experimental results present that\n$\\geq$97% and $>$97.5% prediction accuracy are achieved using the centralized\nand decentralized federated learning-based frameworks respectively. The results\nalso show that the using centralized federated learning the response time can\nbe reduced by $\\sim$75% than the cloud-only framework. Finally, the future\nresearch directions of the use of federated learning in crop yield prediction\nare explored in this paper.",
    "arxiv_id": "http://arxiv.org/abs/2408.02998v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02998v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "A Differential Smoothness-based Compact-Dynamic Graph Convolutional Network for Spatiotemporal Signal Recovery",
    "authors": "Pengcheng Gao, Zicheng Gao, Ye Yuan",
    "abstract": "High quality spatiotemporal signal is vitally important for real application\nscenarios like energy management, traffic planning and cyber security. Due to\nthe uncontrollable factors like abrupt sensors breakdown or communication\nfault, the spatiotemporal signal collected by sensors is always incomplete. A\ndynamic graph convolutional network (DGCN) is effective for processing\nspatiotemporal signal recovery. However, it adopts a static GCN and a sequence\nneural network to explore the spatial and temporal patterns, separately. Such a\nseparated two-step processing is loose spatiotemporal, thereby failing to\ncapture the complex inner spatiotemporal correlation. To address this issue,\nthis paper proposes a Compact-Dynamic Graph Convolutional Network (CDGCN) for\nspatiotemporal signal recovery with the following two-fold ideas: a) leveraging\nthe tensor M-product to build a unified tensor graph convolution framework,\nwhich considers both spatial and temporal patterns simultaneously; and b)\nconstructing a differential smoothness-based objective function to reduce the\nnoise interference in spatiotemporal signal, thereby further improve the\nrecovery accuracy. Experiments on real-world spatiotemporal datasets\ndemonstrate that the proposed CDGCN significantly outperforms the\nstate-of-the-art models in terms of recovery accuracy.",
    "arxiv_id": "http://arxiv.org/abs/2408.02987v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02987v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Wave Interpolation Neural Operator: Interpolated Prediction of Electric Fields Across Untrained Wavelengths",
    "authors": "Joonhyuk Seo, Chanik Kang, Dongjin Seo, Haejun Chung",
    "abstract": "Designing photonic structures requires electromagnetic simulations, which\noften require high computational costs. Researchers have developed surrogate\nsolvers for predicting electric fields to alleviate the computational issues.\nHowever, existing surrogate solvers are limited to performing inference at\nfixed simulation conditions and require retraining for different conditions. To\naddress this, we propose Wave Interpolation Neural Operator (WINO), a novel\nsurrogate solver enabling simulation condition interpolation across a\ncontinuous spectrum of broadband wavelengths. WINO introduces the Fourier Group\nConvolution Shuffling operator and a new conditioning method to efficiently\npredict electric fields from both trained and untrained wavelength data,\nachieving significant improvements in parameter efficiency and spectral\ninterpolation performance. Our model demonstrates approximately 100 times\nfaster performance than traditional finite-difference frequency-domain\nsimulations. Moreover, compared to the state-of-the-art model, we achieve a 74%\nreduction in parameters and 80.5% improvements in prediction accuracy for\nuntrained wavelengths, and 13.2% improvements for trained wavelengths.",
    "arxiv_id": "http://arxiv.org/abs/2408.02971v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02971v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Data-Driven Stochastic Closure Modeling via Conditional Diffusion Model and Neural Operator",
    "authors": "Xinghao Dong, Chuanqi Chen, Jin-Long Wu",
    "abstract": "Closure models are widely used in simulating complex multiscale dynamical\nsystems such as turbulence and the earth system, for which direct numerical\nsimulation that resolves all scales is often too expensive. For those systems\nwithout a clear scale separation, deterministic and local closure models often\nlack enough generalization capability, which limits their performance in many\nreal-world applications. In this work, we propose a data-driven modeling\nframework for constructing stochastic and non-local closure models via\nconditional diffusion model and neural operator. Specifically, the Fourier\nneural operator is incorporated into a score-based diffusion model, which\nserves as a data-driven stochastic closure model for complex dynamical systems\ngoverned by partial differential equations (PDEs). We also demonstrate how\naccelerated sampling methods can improve the efficiency of the data-driven\nstochastic closure model. The results show that the proposed methodology\nprovides a systematic approach via generative machine learning techniques to\nconstruct data-driven stochastic closure models for multiscale dynamical\nsystems with continuous spatiotemporal fields.",
    "arxiv_id": "http://arxiv.org/abs/2408.02965v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02965v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Synaptic Modulation using Interspike Intervals Increases Energy Efficiency of Spiking Neural Networks",
    "authors": "Dylan Adams, Magda Zajaczkowska, Ashiq Anjum, Andrea Soltoggio, Shirin Dora",
    "abstract": "Despite basic differences between Spiking Neural Networks (SNN) and\nArtificial Neural Networks (ANN), most research on SNNs involve adapting\nANN-based methods for SNNs. Pruning (dropping connections) and quantization\n(reducing precision) are often used to improve energy efficiency of SNNs. These\nmethods are very effective for ANNs whose energy needs are determined by\nsignals transmitted on synapses. However, the event-driven paradigm in SNNs\nimplies that energy is consumed by spikes. In this paper, we propose a new\nsynapse model whose weights are modulated by Interspike Intervals (ISI) i.e.\ntime difference between two spikes. SNNs composed of this synapse model, termed\nISI Modulated SNNs (IMSNN), can use gradient descent to estimate how the ISI of\na neuron changes after updating its synaptic parameters. A higher ISI implies\nfewer spikes and vice-versa. The learning algorithm for IMSNNs exploits this\ninformation to selectively propagate gradients such that learning is achieved\nby increasing the ISIs resulting in a network that generates fewer spikes. The\nperformance of IMSNNs with dense and convolutional layers have been evaluated\nin terms of classification accuracy and the number of spikes using the MNIST\nand FashionMNIST datasets. The performance comparison with conventional SNNs\nshows that IMSNNs exhibit upto 90% reduction in the number of spikes while\nmaintaining similar classification accuracy.",
    "arxiv_id": "http://arxiv.org/abs/2408.02961v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02961v1",
    "primary_category": "cs.NE",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Kolmogorov-Arnold PointNet: Deep learning for prediction of fluid fields on irregular geometries",
    "authors": "Ali Kashefi",
    "abstract": "We present Kolmogorov-Arnold PointNet (KA-PointNet) as a novel supervised\ndeep learning framework for the prediction of incompressible steady-state fluid\nflow fields in irregular domains, where the predicted fields are a function of\nthe geometry of the domains. In KA-PointNet, we implement shared\nKolmogorov-Arnold Networks (KANs) in the segmentation branch of the PointNet\narchitecture. We utilize Jacobi polynomials to construct shared KANs. As a\nbenchmark test case, we consider incompressible laminar steady-state flow over\na cylinder, where the geometry of its cross-section varies over the data set.\nWe investigate the performance of Jacobi polynomials with different degrees as\nwell as special cases of Jacobi polynomials such as Legendre polynomials,\nChebyshev polynomials of the first and second kinds, and Gegenbauer\npolynomials, in terms of the computational cost of training and accuracy of\nprediction of the test set. Additionally, we compare the performance of\nPointNet with shared KANs (i.e., KA-PointNet) and PointNet with shared\nMultilayer Perceptrons (MLPs). It is observed that when the number of trainable\nparameters is approximately equal, PointNet with shared KANs (i.e.,\nKA-PointNet) outperforms PointNet with shared MLPs.",
    "arxiv_id": "http://arxiv.org/abs/2408.02950v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02950v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Scaling Laws for Data Poisoning in LLMs",
    "authors": "Dillon Bowen, Brendan Murphy, Will Cai, David Khachaturov, Adam Gleave, Kellin Pelrine",
    "abstract": "Recent work shows that LLMs are vulnerable to data poisoning, in which they\nare trained on partially corrupted or harmful data. Poisoned data is hard to\ndetect, breaks guardrails, and leads to undesirable and harmful behavior. Given\nthe intense efforts by leading labs to train and deploy increasingly larger and\nmore capable LLMs, it is critical to ask if the risk of data poisoning will be\nnaturally mitigated by scale, or if it is an increasing threat. We consider\nthree threat models by which data poisoning can occur: malicious fine-tuning,\nimperfect data curation, and intentional data contamination. Our experiments\nevaluate the effects of data poisoning on 23 frontier LLMs ranging from 1.5-72\nbillion parameters on three datasets which speak to each of our threat models.\nWe find that larger LLMs are increasingly vulnerable, learning harmful behavior\n-- including sleeper agent behavior -- significantly more quickly than smaller\nLLMs with even minimal data poisoning. These results underscore the need for\nrobust safeguards against data poisoning in larger LLMs.",
    "arxiv_id": "http://arxiv.org/abs/2408.02946v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02946v1",
    "primary_category": "cs.CR",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Achieving More with Less: A Tensor-Optimization-Powered Ensemble Method",
    "authors": "Jinghui Yuan, Weijin Jiang, Zhe Cao, Fangyuan Xie, Rong Wang, Feiping Nie, Xuelong Li",
    "abstract": "Ensemble learning is a method that leverages weak learners to produce a\nstrong learner. However, obtaining a large number of base learners requires\nsubstantial time and computational resources. Therefore, it is meaningful to\nstudy how to achieve the performance typically obtained with many base learners\nusing only a few. We argue that to achieve this, it is essential to enhance\nboth classification performance and generalization ability during the ensemble\nprocess. To increase model accuracy, each weak base learner needs to be more\nefficiently integrated. It is observed that different base learners exhibit\nvarying levels of accuracy in predicting different classes. To capitalize on\nthis, we introduce confidence tensors $\\tilde{\\mathbf{\\Theta}}$ and\n$\\tilde{\\mathbf{\\Theta}}_{rst}$ signifies that the $t$-th base classifier\nassigns the sample to class $r$ while it actually belongs to class $s$. To the\nbest of our knowledge, this is the first time an evaluation of the performance\nof base classifiers across different classes has been proposed. The proposed\nconfidence tensor compensates for the strengths and weaknesses of each base\nclassifier in different classes, enabling the method to achieve superior\nresults with a smaller number of base learners. To enhance generalization\nperformance, we design a smooth and convex objective function that leverages\nthe concept of margin, making the strong learner more discriminative.\nFurthermore, it is proved that in gradient matrix of the loss function, the sum\nof each column's elements is zero, allowing us to solve a constrained\noptimization problem using gradient-based methods. We then compare our\nalgorithm with random forests of ten times the size and other classical methods\nacross numerous datasets, demonstrating the superiority of our approach.",
    "arxiv_id": "http://arxiv.org/abs/2408.02936v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02936v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Doubly Stochastic Adaptive Neighbors Clustering via the Marcus Mapping",
    "authors": "Jinghui Yuan, Chusheng Zeng, Fangyuan Xie, Zhe Cao, Rong Wang, Feiping Nie, Xuelong Li",
    "abstract": "Clustering is a fundamental task in machine learning and data science, and\nsimilarity graph-based clustering is an important approach within this domain.\nDoubly stochastic symmetric similarity graphs provide numerous benefits for\nclustering problems and downstream tasks, yet learning such graphs remains a\nsignificant challenge. Marcus theorem states that a strictly positive symmetric\nmatrix can be transformed into a doubly stochastic symmetric matrix by diagonal\nmatrices. However, in clustering, learning sparse matrices is crucial for\ncomputational efficiency. We extend Marcus theorem by proposing the Marcus\nmapping, which indicates that certain sparse matrices can also be transformed\ninto doubly stochastic symmetric matrices via diagonal matrices. Additionally,\nwe introduce rank constraints into the clustering problem and propose the\nDoubly Stochastic Adaptive Neighbors Clustering algorithm based on the Marcus\nMapping (ANCMM). This ensures that the learned graph naturally divides into the\ndesired number of clusters. We validate the effectiveness of our algorithm\nthrough extensive comparisons with state-of-the-art algorithms. Finally, we\nexplore the relationship between the Marcus mapping and optimal transport. We\nprove that the Marcus mapping solves a specific type of optimal transport\nproblem and demonstrate that solving this problem through Marcus mapping is\nmore efficient than directly applying optimal transport methods.",
    "arxiv_id": "http://arxiv.org/abs/2408.02932v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02932v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "The Need for a Big World Simulator: A Scientific Challenge for Continual Learning",
    "authors": "Saurabh Kumar, Hong Jun Jeon, Alex Lewandowski, Benjamin Van Roy",
    "abstract": "The \"small agent, big world\" frame offers a conceptual view that motivates\nthe need for continual learning. The idea is that a small agent operating in a\nmuch bigger world cannot store all information that the world has to offer. To\nperform well, the agent must be carefully designed to ingest, retain, and eject\nthe right information. To enable the development of performant continual\nlearning agents, a number of synthetic environments have been proposed.\nHowever, these benchmarks suffer from limitations, including unnatural\ndistribution shifts and a lack of fidelity to the \"small agent, big world\"\nframing. This paper aims to formalize two desiderata for the design of future\nsimulated environments. These two criteria aim to reflect the objectives and\ncomplexity of continual learning in practical settings while enabling rapid\nprototyping of algorithms on a smaller scale.",
    "arxiv_id": "http://arxiv.org/abs/2408.02930v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02930v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "HARMONIC: Harnessing LLMs for Tabular Data Synthesis and Privacy Protection",
    "authors": "Yuxin Wang, Duanyu Feng, Yongfu Dai, Zhengyu Chen, Jimin Huang, Sophia Ananiadou, Qianqian Xie, Hao Wang",
    "abstract": "Data serves as the fundamental foundation for advancing deep learning,\nparticularly tabular data presented in a structured format, which is highly\nconducive to modeling. However, even in the era of LLM, obtaining tabular data\nfrom sensitive domains remains a challenge due to privacy or copyright\nconcerns. Hence, exploring how to effectively use models like LLMs to generate\nrealistic and privacy-preserving synthetic tabular data is urgent. In this\npaper, we take a step forward to explore LLMs for tabular data synthesis and\nprivacy protection, by introducing a new framework HARMONIC for tabular data\ngeneration and evaluation. In the tabular data generation of our framework,\nunlike previous small-scale LLM-based methods that rely on continued\npre-training, we explore the larger-scale LLMs with fine-tuning to generate\ntabular data and enhance privacy. Based on idea of the k-nearest neighbors\nalgorithm, an instruction fine-tuning dataset is constructed to inspire LLMs to\ndiscover inter-row relationships. Then, with fine-tuning, LLMs are trained to\nremember the format and connections of the data rather than the data itself,\nwhich reduces the risk of privacy leakage. In the evaluation part of our\nframework, we develop specific privacy risk metrics DLT for LLM synthetic data\ngeneration, as well as performance evaluation metrics LLE for downstream LLM\ntasks. Our experiments find that this tabular data generation framework\nachieves equivalent performance to existing methods with better privacy, which\nalso demonstrates our evaluation framework for the effectiveness of synthetic\ndata and privacy risks in LLM scenarios.",
    "arxiv_id": "http://arxiv.org/abs/2408.02927v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02927v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "A Metric Driven Approach to Mixed Precision Training",
    "authors": "Mitchelle Rasquinha, Gil Tabak",
    "abstract": "As deep learning methodologies have developed, it has been generally agreed\nthat increasing neural network size improves model quality. However, this is at\nthe expense of memory and compute requirements, which also need to be\nincreased. Various efficiency techniques have been proposed to rein in hardware\ncosts, one being the use of low precision numerics. Recent accelerators have\nintroduced several different 8-bit data types to help accommodate DNNs in terms\nof numerics. In this paper, we identify a metric driven methodology to aid in\nthe choice of numerics. We demonstrate how such a methodology can help scale\ntraining of a language representation model. The technique can be generalized\nto other model architectures.",
    "arxiv_id": "http://arxiv.org/abs/2408.02897v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02897v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Compromising Embodied Agents with Contextual Backdoor Attacks",
    "authors": "Aishan Liu, Yuguang Zhou, Xianglong Liu, Tianyuan Zhang, Siyuan Liang, Jiakai Wang, Yanjun Pu, Tianlin Li, Junqi Zhang, Wenbo Zhou, Qing Guo, Dacheng Tao",
    "abstract": "Large language models (LLMs) have transformed the development of embodied\nintelligence. By providing a few contextual demonstrations, developers can\nutilize the extensive internal knowledge of LLMs to effortlessly translate\ncomplex tasks described in abstract language into sequences of code snippets,\nwhich will serve as the execution logic for embodied agents. However, this\npaper uncovers a significant backdoor security threat within this process and\nintroduces a novel method called \\method{}. By poisoning just a few contextual\ndemonstrations, attackers can covertly compromise the contextual environment of\na black-box LLM, prompting it to generate programs with context-dependent\ndefects. These programs appear logically sound but contain defects that can\nactivate and induce unintended behaviors when the operational agent encounters\nspecific triggers in its interactive environment. To compromise the LLM's\ncontextual environment, we employ adversarial in-context generation to optimize\npoisoned demonstrations, where an LLM judge evaluates these poisoned prompts,\nreporting to an additional LLM that iteratively optimizes the demonstration in\na two-player adversarial game using chain-of-thought reasoning. To enable\ncontext-dependent behaviors in downstream agents, we implement a dual-modality\nactivation strategy that controls both the generation and execution of program\ndefects through textual and visual triggers. We expand the scope of our attack\nby developing five program defect modes that compromise key aspects of\nconfidentiality, integrity, and availability in embodied agents. To validate\nthe effectiveness of our approach, we conducted extensive experiments across\nvarious tasks, including robot planning, robot manipulation, and compositional\nvisual reasoning. Additionally, we demonstrate the potential impact of our\napproach by successfully attacking real-world autonomous driving systems.",
    "arxiv_id": "http://arxiv.org/abs/2408.02882v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02882v1",
    "primary_category": "cs.AI",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Back-Projection Diffusion: Solving the Wideband Inverse Scattering Problem with Diffusion Models",
    "authors": "Borong Zhang, Mart\u00edn Guerra, Qin Li, Leonardo Zepeda-N\u00fa\u00f1ez",
    "abstract": "We present \\textit{Wideband back-projection diffusion}, an end-to-end\nprobabilistic framework for approximating the posterior distribution induced by\nthe inverse scattering map from wideband scattering data. This framework\nleverages conditional diffusion models coupled with the underlying physics of\nwave-propagation and symmetries in the problem, to produce highly accurate\nreconstructions. The framework introduces a factorization of the score function\ninto a physics-based latent representation inspired by the filtered\nback-propagation formula and a conditional score function conditioned on this\nlatent representation. These two steps are also constrained to obey symmetries\nin the formulation while being amenable to compression by imposing the rank\nstructure found in the filtered back-projection formula. As a result,\nempirically, our framework is able to provide sharp reconstructions\neffortlessly, even recovering sub-Nyquist features in the multiple-scattering\nregime. It has low-sample and computational complexity, its number of\nparameters scales sub-linearly with the target resolution, and it has stable\ntraining dynamics.",
    "arxiv_id": "http://arxiv.org/abs/2408.02866v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02866v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "A Framework for Fine-Tuning LLMs using Heterogeneous Feedback",
    "authors": "Ryan Aponte, Ryan A. Rossi, Shunan Guo, Franck Dernoncourt, Tong Yu, Xiang Chen, Subrata Mitra, Nedim Lipka",
    "abstract": "Large language models (LLMs) have been applied to a wide range of tasks,\nincluding text summarization, web navigation, and chatbots. They have\nbenefitted from supervised fine-tuning (SFT) and reinforcement learning from\nhuman feedback (RLHF) following an unsupervised pretraining. These datasets can\nbe difficult to collect, limited in scope, and vary in sample quality.\nAdditionally, datasets can vary extensively in supervision format, from\nnumerical to binary as well as multi-dimensional with many different values. We\npresent a framework for fine-tuning LLMs using heterogeneous feedback, which\nhas two main components. First, we combine the heterogeneous feedback data into\na single supervision format, compatible with methods like SFT and RLHF. Next,\ngiven this unified feedback dataset, we extract a high-quality and diverse\nsubset to obtain performance increases potentially exceeding the full dataset.\nWe conduct extensive experiments to understand the effectiveness of these\ntechniques for incorporating heterogeneous feedback, and demonstrate\nimprovements from using a high-quality and diverse subset of the data. We find\nthat our framework is able to improve models in multiple areas simultaneously,\nsuch as in instruction following and bias reduction.",
    "arxiv_id": "http://arxiv.org/abs/2408.02861v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02861v1",
    "primary_category": "cs.CL",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Active Learning for WBAN-based Health Monitoring",
    "authors": "Cho-Chun Chiu, Tuan Nguyen, Ting He, Shiqiang Wang, Beom-Su Kim, Ki-Il Kim",
    "abstract": "We consider a novel active learning problem motivated by the need of learning\nmachine learning models for health monitoring in wireless body area network\n(WBAN). Due to the limited resources at body sensors, collecting each unlabeled\nsample in WBAN incurs a nontrivial cost. Moreover, training health monitoring\nmodels typically requires labels indicating the patient's health state that\nneed to be generated by healthcare professionals, which cannot be obtained at\nthe same pace as data collection. These challenges make our problem\nfundamentally different from classical active learning, where unlabeled samples\nare free and labels can be queried in real time. To handle these challenges, we\npropose a two-phased active learning method, consisting of an online phase\nwhere a coreset construction algorithm is proposed to select a subset of\nunlabeled samples based on their noisy predictions, and an offline phase where\nthe selected samples are labeled to train the target model. The samples\nselected by our algorithm are proved to yield a guaranteed error in\napproximating the full dataset in evaluating the loss function. Our evaluation\nbased on real health monitoring data and our own experimentation demonstrates\nthat our solution can drastically save the data curation cost without\nsacrificing the quality of the target model.",
    "arxiv_id": "http://arxiv.org/abs/2408.02849v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02849v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Heterogeneous graph attention network improves cancer multiomics integration",
    "authors": "Sina Tabakhi, Charlotte Vandermeulen, Ian Sudbery, Haiping Lu",
    "abstract": "The increase in high-dimensional multiomics data demands advanced integration\nmodels to capture the complexity of human diseases. Graph-based deep learning\nintegration models, despite their promise, struggle with small patient cohorts\nand high-dimensional features, often applying independent feature selection\nwithout modeling relationships among omics. Furthermore, conventional\ngraph-based omics models focus on homogeneous graphs, lacking multiple types of\nnodes and edges to capture diverse structures. We introduce a Heterogeneous\nGraph ATtention network for omics integration (HeteroGATomics) to improve\ncancer diagnosis. HeteroGATomics performs joint feature selection through a\nmulti-agent system, creating dedicated networks of feature and patient\nsimilarity for each omic modality. These networks are then combined into one\nheterogeneous graph for learning holistic omic-specific representations and\nintegrating predictions across modalities. Experiments on three cancer\nmultiomics datasets demonstrate HeteroGATomics' superior performance in cancer\ndiagnosis. Moreover, HeteroGATomics enhances interpretability by identifying\nimportant biomarkers contributing to the diagnosis outcomes.",
    "arxiv_id": "http://arxiv.org/abs/2408.02845v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02845v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Evaluating Posterior Probabilities: Decision Theory, Proper Scoring Rules, and Calibration",
    "authors": "Luciana Ferrer, Daniel Ramos",
    "abstract": "Most machine learning classifiers are designed to output posterior\nprobabilities for the classes given the input sample. These probabilities may\nbe used to make the categorical decision on the class of the sample; provided\nas input to a downstream system; or provided to a human for interpretation.\nEvaluating the quality of the posteriors generated by these system is an\nessential problem which was addressed decades ago with the invention of proper\nscoring rules (PSRs). Unfortunately, much of the recent machine learning\nliterature uses calibration metrics -- most commonly, the expected calibration\nerror (ECE) -- as a proxy to assess posterior performance. The problem with\nthis approach is that calibration metrics reflect only one aspect of the\nquality of the posteriors, ignoring the discrimination performance. For this\nreason, we argue that calibration metrics should play no role in the assessment\nof posterior quality. Expected PSRs should instead be used for this job,\npreferably normalized for ease of interpretation. In this work, we first give a\nbrief review of PSRs from a practical perspective, motivating their definition\nusing Bayes decision theory. We discuss why expected PSRs provide a principled\nmeasure of the quality of a system's posteriors and why calibration metrics are\nnot the right tool for this job. We argue that calibration metrics, while not\nuseful for performance assessment, may be used as diagnostic tools during\nsystem development. With this purpose in mind, we discuss a simple and\npractical calibration metric, called calibration loss, derived from a\ndecomposition of expected PSRs. We compare this metric with the ECE and with\nthe expected score divergence calibration metric from the PSR literature and\nargue, using theoretical and empirical evidence, that calibration loss is\nsuperior to these two metrics.",
    "arxiv_id": "http://arxiv.org/abs/2408.02841v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02841v1",
    "primary_category": "stat.ML",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Optimizing Cox Models with Stochastic Gradient Descent: Theoretical Foundations and Practical Guidances",
    "authors": "Lang Zeng, Weijing Tang, Zhao Ren, Ying Ding",
    "abstract": "Optimizing Cox regression and its neural network variants poses substantial\ncomputational challenges in large-scale studies. Stochastic gradient descent\n(SGD), known for its scalability in model optimization, has recently been\nadapted to optimize Cox models. Unlike its conventional application, which\ntypically targets a sum of independent individual loss, SGD for Cox models\nupdates parameters based on the partial likelihood of a subset of data. Despite\nits empirical success, the theoretical foundation for optimizing Cox partial\nlikelihood with SGD is largely underexplored. In this work, we demonstrate that\nthe SGD estimator targets an objective function that is batch-size-dependent.\nWe establish that the SGD estimator for the Cox neural network (Cox-NN) is\nconsistent and achieves the optimal minimax convergence rate up to a\npolylogarithmic factor. For Cox regression, we further prove the\n$\\sqrt{n}$-consistency and asymptotic normality of the SGD estimator, with\nvariance depending on the batch size. Furthermore, we quantify the impact of\nbatch size on Cox-NN training and its effect on the SGD estimator's asymptotic\nefficiency in Cox regression. These findings are validated by extensive\nnumerical experiments and provide guidance for selecting batch sizes in SGD\napplications. Finally, we demonstrate the effectiveness of SGD in a real-world\napplication where GD is unfeasible due to the large scale of data.",
    "arxiv_id": "http://arxiv.org/abs/2408.02839v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02839v1",
    "primary_category": "stat.ML",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Interpretation of the Intent Detection Problem as Dynamics in a Low-dimensional Space",
    "authors": "Eduardo Sanchez-Karhunen, Jose F. Quesada-Moreno, Miguel A. Guti\u00e9rrez-Naranjo",
    "abstract": "Intent detection is a text classification task whose aim is to recognize and\nlabel the semantics behind a users query. It plays a critical role in various\nbusiness applications. The output of the intent detection module strongly\nconditions the behavior of the whole system. This sequence analysis task is\nmainly tackled using deep learning techniques. Despite the widespread use of\nthese techniques, the internal mechanisms used by networks to solve the problem\nare poorly understood. Recent lines of work have analyzed the computational\nmechanisms learned by RNNs from a dynamical systems perspective. In this work,\nwe investigate how different RNN architectures solve the SNIPS intent detection\nproblem. Sentences injected into trained networks can be interpreted as\ntrajectories traversing a hidden state space. This space is constrained to a\nlow-dimensional manifold whose dimensionality is related to the embedding and\nhidden layer sizes. To generate predictions, RNN steers the trajectories\ntowards concrete regions, spatially aligned with the output layer matrix rows\ndirections. Underlying the system dynamics, an unexpected fixed point topology\nhas been identified with a limited number of attractors. Our results provide\nnew insights into the inner workings of networks that solve the intent\ndetection task.",
    "arxiv_id": "http://arxiv.org/abs/2408.02838v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02838v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Training a multilayer dynamical spintronic network with standard machine learning tools to perform time series classification",
    "authors": "Erwan Plouet, D\u00e9dalo Sanz-Hern\u00e1ndez, Aymeric Vecchiola, Julie Grollier, Frank Mizrahi",
    "abstract": "The ability to process time-series at low energy cost is critical for many\napplications. Recurrent neural network, which can perform such tasks, are\ncomputationally expensive when implementing in software on conventional\ncomputers. Here we propose to implement a recurrent neural network in hardware\nusing spintronic oscillators as dynamical neurons. Using numerical simulations,\nwe build a multi-layer network and demonstrate that we can use backpropagation\nthrough time (BPTT) and standard machine learning tools to train this network.\nLeveraging the transient dynamics of the spintronic oscillators, we solve the\nsequential digits classification task with $89.83\\pm2.91~\\%$ accuracy, as good\nas the equivalent software network. We devise guidelines on how to choose the\ntime constant of the oscillators as well as hyper-parameters of the network to\nadapt to different input time scales.",
    "arxiv_id": "http://arxiv.org/abs/2408.02835v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02835v1",
    "primary_category": "cond-mat.dis-nn",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "DaCapo: a modular deep learning framework for scalable 3D image segmentation",
    "authors": "William Patton, Jeff L. Rhoades, Marwan Zouinkhi, David G. Ackerman, Caroline Malin-Mayor, Diane Adjavon, Larissa Heinrich, Davis Bennett, Yurii Zubov, CellMap Project Team, Aubrey V. Weigel, Jan Funke",
    "abstract": "DaCapo is a specialized deep learning library tailored to expedite the\ntraining and application of existing machine learning approaches on large,\nnear-isotropic image data. In this correspondence, we introduce DaCapo's unique\nfeatures optimized for this specific domain, highlighting its modular\nstructure, efficient experiment management tools, and scalable deployment\ncapabilities. We discuss its potential to improve access to large-scale,\nisotropic image segmentation and invite the community to explore and contribute\nto this open-source initiative.",
    "arxiv_id": "http://arxiv.org/abs/2408.02834v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02834v1",
    "primary_category": "cs.CV",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Adaptive Learning for Quantum Linear Regression",
    "authors": "Costantino Carugno, Maurizio Ferrari Dacrema, Paolo Cremonesi",
    "abstract": "The recent availability of quantum annealers as cloud-based services has\nenabled new ways to handle machine learning problems, and several relevant\nalgorithms have been adapted to run on these devices. In a recent work, linear\nregression was formulated as a quadratic binary optimization problem that can\nbe solved via quantum annealing. Although this approach promises a\ncomputational time advantage for large datasets, the quality of the solution is\nlimited by the necessary use of a precision vector, used to approximate the\nreal-numbered regression coefficients in the quantum formulation. In this work,\nwe focus on the practical challenge of improving the precision vector encoding:\ninstead of setting an array of generic values equal for all coefficients, we\nallow each one to be expressed by its specific precision, which is tuned with a\nsimple adaptive algorithm. This approach is evaluated on synthetic datasets of\nincreasing size, and linear regression is solved using the D-Wave Advantage\nquantum annealer, as well as classical solvers. To the best of our knowledge,\nthis is the largest dataset ever evaluated for linear regression on a quantum\nannealer. The results show that our formulation is able to deliver improved\nsolution quality in all instances, and could better exploit the potential of\ncurrent quantum devices.",
    "arxiv_id": "http://arxiv.org/abs/2408.02833v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02833v1",
    "primary_category": "quant-ph",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Setting the duration of online A/B experiments",
    "authors": "Harrison H. Li, Chaoyu Yu",
    "abstract": "In designing an online A/B experiment, it is crucial to select a sample size\nand duration that ensure the resulting confidence interval (CI) for the\ntreatment effect is the right width to detect an effect of meaningful magnitude\nwith sufficient statistical power without wasting resources. While the\nrelationship between sample size and CI width is well understood, the effect of\nexperiment duration on CI width remains less clear. This paper provides an\nanalytical formula for the width of a CI based on a ratio treatment effect\nestimator as a function of both sample size (N) and duration (T). The formula\nis derived from a mixed effects model with two variance components. One\ncomponent, referred to as the temporal variance, persists over time for\nexperiments where the same users are kept in the same experiment arm across\ndifferent days. The remaining error variance component, by contrast, decays to\nzero as T gets large. The formula we derive introduces a key parameter that we\ncall the user-specific temporal correlation (UTC), which quantifies the\nrelative sizes of the two variance components and can be estimated from\nhistorical experiments. Higher UTC indicates a slower decay in CI width over\ntime. On the other hand, when the UTC is 0 -- as for experiments where users\nshuffle in and out of the experiment across days -- the CI width decays at the\nstandard parametric 1/T rate. We also study how access to pre-period data for\nthe users in the experiment affects the CI width decay. We show our formula\nclosely explains CI widths on real A/B experiments at YouTube.",
    "arxiv_id": "http://arxiv.org/abs/2408.02830v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02830v1",
    "primary_category": "stat.ME",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Wave-RVFL: A Randomized Neural Network Based on Wave Loss Function",
    "authors": "M. Sajid, A. Quadir, M. Tanveer",
    "abstract": "The random vector functional link (RVFL) network is well-regarded for its\nstrong generalization capabilities in the field of machine learning. However,\nits inherent dependencies on the square loss function make it susceptible to\nnoise and outliers. Furthermore, the calculation of RVFL's unknown parameters\nnecessitates matrix inversion of the entire training sample, which constrains\nits scalability. To address these challenges, we propose the Wave-RVFL, an RVFL\nmodel incorporating the wave loss function. We formulate and solve the proposed\noptimization problem of the Wave-RVFL using the adaptive moment estimation\n(Adam) algorithm in a way that successfully eliminates the requirement for\nmatrix inversion and significantly enhances scalability. The Wave-RVFL exhibits\nrobustness against noise and outliers by preventing over-penalization of\ndeviations, thereby maintaining a balanced approach to managing noise and\noutliers. The proposed Wave-RVFL model is evaluated on multiple UCI datasets,\nboth with and without the addition of noise and outliers, across various\ndomains and sizes. Empirical results affirm the superior performance and\nrobustness of the Wave-RVFL compared to baseline models, establishing it as a\nhighly effective and scalable classification solution.",
    "arxiv_id": "http://arxiv.org/abs/2408.02824v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02824v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Continuous Monitoring via Repeated Significance",
    "authors": "Eric Bax, Arundhyoti Sarkar, Alex Shtoff",
    "abstract": "Requiring statistical significance at multiple interim analyses to declare a\nstatistically significant result for an AB test allows less stringent\nrequirements for significance at each interim analysis. Repeated repeated\nsignificance competes well with methods built on assumptions about the test --\nassumptions that may be impossible to evaluate a priori and may require extra\ndata to evaluate empirically.\n  Instead, requiring repeated significance allows the data itself to prove\ndirectly that the required results are not due to chance alone. We explain how\nto apply tests with repeated significance to continuously monitor unbounded\ntests -- tests that do not have an a priori bound on running time or number of\nobservations. We show that it is impossible to maintain a constant requirement\nfor significance for unbounded tests, but that we can come arbitrarily close to\nthat goal.",
    "arxiv_id": "http://arxiv.org/abs/2408.02821v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02821v1",
    "primary_category": "stat.ME",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Pre-trained Encoder Inference: Revealing Upstream Encoders In Downstream Machine Learning Services",
    "authors": "Shaopeng Fu, Xuexue Sun, Ke Qing, Tianhang Zheng, Di Wang",
    "abstract": "Though pre-trained encoders can be easily accessed online to build downstream\nmachine learning (ML) services quickly, various attacks have been designed to\ncompromise the security and privacy of these encoders. While most attacks\ntarget encoders on the upstream side, it remains unknown how an encoder could\nbe threatened when deployed in a downstream ML service. This paper unveils a\nnew vulnerability: the Pre-trained Encoder Inference (PEI) attack, which posts\nprivacy threats toward encoders hidden behind downstream ML services. By only\nproviding API accesses to a targeted downstream service and a set of candidate\nencoders, the PEI attack can infer which encoder is secretly used by the\ntargeted service based on candidate ones. We evaluate the attack performance of\nPEI against real-world encoders on three downstream tasks: image\nclassification, text classification, and text-to-image generation. Experiments\nshow that the PEI attack succeeds in revealing the hidden encoder in most cases\nand seldom makes mistakes even when the hidden encoder is not in the candidate\nset. We also conducted a case study on one of the most recent vision-language\nmodels, LLaVA, to illustrate that the PEI attack is useful in assisting other\nML attacks such as adversarial attacks. The code is available at\nhttps://github.com/fshp971/encoder-inference.",
    "arxiv_id": "http://arxiv.org/abs/2408.02814v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02814v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Mitigating Malicious Attacks in Federated Learning via Confidence-aware Defense",
    "authors": "Qilei Li, Ahmed M. Abdelmoniem",
    "abstract": "Federated Learning (FL) is an emerging distributed machine learning paradigm\nthat allows multiple clients to collaboratively train a global model without\nsharing private local data. However, FL systems are vulnerable to attacks from\nmalicious clients, who can degrade the global model performance through data\npoisoning and model poisoning. Existing defense methods typically focus on a\nsingle type of attack, such as Byzantine attacks or backdoor attacks, and are\noften ineffective against potential data poisoning attacks like label flipping\nand label shuffling. Additionally, these methods often lack accuracy and\nrobustness in detecting and handling malicious updates. To address these\nissues, we propose a novel method based on model confidence scores, which\nevaluates the uncertainty of client model updates to detect and defend against\nmalicious clients. Our approach is comprehensively effective for both model\npoisoning and data poisoning attacks and is capable of accurately identifying\nand mitigating potential malicious updates from being aggregated. Experimental\nresults demonstrate that our method significantly improves the robustness of FL\nsystems against various types of attacks, also achieving higher model accuracy\nand stability across various scenarios.",
    "arxiv_id": "http://arxiv.org/abs/2408.02813v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02813v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Deciphering Air Travel Disruptions: A Machine Learning Approach",
    "authors": "Aravinda Jatavallabha, Jacob Gerlach, Aadithya Naresh",
    "abstract": "This research investigates flight delay trends by examining factors such as\ndeparture time, airline, and airport. It employs regression machine learning\nmethods to predict the contributions of various sources to delays. Time-series\nmodels, including LSTM, Hybrid LSTM, and Bi-LSTM, are compared with baseline\nregression models such as Multiple Regression, Decision Tree Regression, Random\nForest Regression, and Neural Network. Despite considerable errors in the\nbaseline models, the study aims to identify influential features in delay\nprediction, potentially informing flight planning strategies. Unlike previous\nwork, this research focuses on regression tasks and explores the use of\ntime-series models for predicting flight delays. It offers insights into\naviation operations by independently analyzing each delay component (e.g.,\nsecurity, weather).",
    "arxiv_id": "http://arxiv.org/abs/2408.02802v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02802v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Sparse Deep Learning Models with the $\\ell_1$ Regularization",
    "authors": "Lixin Shen, Rui Wang, Yuesheng Xu, Mingsong Yan",
    "abstract": "Sparse neural networks are highly desirable in deep learning in reducing its\ncomplexity. The goal of this paper is to study how choices of regularization\nparameters influence the sparsity level of learned neural networks. We first\nderive the $\\ell_1$-norm sparsity-promoting deep learning models including\nsingle and multiple regularization parameters models, from a statistical\nviewpoint. We then characterize the sparsity level of a regularized neural\nnetwork in terms of the choice of the regularization parameters. Based on the\ncharacterizations, we develop iterative algorithms for selecting regularization\nparameters so that the weight parameters of the resulting deep neural network\nenjoy prescribed sparsity levels. Numerical experiments are presented to\ndemonstrate the effectiveness of the proposed algorithms in choosing desirable\nregularization parameters and obtaining corresponding neural networks having\nboth of predetermined sparsity levels and satisfactory approximation accuracy.",
    "arxiv_id": "http://arxiv.org/abs/2408.02801v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02801v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Examining Gender and Power on Wikipedia Through Face and Politeness",
    "authors": "Adil Soubki, Shyne Choi, Owen Rambow",
    "abstract": "We propose a framework for analyzing discourse by combining two\ninterdependent concepts from sociolinguistic theory: face acts and politeness.\nWhile politeness has robust existing tools and data, face acts are less\nresourced. We introduce a new corpus created by annotating Wikipedia talk pages\nwith face acts and we use this to train a face act tagger. We then employ our\nframework to study how face and politeness interact with gender and power in\ndiscussions between Wikipedia editors. Among other findings, we observe that\nfemale Wikipedians are not only more polite, which is consistent with prior\nstudies, but that this difference corresponds with significantly more language\ndirected at humbling aspects of their own face. Interestingly, the distinction\nnearly vanishes once limiting to editors with administrative power.",
    "arxiv_id": "http://arxiv.org/abs/2408.02798v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02798v1",
    "primary_category": "cs.CL",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Algorithm-Informed Graph Neural Networks for Leakage Detection and Localization in Water Distribution Networks",
    "authors": "Zepeng Zhang, Olga Fink",
    "abstract": "Detecting and localizing leakages is a significant challenge for the\nefficient and sustainable management of water distribution networks (WDN).\nLeveraging the inherent graph structure of WDNs, recent approaches have used\ngraph-based data-driven methods. However, these methods often learn shortcuts\nthat work well with in-distribution data but fail to generalize to\nout-of-distribution data. To address this limitation and inspired by the\nperfect generalization ability of classical algorithms, we propose an\nalgorithm-informed graph neural network (AIGNN). Recognizing that WDNs function\nas flow networks, incorporating max-flow information can be beneficial for\ninferring pressures. In the proposed framework, we first train AIGNN to emulate\nthe Ford-Fulkerson algorithm for solving max-flow problems. This algorithmic\nknowledge is then transferred to address the pressure estimation problem in\nWDNs. Two AIGNNs are deployed, one to reconstruct pressure based on the current\nmeasurements, and another to predict pressure based on previous measurements.\nLeakages are detected and localized by comparing the outputs of the\nreconstructor and the predictor. By pretraining AIGNNs to reason like\nalgorithms, they are expected to extract more task-relevant and generalizable\nfeatures. Experimental results demonstrate that the proposed algorithm-informed\napproach achieves superior results with better generalization ability compared\nto GNNs that do not incorporate algorithmic knowledge.",
    "arxiv_id": "http://arxiv.org/abs/2408.02797v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02797v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "4D-Var using Hessian approximation and backpropagation applied to automatically-differentiable numerical and machine learning models",
    "authors": "Kylen Solvik, Stephen G. Penny, Stephan Hoyer",
    "abstract": "Constraining a numerical weather prediction (NWP) model with observations via\n4D variational (4D-Var) data assimilation is often difficult to implement in\npractice due to the need to develop and maintain a software-based tangent\nlinear model and adjoint model. One of the most common 4D-Var algorithms uses\nan incremental update procedure, which has been shown to be an approximation of\nthe Gauss-Newton method. Here we demonstrate that when using a forecast model\nthat supports automatic differentiation, an efficient and in some cases more\naccurate alternative approximation of the Gauss-Newton method can be applied by\ncombining backpropagation of errors with Hessian approximation. This approach\ncan be used with either a conventional numerical model implemented within a\nsoftware framework that supports automatic differentiation, or a machine\nlearning (ML) based surrogate model. We test the new approach on a variety of\nLorenz-96 and quasi-geostrophic models. The results indicate potential for a\ndeeper integration of modeling, data assimilation, and new technologies in a\nnext-generation of operational forecast systems that leverage weather models\ndesigned to support automatic differentiation.",
    "arxiv_id": "http://arxiv.org/abs/2408.02767v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02767v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "ConDL: Detector-Free Dense Image Matching",
    "authors": "Monika Kwiatkowski, Simon Matern, Olaf Hellwich",
    "abstract": "In this work, we introduce a deep-learning framework designed for estimating\ndense image correspondences. Our fully convolutional model generates dense\nfeature maps for images, where each pixel is associated with a descriptor that\ncan be matched across multiple images. Unlike previous methods, our model is\ntrained on synthetic data that includes significant distortions, such as\nperspective changes, illumination variations, shadows, and specular highlights.\nUtilizing contrastive learning, our feature maps achieve greater invariance to\nthese distortions, enabling robust matching. Notably, our method eliminates the\nneed for a keypoint detector, setting it apart from many existing\nimage-matching techniques.",
    "arxiv_id": "http://arxiv.org/abs/2408.02766v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02766v1",
    "primary_category": "cs.CV",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Dimensionality Reduction and Nearest Neighbors for Improving Out-of-Distribution Detection in Medical Image Segmentation",
    "authors": "McKell Woodland, Nihil Patel, Austin Castelo, Mais Al Taie, Mohamed Eltaher, Joshua P. Yung, Tucker J. Netherton, Tiffany L. Calderone, Jessica I. Sanchez, Darrel W. Cleere, Ahmed Elsaiey, Nakul Gupta, David Victor, Laura Beretta, Ankit B. Patel Kristy K. Brock",
    "abstract": "Clinically deployed deep learning-based segmentation models are known to fail\non data outside of their training distributions. While clinicians review the\nsegmentations, these models tend to perform well in most instances, which could\nexacerbate automation bias. Therefore, detecting out-of-distribution images at\ninference is critical to warn the clinicians that the model likely failed. This\nwork applied the Mahalanobis distance (MD) post hoc to the bottleneck features\nof four Swin UNETR and nnU-net models that segmented the liver on T1-weighted\nmagnetic resonance imaging and computed tomography. By reducing the dimensions\nof the bottleneck features with either principal component analysis or uniform\nmanifold approximation and projection, images the models failed on were\ndetected with high performance and minimal computational load. In addition,\nthis work explored a non-parametric alternative to the MD, a k-th nearest\nneighbors distance (KNN). KNN drastically improved scalability and performance\nover MD when both were applied to raw and average-pooled bottleneck features.",
    "arxiv_id": "http://arxiv.org/abs/2408.02761v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02761v1",
    "primary_category": "cs.CV",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Classification of Raw MEG/EEG Data with Detach-Rocket Ensemble: An Improved ROCKET Algorithm for Multivariate Time Series Analysis",
    "authors": "Adri\u00e0 Solana, Erik Frans\u00e9n, Gonzalo Uribarri",
    "abstract": "Multivariate Time Series Classification (MTSC) is a ubiquitous problem in\nscience and engineering, particularly in neuroscience, where most data\nacquisition modalities involve the simultaneous time-dependent recording of\nbrain activity in multiple brain regions. In recent years, Random Convolutional\nKernel models such as ROCKET and MiniRocket have emerged as highly effective\ntime series classification algorithms, capable of achieving state-of-the-art\naccuracy results with low computational load. Despite their success, these\ntypes of models face two major challenges when employed in neuroscience: 1)\nthey struggle to deal with high-dimensional data such as EEG and MEG, and 2)\nthey are difficult to interpret. In this work, we present a novel ROCKET-based\nalgorithm, named Detach-Rocket Ensemble, that is specifically designed to\naddress these two problems in MTSC. Our algorithm leverages pruning to provide\nan integrated estimation of channel importance, and ensembles to achieve better\naccuracy and provide a label probability. Using a synthetic multivariate time\nseries classification dataset in which we control the amount of information\ncarried by each of the channels, we first show that our algorithm is able to\ncorrectly recover the channel importance for classification. Then, using two\nreal-world datasets, a MEG dataset and an EEG dataset, we show that\nDetach-Rocket Ensemble is able to provide both interpretable channel relevance\nand competitive classification accuracy, even when applied directly to the raw\nbrain data, without the need for feature engineering.",
    "arxiv_id": "http://arxiv.org/abs/2408.02760v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02760v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "A Novel Hybrid Approach for Tornado Prediction in the United States: Kalman-Convolutional BiLSTM with Multi-Head Attention",
    "authors": "Jiawei Zhou",
    "abstract": "Tornadoes are among the most intense atmospheric vortex phenomena and pose\nsignificant challenges for detection and forecasting. Conventional methods,\nwhich heavily depend on ground-based observations and radar data, are limited\nby issues such as decreased accuracy over greater distances and a high rate of\nfalse positives. To address these challenges, this study utilizes the Seamless\nHybrid Scan Reflectivity (SHSR) dataset from the Multi-Radar Multi-Sensor\n(MRMS) system, which integrates data from multiple radar sources to enhance\naccuracy. A novel hybrid model, the Kalman-Convolutional BiLSTM with Multi-Head\nAttention, is introduced to improve dynamic state estimation and capture both\nspatial and temporal dependencies within the data. This model demonstrates\nsuperior performance in precision, recall, F1-Score, and accuracy compared to\nmethods such as K-Nearest Neighbors (KNN) and LightGBM. The results highlight\nthe considerable potential of advanced machine learning techniques to improve\ntornado prediction and reduce false alarm rates. Future research will focus on\nexpanding datasets, exploring innovative model architectures, and incorporating\nlarge language models (LLMs) to provide deeper insights. This research\nintroduces a novel model for tornado prediction, offering a robust framework\nfor enhancing forecasting accuracy and public safety.",
    "arxiv_id": "http://arxiv.org/abs/2408.02751v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02751v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "KAN we improve on HEP classification tasks? Kolmogorov-Arnold Networks applied to an LHC physics example",
    "authors": "Johannes Erdmann, Florian Mausolf, Jan Lukas Sp\u00e4h",
    "abstract": "Recently, Kolmogorov-Arnold Networks (KANs) have been proposed as an\nalternative to multilayer perceptrons, suggesting advantages in performance and\ninterpretability. We study a typical binary event classification task in\nhigh-energy physics including high-level features and comment on the\nperformance and interpretability of KANs in this context. We find that the\nlearned activation functions of a one-layer KAN resemble the log-likelihood\nratio of the input features. In deeper KANs, the activations in the first KAN\nlayer differ from those in the one-layer KAN, which indicates that the deeper\nKANs learn more complex representations of the data. We study KANs with\ndifferent depths and widths and we compare them to multilayer perceptrons in\nterms of performance and number of trainable parameters. For the chosen\nclassification task, we do not find that KANs are more parameter efficient.\nHowever, small KANs may offer advantages in terms of interpretability that come\nat the cost of only a moderate loss in performance.",
    "arxiv_id": "http://arxiv.org/abs/2408.02743v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02743v1",
    "primary_category": "hep-ph",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "On Using Quasirandom Sequences in Machine Learning for Model Weight Initialization",
    "authors": "Andriy Miranskyy, Adam Sorrenti, Viral Thakar",
    "abstract": "The effectiveness of training neural networks directly impacts computational\ncosts, resource allocation, and model development timelines in machine learning\napplications. An optimizer's ability to train the model adequately (in terms of\ntrained model performance) depends on the model's initial weights. Model weight\ninitialization schemes use pseudorandom number generators (PRNGs) as a source\nof randomness.\n  We investigate whether substituting PRNGs for low-discrepancy quasirandom\nnumber generators (QRNGs) -- namely Sobol' sequences -- as a source of\nrandomness for initializers can improve model performance. We examine\nMulti-Layer Perceptrons (MLP), Convolutional Neural Networks (CNN), Long\nShort-Term Memory (LSTM), and Transformer architectures trained on MNIST,\nCIFAR-10, and IMDB datasets using SGD and Adam optimizers. Our analysis uses\nten initialization schemes: Glorot, He, Lecun (both Uniform and Normal);\nOrthogonal, Random Normal, Truncated Normal, and Random Uniform. Models with\nweights set using PRNG- and QRNG-based initializers are compared pairwise for\neach combination of dataset, architecture, optimizer, and initialization\nscheme.\n  Our findings indicate that QRNG-based neural network initializers either\nreach a higher accuracy or achieve the same accuracy more quickly than\nPRNG-based initializers in 60% of the 120 experiments conducted. Thus, using\nQRNG-based initializers instead of PRNG-based initializers can speed up and\nimprove model training.",
    "arxiv_id": "http://arxiv.org/abs/2408.02654v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02654v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Detection of Compromised Functions in a Serverless Cloud Environment",
    "authors": "Danielle Lavi, Oleg Brodt, Dudu Mimran, Yuval Elovici, Asaf Shabtai",
    "abstract": "Serverless computing is an emerging cloud paradigm with serverless functions\nat its core. While serverless environments enable software developers to focus\non developing applications without the need to actively manage the underlying\nruntime infrastructure, they open the door to a wide variety of security\nthreats that can be challenging to mitigate with existing methods. Existing\nsecurity solutions do not apply to all serverless architectures, since they\nrequire significant modifications to the serverless infrastructure or rely on\nthird-party services for the collection of more detailed data. In this paper,\nwe present an extendable serverless security threat detection model that\nleverages cloud providers' native monitoring tools to detect anomalous behavior\nin serverless applications. Our model aims to detect compromised serverless\nfunctions by identifying post-exploitation abnormal behavior related to\ndifferent types of attacks on serverless functions, and therefore, it is a last\nline of defense. Our approach is not tied to any specific serverless\napplication, is agnostic to the type of threats, and is adaptable through model\nadjustments. To evaluate our model's performance, we developed a serverless\ncybersecurity testbed in an AWS cloud environment, which includes two different\nserverless applications and simulates a variety of attack scenarios that cover\nthe main security threats faced by serverless functions. Our evaluation\ndemonstrates our model's ability to detect all implemented attacks while\nmaintaining a negligible false alarm rate.",
    "arxiv_id": "http://arxiv.org/abs/2408.02641v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02641v1",
    "primary_category": "cs.CR",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Command-line Obfuscation Detection using Small Language Models",
    "authors": "Vojtech Outrata, Michael Adam Polak, Martin Kopp",
    "abstract": "To avoid detection, adversaries often use command-line obfuscation. There are\nnumerous techniques of the command-line obfuscation, all designed to alter the\ncommand-line syntax without affecting its original functionality. This\nvariability forces most security solutions to create an exhaustive enumeration\nof signatures for even a single pattern. In contrast to using signatures, we\nhave implemented a scalable NLP-based detection method that leverages a\ncustom-trained, small transformer language model that can be applied to any\nsource of execution logs. The evaluation on top of real-world telemetry\ndemonstrates that our approach yields high-precision detections even on\nhigh-volume telemetry from a diverse set of environments spanning from\nuniversities and businesses to healthcare or finance. The practical value is\ndemonstrated in a case study of real-world samples detected by our model. We\nshow the model's superiority to signatures on established malware known to\nemploy obfuscation and showcase previously unseen obfuscated samples detected\nby our model.",
    "arxiv_id": "http://arxiv.org/abs/2408.02637v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02637v1",
    "primary_category": "cs.CR",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Learning rheological parameters of non-Newtonian fluids from velocimetry data",
    "authors": "Alexandros Kontogiannis, Richard Hodgkinson, Emily L. Manchester",
    "abstract": "We solve a Bayesian inverse Navier-Stokes (N-S) problem that assimilates\nvelocimetry data in order to jointly reconstruct the flow field and learn the\nunknown N-S parameters. By incorporating a Carreau shear-thinning viscosity\nmodel into the N-S problem, we devise an algorithm that learns the most likely\nCarreau parameters of a shear-thinning fluid, and estimates their\nuncertainties, from velocimetry data alone. We then conduct a flow-MRI\nexperiment to obtain velocimetry data of an axisymmetric laminar jet through an\nidealised medical device (FDA nozzle) for a blood analogue fluid. We show that\nthe algorithm can successfully reconstruct the flow field by learning the most\nlikely Carreau parameters, and that the learned parameters are in very good\nagreement with rheometry measurements. The algorithm accepts any algebraic\neffective viscosity model, as long as the model is differentiable, and it can\nbe extended to more complicated non-Newtonian fluids (e.g. Oldroyd-B fluid) if\na viscoelastic model is incorporated into the N-S problem.",
    "arxiv_id": "http://arxiv.org/abs/2408.02604v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02604v1",
    "primary_category": "physics.flu-dyn",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "AI-Driven Strategies for Reducing Student Withdrawal -- A Study of EMU Student Stopout",
    "authors": "Yan Zhao, Amy Otteson",
    "abstract": "Not everyone who enrolls in college will leave with a certificate or degree,\nbut the number of people who drop out or take a break is much higher than\nexperts previously believed. In December 2013, there were 29 million people\nwith some college education but no degree. That number jumped to 36 million by\nDecember of 2018, according to a new report from the National Student\nClearinghouse Research Center[1]. It is imperative to understand the underlying\nfactors contributing to student withdrawal and to assist decision-makers to\nidentify effective strategies to prevent it. By analyzing the characteristics\nand educational pathways of the stopout student population, our aim is to\nprovide actionable insights that can benefit institutions facing similar\nchallenges. Eastern Michigan University (EMU) faces significant challenges in\nstudent retention, with approximately 55% of its undergraduate students not\ncompleting their degrees within six years. As an institution committed to\nstudent success, EMU conducted a comprehensive study of student withdrawals to\nunderstand the influencing factors. And the paper revealed a high correlation\nbetween certain factors and withdrawals, even in the early stages of university\nattendance. Based on these findings, we developed a predictive model that\nemploys artificial intelligence techniques to assess the potential risk that\nstudents abandon their studies. These models enable universities to implement\nearly intervention strategies, support at-risk students, and improve overall\nhigher education success.",
    "arxiv_id": "http://arxiv.org/abs/2408.02598v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02598v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Operational range bounding of spectroscopy models with anomaly detection",
    "authors": "Lu\u00eds F. Sim\u00f5es, Pierluigi Casale, Mar\u00edlia Felismino, Kai Hou Yip, Ingo P. Waldmann, Giovanna Tinetti, Theresa Lueftinger",
    "abstract": "Safe operation of machine learning models requires architectures that\nexplicitly delimit their operational ranges. We evaluate the ability of anomaly\ndetection algorithms to provide indicators correlated with degraded model\nperformance. By placing acceptance thresholds over such indicators, hard\nboundaries are formed that define the model's coverage. As a use case, we\nconsider the extraction of exoplanetary spectra from transit light curves,\nspecifically within the context of ESA's upcoming Ariel mission. Isolation\nForests are shown to effectively identify contexts where prediction models are\nlikely to fail. Coverage/error trade-offs are evaluated under conditions of\ndata and concept drift. The best performance is seen when Isolation Forests\nmodel projections of the prediction model's explainability SHAP values.",
    "arxiv_id": "http://arxiv.org/abs/2408.02581v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02581v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Artificial Intelligence for Public Health Surveillance in Africa: Applications and Opportunities",
    "authors": "Jean Marie Tshimula, Mitterrand Kalengayi, Dieumerci Makenga, Dorcas Lilonge, Marius Asumani, D\u00e9borah Madiya, \u00c9lie Nkuba Kalonji, Hugues Kanda, Ren\u00e9 Manass\u00e9 Galekwa, Josias Kumbu, Hardy Mikese, Grace Tshimula, Jean Tshibangu Muabila, Christian N. Mayemba, D'Jeff K. Nkashama, Kalonji Kalala, Steve Ataky, Tighana Wenge Basele, Mbuyi Mukendi Didier, Selain K. Kasereka, Maximilien V. Dialufuma, Godwill Ilunga Wa Kumwita, Lionel Muyuku, Jean-Paul Kimpesa, Dominique Muteba, Aaron Aruna Abedi, Lambert Mukendi Ntobo, Gloria M. Bundutidi, D\u00e9sir\u00e9 Kulimba Mashinda, Emmanuel Kabengele Mpinga, Nathana\u00ebl M. Kasoro",
    "abstract": "Artificial Intelligence (AI) is revolutionizing various fields, including\npublic health surveillance. In Africa, where health systems frequently\nencounter challenges such as limited resources, inadequate infrastructure,\nfailed health information systems and a shortage of skilled health\nprofessionals, AI offers a transformative opportunity. This paper investigates\nthe applications of AI in public health surveillance across the continent,\npresenting successful case studies and examining the benefits, opportunities,\nand challenges of implementing AI technologies in African healthcare settings.\nOur paper highlights AI's potential to enhance disease monitoring and health\noutcomes, and support effective public health interventions. The findings\npresented in the paper demonstrate that AI can significantly improve the\naccuracy and timeliness of disease detection and prediction, optimize resource\nallocation, and facilitate targeted public health strategies. Additionally, our\npaper identified key barriers to the widespread adoption of AI in African\npublic health systems and proposed actionable recommendations to overcome these\nchallenges.",
    "arxiv_id": "http://arxiv.org/abs/2408.02575v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02575v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Cross-Modality Clustering-based Self-Labeling for Multimodal Data Classification",
    "authors": "Pawe\u0142 Zyblewski, Leandro L. Minku",
    "abstract": "Technological advances facilitate the ability to acquire multimodal data,\nposing a challenge for recognition systems while also providing an opportunity\nto use the heterogeneous nature of the information to increase the\ngeneralization capability of models. An often overlooked issue is the cost of\nthe labeling process, which is typically high due to the need for a significant\ninvestment in time and money associated with human experts. Existing\nsemi-supervised learning methods often focus on operating in the feature space\ncreated by the fusion of available modalities, neglecting the potential for\ncross-utilizing complementary information available in each modality. To\naddress this problem, we propose Cross-Modality Clustering-based Self-Labeling\n(CMCSL). Based on a small set of pre-labeled data, CMCSL groups instances\nbelonging to each modality in the deep feature space and then propagates known\nlabels within the resulting clusters. Next, information about the instances'\nclass membership in each modality is exchanged based on the Euclidean distance\nto ensure more accurate labeling. Experimental evaluation conducted on 20\ndatasets derived from the MM-IMDb dataset indicates that cross-propagation of\nlabels between modalities -- especially when the number of pre-labeled\ninstances is small -- can allow for more reliable labeling and thus increase\nthe classification performance in each modality.",
    "arxiv_id": "http://arxiv.org/abs/2408.02568v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02568v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Process-constrained batch Bayesian approaches for yield optimization in multi-reactor systems",
    "authors": "Markus Grimm, S\u00e9bastien Paul, Pierre Chainais",
    "abstract": "The optimization of yields in multi-reactor systems, which are advanced tools\nin heterogeneous catalysis research, presents a significant challenge due to\nhierarchical technical constraints. To this respect, this work introduces a\nnovel approach called process-constrained batch Bayesian optimization via\nThompson sampling (pc-BO-TS) and its generalized hierarchical extension\n(hpc-BO-TS). This method, tailored for the efficiency demands in multi-reactor\nsystems, integrates experimental constraints and balances between exploration\nand exploitation in a sequential batch optimization strategy. It offers an\nimprovement over other Bayesian optimization methods. The performance of\npc-BO-TS and hpc-BO-TS is validated in synthetic cases as well as in a\nrealistic scenario based on data obtained from high-throughput experiments done\non a multi-reactor system available in the REALCAT platform. The proposed\nmethods often outperform other sequential Bayesian optimizations and existing\nprocess-constrained batch Bayesian optimization methods. This work proposes a\nnovel approach to optimize the yield of a reaction in a multi-reactor system,\nmarking a significant step forward in digital catalysis and generally in\noptimization methods for chemical engineering.",
    "arxiv_id": "http://arxiv.org/abs/2408.02551v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02551v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "The Role of Functional Muscle Networks in Improving Hand Gesture Perception for Human-Machine Interfaces",
    "authors": "Costanza Armanini, Tuka Alhanai, Farah E. Shamout, S. Farokh Atashzar",
    "abstract": "Developing accurate hand gesture perception models is critical for various\nrobotic applications, enabling effective communication between humans and\nmachines and directly impacting neurorobotics and interactive robots. Recently,\nsurface electromyography (sEMG) has been explored for its rich informational\ncontext and accessibility when combined with advanced machine learning\napproaches and wearable systems. The literature presents numerous approaches to\nboost performance while ensuring robustness for neurorobots using sEMG, often\nresulting in models requiring high processing power, large datasets, and less\nscalable solutions. This paper addresses this challenge by proposing the\ndecoding of muscle synchronization rather than individual muscle activation. We\nstudy coherence-based functional muscle networks as the core of our perception\nmodel, proposing that functional synchronization between muscles and the\ngraph-based network of muscle connectivity encode contextual information about\nintended hand gestures. This can be decoded using shallow machine learning\napproaches without the need for deep temporal networks. Our technique could\nimpact myoelectric control of neurorobots by reducing computational burdens and\nenhancing efficiency. The approach is benchmarked on the Ninapro database,\nwhich contains 12 EMG signals from 40 subjects performing 17 hand gestures. It\nachieves an accuracy of 85.1%, demonstrating improved performance compared to\nexisting methods while requiring much less computational power. The results\nsupport the hypothesis that a coherence-based functional muscle network encodes\ncritical information related to gesture execution, significantly enhancing hand\ngesture perception with potential applications for neurorobotic systems and\ninteractive machines.",
    "arxiv_id": "http://arxiv.org/abs/2408.02547v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02547v1",
    "primary_category": "cs.RO",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "RAG Foundry: A Framework for Enhancing LLMs for Retrieval Augmented Generation",
    "authors": "Daniel Fleischer, Moshe Berchansky, Moshe Wasserblat, Peter Izsak",
    "abstract": "Implementing Retrieval-Augmented Generation (RAG) systems is inherently\ncomplex, requiring deep understanding of data, use cases, and intricate design\ndecisions. Additionally, evaluating these systems presents significant\nchallenges, necessitating assessment of both retrieval accuracy and generative\nquality through a multi-faceted approach. We introduce RAG Foundry, an\nopen-source framework for augmenting large language models for RAG use cases.\nRAG Foundry integrates data creation, training, inference and evaluation into a\nsingle workflow, facilitating the creation of data-augmented datasets for\ntraining and evaluating large language models in RAG settings. This integration\nenables rapid prototyping and experimentation with various RAG techniques,\nallowing users to easily generate datasets and train RAG models using internal\nor specialized knowledge sources. We demonstrate the framework effectiveness by\naugmenting and fine-tuning Llama-3 and Phi-3 models with diverse RAG\nconfigurations, showcasing consistent improvements across three\nknowledge-intensive datasets. Code is released as open-source in\nhttps://github.com/IntelLabs/RAGFoundry.",
    "arxiv_id": "http://arxiv.org/abs/2408.02545v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02545v1",
    "primary_category": "cs.CL",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "LMEMs for post-hoc analysis of HPO Benchmarking",
    "authors": "Anton Geburek, Neeratyoy Mallik, Danny Stoll, Xavier Bouthillier, Frank Hutter",
    "abstract": "The importance of tuning hyperparameters in Machine Learning (ML) and Deep\nLearning (DL) is established through empirical research and applications,\nevident from the increase in new hyperparameter optimization (HPO) algorithms\nand benchmarks steadily added by the community. However, current benchmarking\npractices using averaged performance across many datasets may obscure key\ndifferences between HPO methods, especially for pairwise comparisons. In this\nwork, we apply Linear Mixed-Effect Models-based (LMEMs) significance testing\nfor post-hoc analysis of HPO benchmarking runs. LMEMs allow flexible and\nexpressive modeling on the entire experiment data, including information such\nas benchmark meta-features, offering deeper insights than current analysis\npractices. We demonstrate this through a case study on the PriorBand paper's\nexperiment data to find insights not reported in the original work.",
    "arxiv_id": "http://arxiv.org/abs/2408.02533v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02533v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Single-tap Latency Reduction with Single- or Double- tap Prediction",
    "authors": "Naoto Nishida, Kaori Ikematsu, Junichi Sato, Shota Yamanaka, Kota Tsubouchi",
    "abstract": "Touch surfaces are widely utilized for smartphones, tablet PCs, and laptops\n(touchpad), and single and double taps are the most basic and common operations\non them. The detection of single or double taps causes the single-tap latency\nproblem, which creates a bottleneck in terms of the sensitivity of touch\ninputs. To reduce the single-tap latency, we propose a novel\nmachine-learning-based tap prediction method called PredicTaps. Our method\npredicts whether a detected tap is a single tap or the first contact of a\ndouble tap without having to wait for the hundreds of milliseconds\nconventionally required. We present three evaluations and one user evaluation\nthat demonstrate its broad applicability and usability for various tap\nsituations on two form factors (touchpad and smartphone). The results showed\nPredicTaps reduces the single-tap latency from 150-500 ms to 12 ms on laptops\nand to 17.6 ms on smartphones without reducing usability.",
    "arxiv_id": "http://arxiv.org/abs/2408.02525v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02525v1",
    "primary_category": "cs.HC",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Stem-JEPA: A Joint-Embedding Predictive Architecture for Musical Stem Compatibility Estimation",
    "authors": "Alain Riou, Stefan Lattner, Ga\u00ebtan Hadjeres, Michael Anslow, Geoffroy Peeters",
    "abstract": "This paper explores the automated process of determining stem compatibility\nby identifying audio recordings of single instruments that blend well with a\ngiven musical context. To tackle this challenge, we present Stem-JEPA, a novel\nJoint-Embedding Predictive Architecture (JEPA) trained on a multi-track dataset\nusing a self-supervised learning approach.\n  Our model comprises two networks: an encoder and a predictor, which are\njointly trained to predict the embeddings of compatible stems from the\nembeddings of a given context, typically a mix of several instruments. Training\na model in this manner allows its use in estimating stem compatibility -\nretrieving, aligning, or generating a stem to match a given mix - or for\ndownstream tasks such as genre or key estimation, as the training paradigm\nrequires the model to learn information related to timbre, harmony, and rhythm.\n  We evaluate our model's performance on a retrieval task on the MUSDB18\ndataset, testing its ability to find the missing stem from a mix and through a\nsubjective user study. We also show that the learned embeddings capture\ntemporal alignment information and, finally, evaluate the representations\nlearned by our model on several downstream tasks, highlighting that they\neffectively capture meaningful musical features.",
    "arxiv_id": "http://arxiv.org/abs/2408.02514v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02514v1",
    "primary_category": "cs.SD",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Practical Attacks against Black-box Code Completion Engines",
    "authors": "Slobodan Jenko, Jingxuan He, Niels M\u00fcndler, Mark Vero, Martin Vechev",
    "abstract": "Modern code completion engines, powered by large language models, have\ndemonstrated impressive capabilities to generate functionally correct code\nbased on surrounding context. As these tools are extensively used by millions\nof developers, it is crucial to investigate their security implications. In\nthis work, we present INSEC, a novel attack that directs code completion\nengines towards generating vulnerable code. In line with most commercial\ncompletion engines, such as GitHub Copilot, INSEC assumes only black-box query\naccess to the targeted engine, without requiring any knowledge of the engine's\ninternals. Our attack works by inserting a malicious attack string as a short\ncomment in the completion input. To derive the attack string, we design a\nseries of specialized initialization schemes and an optimization procedure for\nfurther refinement. We demonstrate the strength of INSEC not only on\nstate-of-the-art open-source models but also on black-box commercial services\nsuch as the OpenAI API and GitHub Copilot. On a comprehensive set of\nsecurity-critical test cases covering 16 CWEs across 5 programming languages,\nINSEC significantly increases the likelihood of the considered completion\nengines in generating unsafe code by >50% in absolute, while maintaining the\nability in producing functionally correct code. At the same time, our attack\nhas low resource requirements, and can be developed for a cost of well under\nten USD on commodity hardware.",
    "arxiv_id": "http://arxiv.org/abs/2408.02509v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02509v1",
    "primary_category": "cs.CR",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Automatic rating of incomplete hippocampal inversions evaluated across multiple cohorts",
    "authors": "Lisa Hemforth, Baptiste Couvy-Duchesne, Kevin De Matos, Camille Brianceau, Matthieu Joulot, Tobias Banaschewski, Arun L. W. Bokde, Sylvane Desrivi\u00e8res, Herta Flor, Antoine Grigis, Hugh Garavan, Penny Gowland, Andreas Heinz, R\u00fcdiger Br\u00fchl, Jean-Luc Martinot, Marie-Laure Paill\u00e8re Martinot, Eric Artiges, Dimitri Papadopoulos, Herve Lemaitre, Tomas Paus, Luise Poustka, Sarah Hohmann, Nathalie Holz, Juliane H. Fr\u00f6hner, Michael N. Smolka, Nilakshi Vaidya, Henrik Walter, Robert Whelan, Gunter Schumann, Christian B\u00fcchel, JB Poline, Bernd Itterman, Vincent Frouin, Alexandre Martin, IMAGEN study group, Claire Cury, Olivier Colliot",
    "abstract": "Incomplete Hippocampal Inversion (IHI), sometimes called hippocampal\nmalrotation, is an atypical anatomical pattern of the hippocampus found in\nabout 20% of the general population. IHI can be visually assessed on coronal\nslices of T1 weighted MR images, using a composite score that combines four\nanatomical criteria. IHI has been associated with several brain disorders\n(epilepsy, schizophrenia). However, these studies were based on small samples.\nFurthermore, the factors (genetic or environmental) that contribute to the\ngenesis of IHI are largely unknown. Large-scale studies are thus needed to\nfurther understand IHI and their potential relationships to neurological and\npsychiatric disorders. However, visual evaluation is long and tedious,\njustifying the need for an automatic method. In this paper, we propose, for the\nfirst time, to automatically rate IHI. We proceed by predicting four anatomical\ncriteria, which are then summed up to form the IHI score, providing the\nadvantage of an interpretable score. We provided an extensive experimental\ninvestigation of different machine learning methods and training strategies. We\nperformed automatic rating using a variety of deep learning models (conv5-FC3,\nResNet and SECNN) as well as a ridge regression. We studied the generalization\nof our models using different cohorts and performed multi-cohort learning. We\nrelied on a large population of 2,008 participants from the IMAGEN study, 993\nand 403 participants from the QTIM/QTAB studies as well as 985 subjects from\nthe UKBiobank. We showed that deep learning models outperformed a ridge\nregression. We demonstrated that the performances of the conv5-FC3 network were\nat least as good as more complex networks while maintaining a low complexity\nand computation time. We showed that training on a single cohort may lack in\nvariability while training on several cohorts improves generalization.",
    "arxiv_id": "http://arxiv.org/abs/2408.02496v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02496v1",
    "primary_category": "eess.IV",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "MDM: Advancing Multi-Domain Distribution Matching for Automatic Modulation Recognition Dataset Synthesis",
    "authors": "Dongwei Xu, Jiajun Chen, Yao Lu, Tianhao Xia, Qi Xuan, Wei Wang, Yun Lin, Xiaoniu Yang",
    "abstract": "Recently, deep learning technology has been successfully introduced into\nAutomatic Modulation Recognition (AMR) tasks. However, the success of deep\nlearning is all attributed to the training on large-scale datasets. Such a\nlarge amount of data brings huge pressure on storage, transmission and model\ntraining. In order to solve the problem of large amount of data, some\nresearchers put forward the method of data distillation, which aims to compress\nlarge training data into smaller synthetic datasets to maintain its\nperformance. While numerous data distillation techniques have been developed\nwithin the realm of image processing, the unique characteristics of signals set\nthem apart. Signals exhibit distinct features across various domains,\nnecessitating specialized approaches for their analysis and processing. To this\nend, a novel dataset distillation method--Multi-domain Distribution Matching\n(MDM) is proposed. MDM employs the Discrete Fourier Transform (DFT) to\ntranslate timedomain signals into the frequency domain, and then uses a model\nto compute distribution matching losses between the synthetic and real\ndatasets, considering both the time and frequency domains. Ultimately, these\ntwo losses are integrated to update the synthetic dataset. We conduct extensive\nexperiments on three AMR datasets. Experimental results show that, compared\nwith baseline methods, our method achieves better performance under the same\ncompression ratio. Furthermore, we conduct crossarchitecture generalization\nexperiments on several models, and the experimental results show that our\nsynthetic datasets can generalize well on other unseen models.",
    "arxiv_id": "http://arxiv.org/abs/2408.02714v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02714v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "A First Look at License Compliance Capability of LLMs in Code Generation",
    "authors": "Weiwei Xu, Kai Gao, Hao He, Minghui Zhou",
    "abstract": "Recent advances in Large Language Models (LLMs) have revolutionized code\ngeneration, leading to widespread adoption of AI coding tools by developers.\nHowever, LLMs can generate license-protected code without providing the\nnecessary license information, leading to potential intellectual property\nviolations during software production. This paper addresses the critical, yet\nunderexplored, issue of license compliance in LLM-generated code by\nestablishing a benchmark to evaluate the ability of LLMs to provide accurate\nlicense information for their generated code. To establish this benchmark, we\nconduct an empirical study to identify a reasonable standard for \"striking\nsimilarity\" that excludes the possibility of independent creation, indicating a\ncopy relationship between the LLM output and certain open-source code. Based on\nthis standard, we propose an evaluation benchmark LiCoEval, to evaluate the\nlicense compliance capabilities of LLMs. Using LiCoEval, we evaluate 14 popular\nLLMs, finding that even top-performing LLMs produce a non-negligible proportion\n(0.88% to 2.01%) of code strikingly similar to existing open-source\nimplementations. Notably, most LLMs fail to provide accurate license\ninformation, particularly for code under copyleft licenses. These findings\nunderscore the urgent need to enhance LLM compliance capabilities in code\ngeneration tasks. Our study provides a foundation for future research and\ndevelopment to improve license compliance in AI-assisted software development,\ncontributing to both the protection of open-source software copyrights and the\nmitigation of legal risks for LLM users.",
    "arxiv_id": "http://arxiv.org/abs/2408.02487v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02487v1",
    "primary_category": "cs.SE",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Toward Attention-based TinyML: A Heterogeneous Accelerated Architecture and Automated Deployment Flow",
    "authors": "Philip Wiese, Gamze \u0130slamo\u011flu, Moritz Scherer, Luka Macan, Victor J. B. Jung, Alessio Burrello, Francesco Conti, Luca Benini",
    "abstract": "One of the challenges for Tiny Machine Learning (tinyML) is keeping up with\nthe evolution of Machine Learning models from Convolutional Neural Networks to\nTransformers. We address this by leveraging a heterogeneous architectural\ntemplate coupling RISC-V processors with hardwired accelerators supported by an\nautomated deployment flow. We demonstrate an Attention-based model in a tinyML\npower envelope with an octa-core cluster coupled with an accelerator for\nquantized Attention. Our deployment flow enables an end-to-end 8-bit\nMobileBERT, achieving leading-edge energy efficiency and throughput of 2960\nGOp/J and 154 GOp/s at 32.5 Inf/s consuming 52.0 mW (0.65 V, 22 nm FD-SOI\ntechnology).",
    "arxiv_id": "http://arxiv.org/abs/2408.02473v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02473v1",
    "primary_category": "cs.AR",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Enhancing Heterogeneous Knowledge Graph Completion with a Novel GAT-based Approach",
    "authors": "Wanxu Wei, Yitong Song, Bin Yao",
    "abstract": "Knowledge graphs (KGs) play a vital role in enhancing search results and\nrecommendation systems. With the rapid increase in the size of the KGs, they\nare becoming inaccuracy and incomplete. This problem can be solved by the\nknowledge graph completion methods, of which graph attention network\n(GAT)-based methods stand out since their superior performance. However,\nexisting GAT-based knowledge graph completion methods often suffer from\noverfitting issues when dealing with heterogeneous knowledge graphs, primarily\ndue to the unbalanced number of samples. Additionally, these methods\ndemonstrate poor performance in predicting the tail (head) entity that shares\nthe same relation and head (tail) entity with others. To solve these problems,\nwe propose GATH, a novel GAT-based method designed for Heterogeneous KGs. GATH\nincorporates two separate attention network modules that work synergistically\nto predict the missing entities. We also introduce novel encoding and feature\ntransformation approaches, enabling the robust performance of GATH in scenarios\nwith imbalanced samples. Comprehensive experiments are conducted to evaluate\nthe GATH's performance. Compared with the existing SOTA GAT-based model on\nHits@10 and MRR metrics, our model improves performance by 5.2% and 5.2% on the\nFB15K-237 dataset, and by 4.5% and 14.6% on the WN18RR dataset, respectively.",
    "arxiv_id": "http://arxiv.org/abs/2408.02456v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02456v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Text Conditioned Symbolic Drumbeat Generation using Latent Diffusion Models",
    "authors": "Pushkar Jajoria, James McDermott",
    "abstract": "This study introduces a text-conditioned approach to generating drumbeats\nwith Latent Diffusion Models (LDMs). It uses informative conditioning text\nextracted from training data filenames. By pretraining a text and drumbeat\nencoder through contrastive learning within a multimodal network, aligned\nfollowing CLIP, we align the modalities of text and music closely.\nAdditionally, we examine an alternative text encoder based on multihot text\nencodings. Inspired by musics multi-resolution nature, we propose a novel LSTM\nvariant, MultiResolutionLSTM, designed to operate at various resolutions\nindependently. In common with recent LDMs in the image space, it speeds up the\ngeneration process by running diffusion in a latent space provided by a\npretrained unconditional autoencoder. We demonstrate the originality and\nvariety of the generated drumbeats by measuring distance (both over binary\npianorolls and in the latent space) versus the training dataset and among the\ngenerated drumbeats. We also assess the generated drumbeats through a listening\ntest focused on questions of quality, aptness for the prompt text, and novelty.\nWe show that the generated drumbeats are novel and apt to the prompt text, and\ncomparable in quality to those created by human musicians.",
    "arxiv_id": "http://arxiv.org/abs/2408.02711v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02711v1",
    "primary_category": "cs.SD",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "RCDM: Enabling Robustness for Conditional Diffusion Model",
    "authors": "Weifeng Xu, Xiang Zhu, Xiaoyong Li",
    "abstract": "The conditional diffusion model (CDM) enhances the standard diffusion model\nby providing more control, improving the quality and relevance of the outputs,\nand making the model adaptable to a wider range of complex tasks. However,\ninaccurate conditional inputs in the inverse process of CDM can easily lead to\ngenerating fixed errors in the neural network, which diminishes the\nadaptability of a well-trained model. The existing methods like data\naugmentation, adversarial training, robust optimization can improve the\nrobustness, while they often face challenges such as high computational\ncomplexity, limited applicability to unknown perturbations, and increased\ntraining difficulty. In this paper, we propose a lightweight solution, the\nRobust Conditional Diffusion Model (RCDM), based on control theory to\ndynamically reduce the impact of noise and significantly enhance the model's\nrobustness. RCDM leverages the collaborative interaction between two neural\nnetworks, along with optimal control strategies derived from control theory, to\noptimize the weights of two networks during the sampling process. Unlike\nconventional techniques, RCDM establishes a mathematical relationship between\nfixed errors and the weights of the two neural networks without incurring\nadditional computational overhead. Extensive experiments were conducted on\nMNIST and CIFAR-10 datasets, and the results demonstrate the effectiveness and\nadaptability of our proposed model.",
    "arxiv_id": "http://arxiv.org/abs/2408.02710v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02710v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "On Probabilistic Embeddings in Optimal Dimension Reduction",
    "authors": "Ryan Murray, Adam Pickarski",
    "abstract": "Dimension reduction algorithms are a crucial part of many data science\npipelines, including data exploration, feature creation and selection, and\ndenoising. Despite their wide utilization, many non-linear dimension reduction\nalgorithms are poorly understood from a theoretical perspective. In this work\nwe consider a generalized version of multidimensional scaling, which is posed\nas an optimization problem in which a mapping from a high-dimensional feature\nspace to a lower-dimensional embedding space seeks to preserve either inner\nproducts or norms of the distribution in feature space, and which encompasses\nmany commonly used dimension reduction algorithms. We analytically investigate\nthe variational properties of this problem, leading to the following insights:\n1) Solutions found using standard particle descent methods may lead to\nnon-deterministic embeddings, 2) A relaxed or probabilistic formulation of the\nproblem admits solutions with easily interpretable necessary conditions, 3) The\nglobally optimal solutions to the relaxed problem actually must give a\ndeterministic embedding. This progression of results mirrors the classical\ndevelopment of optimal transportation, and in a case relating to the\nGromov-Wasserstein distance actually gives explicit insight into the structure\nof the optimal embeddings, which are parametrically determined and\ndiscontinuous. Finally, we illustrate that a standard computational\nimplementation of this task does not learn deterministic embeddings, which\nmeans that it learns sub-optimal mappings, and that the embeddings learned in\nthat context have highly misleading clustering structure, underscoring the\ndelicate nature of solving this problem computationally.",
    "arxiv_id": "http://arxiv.org/abs/2408.02433v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02433v1",
    "primary_category": "stat.ML",
    "votes": 1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Attenuation-adjusted deep learning of pore defects in 2D radiographs of additive manufacturing powders",
    "authors": "Andreas Bjerregaard, David Schumacher, Jon Sporring",
    "abstract": "The presence of gas pores in metal feedstock powder for additive\nmanufacturing greatly affects the final AM product. Since current porosity\nanalysis often involves lengthy X-ray computed tomography (XCT) scans with a\nfull rotation around the sample, motivation exists to explore methods that\nallow for high throughput -- possibly enabling in-line porosity analysis during\nmanufacturing. Through labelling pore pixels on single 2D radiographs of\npowders, this work seeks to simulate such future efficient setups. High\nsegmentation accuracy is achieved by combining a model of X-ray attenuation\nthrough particles with a variant of the widely applied UNet architecture;\nnotably, F1-score increases by $11.4\\%$ compared to the baseline UNet. The\nproposed pore segmentation is enabled by: 1) pretraining on synthetic data, 2)\nmaking tight particle cutouts, and 3) subtracting an ideal particle without\npores generated from a distance map inspired by Lambert-Beers law. This paper\nexplores four image processing methods, where the fastest (yet still\nunoptimized) segments a particle in mean $0.014s$ time with F1-score $0.78$,\nand the most accurate in $0.291s$ with F1-score $0.87$. Due to their scalable\nnature, these strategies can be involved in making high throughput porosity\nanalysis of metal feedstock powder for additive manufacturing.",
    "arxiv_id": "http://arxiv.org/abs/2408.02427v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02427v1",
    "primary_category": "cs.CV",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "PENDRAM: Enabling High-Performance and Energy-Efficient Processing of Deep Neural Networks through a Generalized DRAM Data Mapping Policy",
    "authors": "Rachmad Vidya Wicaksana Putra, Muhammad Abdullah Hanif, Muhammad Shafique",
    "abstract": "Convolutional Neural Networks (CNNs), a prominent type of Deep Neural\nNetworks (DNNs), have emerged as a state-of-the-art solution for solving\nmachine learning tasks. To improve the performance and energy efficiency of CNN\ninference, the employment of specialized hardware accelerators is prevalent.\nHowever, CNN accelerators still face performance- and energy-efficiency\nchallenges due to high off-chip memory (DRAM) access latency and energy, which\nare especially crucial for latency- and energy-constrained embedded\napplications. Moreover, different DRAM architectures have different profiles of\naccess latency and energy, thus making it challenging to optimize them for high\nperformance and energy-efficient CNN accelerators. To address this, we present\nPENDRAM, a novel design space exploration methodology that enables\nhigh-performance and energy-efficient CNN acceleration through a generalized\nDRAM data mapping policy. Specifically, it explores the impact of different\nDRAM data mapping policies and DRAM architectures across different CNN\npartitioning and scheduling schemes on the DRAM access latency and energy, then\nidentifies the pareto-optimal design choices. The experimental results show\nthat our DRAM data mapping policy improves the energy-delay-product of DRAM\naccesses in the CNN accelerator over other mapping policies by up to 96%. In\nthis manner, our PENDRAM methodology offers high-performance and\nenergy-efficient CNN acceleration under any given DRAM architectures for\ndiverse embedded AI applications.",
    "arxiv_id": "http://arxiv.org/abs/2408.02412v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02412v1",
    "primary_category": "cs.AR",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "SnapE -- Training Snapshot Ensembles of Link Prediction Models",
    "authors": "Ali Shaban, Heiko Paulheim",
    "abstract": "Snapshot ensembles have been widely used in various fields of prediction.\nThey allow for training an ensemble of prediction models at the cost of\ntraining a single one. They are known to yield more robust predictions by\ncreating a set of diverse base models. In this paper, we introduce an approach\nto transfer the idea of snapshot ensembles to link prediction models in\nknowledge graphs. Moreover, since link prediction in knowledge graphs is a\nsetup without explicit negative examples, we propose a novel training loop that\niteratively creates negative examples using previous snapshot models. An\nevaluation with four base models across four datasets shows that this approach\nconstantly outperforms the single model approach, while keeping the training\ntime constant.",
    "arxiv_id": "http://arxiv.org/abs/2408.02707v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02707v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Terracorder: Sense Long and Prosper",
    "authors": "Josh Millar, Sarab Sethi, Hamed Haddadi, Anil Madhavapeddy",
    "abstract": "In-situ sensing devices need to be deployed in remote environments for long\nperiods of time; minimizing their power consumption is vital for maximising\nboth their operational lifetime and coverage. We introduce Terracorder -- a\nversatile multi-sensor device -- and showcase its exceptionally low power\nconsumption using an on-device reinforcement learning scheduler. We prototype a\nunique device setup for biodiversity monitoring and compare its battery life\nusing our scheduler against a number of fixed schedules; the scheduler captures\nmore than 80% of events at less than 50% of the number of activations of the\nbest-performing fixed schedule. We then explore how a collaborative scheduler\ncan maximise the useful operation of a network of devices, improving overall\nnetwork power consumption and robustness.",
    "arxiv_id": "http://arxiv.org/abs/2408.02407v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02407v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Strategic Federated Learning: Application to Smart Meter Data Clustering",
    "authors": "Hassan Mohamad, Chao Zhang, Samson Lasaulce, Vineeth S Varma, M\u00e9rouane Debbah, Mounir Ghogho",
    "abstract": "Federated learning (FL) involves several clients that share with a fusion\ncenter (FC), the model each client has trained with its own data. Conventional\nFL, which can be interpreted as an estimation or distortion-based approach,\nignores the final use of model information (MI) by the FC and the other\nclients. In this paper, we introduce a novel FL framework in which the FC uses\nan aggregate version of the MI to make decisions that affect the client's\nutility functions. Clients cannot choose the decisions and can only use the MI\nreported to the FC to maximize their utility. Depending on the alignment\nbetween the client and FC utilities, the client may have an individual interest\nin adding strategic noise to the model. This general framework is stated and\nspecialized to the case of clustering, in which noisy cluster representative\ninformation is reported. This is applied to the problem of power consumption\nscheduling. In this context, utility non-alignment occurs, for instance, when\nthe client wants to consume when the price of electricity is low, whereas the\nFC wants the consumption to occur when the total power is the lowest. This is\nillustrated with aggregated real data from Ausgrid \\cite{ausgrid}. Our\nnumerical analysis clearly shows that the client can increase his utility by\nadding noise to the model reported to the FC. Corresponding results and source\ncodes can be downloaded from \\cite{source-code}.",
    "arxiv_id": "http://arxiv.org/abs/2408.02384v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02384v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Bayesian Kolmogorov Arnold Networks (Bayesian_KANs): A Probabilistic Approach to Enhance Accuracy and Interpretability",
    "authors": "Masoud Muhammed Hassan",
    "abstract": "Because of its strong predictive skills, deep learning has emerged as an\nessential tool in many industries, including healthcare. Traditional deep\nlearning models, on the other hand, frequently lack interpretability and omit\nto take prediction uncertainty into account two crucial components of clinical\ndecision making. In order to produce explainable and uncertainty aware\npredictions, this study presents a novel framework called Bayesian Kolmogorov\nArnold Networks (BKANs), which combines the expressive capacity of Kolmogorov\nArnold Networks with Bayesian inference. We employ BKANs on two medical\ndatasets, which are widely used benchmarks for assessing machine learning\nmodels in medical diagnostics: the Pima Indians Diabetes dataset and the\nCleveland Heart Disease dataset. Our method provides useful insights into\nprediction confidence and decision boundaries and outperforms traditional deep\nlearning models in terms of prediction accuracy. Moreover, BKANs' capacity to\nrepresent aleatoric and epistemic uncertainty guarantees doctors receive more\nsolid and trustworthy decision support. Our Bayesian strategy improves the\ninterpretability of the model and considerably minimises overfitting, which is\nimportant for tiny and imbalanced medical datasets, according to experimental\nresults. We present possible expansions to further use BKANs in more\ncomplicated multimodal datasets and address the significance of these\ndiscoveries for future research in building reliable AI systems for healthcare.\nThis work paves the way for a new paradigm in deep learning model deployment in\nvital sectors where transparency and reliability are crucial.",
    "arxiv_id": "http://arxiv.org/abs/2408.02706v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02706v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "PSNE: Efficient Spectral Sparsification Algorithms for Scaling Network Embedding",
    "authors": "Longlong Lin, Yunfeng Yu, Zihao Wang, Zeli Wang, Yuying Zhao, Jin Zhao, Tao Jia",
    "abstract": "Network embedding has numerous practical applications and has received\nextensive attention in graph learning, which aims at mapping vertices into a\nlow-dimensional and continuous dense vector space by preserving the underlying\nstructural properties of the graph. Many network embedding methods have been\nproposed, among which factorization of the Personalized PageRank (PPR for\nshort) matrix has been empirically and theoretically well supported recently.\nHowever, several fundamental issues cannot be addressed. (1) Existing methods\ninvoke a seminal Local Push subroutine to approximate \\textit{a single} row or\ncolumn of the PPR matrix. Thus, they have to execute $n$ ($n$ is the number of\nnodes) Local Push subroutines to obtain a provable PPR matrix, resulting in\nprohibitively high computational costs for large $n$. (2) The PPR matrix has\nlimited power in capturing the structural similarity between vertices, leading\nto performance degradation. To overcome these dilemmas, we propose PSNE, an\nefficient spectral s\\textbf{P}arsification method for \\textbf{S}caling\n\\textbf{N}etwork \\textbf{E}mbedding, which can fast obtain the embedding\nvectors that retain strong structural similarities. Specifically, PSNE first\ndesigns a matrix polynomial sparser to accelerate the calculation of the PPR\nmatrix, which has a theoretical guarantee in terms of the Frobenius norm.\nSubsequently, PSNE proposes a simple but effective multiple-perspective\nstrategy to enhance further the representation power of the obtained\napproximate PPR matrix. Finally, PSNE applies a randomized singular value\ndecomposition algorithm on the sparse and multiple-perspective PPR matrix to\nget the target embedding vectors. Experimental evaluation of real-world and\nsynthetic datasets shows that our solutions are indeed more efficient,\neffective, and scalable compared with ten competitors.",
    "arxiv_id": "http://arxiv.org/abs/2408.02705v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02705v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "StoDIP: Efficient 3D MRF image reconstruction with deep image priors and stochastic iterations",
    "authors": "Perla Mayo, Matteo Cencini, Carolin M. Pirkl, Marion I. Menzel, Michela Tosetti, Bjoern H. Menze, Mohammad Golbabaee",
    "abstract": "Magnetic Resonance Fingerprinting (MRF) is a time-efficient approach to\nquantitative MRI for multiparametric tissue mapping. The reconstruction of\nquantitative maps requires tailored algorithms for removing aliasing artefacts\nfrom the compressed sampled MRF acquisitions. Within approaches found in the\nliterature, many focus solely on two-dimensional (2D) image reconstruction,\nneglecting the extension to volumetric (3D) scans despite their higher\nrelevance and clinical value. A reason for this is that transitioning to 3D\nimaging without appropriate mitigations presents significant challenges,\nincluding increased computational cost and storage requirements, and the need\nfor large amount of ground-truth (artefact-free) data for training. To address\nthese issues, we introduce StoDIP, a new algorithm that extends the\nground-truth-free Deep Image Prior (DIP) reconstruction to 3D MRF imaging.\nStoDIP employs memory-efficient stochastic updates across the multicoil MRF\ndata, a carefully selected neural network architecture, as well as faster\nnonuniform FFT (NUFFT) transformations. This enables a faster convergence\ncompared against a conventional DIP implementation without these features.\nTested on a dataset of whole-brain scans from healthy volunteers, StoDIP\ndemonstrated superior performance over the ground-truth-free reconstruction\nbaselines, both quantitatively and qualitatively.",
    "arxiv_id": "http://arxiv.org/abs/2408.02367v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02367v1",
    "primary_category": "eess.IV",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Dialogue Ontology Relation Extraction via Constrained Chain-of-Thought Decoding",
    "authors": "Renato Vukovic, David Arps, Carel van Niekerk, Benjamin Matthias Ruppik, Hsien-Chin Lin, Michael Heck, Milica Ga\u0161i\u0107",
    "abstract": "State-of-the-art task-oriented dialogue systems typically rely on\ntask-specific ontologies for fulfilling user queries. The majority of\ntask-oriented dialogue data, such as customer service recordings, comes without\nontology and annotation. Such ontologies are normally built manually, limiting\nthe application of specialised systems. Dialogue ontology construction is an\napproach for automating that process and typically consists of two steps: term\nextraction and relation extraction. In this work, we focus on relation\nextraction in a transfer learning set-up. To improve the generalisation, we\npropose an extension to the decoding mechanism of large language models. We\nadapt Chain-of-Thought (CoT) decoding, recently developed for reasoning\nproblems, to generative relation extraction. Here, we generate multiple\nbranches in the decoding space and select the relations based on a confidence\nthreshold. By constraining the decoding to ontology terms and relations, we aim\nto decrease the risk of hallucination. We conduct extensive experimentation on\ntwo widely used datasets and find improvements in performance on target\nontology for source fine-tuned and one-shot prompted large language models.",
    "arxiv_id": "http://arxiv.org/abs/2408.02361v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02361v1",
    "primary_category": "cs.CL",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "On the consistent reasoning paradox of intelligence and optimal trust in AI: The power of 'I don't know'",
    "authors": "Alexander Bastounis, Paolo Campodonico, Mihaela van der Schaar, Ben Adcock, Anders C. Hansen",
    "abstract": "We introduce the Consistent Reasoning Paradox (CRP). Consistent reasoning,\nwhich lies at the core of human intelligence, is the ability to handle tasks\nthat are equivalent, yet described by different sentences ('Tell me the time!'\nand 'What is the time?'). The CRP asserts that consistent reasoning implies\nfallibility -- in particular, human-like intelligence in AI necessarily comes\nwith human-like fallibility. Specifically, it states that there are problems,\ne.g. in basic arithmetic, where any AI that always answers and strives to mimic\nhuman intelligence by reasoning consistently will hallucinate (produce wrong,\nyet plausible answers) infinitely often. The paradox is that there exists a\nnon-consistently reasoning AI (which therefore cannot be on the level of human\nintelligence) that will be correct on the same set of problems. The CRP also\nshows that detecting these hallucinations, even in a probabilistic sense, is\nstrictly harder than solving the original problems, and that there are problems\nthat an AI may answer correctly, but it cannot provide a correct logical\nexplanation for how it arrived at the answer. Therefore, the CRP implies that\nany trustworthy AI (i.e., an AI that never answers incorrectly) that also\nreasons consistently must be able to say 'I don't know'. Moreover, this can\nonly be done by implicitly computing a new concept that we introduce, termed\nthe 'I don't know' function -- something currently lacking in modern AI. In\nview of these insights, the CRP also provides a glimpse into the behaviour of\nArtificial General Intelligence (AGI). An AGI cannot be 'almost sure', nor can\nit always explain itself, and therefore to be trustworthy it must be able to\nsay 'I don't know'.",
    "arxiv_id": "http://arxiv.org/abs/2408.02357v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02357v1",
    "primary_category": "cs.AI",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Quantile Regression using Random Forest Proximities",
    "authors": "Mingshu Li, Bhaskarjit Sarmah, Dhruv Desai, Joshua Rosaler, Snigdha Bhagat, Philip Sommer, Dhagash Mehta",
    "abstract": "Due to the dynamic nature of financial markets, maintaining models that\nproduce precise predictions over time is difficult. Often the goal isn't just\npoint prediction but determining uncertainty. Quantifying uncertainty,\nespecially the aleatoric uncertainty due to the unpredictable nature of market\ndrivers, helps investors understand varying risk levels. Recently, quantile\nregression forests (QRF) have emerged as a promising solution: Unlike most\nbasic quantile regression methods that need separate models for each quantile,\nquantile regression forests estimate the entire conditional distribution of the\ntarget variable with a single model, while retaining all the salient features\nof a typical random forest. We introduce a novel approach to compute quantile\nregressions from random forests that leverages the proximity (i.e., distance\nmetric) learned by the model and infers the conditional distribution of the\ntarget variable. We evaluate the proposed methodology using publicly available\ndatasets and then apply it towards the problem of forecasting the average daily\nvolume of corporate bonds. We show that using quantile regression using Random\nForest proximities demonstrates superior performance in approximating\nconditional target distributions and prediction intervals to the original\nversion of QRF. We also demonstrate that the proposed framework is\nsignificantly more computationally efficient than traditional approaches to\nquantile regressions.",
    "arxiv_id": "http://arxiv.org/abs/2408.02355v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02355v1",
    "primary_category": "stat.ML",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "RECE: Reduced Cross-Entropy Loss for Large-Catalogue Sequential Recommenders",
    "authors": "Danil Gusak, Gleb Mezentsev, Ivan Oseledets, Evgeny Frolov",
    "abstract": "Scalability is a major challenge in modern recommender systems. In sequential\nrecommendations, full Cross-Entropy (CE) loss achieves state-of-the-art\nrecommendation quality but consumes excessive GPU memory with large item\ncatalogs, limiting its practicality. Using a GPU-efficient locality-sensitive\nhashing-like algorithm for approximating large tensor of logits, this paper\nintroduces a novel RECE (REduced Cross-Entropy) loss. RECE significantly\nreduces memory consumption while allowing one to enjoy the state-of-the-art\nperformance of full CE loss. Experimental results on various datasets show that\nRECE cuts training peak memory usage by up to 12 times compared to existing\nmethods while retaining or exceeding performance metrics of CE loss. The\napproach also opens up new possibilities for large-scale applications in other\ndomains.",
    "arxiv_id": "http://arxiv.org/abs/2408.02354v2",
    "pdf_url": "http://arxiv.org/pdf/2408.02354v2",
    "primary_category": "cs.IR",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Active Sensing of Knee Osteoarthritis Progression with Reinforcement Learning",
    "authors": "Khanh Nguyen, Huy Hoang Nguyen, Egor Panfilov, Aleksei Tiulpin",
    "abstract": "Osteoarthritis (OA) is the most common musculoskeletal disease, which has no\ncure. Knee OA (KOA) is one of the highest causes of disability worldwide, and\nit costs billions of United States dollars to the global community. Prediction\nof KOA progression has been of high interest to the community for years, as it\ncan advance treatment development through more efficient clinical trials and\nimprove patient outcomes through more efficient healthcare utilization.\nExisting approaches for predicting KOA, however, are predominantly static, i.e.\nconsider data from a single time point to predict progression many years into\nthe future, and knee level, i.e. consider progression in a single joint only.\nDue to these and related reasons, these methods fail to deliver the level of\npredictive performance, which is sufficient to result in cost savings and\nbetter patient outcomes. Collecting extensive data from all patients on a\nregular basis could address the issue, but it is limited by the high cost at a\npopulation level. In this work, we propose to go beyond static prediction\nmodels in OA, and bring a novel Active Sensing (AS) approach, designed to\ndynamically follow up patients with the objective of maximizing the number of\ninformative data acquisitions, while minimizing their total cost over a period\nof time. Our approach is based on Reinforcement Learning (RL), and it leverages\na novel reward function designed specifically for AS of disease progression in\nmore than one part of a human body. Our method is end-to-end, relies on\nmulti-modal Deep Learning, and requires no human input at inference time.\nThroughout an exhaustive experimental evaluation, we show that using RL can\nprovide a higher monetary benefit when compared to state-of-the-art baselines.",
    "arxiv_id": "http://arxiv.org/abs/2408.02349v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02349v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Exploiting Hankel-Toeplitz Structures for Fast Computation of Kernel Precision Matrices",
    "authors": "Frida Viset, Anton Kullberg, Frederiek Wesel, Arno Solin",
    "abstract": "The Hilbert-space Gaussian Process (HGP) approach offers a\nhyperparameter-independent basis function approximation for speeding up\nGaussian Process (GP) inference by projecting the GP onto M basis functions.\nThese properties result in a favorable data-independent $\\mathcal{O}(M^3)$\ncomputational complexity during hyperparameter optimization but require a\ndominating one-time precomputation of the precision matrix costing\n$\\mathcal{O}(NM^2)$ operations. In this paper, we lower this dominating\ncomputational complexity to $\\mathcal{O}(NM)$ with no additional\napproximations. We can do this because we realize that the precision matrix can\nbe split into a sum of Hankel-Toeplitz matrices, each having $\\mathcal{O}(M)$\nunique entries. Based on this realization we propose computing only these\nunique entries at $\\mathcal{O}(NM)$ costs. Further, we develop two theorems\nthat prescribe sufficient conditions for the complexity reduction to hold\ngenerally for a wide range of other approximate GP models, such as the\nVariational Fourier Feature (VFF) approach. The two theorems do this with no\nassumptions on the data and no additional approximations of the GP models\nthemselves. Thus, our contribution provides a pure speed-up of several\nexisting, widely used, GP approximations, without further approximations.",
    "arxiv_id": "http://arxiv.org/abs/2408.02346v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02346v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Machine Learning Applications in Medical Prognostics: A Comprehensive Review",
    "authors": "Michael Fascia",
    "abstract": "Machine learning (ML) has revolutionized medical prognostics by integrating\nadvanced algorithms with clinical data to enhance disease prediction, risk\nassessment, and patient outcome forecasting. This comprehensive review\ncritically examines the application of various ML techniques in medical\nprognostics, focusing on their efficacy, challenges, and future directions. The\nmethodologies discussed include Random Forest (RF) for sepsis prediction,\nlogistic regression for cardiovascular risk assessment, Convolutional Neural\nNetworks (CNNs) for cancer detection, and Long Short-Term Memory (LSTM)\nnetworks for predicting clinical deterioration. RF models demonstrate robust\nperformance in handling high-dimensional data and capturing non-linear\nrelationships, making them particularly effective for sepsis prediction.\nLogistic regression remains valuable for its interpretability and ease of use\nin cardiovascular risk assessment. CNNs have shown exceptional accuracy in\ncancer detection, leveraging their ability to learn complex visual patterns\nfrom medical imaging. LSTM networks excel in analyzing temporal data, providing\naccurate predictions of clinical deterioration. The review highlights the\nstrengths and limitations of each technique, the importance of model\ninterpretability, and the challenges of data quality and privacy. Future\nresearch directions include the integration of multi-modal data sources, the\napplication of transfer learning, and the development of continuous learning\nsystems. These advancements aim to enhance the predictive power and clinical\napplicability of ML models, ultimately improving patient outcomes in healthcare\nsettings.",
    "arxiv_id": "http://arxiv.org/abs/2408.02344v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02344v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Spatial-temporal Graph Convolutional Networks with Diversified Transformation for Dynamic Graph Representation Learning",
    "authors": "Ling Wang, Yixiang Huang, Hao Wu",
    "abstract": "Dynamic graphs (DG) are often used to describe evolving interactions between\nnodes in real-world applications. Temporal patterns are a natural feature of\nDGs and are also key to representation learning. However, existing dynamic GCN\nmodels are mostly composed of static GCNs and sequence modules, which results\nin the separation of spatiotemporal information and cannot effectively capture\ncomplex temporal patterns in DGs. To address this problem, this study proposes\na spatial-temporal graph convolutional networks with diversified transformation\n(STGCNDT), which includes three aspects: a) constructing a unified graph tensor\nconvolutional network (GTCN) using tensor M-products without the need to\nrepresent spatiotemporal information separately; b) introducing three\ntransformation schemes in GTCN to model complex temporal patterns to aggregate\ntemporal information; and c) constructing an ensemble of diversified\ntransformation schemes to obtain higher representation capabilities. Empirical\nstudies on four DGs that appear in communication networks show that the\nproposed STGCNDT significantly outperforms state-of-the-art models in solving\nlink weight estimation tasks due to the diversified transformations.",
    "arxiv_id": "http://arxiv.org/abs/2408.02704v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02704v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Developing PUGG for Polish: A Modern Approach to KBQA, MRC, and IR Dataset Construction",
    "authors": "Albert Sawczyn, Katsiaryna Viarenich, Konrad Wojtasik, Aleksandra Domoga\u0142a, Marcin Oleksy, Maciej Piasecki, Tomasz Kajdanowicz",
    "abstract": "Advancements in AI and natural language processing have revolutionized\nmachine-human language interactions, with question answering (QA) systems\nplaying a pivotal role. The knowledge base question answering (KBQA) task,\nutilizing structured knowledge graphs (KG), allows for handling extensive\nknowledge-intensive questions. However, a significant gap exists in KBQA\ndatasets, especially for low-resource languages. Many existing construction\npipelines for these datasets are outdated and inefficient in human labor, and\nmodern assisting tools like Large Language Models (LLM) are not utilized to\nreduce the workload. To address this, we have designed and implemented a\nmodern, semi-automated approach for creating datasets, encompassing tasks such\nas KBQA, Machine Reading Comprehension (MRC), and Information Retrieval (IR),\ntailored explicitly for low-resource environments. We executed this pipeline\nand introduced the PUGG dataset, the first Polish KBQA dataset, and novel\ndatasets for MRC and IR. Additionally, we provide a comprehensive\nimplementation, insightful findings, detailed statistics, and evaluation of\nbaseline models.",
    "arxiv_id": "http://arxiv.org/abs/2408.02337v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02337v1",
    "primary_category": "cs.AI",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Infusing Environmental Captions for Long-Form Video Language Grounding",
    "authors": "Hyogun Lee, Soyeon Hong, Mujeen Sung, Jinwoo Choi",
    "abstract": "In this work, we tackle the problem of long-form video-language grounding\n(VLG). Given a long-form video and a natural language query, a model should\ntemporally localize the precise moment that answers the query. Humans can\neasily solve VLG tasks, even with arbitrarily long videos, by discarding\nirrelevant moments using extensive and robust knowledge gained from experience.\nUnlike humans, existing VLG methods are prone to fall into superficial cues\nlearned from small-scale datasets, even when they are within irrelevant frames.\nTo overcome this challenge, we propose EI-VLG, a VLG method that leverages\nricher textual information provided by a Multi-modal Large Language Model\n(MLLM) as a proxy for human experiences, helping to effectively exclude\nirrelevant frames. We validate the effectiveness of the proposed method via\nextensive experiments on a challenging EgoNLQ benchmark.",
    "arxiv_id": "http://arxiv.org/abs/2408.02336v2",
    "pdf_url": "http://arxiv.org/pdf/2408.02336v2",
    "primary_category": "cs.CV",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "A Sharp Convergence Theory for The Probability Flow ODEs of Diffusion Models",
    "authors": "Gen Li, Yuting Wei, Yuejie Chi, Yuxin Chen",
    "abstract": "Diffusion models, which convert noise into new data instances by learning to\nreverse a diffusion process, have become a cornerstone in contemporary\ngenerative modeling. In this work, we develop non-asymptotic convergence theory\nfor a popular diffusion-based sampler (i.e., the probability flow ODE sampler)\nin discrete time, assuming access to $\\ell_2$-accurate estimates of the (Stein)\nscore functions. For distributions in $\\mathbb{R}^d$, we prove that\n$d/\\varepsilon$ iterations -- modulo some logarithmic and lower-order terms --\nare sufficient to approximate the target distribution to within $\\varepsilon$\ntotal-variation distance. This is the first result establishing nearly linear\ndimension-dependency (in $d$) for the probability flow ODE sampler. Imposing\nonly minimal assumptions on the target data distribution (e.g., no smoothness\nassumption is imposed), our results also characterize how $\\ell_2$ score\nestimation errors affect the quality of the data generation processes. In\ncontrast to prior works, our theory is developed based on an elementary yet\nversatile non-asymptotic approach without the need of resorting to SDE and ODE\ntoolboxes.",
    "arxiv_id": "http://arxiv.org/abs/2408.02320v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02320v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "A Lean Transformer Model for Dynamic Malware Analysis and Detection",
    "authors": "Tony Quertier, Benjamin Marais, Gr\u00e9goire Barru\u00e9, St\u00e9phane Morucci, S\u00e9van Az\u00e9, S\u00e9bastien Salladin",
    "abstract": "Malware is a fast-growing threat to the modern computing world and existing\nlines of defense are not efficient enough to address this issue. This is mainly\ndue to the fact that many prevention solutions rely on signature-based\ndetection methods that can easily be circumvented by hackers. Therefore, there\nis a recurrent need for behavior-based analysis where a suspicious file is ran\nin a secured environment and its traces are collected to reports for analysis.\nPrevious works have shown some success leveraging Neural Networks and API calls\nsequences extracted from these execution reports.\n  Recently, Large Language Models and Generative AI have demonstrated\nimpressive capabilities mainly in Natural Language Processing tasks and\npromising applications in the cybersecurity field for both attackers and\ndefenders.\n  In this paper, we design an Encoder-Only model, based on the Transformers\narchitecture, to detect malicious files, digesting their API call sequences\ncollected by an execution emulation solution. We are also limiting the size of\nthe model architecture and the number of its parameters since it is often\nconsidered that Large Language Models may be overkill for specific tasks such\nas the one we are dealing with hereafter. In addition to achieving decent\ndetection results, this approach has the advantage of reducing our carbon\nfootprint by limiting training and inference times and facilitating technical\noperations with less hardware requirements.\n  We also carry out some analysis of our results and highlight the limits and\npossible improvements when using Transformers to analyze malicious files.",
    "arxiv_id": "http://arxiv.org/abs/2408.02313v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02313v1",
    "primary_category": "cs.CR",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Optimization of Iterative Blind Detection based on Expectation Maximization and Belief Propagation",
    "authors": "Luca Schmid, Tomer Raviv, Nir Shlezinger, Laurent Schmalen",
    "abstract": "We study iterative blind symbol detection for block-fading linear\ninter-symbol interference channels. Based on the factor graph framework, we\ndesign a joint channel estimation and detection scheme that combines the\nexpectation maximization (EM) algorithm and the ubiquitous belief propagation\n(BP) algorithm. Interweaving the iterations of both schemes significantly\nreduces the EM algorithm's computational burden while retaining its excellent\nperformance. To this end, we apply simple yet effective model-based learning\nmethods to find a suitable parameter update schedule by introducing momentum in\nboth the EM parameter updates as well as in the BP message passing. Numerical\nsimulations verify that the proposed method can learn efficient schedules that\ngeneralize well and even outperform coherent BP detection in high\nsignal-to-noise scenarios.",
    "arxiv_id": "http://arxiv.org/abs/2408.02312v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02312v1",
    "primary_category": "cs.IT",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "On the Robustness of Malware Detectors to Adversarial Samples",
    "authors": "Muhammad Salman, Benjamin Zi Hao Zhao, Hassan Jameel Asghar, Muhammad Ikram, Sidharth Kaushik, Mohamed Ali Kaafar",
    "abstract": "Adversarial examples add imperceptible alterations to inputs with the\nobjective to induce misclassification in machine learning models. They have\nbeen demonstrated to pose significant challenges in domains like image\nclassification, with results showing that an adversarially perturbed image to\nevade detection against one classifier is most likely transferable to other\nclassifiers. Adversarial examples have also been studied in malware analysis.\nUnlike images, program binaries cannot be arbitrarily perturbed without\nrendering them non-functional. Due to the difficulty of crafting adversarial\nprogram binaries, there is no consensus on the transferability of adversarially\nperturbed programs to different detectors. In this work, we explore the\nrobustness of malware detectors against adversarially perturbed malware. We\ninvestigate the transferability of adversarial attacks developed against one\ndetector, against other machine learning-based malware detectors, and code\nsimilarity techniques, specifically, locality sensitive hashing-based\ndetectors. Our analysis reveals that adversarial program binaries crafted for\none detector are generally less effective against others. We also evaluate an\nensemble of detectors and show that they can potentially mitigate the impact of\nadversarial program binaries. Finally, we demonstrate that substantial program\nchanges made to evade detection may result in the transformation technique\nbeing identified, implying that the adversary must make minimal changes to the\nprogram binary.",
    "arxiv_id": "http://arxiv.org/abs/2408.02310v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02310v1",
    "primary_category": "cs.CR",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Network Fission Ensembles for Low-Cost Self-Ensembles",
    "authors": "Hojung Lee, Jong-Seok Lee",
    "abstract": "Recent ensemble learning methods for image classification have been shown to\nimprove classification accuracy with low extra cost. However, they still\nrequire multiple trained models for ensemble inference, which eventually\nbecomes a significant burden when the model size increases. In this paper, we\npropose a low-cost ensemble learning and inference, called Network Fission\nEnsembles (NFE), by converting a conventional network itself into a multi-exit\nstructure. Starting from a given initial network, we first prune some of the\nweights to reduce the training burden. We then group the remaining weights into\nseveral sets and create multiple auxiliary paths using each set to construct\nmulti-exits. We call this process Network Fission. Through this, multiple\noutputs can be obtained from a single network, which enables ensemble learning.\nSince this process simply changes the existing network structure to multi-exits\nwithout using additional networks, there is no extra computational burden for\nensemble learning and inference. Moreover, by learning from multiple losses of\nall exits, the multi-exits improve performance via regularization, and high\nperformance can be achieved even with increased network sparsity. With our\nsimple yet effective method, we achieve significant improvement compared to\nexisting ensemble methods. The code is available at\nhttps://github.com/hjdw2/NFE.",
    "arxiv_id": "http://arxiv.org/abs/2408.02301v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02301v1",
    "primary_category": "cs.CV",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Backward Compatibility in Attributive Explanation and Enhanced Model Training Method",
    "authors": "Ryuta Matsuno",
    "abstract": "Model update is a crucial process in the operation of ML/AI systems. While\nupdating a model generally enhances the average prediction performance, it also\nsignificantly impacts the explanations of predictions. In real-world\napplications, even minor changes in explanations can have detrimental\nconsequences. To tackle this issue, this paper introduces BCX, a quantitative\nmetric that evaluates the backward compatibility of feature attribution\nexplanations between pre- and post-update models. BCX utilizes practical\nagreement metrics to calculate the average agreement between the explanations\nof pre- and post-update models, specifically among samples on which both models\naccurately predict. In addition, we propose BCXR, a BCX-aware model training\nmethod by designing surrogate losses which theoretically lower bounds agreement\nscores. Furthermore, we present a universal variant of BCXR that improves all\nagreement metrics, utilizing L2 distance among the explanations of the models.\nTo validate our approach, we conducted experiments on eight real-world\ndatasets, demonstrating that BCXR achieves superior trade-offs between\npredictive performances and BCX scores, showcasing the effectiveness of our\nBCXR methods.",
    "arxiv_id": "http://arxiv.org/abs/2408.02298v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02298v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Heart Rate and its Variability from Short-term ECG Recordings as Biomarkers for Detecting Mild Cognitive Impairment in Indian Population",
    "authors": "Anjo Xavier, Sneha Noble, Justin Joseph, Thomas Gregor Issac",
    "abstract": "Alterations in Heart Rate (HR) and Heart Rate Variability (HRV) can reflect\nautonomic dysfunction associated with neurodegeneration. We investigate the\ninfluence of Mild Cognitive Impairment (MCI) on HR and its variability measures\nin the Indian population by designing a complete signal processing pipeline to\ndetect the R-wave peaks and compute HR and HRV features from ECG recordings of\n10 seconds, for point-of-care applications. The study cohort involves 297 urban\nparticipants, among which 48.48% are male and 51.51% are female. From the\nAddenbrooke's Cognitive Examination-III (ACE-III), MCI is detected in 19.19% of\nparticipants and the rest, 80.8% of them are cognitively healthy. Statistical\nfeatures like central tendency (mean and root mean square (RMS) of the\nNormal-to-Normal (NN) intervals) and dispersion (standard deviation (SD) of all\nNN intervals (SDNN) and root mean square of successive differences of NN\nintervals (RMSSD)) of beat-to-beat intervals are computed. The Wilcoxon rank\nsum test reveals that mean of NN intervals (p = 0.0021), the RMS of NN\nintervals (p = 0.0014), the SDNN (p = 0.0192) and the RMSSD (p = 0.0206) values\ndiffer significantly between MCI and non-MCI classes, for a level of\nsignificance, 0.05. Machine learning classifiers like, Support Vector Machine\n(SVM), Discriminant Analysis (DA) and Naive Bayes (NB) driven by mean NN\nintervals, RMS, SDNN and RMSSD, show a high accuracy of 80.80% on each\nindividual feature input. Individuals with MCI are observed to have\ncomparatively higher HR than healthy subjects. HR and its variability can be\nconsidered as potential biomarkers for detecting MCI.",
    "arxiv_id": "http://arxiv.org/abs/2408.02296v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02296v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Generalized Gaussian Temporal Difference Error For Uncertainty-aware Reinforcement Learning",
    "authors": "Seyeon Kim, Joonhun Lee, Namhoon Cho, Sungjun Han, Seungeon Baek",
    "abstract": "Conventional uncertainty-aware temporal difference (TD) learning methods\noften rely on simplistic assumptions, typically including a zero-mean Gaussian\ndistribution for TD errors. Such oversimplification can lead to inaccurate\nerror representations and compromised uncertainty estimation. In this paper, we\nintroduce a novel framework for generalized Gaussian error modeling in deep\nreinforcement learning, applicable to both discrete and continuous control\nsettings. Our framework enhances the flexibility of error distribution modeling\nby incorporating higher-order moments, particularly kurtosis, thereby improving\nthe estimation and mitigation of data-dependent noise, i.e., aleatoric\nuncertainty. We examine the influence of the shape parameter of the generalized\nGaussian distribution (GGD) on aleatoric uncertainty and provide a closed-form\nexpression that demonstrates an inverse relationship between uncertainty and\nthe shape parameter. Additionally, we propose a theoretically grounded\nweighting scheme to fully leverage the GGD. To address epistemic uncertainty,\nwe enhance the batch inverse variance weighting by incorporating bias reduction\nand kurtosis considerations, resulting in improved robustness. Extensive\nexperimental evaluations using policy gradient algorithms demonstrate the\nconsistent efficacy of our method, showcasing significant performance\nimprovements.",
    "arxiv_id": "http://arxiv.org/abs/2408.02295v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02295v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Hardware Aware Ensemble Selection for Balancing Predictive Accuracy and Cost",
    "authors": "Jannis Maier, Felix M\u00f6ller, Lennart Purucker",
    "abstract": "Automated Machine Learning (AutoML) significantly simplifies the deployment\nof machine learning models by automating tasks from data preprocessing to model\nselection to ensembling. AutoML systems for tabular data often employ post hoc\nensembling, where multiple models are combined to improve predictive accuracy.\nThis typically results in longer inference times, a major limitation in\npractical deployments. Addressing this, we introduce a hardware-aware ensemble\nselection approach that integrates inference time into post hoc ensembling. By\nleveraging an existing framework for ensemble selection with quality diversity\noptimization, our method evaluates ensemble candidates for their predictive\naccuracy and hardware efficiency. This dual focus allows for a balanced\nconsideration of accuracy and operational efficiency. Thus, our approach\nenables practitioners to choose from a Pareto front of accurate and efficient\nensembles. Our evaluation using 83 classification datasets shows that our\napproach sustains competitive accuracy and can significantly improve ensembles'\noperational efficiency. The results of this study provide a foundation for\nextending these principles to additional hardware constraints, setting the\nstage for the development of more resource-efficient AutoML systems.",
    "arxiv_id": "http://arxiv.org/abs/2408.02280v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02280v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "DRFormer: Multi-Scale Transformer Utilizing Diverse Receptive Fields for Long Time-Series Forecasting",
    "authors": "Ruixin Ding, Yuqi Chen, Yu-Ting Lan, Wei Zhang",
    "abstract": "Long-term time series forecasting (LTSF) has been widely applied in finance,\ntraffic prediction, and other domains. Recently, patch-based transformers have\nemerged as a promising approach, segmenting data into sub-level patches that\nserve as input tokens. However, existing methods mostly rely on predetermined\npatch lengths, necessitating expert knowledge and posing challenges in\ncapturing diverse characteristics across various scales. Moreover, time series\ndata exhibit diverse variations and fluctuations across different temporal\nscales, which traditional approaches struggle to model effectively. In this\npaper, we propose a dynamic tokenizer with a dynamic sparse learning algorithm\nto capture diverse receptive fields and sparse patterns of time series data. In\norder to build hierarchical receptive fields, we develop a multi-scale\nTransformer model, coupled with multi-scale sequence extraction, capable of\ncapturing multi-resolution features. Additionally, we introduce a group-aware\nrotary position encoding technique to enhance intra- and inter-group position\nawareness among representations across different temporal scales. Our proposed\nmodel, named DRFormer, is evaluated on various real-world datasets, and\nexperimental results demonstrate its superiority compared to existing methods.\nOur code is available at: https://github.com/ruixindingECNU/DRFormer.",
    "arxiv_id": "http://arxiv.org/abs/2408.02279v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02279v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "One-Shot Collaborative Data Distillation",
    "authors": "Rayne Holland, Chandra Thapa, Sarah Ali Siddiqui, Wei Shao, Seyit Camtepe",
    "abstract": "Large machine-learning training datasets can be distilled into small\ncollections of informative synthetic data samples. These synthetic sets support\nefficient model learning and reduce the communication cost of data sharing.\nThus, high-fidelity distilled data can support the efficient deployment of\nmachine learning applications in distributed network environments. A naive way\nto construct a synthetic set in a distributed environment is to allow each\nclient to perform local data distillation and to merge local distillations at a\ncentral server. However, the quality of the resulting set is impaired by\nheterogeneity in the distributions of the local data held by clients. To\novercome this challenge, we introduce the first collaborative data distillation\ntechnique, called CollabDM, which captures the global distribution of the data\nand requires only a single round of communication between client and server.\nOur method outperforms the state-of-the-art one-shot learning method on skewed\ndata in distributed learning environments. We also show the promising practical\nbenefits of our method when applied to attack detection in 5G networks.",
    "arxiv_id": "http://arxiv.org/abs/2408.02266v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02266v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Contrastive Learning and Abstract Concepts: The Case of Natural Numbers",
    "authors": "Daniel N. Nissani",
    "abstract": "Contrastive Learning (CL) has been successfully applied to classification and\nother downstream tasks related to concrete concepts, such as objects contained\nin the ImageNet dataset. No attempts seem to have been made so far in applying\nthis promising scheme to more abstract entities. A prominent example of these\ncould be the concept of (discrete) Quantity. CL can be frequently interpreted\nas a self-supervised scheme guided by some profound and ubiquitous conservation\nprinciple (e.g. conservation of identity in object classification tasks). In\nthis introductory work we apply a suitable conservation principle to the\nsemi-abstract concept of natural numbers by which discrete quantities can be\nestimated or predicted. We experimentally show, by means of a toy problem, that\ncontrastive learning can be trained to count at a glance with high accuracy\nboth at human as well as at super-human ranges.. We compare this with the\nresults of a trained-to-count at a glance supervised learning (SL) neural\nnetwork scheme of similar architecture. We show that both schemes exhibit\nsimilar good performance on baseline experiments, where the distributions of\nthe training and testing stages are equal. Importantly, we demonstrate that in\nsome generalization scenarios, where training and testing distributions differ,\nCL boasts more robust and much better error performance.",
    "arxiv_id": "http://arxiv.org/abs/2408.02247v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02247v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Methods to improve run time of hydrologic models: opportunities and challenges in the machine learning era",
    "authors": "Supath Dhital",
    "abstract": "The application of Machine Learning (ML) to hydrologic modeling is fledgling.\nIts applicability to capture the dependencies on watersheds to forecast better\nwithin a short period is fascinating. One of the key reasons to adopt ML\nalgorithms over physics-based models is its computational efficiency advantage\nand flexibility to work with various data sets. The diverse applications,\nparticularly in emergency response and expanding over a large scale, demand the\nhydrological model in a short time and make researchers adopt data-driven\nmodeling approaches unhesitatingly. In this work, in the era of ML and deep\nlearning (DL), how it can help to improve the overall run time of physics-based\nmodel and potential constraints that should be addressed while modeling. This\npaper covers the opportunities and challenges of adopting ML for hydrological\nmodeling and subsequently how it can help to improve the simulation time of\nphysics-based models and future works that should be addressed.",
    "arxiv_id": "http://arxiv.org/abs/2408.02242v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02242v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Large Language Model Aided QoS Prediction for Service Recommendation",
    "authors": "Huiying Liu, Zekun Zhang, Qilin Wu, Yiwen Zhang",
    "abstract": "Large language models (LLMs) have seen rapid improvement in the recent years,\nand are used in a wider range of applications. After being trained on large\ntext corpus, LLMs obtain the capability of extracting rich features from\ntextual data. Such capability is potentially useful for the web service\nrecommendation task, where the web users and services have intrinsic attributes\nthat can be described using natural language sentences and are useful for\nrecommendation. In this paper, we explore the possibility and practicality of\nusing LLMs for web service recommendation. We propose the large language model\naided QoS prediction (llmQoS) model, which use LLMs to extract useful\ninformation from attributes of web users and services via descriptive\nsentences. This information is then used in combination with the QoS values of\nhistorical interactions of users and services, to predict QoS values for any\ngiven user-service pair. Our proposed model is shown to overcome the data\nsparsity issue for QoS prediction. We show that on the WSDream dataset, llmQoS\noutperforms comparable baseline models consistently.",
    "arxiv_id": "http://arxiv.org/abs/2408.02223v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02223v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Climate-Driven Doubling of Maize Loss Probability in U.S. Crop Insurance: Spatiotemporal Prediction and Possible Policy Responses",
    "authors": "A Samuel Pottinger, Lawson Connor, Brookie Guzder-Williams, Maya Weltman-Fahs, Timothy Bowles",
    "abstract": "Climate change not only threatens agricultural producers but also strains\nfinancial institutions. These important food system actors include government\nentities tasked with both insuring grower livelihoods and supporting response\nto continued global warming. We use an artificial neural network to predict\nfuture maize yields in the U.S. Corn Belt, finding alarming changes to\ninstitutional risk exposure within the Federal Crop Insurance Program.\nSpecifically, our machine learning method anticipates more frequent and more\nsevere yield losses that would result in the annual probability of Yield\nProtection (YP) claims to more than double at mid-century relative to\nsimulations without continued climate change. Furthermore, our dual finding of\nrelatively unchanged average yields paired with decreasing yield stability\nreveals targeted opportunities to adjust coverage formulas to include\nvariability. This important structural shift may help regulators support grower\nadaptation to continued climate change by recognizing the value of\nrisk-reducing strategies such as regenerative agriculture. Altogether, paired\nwith open source interactive tools for deeper investigation, our risk profile\nsimulations fill an actionable gap in current understanding, bridging granular\nhistoric yield estimation and climate-informed prediction of future\ninsurer-relevant loss.",
    "arxiv_id": "http://arxiv.org/abs/2408.02217v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02217v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Multi-level Traffic-Responsive Tilt Camera Surveillance through Predictive Correlated Online Learning",
    "authors": "Tao Li, Zilin Bian, Haozhe Lei, Fan Zuo, Ya-Ting Yang, Quanyan Zhu, Zhenning Li, Kaan Ozbay",
    "abstract": "In urban traffic management, the primary challenge of dynamically and\nefficiently monitoring traffic conditions is compounded by the insufficient\nutilization of thousands of surveillance cameras along the intelligent\ntransportation system. This paper introduces the multi-level Traffic-responsive\nTilt Camera surveillance system (TTC-X), a novel framework designed for dynamic\nand efficient monitoring and management of traffic in urban networks. By\nleveraging widely deployed pan-tilt-cameras (PTCs), TTC-X overcomes the\nlimitations of a fixed field of view in traditional surveillance systems by\nproviding mobilized and 360-degree coverage. The innovation of TTC-X lies in\nthe integration of advanced machine learning modules, including a\ndetector-predictor-controller structure, with a novel Predictive Correlated\nOnline Learning (PiCOL) methodology and the Spatial-Temporal Graph Predictor\n(STGP) for real-time traffic estimation and PTC control. The TTC-X is tested\nand evaluated under three experimental scenarios (e.g., maximum traffic flow\ncapture, dynamic route planning, traffic state estimation) based on a\nsimulation environment calibrated using real-world traffic data in Brooklyn,\nNew York. The experimental results showed that TTC-X captured over 60\\% total\nnumber of vehicles at the network level, dynamically adjusted its route\nrecommendation in reaction to unexpected full-lane closure events, and\nreconstructed link-level traffic states with best MAE less than 1.25\nvehicle/hour. Demonstrating scalability, cost-efficiency, and adaptability,\nTTC-X emerges as a powerful solution for urban traffic management in both\ncyber-physical and real-world environments.",
    "arxiv_id": "http://arxiv.org/abs/2408.02208v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02208v1",
    "primary_category": "eess.SY",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Evaluating the Performance of Large Language Models for SDG Mapping (Technical Report)",
    "authors": "Hui Yin, Amir Aryani, Nakul Nambiar",
    "abstract": "The use of large language models (LLMs) is expanding rapidly, and open-source\nversions are becoming available, offering users safer and more adaptable\noptions. These models enable users to protect data privacy by eliminating the\nneed to provide data to third parties and can be customized for specific tasks.\nIn this study, we compare the performance of various language models on the\nSustainable Development Goal (SDG) mapping task, using the output of GPT-4o as\nthe baseline. The selected open-source models for comparison include Mixtral,\nLLaMA 2, LLaMA 3, Gemma, and Qwen2. Additionally, GPT-4o-mini, a more\nspecialized version of GPT-4o, was included to extend the comparison. Given the\nmulti-label nature of the SDG mapping task, we employed metrics such as F1\nscore, precision, and recall with micro-averaging to evaluate different aspects\nof the models' performance. These metrics are derived from the confusion matrix\nto ensure a comprehensive evaluation. We provide a clear observation and\nanalysis of each model's performance by plotting curves based on F1 score,\nprecision, and recall at different thresholds. According to the results of this\nexperiment, LLaMA 2 and Gemma still have significant room for improvement. The\nother four models do not exhibit particularly large differences in performance.\nThe outputs from all seven models are available on Zenodo:\nhttps://doi.org/10.5281/zenodo.12789375.",
    "arxiv_id": "http://arxiv.org/abs/2408.02201v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02201v1",
    "primary_category": "cs.LG",
    "votes": -1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Synergistic Learning with Multi-Task DeepONet for Efficient PDE Problem Solving",
    "authors": "Varun Kumar, Somdatta Goswami, Katiana Kontolati, Michael D. Shields, George Em Karniadakis",
    "abstract": "Multi-task learning (MTL) is an inductive transfer mechanism designed to\nleverage useful information from multiple tasks to improve generalization\nperformance compared to single-task learning. It has been extensively explored\nin traditional machine learning to address issues such as data sparsity and\noverfitting in neural networks. In this work, we apply MTL to problems in\nscience and engineering governed by partial differential equations (PDEs).\nHowever, implementing MTL in this context is complex, as it requires\ntask-specific modifications to accommodate various scenarios representing\ndifferent physical processes. To this end, we present a multi-task deep\noperator network (MT-DeepONet) to learn solutions across various functional\nforms of source terms in a PDE and multiple geometries in a single concurrent\ntraining session. We introduce modifications in the branch network of the\nvanilla DeepONet to account for various functional forms of a parameterized\ncoefficient in a PDE. Additionally, we handle parameterized geometries by\nintroducing a binary mask in the branch network and incorporating it into the\nloss term to improve convergence and generalization to new geometry tasks. Our\napproach is demonstrated on three benchmark problems: (1) learning different\nfunctional forms of the source term in the Fisher equation; (2) learning\nmultiple geometries in a 2D Darcy Flow problem and showcasing better transfer\nlearning capabilities to new geometries; and (3) learning 3D parameterized\ngeometries for a heat transfer problem and demonstrate the ability to predict\non new but similar geometries. Our MT-DeepONet framework offers a novel\napproach to solving PDE problems in engineering and science under a unified\numbrella based on synergistic learning that reduces the overall training cost\nfor neural operators.",
    "arxiv_id": "http://arxiv.org/abs/2408.02198v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02198v1",
    "primary_category": "cs.LG",
    "votes": 1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "CodeACT: Code Adaptive Compute-efficient Tuning Framework for Code LLMs",
    "authors": "Weijie Lv, Xuan Xia, Sheng-Jun Huang",
    "abstract": "Large language models (LLMs) have shown great potential in code-related\ntasks, yet open-source models lag behind their closed-source counterparts. To\nbridge this performance gap, existing methods generate vast amounts of\nsynthetic data for fine-tuning, leading to inefficiencies in training.\nMotivated by the need for more effective and efficient training, we propose the\nCode Adaptive Compute-efficient Tuning (CodeACT) framework. CodeACT introduces\nthe Complexity and Diversity Aware Sampling (CDAS) method to select\nhigh-quality training data based on complexity and diversity, and the Dynamic\nPack padding strategy to reduce computational resource usage by minimizing\npadding tokens during training. Experimental results demonstrate that\nCodeACT-DeepSeek-Coder-6.7B, fine-tuned on only 40% of the EVOL-Instruct data,\nachieves an 8.6% performance increase on HumanEval, reduces training time by\n78%, and decreases peak GPU memory usage by 27%. These findings underscore\nCodeACT's ability to enhance the performance and efficiency of open-source\nmodels. By optimizing both the data selection and training processes, CodeACT\noffers a comprehensive approach to improving the capabilities of open-source\nLLMs while significantly reducing computational requirements, addressing the\ndual challenges of data quality and training efficiency, and paving the way for\nmore resource-efficient and performant models.",
    "arxiv_id": "http://arxiv.org/abs/2408.02193v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02193v1",
    "primary_category": "cs.CL",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "SelfBC: Self Behavior Cloning for Offline Reinforcement Learning",
    "authors": "Shirong Liu, Chenjia Bai, Zixian Guo, Hao Zhang, Gaurav Sharma, Yang Liu",
    "abstract": "Policy constraint methods in offline reinforcement learning employ additional\nregularization techniques to constrain the discrepancy between the learned\npolicy and the offline dataset. However, these methods tend to result in overly\nconservative policies that resemble the behavior policy, thus limiting their\nperformance. We investigate this limitation and attribute it to the static\nnature of traditional constraints. In this paper, we propose a novel dynamic\npolicy constraint that restricts the learned policy on the samples generated by\nthe exponential moving average of previously learned policies. By integrating\nthis self-constraint mechanism into off-policy methods, our method facilitates\nthe learning of non-conservative policies while avoiding policy collapse in the\noffline setting. Theoretical results show that our approach results in a nearly\nmonotonically improved reference policy. Extensive experiments on the D4RL\nMuJoCo domain demonstrate that our proposed method achieves state-of-the-art\nperformance among the policy constraint methods.",
    "arxiv_id": "http://arxiv.org/abs/2408.02165v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02165v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Distilling Machine Learning's Added Value: Pareto Fronts in Atmospheric Applications",
    "authors": "Tom Beucler, Arthur Grundner, Sara Shamekh, Peter Ukkonen, Matthew Chantry, Ryan Lagerquist",
    "abstract": "While the added value of machine learning (ML) for weather and climate\napplications is measurable, explaining it remains challenging, especially for\nlarge deep learning models. Inspired by climate model hierarchies, we propose\nthat a full hierarchy of Pareto-optimal models, defined within an appropriately\ndetermined error-complexity plane, can guide model development and help\nunderstand the models' added value. We demonstrate the use of Pareto fronts in\natmospheric physics through three sample applications, with hierarchies ranging\nfrom semi-empirical models with minimal tunable parameters (simplest) to deep\nlearning algorithms (most complex). First, in cloud cover parameterization, we\nfind that neural networks identify nonlinear relationships between cloud cover\nand its thermodynamic environment, and assimilate previously neglected features\nsuch as vertical gradients in relative humidity that improve the representation\nof low cloud cover. This added value is condensed into a ten-parameter equation\nthat rivals the performance of deep learning models. Second, we establish a ML\nmodel hierarchy for emulating shortwave radiative transfer, distilling the\nimportance of bidirectional vertical connectivity for accurately representing\nabsorption and scattering, especially for multiple cloud layers. Third, we\nemphasize the importance of convective organization information when modeling\nthe relationship between tropical precipitation and its surrounding\nenvironment. We discuss the added value of temporal memory when high-resolution\nspatial information is unavailable, with implications for precipitation\nparameterization. Therefore, by comparing data-driven models directly with\nexisting schemes using Pareto optimality, we promote process understanding by\nhierarchically unveiling system complexity, with the hope of improving the\ntrustworthiness of ML models in atmospheric applications.",
    "arxiv_id": "http://arxiv.org/abs/2408.02161v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02161v1",
    "primary_category": "physics.comp-ph",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "SPINEX-TimeSeries: Similarity-based Predictions with Explainable Neighbors Exploration for Time Series and Forecasting Problems",
    "authors": "Ahmed Z Naser, MZ Naser",
    "abstract": "This paper introduces a new addition to the SPINEX (Similarity-based\nPredictions with Explainable Neighbors Exploration) family, tailored\nspecifically for time series and forecasting analysis. This new algorithm\nleverages the concept of similarity and higher-order temporal interactions\nacross multiple time scales to enhance predictive accuracy and interpretability\nin forecasting. To evaluate the effectiveness of SPINEX, we present\ncomprehensive benchmarking experiments comparing it against 18 algorithms and\nacross 49 synthetic and real datasets characterized by varying trends,\nseasonality, and noise levels. Our performance assessment focused on\nforecasting accuracy and computational efficiency. Our findings reveal that\nSPINEX consistently ranks among the top 5 performers in forecasting precision\nand has a superior ability to handle complex temporal dynamics compared to\ncommonly adopted algorithms. Moreover, the algorithm's explainability features,\nPareto efficiency, and medium complexity (on the order of O(log n)) are\ndemonstrated through detailed visualizations to enhance the prediction and\ndecision-making process. We note that integrating similarity-based concepts\nopens new avenues for research in predictive analytics, promising more accurate\nand transparent decision making.",
    "arxiv_id": "http://arxiv.org/abs/2408.02159v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02159v1",
    "primary_category": "stat.ME",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "ARVO: Atlas of Reproducible Vulnerabilities for Open Source Software",
    "authors": "Xiang Mei, Pulkit Singh Singaria, Jordi Del Castillo, Haoran Xi, Abdelouahab, Benchikh, Tiffany Bao, Ruoyu Wang, Yan Shoshitaishvili, Adam Doup\u00e9, Hammond Pearce, Brendan Dolan-Gavitt",
    "abstract": "High-quality datasets of real-world vulnerabilities are enormously valuable\nfor downstream research in software security, but existing datasets are\ntypically small, require extensive manual effort to update, and are missing\ncrucial features that such research needs. In this paper, we introduce ARVO: an\nAtlas of Reproducible Vulnerabilities in Open-source software. By sourcing\nvulnerabilities from C/C++ projects that Google's OSS-Fuzz discovered and\nimplementing a reliable re-compilation system, we successfully reproduce more\nthan 5,000 memory vulnerabilities across over 250 projects, each with a\ntriggering input, the canonical developer-written patch for fixing the\nvulnerability, and the ability to automatically rebuild the project from source\nand run it at its vulnerable and patched revisions. Moreover, our dataset can\nbe automatically updated as OSS-Fuzz finds new vulnerabilities, allowing it to\ngrow over time. We provide a thorough characterization of the ARVO dataset,\nshow that it can locate fixes more accurately than Google's own OSV\nreproduction effort, and demonstrate its value for future research through two\ncase studies: firstly evaluating real-world LLM-based vulnerability repair, and\nsecondly identifying over 300 falsely patched (still-active) zero-day\nvulnerabilities from projects improperly labeled by OSS-Fuzz.",
    "arxiv_id": "http://arxiv.org/abs/2408.02153v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02153v1",
    "primary_category": "cs.CR",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Generative Retrieval with Few-shot Indexing",
    "authors": "Arian Askari, Chuan Meng, Mohammad Aliannejadi, Zhaochun Ren, Evangelos Kanoulas, Suzan Verberne",
    "abstract": "Existing generative retrieval (GR) approaches rely on training-based\nindexing, i.e., fine-tuning a model to memorise the associations between a\nquery and the document identifier (docid) of a relevant document.\nTraining-based indexing has three limitations: high training overhead,\nunder-utilization of the pre-trained knowledge of large language models (LLMs),\nand challenges in adapting to a dynamic document corpus. To address the above\nissues, we propose a novel few-shot indexing-based GR framework (Few-Shot GR).\nIt has a novel few-shot indexing process, where we prompt an LLM to generate\ndocids for all documents in a corpus, ultimately creating a docid bank for the\nentire corpus. During retrieval, we feed a query to the same LLM and constrain\nit to generate a docid within the docid bank created during indexing, and then\nmap the generated docid back to its corresponding document. Few-Shot GR relies\nsolely on prompting an LLM without requiring any training, making it more\nefficient. Moreover, we devise few-shot indexing with one-to-many mapping to\nfurther enhance Few-Shot GR. Experiments show that Few-Shot GR achieves\nsuperior performance to state-of-the-art GR methods that require heavy\ntraining.",
    "arxiv_id": "http://arxiv.org/abs/2408.02152v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02152v1",
    "primary_category": "cs.IR",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "VidModEx: Interpretable and Efficient Black Box Model Extraction for High-Dimensional Spaces",
    "authors": "Somnath Sendhil Kumar, Yuvaraj Govindarajulu, Pavan Kulkarni, Manojkumar Parmar",
    "abstract": "In the domain of black-box model extraction, conventional methods reliant on\nsoft labels or surrogate datasets struggle with scaling to high-dimensional\ninput spaces and managing the complexity of an extensive array of interrelated\nclasses. In this work, we present a novel approach that utilizes SHAP (SHapley\nAdditive exPlanations) to enhance synthetic data generation. SHAP quantifies\nthe individual contributions of each input feature towards the victim model's\noutput, facilitating the optimization of an energy-based GAN towards a\ndesirable output. This method significantly boosts performance, achieving a\n16.45% increase in the accuracy of image classification models and extending to\nvideo classification models with an average improvement of 26.11% and a maximum\nof 33.36% on challenging datasets such as UCF11, UCF101, Kinetics 400, Kinetics\n600, and Something-Something V2. We further demonstrate the effectiveness and\npractical utility of our method under various scenarios, including the\navailability of top-k prediction probabilities, top-k prediction labels, and\ntop-1 labels.",
    "arxiv_id": "http://arxiv.org/abs/2408.02140v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02140v1",
    "primary_category": "cs.CV",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Model Hijacking Attack in Federated Learning",
    "authors": "Zheng Li, Siyuan Wu, Ruichuan Chen, Paarijaat Aditya, Istemi Ekin Akkus, Manohar Vanga, Min Zhang, Hao Li, Yang Zhang",
    "abstract": "Machine learning (ML), driven by prominent paradigms such as centralized and\nfederated learning, has made significant progress in various critical\napplications ranging from autonomous driving to face recognition. However, its\nremarkable success has been accompanied by various attacks. Recently, the model\nhijacking attack has shown that ML models can be hijacked to execute tasks\ndifferent from their original tasks, which increases both accountability and\nparasitic computational risks. Nevertheless, thus far, this attack has only\nfocused on centralized learning. In this work, we broaden the scope of this\nattack to the federated learning domain, where multiple clients collaboratively\ntrain a global model without sharing their data. Specifically, we present\nHijackFL, the first-of-its-kind hijacking attack against the global model in\nfederated learning. The adversary aims to force the global model to perform a\ndifferent task (called hijacking task) from its original task without the\nserver or benign client noticing. To accomplish this, unlike existing methods\nthat use data poisoning to modify the target model's parameters, HijackFL\nsearches for pixel-level perturbations based on their local model (without\nmodifications) to align hijacking samples with the original ones in the feature\nspace. When performing the hijacking task, the adversary applies these cloaks\nto the hijacking samples, compelling the global model to identify them as\noriginal samples and predict them accordingly. We conduct extensive experiments\non four benchmark datasets and three popular models. Empirical results\ndemonstrate that its attack performance outperforms baselines. We further\ninvestigate the factors that affect its performance and discuss possible\ndefenses to mitigate its impact.",
    "arxiv_id": "http://arxiv.org/abs/2408.02131v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02131v1",
    "primary_category": "cs.CR",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "FovEx: Human-inspired Explanations for Vision Transformers and Convolutional Neural Networks",
    "authors": "Mahadev Prasad Panda, Matteo Tiezzi, Martina Vilas, Gemma Roig, Bjoern M. Eskofier, Dario Zanca",
    "abstract": "Explainability in artificial intelligence (XAI) remains a crucial aspect for\nfostering trust and understanding in machine learning models. Current visual\nexplanation techniques, such as gradient-based or class-activation-based\nmethods, often exhibit a strong dependence on specific model architectures.\nConversely, perturbation-based methods, despite being model-agnostic, are\ncomputationally expensive as they require evaluating models on a large number\nof forward passes. In this work, we introduce Foveation-based Explanations\n(FovEx), a novel XAI method inspired by human vision. FovEx seamlessly\nintegrates biologically inspired perturbations by iteratively creating foveated\nrenderings of the image and combines them with gradient-based visual\nexplorations to determine locations of interest efficiently. These locations\nare selected to maximize the performance of the model to be explained with\nrespect to the downstream task and then combined to generate an attribution\nmap. We provide a thorough evaluation with qualitative and quantitative\nassessments on established benchmarks. Our method achieves state-of-the-art\nperformance on both transformers (on 4 out of 5 metrics) and convolutional\nmodels (on 3 out of 5 metrics), demonstrating its versatility among various\narchitectures. Furthermore, we show the alignment between the explanation map\nproduced by FovEx and human gaze patterns (+14\\% in NSS compared to RISE,\n+203\\% in NSS compared to GradCAM). This comparison enhances our confidence in\nFovEx's ability to close the interpretation gap between humans and machines.",
    "arxiv_id": "http://arxiv.org/abs/2408.02123v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02123v1",
    "primary_category": "cs.CV",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Value-Based Rationales Improve Social Experience: A Multiagent Simulation Study",
    "authors": "Sz-Ting Tzeng, Nirav Ajmeri, Munindar P. Singh",
    "abstract": "We propose Exanna, a framework to realize agents that incorporate values in\ndecision making. An Exannaagent considers the values of itself and others when\nproviding rationales for its actions and evaluating the rationales provided by\nothers. Via multiagent simulation, we demonstrate that considering values in\ndecision making and producing rationales, especially for norm-deviating\nactions, leads to (1) higher conflict resolution, (2) better social experience,\n(3) higher privacy, and (4) higher flexibility.",
    "arxiv_id": "http://arxiv.org/abs/2408.02117v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02117v1",
    "primary_category": "cs.MA",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Recent Advances in Multi-Choice Machine Reading Comprehension: A Survey on Methods and Datasets",
    "authors": "Shima Foolad, Kourosh Kiani, Razieh Rastgoo",
    "abstract": "This paper provides a thorough examination of recent developments in the\nfield of multi-choice Machine Reading Comprehension (MRC). Focused on benchmark\ndatasets, methodologies, challenges, and future trajectories, our goal is to\noffer researchers a comprehensive overview of the current landscape in\nmulti-choice MRC. The analysis delves into 30 existing cloze-style and\nmultiple-choice MRC benchmark datasets, employing a refined classification\nmethod based on attributes such as corpus style, domain, complexity, context\nstyle, question style, and answer style. This classification system enhances\nour understanding of each dataset's diverse attributes and categorizes them\nbased on their complexity. Furthermore, the paper categorizes recent\nmethodologies into Fine-tuned and Prompt-tuned methods. Fine-tuned methods\ninvolve adapting pre-trained language models (PLMs) to a specific task through\nretraining on domain-specific datasets, while prompt-tuned methods use prompts\nto guide PLM response generation, presenting potential applications in\nzero-shot or few-shot learning scenarios. By contributing to ongoing\ndiscussions, inspiring future research directions, and fostering innovations,\nthis paper aims to propel multi-choice MRC towards new frontiers of\nachievement.",
    "arxiv_id": "http://arxiv.org/abs/2408.02114v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02114v1",
    "primary_category": "cs.CL",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Understanding Deep Learning via Notions of Rank",
    "authors": "Noam Razin",
    "abstract": "Despite the extreme popularity of deep learning in science and industry, its\nformal understanding is limited. This thesis puts forth notions of rank as key\nfor developing a theory of deep learning, focusing on the fundamental aspects\nof generalization and expressiveness. In particular, we establish that\ngradient-based training can induce an implicit regularization towards low rank\nfor several neural network architectures, and demonstrate empirically that this\nphenomenon may facilitate an explanation of generalization over natural data\n(e.g., audio, images, and text). Then, we characterize the ability of graph\nneural networks to model interactions via a notion of rank, which is commonly\nused for quantifying entanglement in quantum physics. A central tool underlying\nthese results is a connection between neural networks and tensor\nfactorizations. Practical implications of our theory for designing explicit\nregularization schemes and data preprocessing algorithms are presented.",
    "arxiv_id": "http://arxiv.org/abs/2408.02111v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02111v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "A Multi-class Ride-hailing Service Subsidy System Utilizing Deep Causal Networks",
    "authors": "Zhe Yu, Chi Xia, Shaosheng Cao, Lin Zhou",
    "abstract": "In the ride-hailing industry, subsidies are predominantly employed to\nincentivize consumers to place more orders, thereby fostering market growth.\nCausal inference techniques are employed to estimate the consumer elasticity\nwith different subsidy levels. However, the presence of confounding effects\nposes challenges in achieving an unbiased estimate of the uplift effect. We\nintroduce a consumer subsidizing system to capture relationships between\nsubsidy propensity and the treatment effect, which proves effective while\nmaintaining a lightweight online environment.",
    "arxiv_id": "http://arxiv.org/abs/2408.02065v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02065v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "MedSyn: LLM-based Synthetic Medical Text Generation Framework",
    "authors": "Gleb Kumichev, Pavel Blinov, Yulia Kuzkina, Vasily Goncharov, Galina Zubkova, Nikolai Zenovkin, Aleksei Goncharov, Andrey Savchenko",
    "abstract": "Generating synthetic text addresses the challenge of data availability in\nprivacy-sensitive domains such as healthcare. This study explores the\napplicability of synthetic data in real-world medical settings. We introduce\nMedSyn, a novel medical text generation framework that integrates large\nlanguage models with a Medical Knowledge Graph (MKG). We use MKG to sample\nprior medical information for the prompt and generate synthetic clinical notes\nwith GPT-4 and fine-tuned LLaMA models. We assess the benefit of synthetic data\nthrough application in the ICD code prediction task. Our research indicates\nthat synthetic data can increase the classification accuracy of vital and\nchallenging codes by up to 17.8% compared to settings without synthetic data.\nFurthermore, to provide new data for further research in the healthcare domain,\nwe present the largest open-source synthetic dataset of clinical notes for the\nRussian language, comprising over 41k samples covering 219 ICD-10 codes.",
    "arxiv_id": "http://arxiv.org/abs/2408.02056v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02056v1",
    "primary_category": "cs.CL",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "DeepNetBeam: A Framework for the Analysis of Functionally Graded Porous Beams",
    "authors": "Mohammad Sadegh Eshaghi, Mostafa Bamdad, Cosmin Anitescu, Yizheng Wang, Xiaoying Zhuang, Timon Rabczuk",
    "abstract": "This study investigates different Scientific Machine Learning (SciML)\napproaches for the analysis of functionally graded (FG) porous beams and\ncompares them under a new framework. The beam material properties are assumed\nto vary as an arbitrary continuous function. The methods consider the output of\na neural network/operator as an approximation to the displacement fields and\nderive the equations governing beam behavior based on the continuum\nformulation. The methods are implemented in the framework and formulated by\nthree approaches: (a) the vector approach leads to a Physics-Informed Neural\nNetwork (PINN), (b) the energy approach brings about the Deep Energy Method\n(DEM), and (c) the data-driven approach, which results in a class of Neural\nOperator methods. Finally, a neural operator has been trained to predict the\nresponse of the porous beam with functionally graded material under any\nporosity distribution pattern and any arbitrary traction condition. The results\nare validated with analytical and numerical reference solutions. The data and\ncode accompanying this manuscript will be publicly available at\nhttps://github.com/eshaghi-ms/DeepNetBeam.",
    "arxiv_id": "http://arxiv.org/abs/2408.02698v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02698v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "EOL: Transductive Few-Shot Open-Set Recognition by Enhancing Outlier Logits",
    "authors": "Mateusz Ochal, Massimiliano Patacchiola, Malik Boudiaf, Sen Wang",
    "abstract": "In Few-Shot Learning (FSL), models are trained to recognise unseen objects\nfrom a query set, given a few labelled examples from a support set. In standard\nFSL, models are evaluated on query instances sampled from the same class\ndistribution of the support set. In this work, we explore the more nuanced and\npractical challenge of Open-Set Few-Shot Recognition (OSFSL). Unlike standard\nFSL, OSFSL incorporates unknown classes into the query set, thereby requiring\nthe model not only to classify known classes but also to identify outliers.\nBuilding on the groundwork laid by previous studies, we define a novel\ntransductive inference technique that leverages the InfoMax principle to\nexploit the unlabelled query set. We called our approach the Enhanced Outlier\nLogit (EOL) method. EOL refines class prototype representations through model\ncalibration, effectively balancing the inlier-outlier ratio. This calibration\nenhances pseudo-label accuracy for the query set and improves the optimisation\nobjective within the transductive inference process. We provide a comprehensive\nempirical evaluation demonstrating that EOL consistently surpasses traditional\nmethods, recording performance improvements ranging from approximately $+1.3%$\nto $+6.3%$ across a variety of classification and outlier detection metrics and\nbenchmarks, even in the presence of inlier-outlier imbalance.",
    "arxiv_id": "http://arxiv.org/abs/2408.02052v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02052v1",
    "primary_category": "cs.CV",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Recovering the state and dynamics of autonomous system with partial states solution using neural networks",
    "authors": "Vijay Kag",
    "abstract": "In this paper we explore the performance of deep hidden physics model (M.\nRaissi 2018) for autonomous system, this systems do not explicitly depend on\ntime. The dynamics of states are dependent on states itself. Such systems can\nbe found in nature and have applications\n  in modeling chemical concentrations, population dynamics, n-body problems in\nphysics etc. In this work we are going to see how we can obtain dynamics of\nstates based on solution of limited partial states. The proposed method can\nfind the state and dynamics of which the data is provided in the training,\nalthough we do not claim to accurately find the solution of states whose data\nis not utilized while training.",
    "arxiv_id": "http://arxiv.org/abs/2408.02050v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02050v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "DNA-SE: Towards Deep Neural-Nets Assisted Semiparametric Estimation",
    "authors": "Qinshuo Liu, Zixin Wang, Xi-An Li, Xinyao Ji, Lei Zhang, Lin Liu, Zhonghua Liu",
    "abstract": "Semiparametric statistics play a pivotal role in a wide range of domains,\nincluding but not limited to missing data, causal inference, and transfer\nlearning, to name a few. In many settings, semiparametric theory leads to\n(nearly) statistically optimal procedures that yet involve numerically solving\nFredholm integral equations of the second kind. Traditional numerical methods,\nsuch as polynomial or spline approximations, are difficult to scale to\nmulti-dimensional problems. Alternatively, statisticians may choose to\napproximate the original integral equations by ones with closed-form solutions,\nresulting in computationally more efficient, but statistically suboptimal or\neven incorrect procedures. To bridge this gap, we propose a novel framework by\nformulating the semiparametric estimation problem as a bi-level optimization\nproblem; and then we develop a scalable algorithm called Deep Neural-Nets\nAssisted Semiparametric Estimation (DNA-SE) by leveraging the universal\napproximation property of Deep Neural-Nets (DNN) to streamline semiparametric\nprocedures. Through extensive numerical experiments and a real data analysis,\nwe demonstrate the numerical and statistical advantages of $\\dnase$ over\ntraditional methods. To the best of our knowledge, we are the first to bring\nDNN into semiparametric statistics as a numerical solver of integral equations\nin our proposed general framework.",
    "arxiv_id": "http://arxiv.org/abs/2408.02045v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02045v1",
    "primary_category": "stat.ML",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Enhancing Human Action Recognition and Violence Detection Through Deep Learning Audiovisual Fusion",
    "authors": "Pooya Janani, Amirabolfazl Suratgar, Afshin Taghvaeipour",
    "abstract": "This paper proposes a hybrid fusion-based deep learning approach based on two\ndifferent modalities, audio and video, to improve human activity recognition\nand violence detection in public places. To take advantage of audiovisual\nfusion, late fusion, intermediate fusion, and hybrid fusion-based deep learning\n(HFBDL) are used and compared. Since the objective is to detect and recognize\nhuman violence in public places, Real-life violence situation (RLVS) dataset is\nexpanded and used. Simulating results of HFBDL show 96.67\\% accuracy on\nvalidation data, which is more accurate than the other state-of-the-art methods\non this dataset. To showcase our model's ability in real-world scenarios,\nanother dataset of 54 sounded videos of both violent and non-violent situations\nwas recorded. The model could successfully detect 52 out of 54 videos\ncorrectly. The proposed method shows a promising performance on real scenarios.\nThus, it can be used for human action recognition and violence detection in\npublic places for security purposes.",
    "arxiv_id": "http://arxiv.org/abs/2408.02033v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02033v1",
    "primary_category": "cs.CV",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Scenario-based Thermal Management Parametrization Through Deep Reinforcement Learning",
    "authors": "Thomas Rudolf, Philip Muhl, S\u00f6ren Hohmann, Lutz Eckstein",
    "abstract": "The thermal system of battery electric vehicles demands advanced control. Its\nthermal management needs to effectively control active components across\nvarying operating conditions. While robust control function parametrization is\nrequired, current methodologies show significant drawbacks. They consume\nconsiderable time, human effort, and extensive real-world testing.\nConsequently, there is a need for innovative and intelligent solutions that are\ncapable of autonomously parametrizing embedded controllers. Addressing this\nissue, our paper introduces a learning-based tuning approach. We propose a\nmethodology that benefits from automated scenario generation for increased\nrobustness across vehicle usage scenarios. Our deep reinforcement learning\nagent processes the tuning task context and incorporates an image-based\ninterpretation of embedded parameter sets. We demonstrate its applicability to\na valve controller parametrization task and verify it in real-world vehicle\ntesting. The results highlight the competitive performance to baseline methods.\nThis novel approach contributes to the shift towards virtual development of\nthermal management functions, with promising potential of large-scale parameter\ntuning in the automotive industry.",
    "arxiv_id": "http://arxiv.org/abs/2408.02022v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02022v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Personalized Federated Learning on Heterogeneous and Long-Tailed Data via Expert Collaborative Learning",
    "authors": "Fengling Lv, Xinyi Shang, Yang Zhou, Yiqun Zhang, Mengke Li, Yang Lu",
    "abstract": "Personalized Federated Learning (PFL) aims to acquire customized models for\neach client without disclosing raw data by leveraging the collective knowledge\nof distributed clients. However, the data collected in real-world scenarios is\nlikely to follow a long-tailed distribution. For example, in the medical\ndomain, it is more common for the number of general health notes to be much\nlarger than those specifically relatedto certain diseases. The presence of\nlong-tailed data can significantly degrade the performance of PFL models.\nAdditionally, due to the diverse environments in which each client operates,\ndata heterogeneity is also a classic challenge in federated learning. In this\npaper, we explore the joint problem of global long-tailed distribution and data\nheterogeneity in PFL and propose a method called Expert Collaborative Learning\n(ECL) to tackle this problem. Specifically, each client has multiple experts,\nand each expert has a different training subset, which ensures that each class,\nespecially the minority classes, receives sufficient training. Multiple experts\ncollaborate synergistically to produce the final prediction output. Without\nspecial bells and whistles, the vanilla ECL outperforms other state-of-the-art\nPFL methods on several benchmark datasets under different degrees of data\nheterogeneity and long-tailed distribution.",
    "arxiv_id": "http://arxiv.org/abs/2408.02019v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02019v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Why Rectified Power Unit Networks Fail and How to Improve It: An Effective Theory Perspective",
    "authors": "Taeyoung Kim, Myungjoo Kang",
    "abstract": "The Rectified Power Unit (RePU) activation functions, unlike the Rectified\nLinear Unit (ReLU), have the advantage of being a differentiable function when\nconstructing neural networks. However, it can be experimentally observed when\ndeep layers are stacked, neural networks constructed with RePU encounter\ncritical issues. These issues include the values exploding or vanishing and\nfailure of training. And these happen regardless of the hyperparameter\ninitialization. From the perspective of effective theory, we aim to identify\nthe causes of this phenomenon and propose a new activation function that\nretains the advantages of RePU while overcoming its drawbacks.",
    "arxiv_id": "http://arxiv.org/abs/2408.02697v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02697v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Unsupervised Representation Learning by Balanced Self Attention Matching",
    "authors": "Daniel Shalam, Simon Korman",
    "abstract": "Many leading self-supervised methods for unsupervised representation\nlearning, in particular those for embedding image features, are built on\nvariants of the instance discrimination task, whose optimization is known to be\nprone to instabilities that can lead to feature collapse. Different techniques\nhave been devised to circumvent this issue, including the use of negative pairs\nwith different contrastive losses, the use of external memory banks, and\nbreaking of symmetry by using separate encoding networks with possibly\ndifferent structures. Our method, termed BAM, rather than directly matching\nfeatures of different views (augmentations) of input images, is based on\nmatching their self-attention vectors, which are the distributions of\nsimilarities to the entire set of augmented images of a batch. We obtain rich\nrepresentations and avoid feature collapse by minimizing a loss that matches\nthese distributions to their globally balanced and entropy regularized version,\nwhich is obtained through a simple self-optimal-transport computation. We\nablate and verify our method through a wide set of experiments that show\ncompetitive performance with leading methods on both semi-supervised and\ntransfer-learning benchmarks. Our implementation and pre-trained models are\navailable at github.com/DanielShalam/BAM .",
    "arxiv_id": "http://arxiv.org/abs/2408.02014v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02014v1",
    "primary_category": "cs.CV",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Towards Automatic Hands-on-Keyboard Attack Detection Using LLMs in EDR Solutions",
    "authors": "Amit Portnoy, Ehud Azikri, Shay Kels",
    "abstract": "Endpoint Detection and Remediation (EDR) platforms are essential for\nidentifying and responding to cyber threats. This study presents a novel\napproach using Large Language Models (LLMs) to detect Hands-on-Keyboard (HOK)\ncyberattacks. Our method involves converting endpoint activity data into\nnarrative forms that LLMs can analyze to distinguish between normal operations\nand potential HOK attacks. We address the challenges of interpreting endpoint\ndata by segmenting narratives into windows and employing a dual training\nstrategy. The results demonstrate that LLM-based models have the potential to\noutperform traditional machine learning methods, offering a promising direction\nfor enhancing EDR capabilities and apply LLMs in cybersecurity.",
    "arxiv_id": "http://arxiv.org/abs/2408.01993v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01993v1",
    "primary_category": "cs.CR",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "MetaWearS: A Shortcut in Wearable Systems Lifecycle with Only a Few Shots",
    "authors": "Alireza Amirshahi, Maedeh H. Toosi, Siamak Mohammadi, Stefano Albini, Pasquale Davide Schiavone, Giovanni Ansaloni, Amir Aminifar, David Atienza",
    "abstract": "Wearable systems provide continuous health monitoring and can lead to early\ndetection of potential health issues. However, the lifecycle of wearable\nsystems faces several challenges. First, effective model training for new\nwearable devices requires substantial labeled data from various subjects\ncollected directly by the wearable. Second, subsequent model updates require\nfurther extensive labeled data for retraining. Finally, frequent model updating\non the wearable device can decrease the battery life in long-term data\nmonitoring. Addressing these challenges, in this paper, we propose MetaWearS, a\nmeta-learning method to reduce the amount of initial data collection required.\nMoreover, our approach incorporates a prototypical updating mechanism,\nsimplifying the update process by modifying the class prototype rather than\nretraining the entire model. We explore the performance of MetaWearS in two\ncase studies, namely, the detection of epileptic seizures and the detection of\natrial fibrillation. We show that by fine-tuning with just a few samples, we\nachieve 70% and 82% AUC for the detection of epileptic seizures and the\ndetection of atrial fibrillation, respectively. Compared to a conventional\napproach, our proposed method performs better with up to 45% AUC. Furthermore,\nupdating the model with only 16 minutes of additional labeled data increases\nthe AUC by up to 5.3%. Finally, MetaWearS reduces the energy consumption for\nmodel updates by 456x and 418x for epileptic seizure and AF detection,\nrespectively.",
    "arxiv_id": "http://arxiv.org/abs/2408.01988v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01988v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Multiview learning with twin parametric margin SVM",
    "authors": "A. Quadir, M. Tanveer",
    "abstract": "Multiview learning (MVL) seeks to leverage the benefits of diverse\nperspectives to complement each other, effectively extracting and utilizing the\nlatent information within the dataset. Several twin support vector\nmachine-based MVL (MvTSVM) models have been introduced and demonstrated\noutstanding performance in various learning tasks. However, MvTSVM-based models\nface significant challenges in the form of computational complexity due to four\nmatrix inversions, the need to reformulate optimization problems in order to\nemploy kernel-generated surfaces for handling non-linear cases, and the\nconstraint of uniform noise assumption in the training data. Particularly in\ncases where the data possesses a heteroscedastic error structure, these\nchallenges become even more pronounced. In view of the aforementioned\nchallenges, we propose multiview twin parametric margin support vector machine\n(MvTPMSVM). MvTPMSVM constructs parametric hyperplanes with the goal of\nmaximizing the parametric margin between two classes, aiming to regulate and\nmanage the impact of the heteroscedastic noise structure existing within the\ndata. The proposed MvTPMSVM model avoids the explicit computation of matrix\ninversions in the dual formulation, leading to enhanced computational\nefficiency. We perform an extensive assessment of the MvTPMSVM model using\nbenchmark datasets such as UCI, KEEL, synthetic, and Animals with Attributes\n(AwA). Our experimental results, coupled with rigorous statistical analyses,\nconfirm the superior generalization capabilities of the proposed MvTPMSVM model\ncompared to the baseline models. The source code of the proposed MvTPMSVM model\nis available at \\url{https://github.com/mtanveer1/MvTPMSVM}.",
    "arxiv_id": "http://arxiv.org/abs/2408.01981v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01981v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Shaping Rewards, Shaping Routes: On Multi-Agent Deep Q-Networks for Routing in Satellite Constellation Networks",
    "authors": "Manuel M. H. Roth, Anupama Hegde, Thomas Delamotte, Andreas Knopp",
    "abstract": "Effective routing in satellite mega-constellations has become crucial to\nfacilitate the handling of increasing traffic loads, more complex network\narchitectures, as well as the integration into 6G networks. To enhance\nadaptability as well as robustness to unpredictable traffic demands, and to\nsolve dynamic routing environments efficiently, machine learning-based\nsolutions are being considered. For network control problems, such as\noptimizing packet forwarding decisions according to Quality of Service\nrequirements and maintaining network stability, deep reinforcement learning\ntechniques have demonstrated promising results. For this reason, we investigate\nthe viability of multi-agent deep Q-networks for routing in satellite\nconstellation networks. We focus specifically on reward shaping and quantifying\ntraining convergence for joint optimization of latency and load balancing in\nstatic and dynamic scenarios. To address identified drawbacks, we propose a\nnovel hybrid solution based on centralized learning and decentralized control.",
    "arxiv_id": "http://arxiv.org/abs/2408.01979v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01979v1",
    "primary_category": "cs.NI",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "RVI-SAC: Average Reward Off-Policy Deep Reinforcement Learning",
    "authors": "Yukinari Hisaki, Isao Ono",
    "abstract": "In this paper, we propose an off-policy deep reinforcement learning (DRL)\nmethod utilizing the average reward criterion. While most existing DRL methods\nemploy the discounted reward criterion, this can potentially lead to a\ndiscrepancy between the training objective and performance metrics in\ncontinuing tasks, making the average reward criterion a recommended\nalternative. We introduce RVI-SAC, an extension of the state-of-the-art\noff-policy DRL method, Soft Actor-Critic (SAC), to the average reward\ncriterion. Our proposal consists of (1) Critic updates based on RVI Q-learning,\n(2) Actor updates introduced by the average reward soft policy improvement\ntheorem, and (3) automatic adjustment of Reset Cost enabling the average reward\nreinforcement learning to be applied to tasks with termination. We apply our\nmethod to the Gymnasium's Mujoco tasks, a subset of locomotion tasks, and\ndemonstrate that RVI-SAC shows competitive performance compared to existing\nmethods.",
    "arxiv_id": "http://arxiv.org/abs/2408.01972v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01972v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "A multi-task deep learning approach for lane-level pavement performance prediction with segment-level data",
    "authors": "Bo Wang, Wenbo Zhang, Yunpeng LI",
    "abstract": "The elaborate pavement performance prediction is an important premise of\nimplementing preventive maintenance. Our survey reveals that in practice, the\npavement performance is usually measured at segment-level, where an unique\nperformance value is obtained for all lanes within one segment of 1km length.\nIt still lacks more elaborate performance analysis at lane-level due to costly\ndata collection and difficulty in prediction modeling. Therefore, this study\ndeveloped a multi-task deep learning approach to predict the lane-level\npavement performance with a large amount of historical segment-level\nperformance measurement data. The unified prediction framework can effectively\naddress inherent correlation and differences across lanes. In specific, the\nprediction framework firstly employed an Long Short-Term Memory (LSTM) layer to\ncapture the segment-level pavement deterioration pattern. Then multiple\ntask-specific LSTM layers were designed based on number of lanes to capture\nlane-level differences in pavement performance. Finally, we concatenated\nmultiple task-specific LSTM outputs with auxiliary features for further\ntraining and obtained the lane-level predictions after fully connected layer.\nThe aforementioned prediction framework was validated with a real case in\nChina. It revealed a better model performance regardless of one-way 2-lane,\n3-lane, and 4-lane scenarios, all lower than 10% in terms of mean absolute\npercentage error. The proposed prediction framework also outperforms other\nensemble learning and shallow machine learning methods in almost every lane.",
    "arxiv_id": "http://arxiv.org/abs/2408.01967v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01967v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Top K Enhanced Reinforcement Learning Attacks on Heterogeneous Graph Node Classification",
    "authors": "Honglin Gao, Gaoxi Xiao",
    "abstract": "Graph Neural Networks (GNNs) have attracted substantial interest due to their\nexceptional performance on graph-based data. However, their robustness,\nespecially on heterogeneous graphs, remains underexplored, particularly against\nadversarial attacks. This paper proposes HeteroKRLAttack, a targeted evasion\nblack-box attack method for heterogeneous graphs. By integrating reinforcement\nlearning with a Top-K algorithm to reduce the action space, our method\nefficiently identifies effective attack strategies to disrupt node\nclassification tasks. We validate the effectiveness of HeteroKRLAttack through\nexperiments on multiple heterogeneous graph datasets, showing significant\nreductions in classification accuracy compared to baseline methods. An ablation\nstudy underscores the critical role of the Top-K algorithm in enhancing attack\nperformance. Our findings highlight potential vulnerabilities in current models\nand provide guidance for future defense strategies against adversarial attacks\non heterogeneous graphs.",
    "arxiv_id": "http://arxiv.org/abs/2408.01964v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01964v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Representation Bias of Adolescents in AI: A Bilingual, Bicultural Study",
    "authors": "Robert Wolfe, Aayushi Dangol, Bill Howe, Alexis Hiniker",
    "abstract": "Popular and news media often portray teenagers with sensationalism, as both a\nrisk to society and at risk from society. As AI begins to absorb some of the\nepistemic functions of traditional media, we study how teenagers in two\ncountries speaking two languages: 1) are depicted by AI, and 2) how they would\nprefer to be depicted. Specifically, we study the biases about teenagers\nlearned by static word embeddings (SWEs) and generative language models (GLMs),\ncomparing these with the perspectives of adolescents living in the U.S. and\nNepal. We find English-language SWEs associate teenagers with societal\nproblems, and more than 50% of the 1,000 words most associated with teenagers\nin the pretrained GloVe SWE reflect such problems. Given prompts about\nteenagers, 30% of outputs from GPT2-XL and 29% from LLaMA-2-7B GLMs discuss\nsocietal problems, most commonly violence, but also drug use, mental illness,\nand sexual taboo. Nepali models, while not free of such associations, are less\ndominated by social problems. Data from workshops with N=13 U.S. adolescents\nand N=18 Nepalese adolescents show that AI presentations are disconnected from\nteenage life, which revolves around activities like school and friendship.\nParticipant ratings of how well 20 trait words describe teens are decorrelated\nfrom SWE associations, with Pearson's r=.02, n.s. in English FastText and\nr=.06, n.s. in GloVe; and r=.06, n.s. in Nepali FastText and r=-.23, n.s. in\nGloVe. U.S. participants suggested AI could fairly present teens by\nhighlighting diversity, while Nepalese participants centered positivity.\nParticipants were optimistic that, if it learned from adolescents, rather than\nmedia sources, AI could help mitigate stereotypes. Our work offers an\nunderstanding of the ways SWEs and GLMs misrepresent a developmentally\nvulnerable group and provides a template for less sensationalized\ncharacterization.",
    "arxiv_id": "http://arxiv.org/abs/2408.01961v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01961v1",
    "primary_category": "cs.CY",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Dataset Scale and Societal Consistency Mediate Facial Impression Bias in Vision-Language AI",
    "authors": "Robert Wolfe, Aayushi Dangol, Alexis Hiniker, Bill Howe",
    "abstract": "Multimodal AI models capable of associating images and text hold promise for\nnumerous domains, ranging from automated image captioning to accessibility\napplications for blind and low-vision users. However, uncertainty about bias\nhas in some cases limited their adoption and availability. In the present work,\nwe study 43 CLIP vision-language models to determine whether they learn\nhuman-like facial impression biases, and we find evidence that such biases are\nreflected across three distinct CLIP model families. We show for the first time\nthat the the degree to which a bias is shared across a society predicts the\ndegree to which it is reflected in a CLIP model. Human-like impressions of\nvisually unobservable attributes, like trustworthiness and sexuality, emerge\nonly in models trained on the largest dataset, indicating that a better fit to\nuncurated cultural data results in the reproduction of increasingly subtle\nsocial biases. Moreover, we use a hierarchical clustering approach to show that\ndataset size predicts the extent to which the underlying structure of facial\nimpression bias resembles that of facial impression bias in humans. Finally, we\nshow that Stable Diffusion models employing CLIP as a text encoder learn facial\nimpression biases, and that these biases intersect with racial biases in Stable\nDiffusion XL-Turbo. While pretrained CLIP models may prove useful for\nscientific studies of bias, they will also require significant dataset curation\nwhen intended for use as general-purpose models in a zero-shot setting.",
    "arxiv_id": "http://arxiv.org/abs/2408.01959v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01959v1",
    "primary_category": "cs.CV",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "EqvAfford: SE(3) Equivariance for Point-Level Affordance Learning",
    "authors": "Yue Chen, Chenrui Tie, Ruihai Wu, Hao Dong",
    "abstract": "Humans perceive and interact with the world with the awareness of\nequivariance, facilitating us in manipulating different objects in diverse\nposes. For robotic manipulation, such equivariance also exists in many\nscenarios. For example, no matter what the pose of a drawer is (translation,\nrotation and tilt), the manipulation strategy is consistent (grasp the handle\nand pull in a line). While traditional models usually do not have the awareness\nof equivariance for robotic manipulation, which might result in more data for\ntraining and poor performance in novel object poses, we propose our EqvAfford\nframework, with novel designs to guarantee the equivariance in point-level\naffordance learning for downstream robotic manipulation, with great performance\nand generalization ability on representative tasks on objects in diverse poses.",
    "arxiv_id": "http://arxiv.org/abs/2408.01953v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01953v1",
    "primary_category": "cs.RO",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Distribution-Level Memory Recall for Continual Learning: Preserving Knowledge and Avoiding Confusion",
    "authors": "Shaoxu Cheng, Kanglei Geng, Chiyuan He, Zihuan Qiu, Linfeng Xu, Heqian Qiu, Lanxiao Wang, Qingbo Wu, Fanman Meng, Hongliang Li",
    "abstract": "Continual Learning (CL) aims to enable Deep Neural Networks (DNNs) to learn\nnew data without forgetting previously learned knowledge. The key to achieving\nthis goal is to avoid confusion at the feature level, i.e., avoiding confusion\nwithin old tasks and between new and old tasks. Previous prototype-based CL\nmethods generate pseudo features for old knowledge replay by adding Gaussian\nnoise to the centroids of old classes. However, the distribution in the feature\nspace exhibits anisotropy during the incremental process, which prevents the\npseudo features from faithfully reproducing the distribution of old knowledge\nin the feature space, leading to confusion in classification boundaries within\nold tasks. To address this issue, we propose the Distribution-Level Memory\nRecall (DMR) method, which uses a Gaussian mixture model to precisely fit the\nfeature distribution of old knowledge at the distribution level and generate\npseudo features in the next stage. Furthermore, resistance to confusion at the\ndistribution level is also crucial for multimodal learning, as the problem of\nmultimodal imbalance results in significant differences in feature responses\nbetween different modalities, exacerbating confusion within old tasks in\nprototype-based CL methods. Therefore, we mitigate the multi-modal imbalance\nproblem by using the Inter-modal Guidance and Intra-modal Mining (IGIM) method\nto guide weaker modalities with prior information from dominant modalities and\nfurther explore useful information within modalities. For the second key, We\npropose the Confusion Index to quantitatively describe a model's ability to\ndistinguish between new and old tasks, and we use the Incremental Mixup Feature\nEnhancement (IMFE) method to enhance pseudo features with new sample features,\nalleviating classification confusion between new and old knowledge.",
    "arxiv_id": "http://arxiv.org/abs/2408.02695v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02695v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Efficient Decision Trees for Tensor Regressions",
    "authors": "Hengrui Luo, Akira Horiguchi, Li Ma",
    "abstract": "We proposed the tensor-input tree (TT) method for scalar-on-tensor and\ntensor-on-tensor regression problems. We first address scalar-on-tensor problem\nby proposing scalar-output regression tree models whose input variable are\ntensors (i.e., multi-way arrays). We devised and implemented fast randomized\nand deterministic algorithms for efficient fitting of scalar-on-tensor trees,\nmaking TT competitive against tensor-input GP models. Based on scalar-on-tensor\ntree models, we extend our method to tensor-on-tensor problems using additive\ntree ensemble approaches. Theoretical justification and extensive experiments\non real and synthetic datasets are provided to illustrate the performance of\nTT.",
    "arxiv_id": "http://arxiv.org/abs/2408.01926v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01926v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Self-Supervised Pretrained Models and Latent Feature Distribution Optimization",
    "authors": "Qiuyu Zhu, Liheng Hu, Sijin Wang",
    "abstract": "In the face of complex natural images, existing deep clustering algorithms\nfall significantly short in terms of clustering accuracy when compared to\nsupervised classification methods, making them less practical. This paper\nintroduces an image clustering algorithm based on self-supervised pretrained\nmodels and latent feature distribution optimization, substantially enhancing\nclustering performance. It is found that: (1) For complex natural images, we\neffectively enhance the discriminative power of latent features by leveraging\nself-supervised pretrained models and their fine-tuning, resulting in improved\nclustering performance. (2) In the latent feature space, by searching for\nk-nearest neighbor images for each training sample and shortening the distance\nbetween the training sample and its nearest neighbor, the discriminative power\nof latent features can be further enhanced, and clustering performance can be\nimproved. (3) In the latent feature space, reducing the distance between sample\nfeatures and the nearest predefined cluster centroids can optimize the\ndistribution of latent features, therefore further improving clustering\nperformance. Through experiments on multiple datasets, our approach outperforms\nthe latest clustering algorithms and achieves state-of-the-art clustering\nresults. When the number of categories in the datasets is small, such as\nCIFAR-10 and STL-10, and there are significant differences between categories,\nour clustering algorithm has similar accuracy to supervised methods without\nusing pretrained models, slightly lower than supervised methods using\npre-trained models. The code linked algorithm is\nhttps://github.com/LihengHu/ICBPL.",
    "arxiv_id": "http://arxiv.org/abs/2408.01920v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01920v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "KAN based Autoencoders for Factor Models",
    "authors": "Tianqi Wang, Shubham Singh",
    "abstract": "Inspired by recent advances in Kolmogorov-Arnold Networks (KANs), we\nintroduce a novel approach to latent factor conditional asset pricing models.\nWhile previous machine learning applications in asset pricing have\npredominantly used Multilayer Perceptrons with ReLU activation functions to\nmodel latent factor exposures, our method introduces a KAN-based autoencoder\nwhich surpasses MLP models in both accuracy and interpretability. Our model\noffers enhanced flexibility in approximating exposures as nonlinear functions\nof asset characteristics, while simultaneously providing users with an\nintuitive framework for interpreting latent factors. Empirical backtesting\ndemonstrates our model's superior ability to explain cross-sectional risk\nexposures. Moreover, long-short portfolios constructed using our model's\npredictions achieve higher Sharpe ratios, highlighting its practical value in\ninvestment management.",
    "arxiv_id": "http://arxiv.org/abs/2408.02694v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02694v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Re-ENACT: Reinforcement Learning for Emotional Speech Generation using Actor-Critic Strategy",
    "authors": "Ravi Shankar, Archana Venkataraman",
    "abstract": "In this paper, we propose the first method to modify the prosodic features of\na given speech signal using actor-critic reinforcement learning strategy. Our\napproach uses a Bayesian framework to identify contiguous segments of\nimportance that links segments of the given utterances to perception of\nemotions in humans. We train a neural network to produce the variational\nposterior of a collection of Bernoulli random variables; our model applies a\nMarkov prior on it to ensure continuity. A sample from this distribution is\nused for downstream emotion prediction. Further, we train the neural network to\npredict a soft assignment over emotion categories as the target variable. In\nthe next step, we modify the prosodic features (pitch, intensity, and rhythm)\nof the masked segment to increase the score of target emotion. We employ an\nactor-critic reinforcement learning to train the prosody modifier by\ndiscretizing the space of modifications. Further, it provides a simple solution\nto the problem of gradient computation through WSOLA operation for rhythm\nmanipulation. Our experiments demonstrate that this framework changes the\nperceived emotion of a given speech utterance to the target. Further, we show\nthat our unified technique is on par with state-of-the-art emotion conversion\nmodels from supervised and unsupervised domains that require pairwise training.",
    "arxiv_id": "http://arxiv.org/abs/2408.01892v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01892v1",
    "primary_category": "eess.AS",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Walk Wisely on Graph: Knowledge Graph Reasoning with Dual Agents via Efficient Guidance-Exploration",
    "authors": "Zijian Wang, Bin Wang, Haifeng Jing, Huayu Li, Hongbo Dou",
    "abstract": "Recent years, multi-hop reasoning has been widely studied for knowledge graph\n(KG) reasoning due to its efficacy and interpretability. However, previous\nmulti-hop reasoning approaches are subject to two primary shortcomings. First,\nagents struggle to learn effective and robust policies at the early phase due\nto sparse rewards. Second, these approaches often falter on specific datasets\nlike sparse knowledge graphs, where agents are required to traverse lengthy\nreasoning paths. To address these problems, we propose a multi-hop reasoning\nmodel with dual agents based on hierarchical reinforcement learning (HRL),\nwhich is named FULORA. FULORA tackles the above reasoning challenges by\neFficient GUidance-ExpLORAtion between dual agents. The high-level agent walks\non the simplified knowledge graph to provide stage-wise hints for the low-level\nagent walking on the original knowledge graph. In this framework, the low-level\nagent optimizes a value function that balances two objectives: (1) maximizing\nreturn, and (2) integrating efficient guidance from the high-level agent.\nExperiments conducted on three real-word knowledge graph datasets demonstrate\nthat FULORA outperforms RL-based baselines, especially in the case of\nlong-distance reasoning.",
    "arxiv_id": "http://arxiv.org/abs/2408.01880v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01880v1",
    "primary_category": "cs.AI",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Safe Semi-Supervised Contrastive Learning Using In-Distribution Data as Positive Examples",
    "authors": "Min Gu Kwak, Hyungu Kahng, Seoung Bum Kim",
    "abstract": "Semi-supervised learning methods have shown promising results in solving many\npractical problems when only a few labels are available. The existing methods\nassume that the class distributions of labeled and unlabeled data are equal;\nhowever, their performances are significantly degraded in class distribution\nmismatch scenarios where out-of-distribution (OOD) data exist in the unlabeled\ndata. Previous safe semi-supervised learning studies have addressed this\nproblem by making OOD data less likely to affect training based on labeled\ndata. However, even if the studies effectively filter out the unnecessary OOD\ndata, they can lose the basic information that all data share regardless of\nclass. To this end, we propose to apply a self-supervised contrastive learning\napproach to fully exploit a large amount of unlabeled data. We also propose a\ncontrastive loss function with coefficient schedule to aggregate as an anchor\nthe labeled negative examples of the same class into positive examples. To\nevaluate the performance of the proposed method, we conduct experiments on\nimage classification datasets - CIFAR-10, CIFAR-100, Tiny ImageNet, and\nCIFAR-100+Tiny ImageNet - under various mismatch ratios. The results show that\nself-supervised contrastive learning significantly improves classification\naccuracy. Moreover, aggregating the in-distribution examples produces better\nrepresentation and consequently further improves classification accuracy.",
    "arxiv_id": "http://arxiv.org/abs/2408.01872v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01872v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "MALADE: Orchestration of LLM-powered Agents with Retrieval Augmented Generation for Pharmacovigilance",
    "authors": "Jihye Choi, Nils Palumbo, Prasad Chalasani, Matthew M. Engelhard, Somesh Jha, Anivarya Kumar, David Page",
    "abstract": "In the era of Large Language Models (LLMs), given their remarkable text\nunderstanding and generation abilities, there is an unprecedented opportunity\nto develop new, LLM-based methods for trustworthy medical knowledge synthesis,\nextraction and summarization. This paper focuses on the problem of\nPharmacovigilance (PhV), where the significance and challenges lie in\nidentifying Adverse Drug Events (ADEs) from diverse text sources, such as\nmedical literature, clinical notes, and drug labels. Unfortunately, this task\nis hindered by factors including variations in the terminologies of drugs and\noutcomes, and ADE descriptions often being buried in large amounts of narrative\ntext. We present MALADE, the first effective collaborative multi-agent system\npowered by LLM with Retrieval Augmented Generation for ADE extraction from drug\nlabel data. This technique involves augmenting a query to an LLM with relevant\ninformation extracted from text resources, and instructing the LLM to compose a\nresponse consistent with the augmented data. MALADE is a general LLM-agnostic\narchitecture, and its unique capabilities are: (1) leveraging a variety of\nexternal sources, such as medical literature, drug labels, and FDA tools (e.g.,\nOpenFDA drug information API), (2) extracting drug-outcome association in a\nstructured format along with the strength of the association, and (3) providing\nexplanations for established associations. Instantiated with GPT-4 Turbo or\nGPT-4o, and FDA drug label data, MALADE demonstrates its efficacy with an Area\nUnder ROC Curve of 0.90 against the OMOP Ground Truth table of ADEs. Our\nimplementation leverages the Langroid multi-agent LLM framework and can be\nfound at https://github.com/jihyechoi77/malade.",
    "arxiv_id": "http://arxiv.org/abs/2408.01869v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01869v1",
    "primary_category": "cs.CL",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Meta-Posterior Consistency for the Bayesian Inference of Metastable System",
    "authors": "Zachary P Adams, Sayan Mukherjee",
    "abstract": "The vast majority of the literature on learning dynamical systems or\nstochastic processes from time series has focused on stable or ergodic systems,\nfor both Bayesian and frequentist inference procedures. However, most\nreal-world systems are only metastable, that is, the dynamics appear to be\nstable on some time scale, but are in fact unstable over longer time scales.\nConsistency of inference for metastable systems may not be possible, but one\ncan ask about metaconsistency: Do inference procedures converge when\nobservations are taken over a large but finite time interval, but diverge on\nlonger time scales? In this paper we introduce, discuss, and quantify\nmetaconsistency in a Bayesian framework. We discuss how metaconsistency can be\nexploited to efficiently infer a model for a sub-system of a larger system,\nwhere inference on the global behavior may require much more data. We also\ndiscuss the relation between meta-consistency and the spectral properties of\nthe model dynamical system in the case of uniformly ergodic diffusions.",
    "arxiv_id": "http://arxiv.org/abs/2408.01868v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01868v1",
    "primary_category": "stat.ML",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Efficient Solutions For An Intriguing Failure of LLMs: Long Context Window Does Not Mean LLMs Can Analyze Long Sequences Flawlessly",
    "authors": "Peyman Hosseini, Ignacio Castro, Iacopo Ghinassi, Matthew Purver",
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\ncomprehending and analyzing lengthy sequential inputs, owing to their extensive\ncontext windows that allow processing millions of tokens in a single forward\npass. However, this paper uncovers a surprising limitation: LLMs fall short\nwhen handling long input sequences. We investigate this issue using three\ndatasets and two tasks (sentiment analysis and news categorization) across\nvarious LLMs, including Claude 3, Gemini Pro, GPT 3.5 Turbo, Llama 3 Instruct,\nand Mistral Instruct models. To address this limitation, we propose and\nevaluate ad-hoc solutions that substantially enhance LLMs' performance on long\ninput sequences by up to 50%, while reducing API cost and latency by up to 93%\nand 50%, respectively.",
    "arxiv_id": "http://arxiv.org/abs/2408.01866v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01866v1",
    "primary_category": "cs.CL",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Batch Active Learning in Gaussian Process Regression using Derivatives",
    "authors": "Hon Sum Alec Yu, Christoph Zimmer, Duy Nguyen-Tuong",
    "abstract": "We investigate the use of derivative information for Batch Active Learning in\nGaussian Process regression models. The proposed approach employs the\npredictive covariance matrix for selection of data batches to exploit full\ncorrelation of samples. We theoretically analyse our proposed algorithm taking\ndifferent optimality criteria into consideration and provide empirical\ncomparisons highlighting the advantage of incorporating derivatives\ninformation. Our results show the effectiveness of our approach across diverse\napplications.",
    "arxiv_id": "http://arxiv.org/abs/2408.01861v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01861v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Using Linearized Optimal Transport to Predict the Evolution of Stochastic Particle Systems",
    "authors": "Nicholas Karris, Evangelos A. Nikitopoulos, Ioannis Kevrekidis, Seungjoon Lee, Alexander Cloninger",
    "abstract": "We develop an algorithm to approximate the time evolution of a probability\nmeasure without explicitly learning an operator that governs the evolution. A\nparticular application of interest is discrete measures $\\mu_t^N$ that arise\nfrom particle systems. In many such situations, the individual particles move\nchaotically on short time scales, making it difficult to learn the dynamics of\na governing operator, but the bulk distribution $\\mu_t^N$ approximates an\nabsolutely continuous measure $\\mu_t$ that evolves ``smoothly.'' If $\\mu_t$ is\nknown on some time interval, then linearized optimal transport theory provides\nan Euler-like scheme for approximating the evolution of $\\mu_t$ using its\n``tangent vector field'' (represented as a time-dependent vector field on\n$\\mathbb R^d$), which can be computed as a limit of optimal transport maps. We\npropose an analog of this Euler approximation to predict the evolution of the\ndiscrete measure $\\mu_t^N$ (without knowing $\\mu_t$). To approximate the\nanalogous tangent vector field, we use a finite difference over a time step\nthat sits between the two time scales of the system -- long enough for the\nlarge-$N$ evolution ($\\mu_t$) to emerge but short enough to satisfactorily\napproximate the derivative object used in the Euler scheme. By allowing the\nlimiting behavior to emerge, the optimal transport maps closely approximate the\nvector field describing the bulk distribution's smooth evolution instead of the\nindividual particles' more chaotic movements. We demonstrate the efficacy of\nthis approach with two illustrative examples, Gaussian diffusion and a cell\nchemotaxis model, and show that our method succeeds in predicting the bulk\nbehavior over relatively large steps.",
    "arxiv_id": "http://arxiv.org/abs/2408.01857v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01857v1",
    "primary_category": "math.NA",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Cost-constrained multi-label group feature selection using shadow features",
    "authors": "Tomasz Klonecki, Pawe\u0142 Teisseyre, Jaesung Lee",
    "abstract": "We consider the problem of feature selection in multi-label classification,\nconsidering the costs assigned to groups of features. In this task, the goal is\nto select a subset of features that will be useful for predicting the label\nvector, but at the same time, the cost associated with the selected features\nwill not exceed the assumed budget. Solving the problem is of great importance\nin medicine, where we may be interested in predicting various diseases based on\ngroups of features. The groups may be associated with parameters obtained from\na certain diagnostic test, such as a blood test. Because diagnostic test costs\ncan be very high, considering cost information when selecting relevant features\nbecomes crucial to reducing the cost of making predictions. We focus on the\nfeature selection method based on information theory. The proposed method\nconsists of two steps. First, we select features sequentially while maximizing\nconditional mutual information until the budget is exhausted. In the second\nstep, we select additional cost-free features, i.e., those coming from groups\nthat have already been used in previous steps. Limiting the number of added\nfeatures is possible using the stop rule based on the concept of so-called\nshadow features, which are randomized counterparts of the original ones. In\ncontrast to existing approaches based on penalized criteria, in our method, we\navoid the need for computationally demanding optimization of the penalty\nparameter. Experiments conducted on the MIMIC medical database show the\neffectiveness of the method, especially when the assumed budget is limited.",
    "arxiv_id": "http://arxiv.org/abs/2408.01851v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01851v1",
    "primary_category": "stat.ML",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Complexity of Minimizing Projected-Gradient-Dominated Functions with Stochastic First-order Oracles",
    "authors": "Saeed Masiha, Saber Salehkaleybar, Niao He, Negar Kiyavash, Patrick Thiran",
    "abstract": "This work investigates the performance limits of projected stochastic\nfirst-order methods for minimizing functions under the\n$(\\alpha,\\tau,\\mathcal{X})$-projected-gradient-dominance property, that asserts\nthe sub-optimality gap $F(\\mathbf{x})-\\min_{\\mathbf{x}'\\in\n\\mathcal{X}}F(\\mathbf{x}')$ is upper-bounded by\n$\\tau\\cdot\\|\\mathcal{G}_{\\eta,\\mathcal{X}}(\\mathbf{x})\\|^{\\alpha}$ for some\n$\\alpha\\in[1,2)$ and $\\tau>0$ and $\\mathcal{G}_{\\eta,\\mathcal{X}}(\\mathbf{x})$\nis the projected-gradient mapping with $\\eta>0$ as a parameter. For non-convex\nfunctions, we show that the complexity lower bound of querying a batch smooth\nfirst-order stochastic oracle to obtain an $\\epsilon$-global-optimum point is\n$\\Omega(\\epsilon^{-{2}/{\\alpha}})$. Furthermore, we show that a projected\nvariance-reduced first-order algorithm can obtain the upper complexity bound of\n$\\mathcal{O}(\\epsilon^{-{2}/{\\alpha}})$, matching the lower bound. For convex\nfunctions, we establish a complexity lower bound of\n$\\Omega(\\log(1/\\epsilon)\\cdot\\epsilon^{-{2}/{\\alpha}})$ for minimizing\nfunctions under a local version of gradient-dominance property, which also\nmatches the upper complexity bound of accelerated stochastic subgradient\nmethods.",
    "arxiv_id": "http://arxiv.org/abs/2408.01839v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01839v1",
    "primary_category": "math.OC",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Neural Network Emulator for Atmospheric Chemical ODE",
    "authors": "Zhi-Song Liu, Petri Clusius, Michael Boy",
    "abstract": "Modeling atmospheric chemistry is complex and computationally intense. Given\nthe recent success of Deep neural networks in digital signal processing, we\npropose a Neural Network Emulator for fast chemical concentration modeling. We\nconsider atmospheric chemistry as a time-dependent Ordinary Differential\nEquation. To extract the hidden correlations between initial states and future\ntime evolution, we propose ChemNNE, an Attention based Neural Network Emulator\n(NNE) that can model the atmospheric chemistry as a neural ODE process. To\nefficiently simulate the chemical changes, we propose the sinusoidal time\nembedding to estimate the oscillating tendency over time. More importantly, we\nuse the Fourier neural operator to model the ODE process for efficient\ncomputation. We also propose three physical-informed losses to supervise the\ntraining optimization. To evaluate our model, we propose a large-scale chemical\ndataset that can be used for neural network training and evaluation. The\nextensive experiments show that our approach achieves state-of-the-art\nperformance in modeling accuracy and computational speed.",
    "arxiv_id": "http://arxiv.org/abs/2408.01829v2",
    "pdf_url": "http://arxiv.org/pdf/2408.01829v2",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Attention is all you need for an improved CNN-based flash flood susceptibility modeling. The case of the ungauged Rheraya watershed, Morocco",
    "authors": "Akram Elghouat, Ahmed Algouti, Abdellah Algouti, Soukaina Baid",
    "abstract": "Effective flood hazard management requires evaluating and predicting flash\nflood susceptibility. Convolutional neural networks (CNNs) are commonly used\nfor this task but face issues like gradient explosion and overfitting. This\nstudy explores the use of an attention mechanism, specifically the\nconvolutional block attention module (CBAM), to enhance CNN models for flash\nflood susceptibility in the ungauged Rheraya watershed, a flood prone region.\nWe used ResNet18, DenseNet121, and Xception as backbone architectures,\nintegrating CBAM at different locations. Our dataset included 16 conditioning\nfactors and 522 flash flood inventory points. Performance was evaluated using\naccuracy, precision, recall, F1-score, and the area under the curve (AUC) of\nthe receiver operating characteristic (ROC). Results showed that CBAM\nsignificantly improved model performance, with DenseNet121 incorporating CBAM\nin each convolutional block achieving the best results (accuracy = 0.95, AUC =\n0.98). Distance to river and drainage density were identified as key factors.\nThese findings demonstrate the effectiveness of the attention mechanism in\nimproving flash flood susceptibility modeling and offer valuable insights for\ndisaster management.",
    "arxiv_id": "http://arxiv.org/abs/2408.02692v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02692v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "STBLLM: Breaking the 1-Bit Barrier with Structured Binary LLMs",
    "authors": "Peijie Dong, Lujun Li, Dayou Du, Yuhan Chen, Zhenheng Tang, Qiang Wang, Wei Xue, Wenhan Luo, Qifeng Liu, Yike Guo, Xiaowen Chu",
    "abstract": "In this paper, we present STBLLM, the first structural binarization framework\nfor compressing Large Language Models (LLMs) to less than 1-bit precision. LLMs\nhave achieved remarkable performance, but their heavy memory requirements have\nhindered widespread adoption, particularly on resource-constrained devices.\nBinarization, which quantifies weights to a mere 1-bit, achieves a milestone in\nincreasing computational efficiency. However, we observe that some weights in\nbinarized LLMs can be randomly flipped without significant performance\ndegradation, indicating the potential for further compression. To exploit this,\nour STBLLM employs an N:M sparsity to perform structural binarization of the\nweights. First, we introduce a new Standardized Importance (SI) metric that\nconsiders weight magnitude and input feature norm to better evaluate weight\nsignificance. Then, we propose a layer-wise approach where different layers of\nthe LLM can be sparsified with varying N:M ratios, balancing compression and\naccuracy. Finally, we use residual approximation with double binarization to\npreserve information for salient weights. In addition, we utilize a\nfine-grained grouping strategy for less important weights that applies\ndifferent quantization schemes to sparse, intermediate, and dense regions. We\nconduct extensive experiments on various language models, including the\nLLaMA-1/2/3, OPT family, and Mistral, to evaluate the effectiveness of STBLLM.\nThe results demonstrate that our approach performs better than other compressed\nbinarization LLM methods while significantly reducing memory requirements.",
    "arxiv_id": "http://arxiv.org/abs/2408.01803v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01803v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "STDA: Spatio-Temporal Dual-Encoder Network Incorporating Driver Attention to Predict Driver Behaviors Under Safety-Critical Scenarios",
    "authors": "Dongyang Xu, Yiran Luo, Tianle Lu, Qingfan Wang, Qing Zhou, Bingbing Nie",
    "abstract": "Accurate behavior prediction for vehicles is essential but challenging for\nautonomous driving. Most existing studies show satisfying performance under\nregular scenarios, but most neglected safety-critical scenarios. In this study,\na spatio-temporal dual-encoder network named STDA for safety-critical scenarios\nwas developed. Considering the exceptional capabilities of human drivers in\nterms of situational awareness and comprehending risks, driver attention was\nincorporated into STDA to facilitate swift identification of the critical\nregions, which is expected to improve both performance and interpretability.\nSTDA contains four parts: the driver attention prediction module, which\npredicts driver attention; the fusion module designed to fuse the features\nbetween driver attention and raw images; the temporary encoder module used to\nenhance the capability to interpret dynamic scenes; and the behavior prediction\nmodule to predict the behavior. The experiment data are used to train and\nvalidate the model. The results show that STDA improves the G-mean from 0.659\nto 0.719 when incorporating driver attention and adopting a temporal encoder\nmodule. In addition, extensive experimentation has been conducted to validate\nthat the proposed module exhibits robust generalization capabilities and can be\nseamlessly integrated into other mainstream models.",
    "arxiv_id": "http://arxiv.org/abs/2408.01774v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01774v1",
    "primary_category": "cs.CV",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Comparison of Embedded Spaces for Deep Learning Classification",
    "authors": "Stefan Scholl",
    "abstract": "Embedded spaces are a key feature in deep learning. Good embedded spaces\nrepresent the data well to support classification and advanced techniques such\nas open-set recognition, few-short learning and explainability. This paper\npresents a compact overview of different techniques to design embedded spaces\nfor classification. It compares different loss functions and constraints on the\nnetwork parameters with respect to the achievable geometric structure of the\nembedded space. The techniques are demonstrated with two and three-dimensional\nembeddings for the MNIST, Fashion MNIST and CIFAR-10 datasets, allowing visual\ninspection of the embedded spaces.",
    "arxiv_id": "http://arxiv.org/abs/2408.01767v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01767v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Joint Model Pruning and Resource Allocation for Wireless Time-triggered Federated Learning",
    "authors": "Xinlu Zhang, Yansha Deng, Toktam Mahmoodi",
    "abstract": "Time-triggered federated learning, in contrast to conventional event-based\nfederated learning, organizes users into tiers based on fixed time intervals.\nHowever, this network still faces challenges due to a growing number of devices\nand limited wireless bandwidth, increasing issues like stragglers and\ncommunication overhead. In this paper, we apply model pruning to wireless\nTime-triggered systems and jointly study the problem of optimizing the pruning\nratio and bandwidth allocation to minimize training loss under communication\nlatency constraints. To solve this joint optimization problem, we perform a\nconvergence analysis on the gradient $l_2$-norm of the asynchronous multi-tier\nfederated learning (FL) model with adaptive model pruning. The convergence\nupper bound is derived and a joint optimization problem of pruning ratio and\nwireless bandwidth is defined to minimize the model training loss under a given\ncommunication latency constraint. The closed-form solutions for wireless\nbandwidth and pruning ratio by using KKT conditions are then formulated. As\nindicated in the simulation experiments, our proposed TT-Prune demonstrates a\n40% reduction in communication cost, compared with the asynchronous multi-tier\nFL without model pruning, while maintaining the model convergence at the same\nlevel.",
    "arxiv_id": "http://arxiv.org/abs/2408.01765v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01765v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Classical Machine Learning: Seventy Years of Algorithmic Learning Evolution",
    "authors": "Absalom E. Ezugwu, Yuh-Shan Ho, Ojonukpe S. Egwuche, Olufisayo S. Ekundayo, Annette Van Der Merwe, Apu K. Saha, Jayanta Pal",
    "abstract": "Machine learning (ML) has transformed numerous fields, but understanding its\nfoundational research is crucial for its continued progress. This paper\npresents an overview of the significant classical ML algorithms and examines\nthe state-of-the-art publications spanning twelve decades through an extensive\nbibliometric analysis study. We analyzed a dataset of highly cited papers from\nprominent ML conferences and journals, employing citation and keyword analyses\nto uncover critical insights. The study further identifies the most influential\npapers and authors, reveals the evolving collaborative networks within the ML\ncommunity, and pinpoints prevailing research themes and emerging focus areas.\nAdditionally, we examine the geographic distribution of highly cited\npublications, highlighting the leading countries in ML research. This study\nprovides a comprehensive overview of the evolution of traditional learning\nalgorithms and their impacts. It discusses challenges and opportunities for\nfuture development, focusing on the Global South. The findings from this paper\noffer valuable insights for both ML experts and the broader research community,\nenhancing understanding of the field's trajectory and its significant influence\non recent advances in learning algorithms.",
    "arxiv_id": "http://arxiv.org/abs/2408.01747v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01747v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Can LLMs predict the convergence of Stochastic Gradient Descent?",
    "authors": "Oussama Zekri, Abdelhakim Benechehab, Ievgen Redko",
    "abstract": "Large-language models are notoriously famous for their impressive performance\nacross a wide range of tasks. One surprising example of such impressive\nperformance is a recently identified capacity of LLMs to understand the\ngoverning principles of dynamical systems satisfying the Markovian property. In\nthis paper, we seek to explore this direction further by studying the dynamics\nof stochastic gradient descent in convex and non-convex optimization. By\nleveraging the theoretical link between the SGD and Markov chains, we show a\nremarkable zero-shot performance of LLMs in predicting the local minima to\nwhich SGD converges for previously unseen starting points. On a more general\nlevel, we inquire about the possibility of using LLMs to perform zero-shot\nrandomized trials for larger deep learning models used in practice.",
    "arxiv_id": "http://arxiv.org/abs/2408.01736v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01736v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Real-time Hybrid System Identification with Online Deterministic Annealing",
    "authors": "Christos Mavridis, Karl Henrik Johansson",
    "abstract": "We introduce a real-time identification method for discrete-time\nstate-dependent switching systems in both the input--output and state-space\ndomains. In particular, we design a system of adaptive algorithms running in\ntwo timescales; a stochastic approximation algorithm implements an online\ndeterministic annealing scheme at a slow timescale and estimates the\nmode-switching signal, and an recursive identification algorithm runs at a\nfaster timescale and updates the parameters of the local models based on the\nestimate of the switching signal. We first focus on piece-wise affine systems\nand discuss identifiability conditions and convergence properties based on the\ntheory of two-timescale stochastic approximation. In contrast to standard\nidentification algorithms for switched systems, the proposed approach gradually\nestimates the number of modes and is appropriate for real-time system\nidentification using sequential data acquisition. The progressive nature of the\nalgorithm improves computational efficiency and provides real-time control over\nthe performance-complexity trade-off. Finally, we address specific challenges\nthat arise in the application of the proposed methodology in identification of\nmore general switching systems. Simulation results validate the efficacy of the\nproposed methodology.",
    "arxiv_id": "http://arxiv.org/abs/2408.01730v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01730v1",
    "primary_category": "eess.SY",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Intuitionistic Fuzzy Generalized Eigenvalue Proximal Support Vector Machine",
    "authors": "A. Quadir, M. A. Ganaie, M. Tanveer",
    "abstract": "Generalized eigenvalue proximal support vector machine (GEPSVM) has attracted\nwidespread attention due to its simple architecture, rapid execution, and\ncommendable performance. GEPSVM gives equal significance to all samples,\nthereby diminishing its robustness and efficacy when confronted with real-world\ndatasets containing noise and outliers. In order to reduce the impact of noises\nand outliers, we propose a novel intuitionistic fuzzy generalized eigenvalue\nproximal support vector machine (IF-GEPSVM). The proposed IF-GEPSVM assigns the\nintuitionistic fuzzy score to each training sample based on its location and\nsurroundings in the high-dimensional feature space by using a kernel function.\nThe solution of the IF-GEPSVM optimization problem is obtained by solving a\ngeneralized eigenvalue problem. Further, we propose an intuitionistic fuzzy\nimproved GEPSVM (IF-IGEPSVM) by solving the standard eigenvalue decomposition\nresulting in simpler optimization problems with less computation cost which\nleads to an efficient intuitionistic fuzzy-based model. We conduct a\ncomprehensive evaluation of the proposed IF-GEPSVM and IF-IGEPSVM models on UCI\nand KEEL datasets. Moreover, to evaluate the robustness of the proposed\nIF-GEPSVM and IF-IGEPSVM models, label noise is introduced into some UCI and\nKEEL datasets. The experimental findings showcase the superior generalization\nperformance of the proposed models when compared to the existing baseline\nmodels, both with and without label noise. Our experimental results, supported\nby rigorous statistical analyses, confirm the superior generalization abilities\nof the proposed IF-GEPSVM and IF-IGEPSVM models over the baseline models.\nFurthermore, we implement the proposed IF-GEPSVM and IF-IGEPSVM models on the\nUSPS recognition dataset, yielding promising results that underscore the\nmodels' effectiveness in practical and real-world applications.",
    "arxiv_id": "http://arxiv.org/abs/2408.01713v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01713v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Invariant Graph Learning Meets Information Bottleneck for Out-of-Distribution Generalization",
    "authors": "Wenyu Mao, Jiancan Wu, Haoyang Liu, Yongduo Sui, Xiang Wang",
    "abstract": "Graph out-of-distribution (OOD) generalization remains a major challenge in\ngraph learning since graph neural networks (GNNs) often suffer from severe\nperformance degradation under distribution shifts. Invariant learning, aiming\nto extract invariant features across varied distributions, has recently emerged\nas a promising approach for OOD generation. Despite the great success of\ninvariant learning in OOD problems for Euclidean data (i.e., images), the\nexploration within graph data remains constrained by the complex nature of\ngraphs. Existing studies, such as data augmentation or causal intervention,\neither suffer from disruptions to invariance during the graph manipulation\nprocess or face reliability issues due to a lack of supervised signals for\ncausal parts. In this work, we propose a novel framework, called Invariant\nGraph Learning based on Information bottleneck theory (InfoIGL), to extract the\ninvariant features of graphs and enhance models' generalization ability to\nunseen distributions. Specifically, InfoIGL introduces a redundancy filter to\ncompress task-irrelevant information related to environmental factors.\nCooperating with our designed multi-level contrastive learning, we maximize the\nmutual information among graphs of the same class in the downstream\nclassification tasks, preserving invariant features for prediction to a great\nextent. An appealing feature of InfoIGL is its strong generalization ability\nwithout depending on supervised signal of invariance. Experiments on both\nsynthetic and real-world datasets demonstrate that our method achieves\nstate-of-the-art performance under OOD generalization for graph classification\ntasks. The source code is available at https://github.com/maowenyu-11/InfoIGL.",
    "arxiv_id": "http://arxiv.org/abs/2408.01697v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01697v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "TreeCSS: An Efficient Framework for Vertical Federated Learning",
    "authors": "Qinbo Zhang, Xiao Yan, Yukai Ding, Quanqing Xu, Chuang Hu, Xiaokai Zhou, Jiawei Jiang",
    "abstract": "Vertical federated learning (VFL) considers the case that the features of\ndata samples are partitioned over different participants. VFL consists of two\nmain steps, i.e., identify the common data samples for all participants\n(alignment) and train model using the aligned data samples (training). However,\nwhen there are many participants and data samples, both alignment and training\nbecome slow. As such, we propose TreeCSS as an efficient VFL framework that\naccelerates the two main steps. In particular, for sample alignment, we design\nan efficient multi-party private set intersection (MPSI) protocol called\nTree-MPSI, which adopts a tree-based structure and a data-volume-aware\nscheduling strategy to parallelize alignment among the participants. As model\ntraining time scales with the number of data samples, we conduct coreset\nselection (CSS) to choose some representative data samples for training. Our\nCCS method adopts a clustering-based scheme for security and generality, which\nfirst clusters the features locally on each participant and then merges the\nlocal clustering results to select representative samples. In addition, we\nweight the samples according to their distances to the centroids to reflect\ntheir importance to model training. We evaluate the effectiveness and\nefficiency of our TreeCSS framework on various datasets and models. The results\nshow that compared with vanilla VFL, TreeCSS accelerates training by up to\n2.93x and achieves comparable model accuracy.",
    "arxiv_id": "http://arxiv.org/abs/2408.01691v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01691v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Controllable Unlearning for Image-to-Image Generative Models via $\\varepsilon$-Constrained Optimization",
    "authors": "Xiaohua Feng, Chaochao Chen, Yuyuan Li, Li Zhang",
    "abstract": "While generative models have made significant advancements in recent years,\nthey also raise concerns such as privacy breaches and biases. Machine\nunlearning has emerged as a viable solution, aiming to remove specific training\ndata, e.g., containing private information and bias, from models. In this\npaper, we study the machine unlearning problem in Image-to-Image (I2I)\ngenerative models. Previous studies mainly treat it as a single objective\noptimization problem, offering a solitary solution, thereby neglecting the\nvaried user expectations towards the trade-off between complete unlearning and\nmodel utility. To address this issue, we propose a controllable unlearning\nframework that uses a control coefficient $\\varepsilon$ to control the\ntrade-off. We reformulate the I2I generative model unlearning problem into a\n$\\varepsilon$-constrained optimization problem and solve it with a\ngradient-based method to find optimal solutions for unlearning boundaries.\nThese boundaries define the valid range for the control coefficient. Within\nthis range, every yielded solution is theoretically guaranteed with Pareto\noptimality. We also analyze the convergence rate of our framework under various\ncontrol functions. Extensive experiments on two benchmark datasets across three\nmainstream I2I models demonstrate the effectiveness of our controllable\nunlearning framework.",
    "arxiv_id": "http://arxiv.org/abs/2408.01689v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01689v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Symmetric Graph Contrastive Learning against Noisy Views for Recommendation",
    "authors": "Chu Zhao, Enneng Yang, Yuliang Liang, Jianzhe Zhao, Guibing Guo, Xingwei Wang",
    "abstract": "Graph Contrastive Learning (GCL) leverages data augmentation techniques to\nproduce contrasting views, enhancing the accuracy of recommendation systems\nthrough learning the consistency between contrastive views. However, existing\naugmentation methods, such as directly perturbing interaction graph (e.g.,\nnode/edge dropout), may interfere with the original connections and generate\npoor contrasting views, resulting in sub-optimal performance. In this paper, we\ndefine the views that share only a small amount of information with the\noriginal graph due to poor data augmentation as noisy views (i.e., the last 20%\nof the views with a cosine similarity value less than 0.1 to the original\nview). We demonstrate through detailed experiments that noisy views will\nsignificantly degrade recommendation performance. Further, we propose a\nmodel-agnostic Symmetric Graph Contrastive Learning (SGCL) method with\ntheoretical guarantees to address this issue. Specifically, we introduce\nsymmetry theory into graph contrastive learning, based on which we propose a\nsymmetric form and contrast loss resistant to noisy interference. We provide\ntheoretical proof that our proposed SGCL method has a high tolerance to noisy\nviews. Further demonstration is given by conducting extensive experiments on\nthree real-world datasets. The experimental results demonstrate that our\napproach substantially increases recommendation accuracy, with relative\nimprovements reaching as high as 12.25% over nine other competing models. These\nresults highlight the efficacy of our method.",
    "arxiv_id": "http://arxiv.org/abs/2408.02691v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02691v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Deep Reinforcement Learning for Dynamic Order Picking in Warehouse Operations",
    "authors": "Sasan Mahmoudinazlou, Abhay Sobhanan, Hadi Charkhgard, Ali Eshragh, George Dunn",
    "abstract": "Order picking is a crucial operation in warehouses that significantly impacts\noverall efficiency and profitability. This study addresses the dynamic order\npicking problem, a significant concern in modern warehouse management where\nreal-time adaptation to fluctuating order arrivals and efficient picker routing\nare crucial. Traditional methods, often assuming fixed order sets, fall short\nin this dynamic environment. We utilize Deep Reinforcement Learning (DRL) as a\nsolution methodology to handle the inherent uncertainties in customer demands.\nWe focus on a single-block warehouse with an autonomous picking device,\neliminating human behavioral factors. Our DRL framework enables the dynamic\noptimization of picker routes, significantly reducing order throughput times,\nespecially under high order arrival rates. Experiments demonstrate a\nsubstantial decrease in order throughput time and unfulfilled orders compared\nto benchmark algorithms. We further investigate integrating a hyperparameter in\nthe reward function that allows for flexible balancing between distance\ntraveled and order completion time. Finally, we demonstrate the robustness of\nour DRL model for out-of-sample test instances.",
    "arxiv_id": "http://arxiv.org/abs/2408.01656v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01656v1",
    "primary_category": "math.OC",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Coordinating Planning and Tracking in Layered Control Policies via Actor-Critic Learning",
    "authors": "Fengjun Yang, Nikolai Matni",
    "abstract": "We propose a reinforcement learning (RL)-based algorithm to jointly train (1)\na trajectory planner and (2) a tracking controller in a layered control\narchitecture. Our algorithm arises naturally from a rewrite of the underlying\noptimal control problem that lends itself to an actor-critic learning approach.\nBy explicitly learning a \\textit{dual} network to coordinate the interaction\nbetween the planning and tracking layers, we demonstrate the ability to achieve\nan effective consensus between the two components, leading to an interpretable\npolicy. We theoretically prove that our algorithm converges to the optimal dual\nnetwork in the Linear Quadratic Regulator (LQR) setting and empirically\nvalidate its applicability to nonlinear systems through simulation experiments\non a unicycle model.",
    "arxiv_id": "http://arxiv.org/abs/2408.01639v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01639v1",
    "primary_category": "eess.SY",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "A Comparative Analysis of Wealth Index Predictions in Africa between three Multi-Source Inference Models",
    "authors": "M\u00e1rton Karsai, J\u00e1nos Kert\u00e9sz, Lisette Esp\u00edn-Noboa",
    "abstract": "Poverty map inference is a critical area of research, with growing interest\nin both traditional and modern techniques, ranging from regression models to\nconvolutional neural networks applied to tabular data, images, and networks.\nDespite extensive focus on the validation of training phases, the scrutiny of\nfinal predictions remains limited. Here, we compare the Relative Wealth Index\n(RWI) inferred by Chi et al. (2021) with the International Wealth Index (IWI)\ninferred by Lee and Braithwaite (2022) and Esp\\'in-Noboa et al. (2023) across\nsix Sub-Saharan African countries. Our analysis focuses on identifying trends\nand discrepancies in wealth predictions over time. Our results show that the\npredictions by Chi et al. and Esp\\'in-Noboa et al. align with general GDP\ntrends, with differences expected due to the distinct time-frames of the\ntraining sets. However, predictions by Lee and Braithwaite diverge\nsignificantly, indicating potential issues with the validity of the model.\nThese discrepancies highlight the need for policymakers and stakeholders in\nAfrica to rigorously audit models that predict wealth, especially those used\nfor decision-making on the ground. These and other techniques require\ncontinuous verification and refinement to enhance their reliability and ensure\nthat poverty alleviation strategies are well-founded.",
    "arxiv_id": "http://arxiv.org/abs/2408.01631v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01631v1",
    "primary_category": "physics.soc-ph",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Fair Risk Minimization under Causal Path-Specific Effect Constraints",
    "authors": "Razieh Nabi, David Benkeser",
    "abstract": "This paper introduces a framework for estimating fair optimal predictions\nusing machine learning where the notion of fairness can be quantified using\npath-specific causal effects. We use a recently developed approach based on\nLagrange multipliers for infinite-dimensional functional estimation to derive\nclosed-form solutions for constrained optimization based on mean squared error\nand cross-entropy risk criteria. The theoretical forms of the solutions are\nanalyzed in detail and described as nuanced adjustments to the unconstrained\nminimizer. This analysis highlights important trade-offs between risk\nminimization and achieving fairnes. The theoretical solutions are also used as\nthe basis for construction of flexible semiparametric estimation strategies for\nthese nuisance components. We describe the robustness properties of our\nestimators in terms of achieving the optimal constrained risk, as well as in\nterms of controlling the value of the constraint. We study via simulation the\nimpact of using robust estimators of pathway-specific effects to validate our\ntheory. This work advances the discourse on algorithmic fairness by integrating\ncomplex causal considerations into model training, thus providing strategies\nfor implementing fair models in real-world applications.",
    "arxiv_id": "http://arxiv.org/abs/2408.01630v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01630v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Positive-Unlabeled Constraint Learning (PUCL) for Inferring Nonlinear Continuous Constraints Functions from Expert Demonstrations",
    "authors": "Baiyu Peng, Aude Billard",
    "abstract": "Planning for a wide range of real-world robotic tasks necessitates to know\nand write all constraints. However, instances exist where these constraints are\neither unknown or challenging to specify accurately. A possible solution is to\ninfer the unknown constraints from expert demonstration. This paper presents a\nnovel Positive-Unlabeled Constraint Learning (PUCL) algorithm to infer a\ncontinuous arbitrary constraint function from demonstration, without requiring\nprior knowledge of the true constraint parameterization or environmental model\nas existing works. Within our framework, we treat all data in demonstrations as\npositive (feasible) data, and learn a control policy to generate potentially\ninfeasible trajectories, which serve as unlabeled data. In each iteration, we\nfirst update the policy and then a two-step positive-unlabeled learning\nprocedure is applied, where it first identifies reliable infeasible data using\na distance metric, and secondly learns a binary feasibility classifier (i.e.,\nconstraint function) from the feasible demonstrations and reliable infeasible\ndata. The proposed framework is flexible to learn complex-shaped constraint\nboundary and will not mistakenly classify demonstrations as infeasible as\nprevious methods. The effectiveness of the proposed method is verified in three\nrobotic tasks, using a networked policy or a dynamical system policy. It\nsuccessfully infers and transfers the continuous nonlinear constraints and\noutperforms other baseline methods in terms of constraint accuracy and policy\nsafety.",
    "arxiv_id": "http://arxiv.org/abs/2408.01622v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01622v1",
    "primary_category": "cs.RO",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Data-Driven Machine Learning Approaches for Predicting In-Hospital Sepsis Mortality",
    "authors": "Arseniy Shumilov, Yueting Zhu, Negin Ashrafi, Gaojie Lian, Shilong Ren, Maryam Pishgar",
    "abstract": "Background: Sepsis is a severe condition responsible for many deaths\nworldwide. Accurate prediction of sepsis outcomes is crucial for timely and\neffective treatment. Although previous studies have used ML to forecast\noutcomes, they faced limitations in feature selection and model\ncomprehensibility, resulting in less effective predictions. Thus, this research\naims to develop an interpretable and accurate ML model to help clinical\nprofessionals predict in-hospital mortality.\n  Methods: We analyzed ICU patient records from the MIMIC-III database based on\nspecific criteria and extracted relevant data. Our feature selection process\nincluded a literature review, clinical input refinement, and using Random\nForest to select the top 35 features. We performed data preprocessing,\nincluding cleaning, imputation, standardization, and applied SMOTE for\noversampling to address imbalance, resulting in 4,683 patients, with admission\ncounts of 17,429. We compared the performance of Random Forest, Gradient\nBoosting, Logistic Regression, SVM, and KNN models.\n  Results: The Random Forest model was the most effective in predicting\nsepsis-related in-hospital mortality. It outperformed other models, achieving\nan accuracy of 0.90 and an AUROC of 0.97, significantly better than the\nexisting literature. Our meticulous feature selection contributed to the\nmodel's precision and identified critical determinants of sepsis mortality.\nThese results underscore the pivotal role of data-driven ML in healthcare,\nespecially for predicting in-hospital mortality due to sepsis.\n  Conclusion: This study represents a significant advancement in predicting\nin-hospital sepsis mortality, highlighting the potential of ML in healthcare.\nThe implications are profound, offering a data-driven approach that enhances\ndecision-making in patient care and reduces in-hospital mortality.",
    "arxiv_id": "http://arxiv.org/abs/2408.01612v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01612v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Deep Learning Meets OBIA: Tasks, Challenges, Strategies, and Perspectives",
    "authors": "Lei Ma, Ziyun Yan, Mengmeng Li, Tao Liu, Liqin Tan, Xuan Wang, Weiqiang He, Ruikun Wang, Guangjun He, Heng Lu, Thomas Blaschke",
    "abstract": "Deep learning has gained significant attention in remote sensing, especially\nin pixel- or patch-level applications. Despite initial attempts to integrate\ndeep learning into object-based image analysis (OBIA), its full potential\nremains largely unexplored. In this article, as OBIA usage becomes more\nwidespread, we conducted a comprehensive review and expansion of its task\nsubdomains, with or without the integration of deep learning. Furthermore, we\nhave identified and summarized five prevailing strategies to address the\nchallenge of deep learning's limitations in directly processing unstructured\nobject data within OBIA, and this review also recommends some important future\nresearch directions. Our goal with these endeavors is to inspire more\nexploration in this fascinating yet overlooked area and facilitate the\nintegration of deep learning into OBIA processing workflows.",
    "arxiv_id": "http://arxiv.org/abs/2408.01607v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01607v1",
    "primary_category": "cs.CV",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "CYBERSECEVAL 3: Advancing the Evaluation of Cybersecurity Risks and Capabilities in Large Language Models",
    "authors": "Shengye Wan, Cyrus Nikolaidis, Daniel Song, David Molnar, James Crnkovich, Jayson Grace, Manish Bhatt, Sahana Chennabasappa, Spencer Whitman, Stephanie Ding, Vlad Ionescu, Yue Li, Joshua Saxe",
    "abstract": "We are releasing a new suite of security benchmarks for LLMs, CYBERSECEVAL 3,\nto continue the conversation on empirically measuring LLM cybersecurity risks\nand capabilities. CYBERSECEVAL 3 assesses 8 different risks across two broad\ncategories: risk to third parties, and risk to application developers and end\nusers. Compared to previous work, we add new areas focused on offensive\nsecurity capabilities: automated social engineering, scaling manual offensive\ncyber operations, and autonomous offensive cyber operations. In this paper we\ndiscuss applying these benchmarks to the Llama 3 models and a suite of\ncontemporaneous state-of-the-art LLMs, enabling us to contextualize risks both\nwith and without mitigations in place.",
    "arxiv_id": "http://arxiv.org/abs/2408.01605v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01605v1",
    "primary_category": "cs.CR",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "FIVB ranking: Misstep in the right direction",
    "authors": "Salma Tenni, Daniel Gomes de Pinho Zanco, Leszek Szczecinski",
    "abstract": "This work uses a statistical framework to present and evaluate the ranking\nalgorithm that has been used by F\\'ed\\'eration Internationale de Volleyball\n(FIVB) since 2020. The salient feature of the FIVB ranking is the use of the\nprobabilistic model, which explicitly calculates the probabilities of the games\nto come. This explicit modeling is new in the context of official ranking, and\nwe study the optimality of its parameters as well as its relationship with the\nranking algorithm as such. The analysis is carried out using both analytical\nand numerical methods. We conclude that, from the modeling perspective, the use\nof the home-field advantage (HFA) would be beneficial and that the weighting of\nthe game results is counterproductive. Regarding the algorithm itself, we\nexplain the rationale beyond the approximations currently used and explain how\nto find new parameters which improve the performance. Finally, we propose a new\nmodel that drastically simplifies both the implementation and interpretation of\nthe resulting algorithm.",
    "arxiv_id": "http://arxiv.org/abs/2408.01603v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01603v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Physics-Informed Geometry-Aware Neural Operator",
    "authors": "Weiheng Zhong, Hadi Meidani",
    "abstract": "Engineering design problems often involve solving parametric Partial\nDifferential Equations (PDEs) under variable PDE parameters and domain\ngeometry. Recently, neural operators have shown promise in learning PDE\noperators and quickly predicting the PDE solutions. However, training these\nneural operators typically requires large datasets, the acquisition of which\ncan be prohibitively expensive. To overcome this, physics-informed training\noffers an alternative way of building neural operators, eliminating the high\ncomputational costs associated with Finite Element generation of training data.\nNevertheless, current physics-informed neural operators struggle with\nlimitations, either in handling varying domain geometries or varying PDE\nparameters. In this research, we introduce a novel method, the Physics-Informed\nGeometry-Aware Neural Operator (PI-GANO), designed to simultaneously generalize\nacross both PDE parameters and domain geometries. We adopt a geometry encoder\nto capture the domain geometry features, and design a novel pipeline to\nintegrate this component within the existing DCON architecture. Numerical\nresults demonstrate the accuracy and efficiency of the proposed method.",
    "arxiv_id": "http://arxiv.org/abs/2408.01600v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01600v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Trustworthy Machine Learning under Social and Adversarial Data Sources",
    "authors": "Han Shao",
    "abstract": "Machine learning has witnessed remarkable breakthroughs in recent years. As\nmachine learning permeates various aspects of daily life, individuals and\norganizations increasingly interact with these systems, exhibiting a wide range\nof social and adversarial behaviors. These behaviors may have a notable impact\non the behavior and performance of machine learning systems. Specifically,\nduring these interactions, data may be generated by strategic individuals,\ncollected by self-interested data collectors, possibly poisoned by adversarial\nattackers, and used to create predictors, models, and policies satisfying\nmultiple objectives. As a result, the machine learning systems' outputs might\ndegrade, such as the susceptibility of deep neural networks to adversarial\nexamples (Shafahi et al., 2018; Szegedy et al., 2013) and the diminished\nperformance of classic algorithms in the presence of strategic individuals\n(Ahmadi et al., 2021). Addressing these challenges is imperative for the\nsuccess of machine learning in societal settings.",
    "arxiv_id": "http://arxiv.org/abs/2408.01596v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01596v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Conformal Diffusion Models for Individual Treatment Effect Estimation and Inference",
    "authors": "Hengrui Cai, Huaqing Jin, Lexin Li",
    "abstract": "Estimating treatment effects from observational data is of central interest\nacross numerous application domains. Individual treatment effect offers the\nmost granular measure of treatment effect on an individual level, and is the\nmost useful to facilitate personalized care. However, its estimation and\ninference remain underdeveloped due to several challenges. In this article, we\npropose a novel conformal diffusion model-based approach that addresses those\nintricate challenges. We integrate the highly flexible diffusion modeling, the\nmodel-free statistical inference paradigm of conformal inference, along with\npropensity score and covariate local approximation that tackle distributional\nshifts. We unbiasedly estimate the distributions of potential outcomes for\nindividual treatment effect, construct an informative confidence interval, and\nestablish rigorous theoretical guarantees. We demonstrate the competitive\nperformance of the proposed method over existing solutions through extensive\nnumerical studies.",
    "arxiv_id": "http://arxiv.org/abs/2408.01582v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01582v1",
    "primary_category": "stat.ML",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Huge Ensembles Part II: Properties of a Huge Ensemble of Hindcasts Generated with Spherical Fourier Neural Operators",
    "authors": "Ankur Mahesh, William Collins, Boris Bonev, Noah Brenowitz, Yair Cohen, Peter Harrington, Karthik Kashinath, Thorsten Kurth, Joshua North, Travis OBrien, Michael Pritchard, David Pruitt, Mark Risser, Shashank Subramanian, Jared Willard",
    "abstract": "In Part I, we created an ensemble based on Spherical Fourier Neural\nOperators. As initial condition perturbations, we used bred vectors, and as\nmodel perturbations, we used multiple checkpoints trained independently from\nscratch. Based on diagnostics that assess the ensemble's physical fidelity, our\nensemble has comparable performance to operational weather forecasting systems.\nHowever, it requires several orders of magnitude fewer computational resources.\nHere in Part II, we generate a huge ensemble (HENS), with 7,424 members\ninitialized each day of summer 2023. We enumerate the technical requirements\nfor running huge ensembles at this scale. HENS precisely samples the tails of\nthe forecast distribution and presents a detailed sampling of internal\nvariability. For extreme climate statistics, HENS samples events 4$\\sigma$ away\nfrom the ensemble mean. At each grid cell, HENS improves the skill of the most\naccurate ensemble member and enhances coverage of possible future trajectories.\nAs a weather forecasting model, HENS issues extreme weather forecasts with\nbetter uncertainty quantification. It also reduces the probability of outlier\nevents, in which the verification value lies outside the ensemble forecast\ndistribution.",
    "arxiv_id": "http://arxiv.org/abs/2408.01581v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01581v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Spatio-Temporal Partial Sensing Forecast for Long-term Traffic",
    "authors": "Zibo Liu, Zhe Jiang, Zelin Xu, Tingsong Xiao, Zhengkun Xiao, Haibo Wang, Shigang Chen",
    "abstract": "Traffic forecasting uses recent measurements by sensors installed at chosen\nlocations to forecast the future road traffic. Existing work either assumes all\nlocations are equipped with sensors or focuses on short-term forecast. This\npaper studies partial sensing traffic forecast of long-term traffic, assuming\nsensors only at some locations. The study is important in lowering the\ninfrastructure investment cost in traffic management since deploying sensors at\nall locations could incur prohibitively high cost. However, the problem is\nchallenging due to the unknown distribution at unsensed locations, the\nintricate spatio-temporal correlation in long-term forecasting, as well as\nnoise in data and irregularities in traffic patterns (e.g., road closure). We\npropose a Spatio-Temporal Partial Sensing (STPS) forecast model for long-term\ntraffic prediction, with several novel contributions, including a rank-based\nembedding technique to capture irregularities and overcome noise, a spatial\ntransfer matrix to overcome the spatial distribution shift from permanently\nsensed locations to unsensed locations, and a multi-step training process that\nutilizes all available data to successively refine the model parameters for\nbetter accuracy. Extensive experiments on several real-world traffic datasets\ndemonstrate that STPS outperforms the state-of-the-art and achieves superior\naccuracy in partial sensing long-term forecasting.",
    "arxiv_id": "http://arxiv.org/abs/2408.02689v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02689v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Deep Learning Framework for History Matching CO2 Storage with 4D Seismic and Monitoring Well Data",
    "authors": "Nanzhe Wang, Louis J. Durlofsky",
    "abstract": "Geological carbon storage entails the injection of megatonnes of\nsupercritical CO2 into subsurface formations. The properties of these\nformations are usually highly uncertain, which makes design and optimization of\nlarge-scale storage operations challenging. In this paper we introduce a\nhistory matching strategy that enables the calibration of formation properties\nbased on early-time observations. Early-time assessments are essential to\nassure the operation is performing as planned. Our framework involves two\nfit-for-purpose deep learning surrogate models that provide predictions for\nin-situ monitoring well data and interpreted time-lapse (4D) seismic saturation\ndata. These two types of data are at very different scales of resolution, so it\nis appropriate to construct separate, specialized deep learning networks for\ntheir prediction. This approach results in a workflow that is more\nstraightforward to design and more efficient to train than a single surrogate\nthat provides global high-fidelity predictions. The deep learning models are\nintegrated into a hierarchical Markov chain Monte Carlo (MCMC) history matching\nprocedure. History matching is performed on a synthetic case with and without\n4D seismic data, which allows us to quantify the impact of 4D seismic on\nuncertainty reduction. The use of both data types is shown to provide\nsubstantial uncertainty reduction in key geomodel parameters and to enable\naccurate predictions of CO2 plume dynamics. The overall history matching\nframework developed in this study represents an efficient way to integrate\nmultiple data types and to assess the impact of each on uncertainty reduction\nand performance predictions.",
    "arxiv_id": "http://arxiv.org/abs/2408.01575v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01575v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Counterfactual Explanations for Medical Image Classification and Regression using Diffusion Autoencoder",
    "authors": "Matan Atad, David Schinz, Hendrik Moeller, Robert Graf, Benedikt Wiestler, Daniel Rueckert, Nassir Navab, Jan S. Kirschke, Matthias Keicher",
    "abstract": "Counterfactual explanations (CEs) aim to enhance the interpretability of\nmachine learning models by illustrating how alterations in input features would\naffect the resulting predictions. Common CE approaches require an additional\nmodel and are typically constrained to binary counterfactuals. In contrast, we\npropose a novel method that operates directly on the latent space of a\ngenerative model, specifically a Diffusion Autoencoder (DAE). This approach\noffers inherent interpretability by enabling the generation of CEs and the\ncontinuous visualization of the model's internal representation across decision\nboundaries.\n  Our method leverages the DAE's ability to encode images into a semantically\nrich latent space in an unsupervised manner, eliminating the need for labeled\ndata or separate feature extraction models. We show that these latent\nrepresentations are helpful for medical condition classification and the\nordinal regression of severity pathologies, such as vertebral compression\nfractures (VCF) and diabetic retinopathy (DR). Beyond binary CEs, our method\nsupports the visualization of ordinal CEs using a linear model, providing\ndeeper insights into the model's decision-making process and enhancing\ninterpretability.\n  Experiments across various medical imaging datasets demonstrate the method's\nadvantages in interpretability and versatility. The linear manifold of the\nDAE's latent space allows for meaningful interpolation and manipulation, making\nit a powerful tool for exploring medical image properties. Our code is\navailable at https://github.com/matanat/dae_counterfactual.",
    "arxiv_id": "http://arxiv.org/abs/2408.01571v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01571v1",
    "primary_category": "cs.CV",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Robot-Enabled Machine Learning-Based Diagnosis of Gastric Cancer Polyps Using Partial Surface Tactile Imaging",
    "authors": "Siddhartha Kapuria, Jeff Bonyun, Yash Kulkarni, Naruhiko Ikoma, Sandeep Chinchali, Farshid Alambeigi",
    "abstract": "In this paper, to collectively address the existing limitations on endoscopic\ndiagnosis of Advanced Gastric Cancer (AGC) Tumors, for the first time, we\npropose (i) utilization and evaluation of our recently developed Vision-based\nTactile Sensor (VTS), and (ii) a complementary Machine Learning (ML) algorithm\nfor classifying tumors using their textural features. Leveraging a seven DoF\nrobotic manipulator and unique custom-designed and additively-manufactured\nrealistic AGC tumor phantoms, we demonstrated the advantages of automated data\ncollection using the VTS addressing the problem of data scarcity and biases\nencountered in traditional ML-based approaches. Our synthetic-data-trained ML\nmodel was successfully evaluated and compared with traditional ML models\nutilizing various statistical metrics even under mixed morphological\ncharacteristics and partial sensor contact.",
    "arxiv_id": "http://arxiv.org/abs/2408.01554v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01554v1",
    "primary_category": "cs.RO",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Momentum Capture and Prediction System Based on Wimbledon Open2023 Tournament Data",
    "authors": "Chang Liu, Tongyuan Yang, Yan Zhao",
    "abstract": "There is a hidden energy in tennis, which cannot be seen or touched. It is\nthe force that controls the flow of the game and is present in all types of\nmatches. This mysterious force is Momentum. This study introduces an evaluation\nmodel that synergizes the Entropy Weight Method (EWM) and Gray Relation\nAnalysis (GRA) to quantify momentum's impact on match outcomes. Empirical\nvalidation was conducted through Mann-Whitney U and Kolmogorov-Smirnov tests,\nwhich yielded p values of 0.0043 and 0.00128,respectively. These results\nunderscore the non-random association between momentum shifts and match\noutcomes, highlighting the critical role of momentum in tennis. Otherwise, our\ninvestigation foucus is the creation of a predictive model that combines the\nadvanced machine learning algorithm XGBoost with the SHAP framework. This model\nenables precise predictions of match swings with exceptional accuracy (0.999013\nfor multiple matches and 0.992738 for finals). The model's ability to identify\nthe influence of specific factors on match dynamics,such as bilateral distance\nrun during points, demonstrates its prowess.The model's generalizability was\nthoroughly evaluated using datasets from the four Grand Slam tournaments. The\nresults demonstrate its remarkable adaptability to different match\nscenarios,despite minor variations in predictive accuracy. It offers strategic\ninsights that can help players effectively respond to opponents' shifts in\nmomentum,enhancing their competitive edge.",
    "arxiv_id": "http://arxiv.org/abs/2408.01544v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01544v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Active Learning for Neural PDE Solvers",
    "authors": "Daniel Musekamp, Marimuthu Kalimuthu, David Holzm\u00fcller, Makoto Takamoto, Mathias Niepert",
    "abstract": "Solving partial differential equations (PDEs) is a fundamental problem in\nengineering and science. While neural PDE solvers can be more efficient than\nestablished numerical solvers, they often require large amounts of training\ndata that is costly to obtain. Active Learning (AL) could help surrogate models\nreach the same accuracy with smaller training sets by querying classical\nsolvers with more informative initial conditions and PDE parameters. While AL\nis more common in other domains, it has yet to be studied extensively for\nneural PDE solvers. To bridge this gap, we introduce AL4PDE, a modular and\nextensible active learning benchmark. It provides multiple parametric PDEs and\nstate-of-the-art surrogate models for the solver-in-the-loop setting, enabling\nthe evaluation of existing and the development of new AL methods for PDE\nsolving. We use the benchmark to evaluate batch active learning algorithms such\nas uncertainty- and feature-based methods. We show that AL reduces the average\nerror by up to 71% compared to random sampling and significantly reduces\nworst-case errors. Moreover, AL generates similar datasets across repeated\nruns, with consistent distributions over the PDE parameters and initial\nconditions. The acquired datasets are reusable, providing benefits for\nsurrogate models not involved in the data generation.",
    "arxiv_id": "http://arxiv.org/abs/2408.01536v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01536v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "An Adaptive Tensor-Train Decomposition Approach for Efficient Deep Neural Network Compression",
    "authors": "Shiyi Luo, Mingshuo Liu, Pu Sun, Yifeng Yu, Shangping Ren, Yu Bai",
    "abstract": "In the field of model compression, choosing an appropriate rank for tensor\ndecomposition is pivotal for balancing model compression rate and efficiency.\nHowever, this selection, whether done manually or through optimization-based\nautomatic methods, often increases computational complexity. Manual rank\nselection lacks efficiency and scalability, often requiring extensive\ntrial-and-error, while optimization-based automatic methods significantly\nincrease the computational burden. To address this, we introduce a novel,\nautomatic, and budget-aware rank selection method for efficient model\ncompression, which employs Layer-Wise Imprinting Quantitation (LWIQ). LWIQ\nquantifies each layer's significance within a neural network by integrating a\nproxy classifier. This classifier assesses the layer's impact on overall model\nperformance, allowing for a more informed adjustment of tensor rank.\nFurthermore, our approach includes a scaling factor to cater to varying\ncomputational budget constraints. This budget awareness eliminates the need for\nrepetitive rank recalculations for different budget scenarios. Experimental\nresults on the CIFAR-10 dataset show that our LWIQ improved by 63.2$\\%$ in rank\nsearch efficiency, and the accuracy only dropped by 0.86$\\%$ with 3.2x less\nmodel size on the ResNet-56 model as compared to the state-of-the-art\nproxy-based automatic tensor rank selection method.",
    "arxiv_id": "http://arxiv.org/abs/2408.01534v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01534v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "A Structured Framework for Predicting Sustainable Aviation Fuel Properties using Liquid-Phase FTIR and Machine Learning",
    "authors": "Ana E. Comesana, Sharon S. Chen, Kyle E. Niemeyer, Vi H. Rapp",
    "abstract": "Sustainable aviation fuels have the potential for reducing emissions and\nenvironmental impact. To help identify viable sustainable aviation fuels and\naccelerate research, several machine learning models have been developed to\npredict relevant physiochemical properties. However, many of the models have\nlimited applicability, leverage data from complex analytical techniques with\nconfined spectral ranges, or use feature decomposition methods that have\nlimited interpretability. Using liquid-phase Fourier Transform Infrared (FTIR)\nspectra, this study presents a structured method for creating accurate and\ninterpretable property prediction models for neat molecules, aviation fuels,\nand blends. Liquid-phase FTIR spectra measurements can be collected quickly and\nconsistently, offering high reliability, sensitivity, and component specificity\nusing less than 2 mL of sample. The method first decomposes FTIR spectra into\nfundamental building blocks using Non-negative Matrix Factorization (NMF) to\nenable scientific analysis of FTIR spectra attributes and fuel properties. The\nNMF features are then used to create five ensemble models for predicting final\nboiling point, flash point, freezing point, density at 15C, and kinematic\nviscosity at -20C. All models were trained using experimental property data\nfrom neat molecules, aviation fuels, and blends. The models accurately predict\nproperties while enabling interpretation of relationships between compositional\nelements of a fuel, such as functional groups or chemical classes, and its\nproperties. To support sustainable aviation fuel research and development, the\nmodels and data are available on an interactive web tool.",
    "arxiv_id": "http://arxiv.org/abs/2408.01530v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01530v1",
    "primary_category": "physics.chem-ph",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Can multivariate Granger causality detect directed connectivity of a multistable and dynamic biological decision network model?",
    "authors": "Abdoreza Asadpour, KongFatt Wong-Lin",
    "abstract": "Extracting causal connections can advance interpretable AI and machine\nlearning. Granger causality (GC) is a robust statistical method for estimating\ndirected influences (DC) between signals. While GC has been widely applied to\nanalysing neuronal signals in biological neural networks and other domains, its\napplication to complex, nonlinear, and multistable neural networks is less\nexplored. In this study, we applied time-domain multi-variate Granger causality\n(MVGC) to the time series neural activity of all nodes in a trained multistable\nbiologically based decision neural network model with real-time decision\nuncertainty monitoring. Our analysis demonstrated that challenging two-choice\ndecisions, where input signals could be closely matched, and the appropriate\napplication of fine-grained sliding time windows, could readily reveal the\noriginal model's DC. Furthermore, the identified DC varied based on whether the\nnetwork had correct or error decisions. Integrating the identified DC from\ndifferent decision outcomes recovered most of the original model's\narchitecture, despite some spurious and missing connectivity. This approach\ncould be used as an initial exploration to enhance the interpretability and\ntransparency of dynamic multistable and nonlinear biological or AI systems by\nrevealing causal connections throughout different phases of neural network\ndynamics and outcomes.",
    "arxiv_id": "http://arxiv.org/abs/2408.01528v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01528v1",
    "primary_category": "q-bio.NC",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Analyzing LLMs' Capabilities to Establish Implicit User Sentiment of Software Desirability",
    "authors": "Sherri Weitl-Harms, John D. Hastings, Jonah Lum",
    "abstract": "This study explores the use of several LLMs for providing quantitative\nzero-shot sentiment analysis of implicit software desirability expressed by\nusers. The study provides scaled numerical sentiment analysis unlike other\nmethods that simply classify sentiment as positive, neutral, or negative.\nNumerical analysis provides deeper insights into the magnitude of sentiment, to\ndrive better decisions regarding product desirability.\n  Data is collected through the use of the Microsoft Product Desirability\nToolkit (PDT), a well-known qualitative user experience analysis tool. For\ninitial exploration, the PDT metric was given to users of ZORQ, a gamification\nsystem used in undergraduate computer science education. The PDT data collected\nwas fed through several LLMs (Claude Sonnet 3 and 3.5, GPT4, and GPT4o) and\nthrough a leading transfer learning technique, Twitter-Roberta-Base-Sentiment\n(TRBS), and through Vader, a leading sentiment analysis tool, for quantitative\nsentiment analysis. Each system was asked to evaluate the data in two ways,\nfirst by looking at the sentiment expressed in the PDT word/explanation pairs;\nand by looking at the sentiment expressed by the users in their grouped\nselection of five words and explanations, as a whole. Each LLM was also asked\nto provide its confidence (low, medium, high) in its sentiment score, along\nwith an explanation of why it selected the sentiment value.\n  All LLMs tested were able to statistically detect user sentiment from the\nusers' grouped data, whereas TRBS and Vader were not. The confidence and\nexplanation of confidence provided by the LLMs assisted in understanding the\nuser sentiment. This study adds to a deeper understanding of evaluating user\nexperiences, toward the goal of creating a universal tool that quantifies\nimplicit sentiment expressed.",
    "arxiv_id": "http://arxiv.org/abs/2408.01527v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01527v1",
    "primary_category": "cs.CL",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "A probabilistic framework for learning non-intrusive corrections to long-time climate simulations from short-time training data",
    "authors": "Benedikt Barthel Sorensen, Leonardo Zepeda-N\u00fa\u00f1ez, Ignacio Lopez-Gomez, Zhong Yi Wan, Rob Carver, Fei Sha, Themistoklis Sapsis",
    "abstract": "Chaotic systems, such as turbulent flows, are ubiquitous in science and\nengineering. However, their study remains a challenge due to the large range\nscales, and the strong interaction with other, often not fully understood,\nphysics. As a consequence, the spatiotemporal resolution required for accurate\nsimulation of these systems is typically computationally infeasible,\nparticularly for applications of long-term risk assessment, such as the\nquantification of extreme weather risk due to climate change. While data-driven\nmodeling offers some promise of alleviating these obstacles, the scarcity of\nhigh-quality simulations results in limited available data to train such\nmodels, which is often compounded by the lack of stability for long-horizon\nsimulations. As such, the computational, algorithmic, and data restrictions\ngenerally imply that the probability of rare extreme events is not accurately\ncaptured. In this work we present a general strategy for training neural\nnetwork models to non-intrusively correct under-resolved long-time simulations\nof chaotic systems. The approach is based on training a post-processing\ncorrection operator on under-resolved simulations nudged towards a\nhigh-fidelity reference. This enables us to learn the dynamics of the\nunderlying system directly, which allows us to use very little training data,\neven when the statistics thereof are far from converged. Additionally, through\nthe use of probabilistic network architectures we are able to leverage the\nuncertainty due to the limited training data to further improve extrapolation\ncapabilities. We apply our framework to severely under-resolved simulations of\nquasi-geostrophic flow and demonstrate its ability to accurately predict the\nanisotropic statistics over time horizons more than 30 times longer than the\ndata seen in training.",
    "arxiv_id": "http://arxiv.org/abs/2408.02688v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02688v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Gradient flow in parameter space is equivalent to linear interpolation in output space",
    "authors": "Thomas Chen, Patr\u00edcia Mu\u00f1oz Ewald",
    "abstract": "We prove that the usual gradient flow in parameter space that underlies many\ntraining algorithms for neural networks in deep learning can be continuously\ndeformed into an adapted gradient flow which yields (constrained) Euclidean\ngradient flow in output space. Moreover, if the Jacobian of the outputs with\nrespect to the parameters is full rank (for fixed training data), then the time\nvariable can be reparametrized so that the resulting flow is simply linear\ninterpolation, and a global minimum can be achieved.",
    "arxiv_id": "http://arxiv.org/abs/2408.01517v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01517v1",
    "primary_category": "cs.LG",
    "votes": 1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Adaptive Planning with Generative Models under Uncertainty",
    "authors": "Pascal Jutras-Dub\u00e9, Ruqi Zhang, Aniket Bera",
    "abstract": "Planning with generative models has emerged as an effective decision-making\nparadigm across a wide range of domains, including reinforcement learning and\nautonomous navigation. While continuous replanning at each timestep might seem\nintuitive because it allows decisions to be made based on the most recent\nenvironmental observations, it results in substantial computational challenges,\nprimarily due to the complexity of the generative model's underlying deep\nlearning architecture. Our work addresses this challenge by introducing a\nsimple adaptive planning policy that leverages the generative model's ability\nto predict long-horizon state trajectories, enabling the execution of multiple\nactions consecutively without the need for immediate replanning. We propose to\nuse the predictive uncertainty derived from a Deep Ensemble of inverse dynamics\nmodels to dynamically adjust the intervals between planning sessions. In our\nexperiments conducted on locomotion tasks within the OpenAI Gym framework, we\ndemonstrate that our adaptive planning policy allows for a reduction in\nreplanning frequency to only about 10% of the steps without compromising the\nperformance. Our results underscore the potential of generative modeling as an\nefficient and effective tool for decision-making.",
    "arxiv_id": "http://arxiv.org/abs/2408.01510v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01510v1",
    "primary_category": "cs.RO",
    "votes": 1,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Efficient Graph Coloring with Neural Networks: A Physics-Inspired Approach for Large Graphs",
    "authors": "Lorenzo Colantonio, Andrea Cacioppo, Federico Scarpati, Stefano Giagu",
    "abstract": "The graph coloring problem is an optimization problem involving the\nassignment of one of q colors to each vertex of a graph such that no two\nadjacent vertices share the same color. This problem is NP-hard and arises in\nvarious practical applications. In this work, we present a novel algorithm that\nleverages graph neural networks to tackle the problem efficiently, particularly\nfor large graphs. We propose a physics-inspired approach that leverages tools\nused in statistical mechanics to improve the training and performance of the\nalgorithm. The scaling of our method is evaluated for different connectivities\nand graph sizes. Finally, we demonstrate the effectiveness of our method on a\ndataset of Erdos-Renyi graphs, showing its applicability also in hard-to-solve\nconnectivity regions where traditional methods struggle.",
    "arxiv_id": "http://arxiv.org/abs/2408.01503v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01503v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "NeuralFactors: A Novel Factor Learning Approach to Generative Modeling of Equities",
    "authors": "Achintya Gopal",
    "abstract": "The use of machine learning for statistical modeling (and thus, generative\nmodeling) has grown in popularity with the proliferation of time series models,\ntext-to-image models, and especially large language models. Fundamentally, the\ngoal of classical factor modeling is statistical modeling of stock returns, and\nin this work, we explore using deep generative modeling to enhance classical\nfactor models. Prior work has explored the use of deep generative models in\norder to model hundreds of stocks, leading to accurate risk forecasting and\nalpha portfolio construction; however, that specific model does not allow for\neasy factor modeling interpretation in that the factor exposures cannot be\ndeduced. In this work, we introduce NeuralFactors, a novel machine-learning\nbased approach to factor analysis where a neural network outputs factor\nexposures and factor returns, trained using the same methodology as variational\nautoencoders. We show that this model outperforms prior approaches both in\nterms of log-likelihood performance and computational efficiency. Further, we\nshow that this method is competitive to prior work in generating realistic\nsynthetic data, covariance estimation, risk analysis (e.g., value at risk, or\nVaR, of portfolios), and portfolio optimization. Finally, due to the connection\nto classical factor analysis, we analyze how the factors our model learns\ncluster together and show that the factor exposures could be used for embedding\nstocks.",
    "arxiv_id": "http://arxiv.org/abs/2408.01499v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01499v1",
    "primary_category": "q-fin.ST",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Using a CNN Model to Assess Visual Artwork's Creativity",
    "authors": "Zhehan Zhang, Meihua Qian, Li Luo, Ripon Saha, Qianyi Gao, Xinxin Song",
    "abstract": "Assessing artistic creativity has long challenged researchers, with\ntraditional methods proving time-consuming. Recent studies have applied machine\nlearning to evaluate creativity in drawings, but not paintings. Our research\naddresses this gap by developing a CNN model to automatically assess the\ncreativity of students' paintings. Using a dataset of 600 paintings by\nprofessionals and children, our model achieved 90% accuracy and faster\nevaluation times than human raters. This approach demonstrates the potential of\nmachine learning in advancing artistic creativity assessment, offering a more\nefficient alternative to traditional methods.",
    "arxiv_id": "http://arxiv.org/abs/2408.01481v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01481v1",
    "primary_category": "cs.CV",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Mission Impossible: A Statistical Perspective on Jailbreaking LLMs",
    "authors": "Jingtong Su, Julia Kempe, Karen Ullrich",
    "abstract": "Large language models (LLMs) are trained on a deluge of text data with\nlimited quality control. As a result, LLMs can exhibit unintended or even\nharmful behaviours, such as leaking information, fake news or hate speech.\nCountermeasures, commonly referred to as preference alignment, include\nfine-tuning the pretrained LLMs with carefully crafted text examples of desired\nbehaviour. Even then, empirical evidence shows preference aligned LLMs can be\nenticed to harmful behaviour. This so called jailbreaking of LLMs is typically\nachieved by adversarially modifying the input prompt to the LLM. Our paper\nprovides theoretical insights into the phenomenon of preference alignment and\njailbreaking from a statistical perspective. Under our framework, we first show\nthat pretrained LLMs will mimic harmful behaviour if present in the training\ncorpus. Under that same framework, we then introduce a statistical notion of\nalignment, and lower-bound the jailbreaking probability, showing that it is\nunpreventable under reasonable assumptions. Based on our insights, we propose\nan alteration to the currently prevalent alignment strategy RLHF. Specifically,\nwe introduce a simple modification to the RLHF objective, we call E-RLHF, that\naims to increase the likelihood of safe responses. E-RLHF brings no additional\ntraining cost, and is compatible with other methods. Empirically, we\ndemonstrate that E-RLHF outperforms RLHF on all alignment problems put forward\nby the AdvBench and HarmBench project without sacrificing model performance as\nmeasured by the MT-Bench project.",
    "arxiv_id": "http://arxiv.org/abs/2408.01420v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01420v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Talk Less, Interact Better: Evaluating In-context Conversational Adaptation in Multimodal LLMs",
    "authors": "Yilun Hua, Yoav Artzi",
    "abstract": "Humans spontaneously use increasingly efficient language as interactions\nprogress, by adapting and forming ad-hoc conventions. This phenomenon has been\nstudied extensively using reference games, showing properties of human language\nthat go beyond relaying intents. It remains unexplored whether multimodal large\nlanguage models (MLLMs) similarly increase communication efficiency during\ninteractions, and what mechanisms they may adopt for this purpose. We introduce\nICCA, an automated framework to evaluate such conversational adaptation as an\nin-context behavior in MLLMs. We evaluate several state-of-the-art MLLMs, and\nobserve that while they may understand the increasingly efficient language of\ntheir interlocutor, they do not spontaneously make their own language more\nefficient over time. This latter ability can only be elicited in some models\n(e.g., GPT-4) with heavy-handed prompting. This shows that this property of\nlinguistic interaction does not arise from current training regimes, even\nthough it is a common hallmark of human language. ICCA is available at\nhttps://github.com/lil-lab/ICCA.",
    "arxiv_id": "http://arxiv.org/abs/2408.01417v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01417v1",
    "primary_category": "cs.CL",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "The Quest for the Right Mediator: A History, Survey, and Theoretical Grounding of Causal Interpretability",
    "authors": "Aaron Mueller, Jannik Brinkmann, Millicent Li, Samuel Marks, Koyena Pal, Nikhil Prakash, Can Rager, Aruna Sankaranarayanan, Arnab Sen Sharma, Jiuding Sun, Eric Todd, David Bau, Yonatan Belinkov",
    "abstract": "Interpretability provides a toolset for understanding how and why neural\nnetworks behave in certain ways. However, there is little unity in the field:\nmost studies employ ad-hoc evaluations and do not share theoretical\nfoundations, making it difficult to measure progress and compare the pros and\ncons of different techniques. Furthermore, while mechanistic understanding is\nfrequently discussed, the basic causal units underlying these mechanisms are\noften not explicitly defined. In this paper, we propose a perspective on\ninterpretability research grounded in causal mediation analysis. Specifically,\nwe describe the history and current state of interpretability taxonomized\naccording to the types of causal units (mediators) employed, as well as methods\nused to search over mediators. We discuss the pros and cons of each mediator,\nproviding insights as to when particular kinds of mediators and search methods\nare most appropriate depending on the goals of a given study. We argue that\nthis framing yields a more cohesive narrative of the field, as well as\nactionable insights for future work. Specifically, we recommend a focus on\ndiscovering new mediators with better trade-offs between human-interpretability\nand compute-efficiency, and which can uncover more sophisticated abstractions\nfrom neural networks than the primarily linear mediators employed in current\nwork. We also argue for more standardized evaluations that enable principled\ncomparisons across mediator types, such that we can better understand when\nparticular causal units are better suited to particular use cases.",
    "arxiv_id": "http://arxiv.org/abs/2408.01416v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01416v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Conditional LoRA Parameter Generation",
    "authors": "Xiaolong Jin, Kai Wang, Dongwen Tang, Wangbo Zhao, Yukun Zhou, Junshu Tang, Yang You",
    "abstract": "Generative models have achieved remarkable success in image, video, and text\ndomains. Inspired by this, researchers have explored utilizing generative\nmodels to generate neural network parameters. However, these efforts have been\nlimited by the parameter size and the practicality of generating\nhigh-performance parameters. In this paper, we propose COND P-DIFF, a novel\napproach that demonstrates the feasibility of controllable high-performance\nparameter generation, particularly for LoRA (Low-Rank Adaptation) weights,\nduring the fine-tuning process. Specifically, we employ an autoencoder to\nextract efficient latent representations for parameters. We then train a\nconditional latent diffusion model to synthesize high-performing model\nparameters from random noise based on specific task conditions. Experimental\nresults in both computer vision and natural language processing domains\nconsistently demonstrate that COND P-DIFF can generate high-performance\nparameters conditioned on the given task. Moreover, we observe that the\nparameter distribution generated by COND P-DIFF exhibits differences compared\nto the distribution obtained through normal optimization methods, indicating a\ncertain level of generalization capability. Our work paves the way for further\nexploration of condition-driven parameter generation, offering a promising\ndirection for task-specific adaptation of neural networks.",
    "arxiv_id": "http://arxiv.org/abs/2408.01415v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01415v1",
    "primary_category": "cs.AI",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Derivation of Back-propagation for Graph Convolutional Networks using Matrix Calculus and its Application to Explainable Artificial Intelligence",
    "authors": "Yen-Che Hsiao, Rongting Yue, Abhishek Dutta",
    "abstract": "This paper provides a comprehensive and detailed derivation of the\nbackpropagation algorithm for graph convolutional neural networks using matrix\ncalculus. The derivation is extended to include arbitrary element-wise\nactivation functions and an arbitrary number of layers. The study addresses two\nfundamental problems, namely node classification and link prediction. To\nvalidate our method, we compare it with reverse-mode automatic differentiation.\nThe experimental results demonstrate that the median sum of squared errors of\nthe updated weight matrices, when comparing our method to the approach using\nreverse-mode automatic differentiation, falls within the range of $10^{-18}$ to\n$10^{-14}$. These outcomes are obtained from conducting experiments on a\nfive-layer graph convolutional network, applied to a node classification\nproblem on Zachary's karate club social network and a link prediction problem\non a drug-drug interaction network. Finally, we show how the derived\nclosed-form solution can facilitate the development of explainable AI and\nsensitivity analysis.",
    "arxiv_id": "http://arxiv.org/abs/2408.01408v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01408v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Pre-trained Language Models Improve the Few-shot Prompt Ability of Decision Transformer",
    "authors": "Yu Yang, Pan Xu",
    "abstract": "Decision Transformer (DT) has emerged as a promising class of algorithms in\noffline reinforcement learning (RL) tasks, leveraging pre-collected datasets\nand Transformer's capability to model long sequences. Recent works have\ndemonstrated that using parts of trajectories from training tasks as prompts in\nDT enhances its performance on unseen tasks, giving rise to Prompt-DT methods.\nHowever, collecting data from specific environments can be both costly and\nunsafe in many scenarios, leading to suboptimal performance and limited\nfew-shot prompt abilities due to the data-hungry nature of Transformer-based\nmodels. Additionally, the limited datasets used in pre-training make it\nchallenging for Prompt-DT type of methods to distinguish between various RL\ntasks through prompts alone. To address these challenges, we introduce the\nLanguage model-initialized Prompt Decision Transformer (LPDT), which leverages\npre-trained language models for meta-RL tasks and fine-tunes the model using\nLow-rank Adaptation (LoRA). We further incorporate prompt regularization to\neffectively differentiate between tasks based on prompt feature\nrepresentations. Our approach integrates pre-trained language model and RL\ntasks seamlessly. Extensive empirical studies demonstrate that initializing\nwith a pre-trained language model significantly enhances the performance of\nPrompt-DT on unseen tasks compared to baseline methods.",
    "arxiv_id": "http://arxiv.org/abs/2408.01402v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01402v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "FT K-Means: A High-Performance K-Means on GPU with Fault Tolerance",
    "authors": "Shixun Wu, Yitong Ding, Yujia Zhai, Jinyang Liu, Jiajun Huang, Zizhe Jian, Huangliang Dai, Sheng Di, Bryan M. Wong, Zizhong Chen, Franck Cappello",
    "abstract": "K-Means is a widely used algorithm in clustering, however, its efficiency is\nprimarily constrained by the computational cost of distance computing. Existing\nimplementations suffer from suboptimal utilization of computational units and\nlack resilience against soft errors. To address these challenges, we introduce\nFT K-Means, a high-performance GPU-accelerated implementation of K-Means with\nonline fault tolerance. We first present a stepwise optimization strategy that\nachieves competitive performance compared to NVIDIA's cuML library. We further\nimprove FT K-Means with a template-based code generation framework that\nsupports different data types and adapts to different input shapes. A novel\nwarp-level tensor-core error correction scheme is proposed to address the\nfailure of existing fault tolerance methods due to memory asynchronization\nduring copy operations. Our experimental evaluations on NVIDIA T4 GPU and A100\nGPU demonstrate that FT K-Means without fault tolerance outperforms cuML's\nK-Means implementation, showing a performance increase of 10\\%-300\\% in\nscenarios involving irregular data shapes. Moreover, the fault tolerance\nfeature of FT K-Means introduces only an overhead of 11\\%, maintaining robust\nperformance even with tens of errors injected per second.",
    "arxiv_id": "http://arxiv.org/abs/2408.01391v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01391v1",
    "primary_category": "cs.DC",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "NeuralBeta: Estimating Beta Using Deep Learning",
    "authors": "Yuxin Liu, Jimin Lin, Achintya Gopal",
    "abstract": "Traditional approaches to estimating beta in finance often involve rigid\nassumptions and fail to adequately capture beta dynamics, limiting their\neffectiveness in use cases like hedging. To address these limitations, we have\ndeveloped a novel method using neural networks called NeuralBeta, which is\ncapable of handling both univariate and multivariate scenarios and tracking the\ndynamic behavior of beta. To address the issue of interpretability, we\nintroduce a new output layer inspired by regularized weighted linear\nregression, which provides transparency into the model's decision-making\nprocess. We conducted extensive experiments on both synthetic and market data,\ndemonstrating NeuralBeta's superior performance compared to benchmark methods\nacross various scenarios, especially instances where beta is highly\ntime-varying, e.g., during regime shifts in the market. This model not only\nrepresents an advancement in the field of beta estimation, but also shows\npotential for applications in other financial contexts that assume linear\nrelationships.",
    "arxiv_id": "http://arxiv.org/abs/2408.01387v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01387v1",
    "primary_category": "q-fin.ST",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Explaining a probabilistic prediction on the simplex with Shapley compositions",
    "authors": "Paul-Gauthier No\u00e9, Miquel Perell\u00f3-Nieto, Jean-Fran\u00e7ois Bonastre, Peter Flach",
    "abstract": "Originating in game theory, Shapley values are widely used for explaining a\nmachine learning model's prediction by quantifying the contribution of each\nfeature's value to the prediction. This requires a scalar prediction as in\nbinary classification, whereas a multiclass probabilistic prediction is a\ndiscrete probability distribution, living on a multidimensional simplex. In\nsuch a multiclass setting the Shapley values are typically computed separately\non each class in a one-vs-rest manner, ignoring the compositional nature of the\noutput distribution. In this paper, we introduce Shapley compositions as a\nwell-founded way to properly explain a multiclass probabilistic prediction,\nusing the Aitchison geometry from compositional data analysis. We prove that\nthe Shapley composition is the unique quantity satisfying linearity, symmetry\nand efficiency on the Aitchison simplex, extending the corresponding axiomatic\nproperties of the standard Shapley value. We demonstrate this proper multiclass\ntreatment in a range of scenarios.",
    "arxiv_id": "http://arxiv.org/abs/2408.01382v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01382v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Resampling and averaging coordinates on data",
    "authors": "Andrew J. Blumberg, Mathieu Carriere, Jun Hou Fung, Michael A. Mandell",
    "abstract": "We introduce algorithms for robustly computing intrinsic coordinates on point\nclouds. Our approach relies on generating many candidate coordinates by\nsubsampling the data and varying hyperparameters of the embedding algorithm\n(e.g., manifold learning). We then identify a subset of representative\nembeddings by clustering the collection of candidate coordinates and using\nshape descriptors from topological data analysis. The final output is the\nembedding obtained as an average of the representative embeddings using\ngeneralized Procrustes analysis. We validate our algorithm on both synthetic\ndata and experimental measurements from genomics, demonstrating robustness to\nnoise and outliers.",
    "arxiv_id": "http://arxiv.org/abs/2408.01379v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01379v1",
    "primary_category": "stat.ML",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Adaptive Recruitment Resource Allocation to Improve Cohort Representativeness in Participatory Biomedical Datasets",
    "authors": "Victor Borza, Andrew Estornell, Ellen Wright Clayton, Chien-Ju Ho, Russell Rothman, Yevgeniy Vorobeychik, Bradley Malin",
    "abstract": "Large participatory biomedical studies, studies that recruit individuals to\njoin a dataset, are gaining popularity and investment, especially for analysis\nby modern AI methods. Because they purposively recruit participants, these\nstudies are uniquely able to address a lack of historical representation, an\nissue that has affected many biomedical datasets. In this work, we define\nrepresentativeness as the similarity to a target population distribution of a\nset of attributes and our goal is to mirror the U.S. population across\ndistributions of age, gender, race, and ethnicity. Many participatory studies\nrecruit at several institutions, so we introduce a computational approach to\nadaptively allocate recruitment resources among sites to improve\nrepresentativeness. In simulated recruitment of 10,000-participant cohorts from\nmedical centers in the STAR Clinical Research Network, we show that our\napproach yields a more representative cohort than existing baselines. Thus, we\nhighlight the value of computational modeling in guiding recruitment efforts.",
    "arxiv_id": "http://arxiv.org/abs/2408.01375v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01375v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Hybrid Coordinate Descent for Efficient Neural Network Learning Using Line Search and Gradient Descent",
    "authors": "Yen-Che Hsiao, Abhishek Dutta",
    "abstract": "This paper presents a novel coordinate descent algorithm leveraging a\ncombination of one-directional line search and gradient information for\nparameter updates for a squared error loss function. Each parameter undergoes\nupdates determined by either the line search or gradient method, contingent\nupon whether the modulus of the gradient of the loss with respect to that\nparameter surpasses a predefined threshold. Notably, a larger threshold value\nenhances algorithmic efficiency. Despite the potentially slower nature of the\nline search method relative to gradient descent, its parallelizability\nfacilitates computational time reduction. Experimental validation conducted on\na 2-layer Rectified Linear Unit network with synthetic data elucidates the\nimpact of hyperparameters on convergence rates and computational efficiency.",
    "arxiv_id": "http://arxiv.org/abs/2408.01374v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01374v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Data Debugging is NP-hard for Classifiers Trained with SGD",
    "authors": "Zizheng Guo, Pengyu Chen, Yanzhang Fu, Dongjing Miao",
    "abstract": "Data debugging is to find a subset of the training data such that the model\nobtained by retraining on the subset has a better accuracy. A bunch of\nheuristic approaches are proposed, however, none of them are guaranteed to\nsolve this problem effectively. This leaves an open issue whether there exists\nan efficient algorithm to find the subset such that the model obtained by\nretraining on it has a better accuracy. To answer this open question and\nprovide theoretical basis for further study on developing better algorithms for\ndata debugging, we investigate the computational complexity of the problem\nnamed Debuggable. Given a machine learning model $\\mathcal{M}$ obtained by\ntraining on dataset $D$ and a test instance\n$(\\mathbf{x}_\\text{test},y_\\text{test})$ where\n$\\mathcal{M}(\\mathbf{x}_\\text{test})\\neq y_\\text{test}$, Debuggable is to\ndetermine whether there exists a subset $D^\\prime$ of $D$ such that the model\n$\\mathcal{M}^\\prime$ obtained by retraining on $D^\\prime$ satisfies\n$\\mathcal{M}^\\prime(\\mathbf{x}_\\text{test})=y_\\text{test}$. To cover a wide\nrange of commonly used models, we take SGD-trained linear classifier as the\nmodel and derive the following main results. (1) If the loss function and the\ndimension of the model are not fixed, Debuggable is NP-complete regardless of\nthe training order in which all the training samples are processed during SGD.\n(2) For hinge-like loss functions, a comprehensive analysis on the\ncomputational complexity of Debuggable is provided; (3) If the loss function is\na linear function, Debuggable can be solved in linear time, that is, data\ndebugging can be solved easily in this case. These results not only highlight\nthe limitations of current approaches but also offer new insights into data\ndebugging.",
    "arxiv_id": "http://arxiv.org/abs/2408.01365v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01365v1",
    "primary_category": "cs.CC",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Autoencoders in Function Space",
    "authors": "Justin Bunker, Mark Girolami, Hefin Lambley, Andrew M. Stuart, T. J. Sullivan",
    "abstract": "Autoencoders have found widespread application, in both their original\ndeterministic form and in their variational formulation (VAEs). In scientific\napplications it is often of interest to consider data that are comprised of\nfunctions; the same perspective is useful in image processing. In practice,\ndiscretisation (of differential equations arising in the sciences) or\npixellation (of images) renders problems finite dimensional, but conceiving\nfirst of algorithms that operate on functions, and only then discretising or\npixellating, leads to better algorithms that smoothly operate between different\nlevels of discretisation or pixellation. In this paper function-space versions\nof the autoencoder (FAE) and variational autoencoder (FVAE) are introduced,\nanalysed, and deployed. Well-definedness of the objective function governing\nVAEs is a subtle issue, even in finite dimension, and more so on function\nspace. The FVAE objective is well defined whenever the data distribution is\ncompatible with the chosen generative model; this happens, for example, when\nthe data arise from a stochastic differential equation. The FAE objective is\nvalid much more broadly, and can be straightforwardly applied to data governed\nby differential equations. Pairing these objectives with neural operator\narchitectures, which can thus be evaluated on any mesh, enables new\napplications of autoencoders to inpainting, superresolution, and generative\nmodelling of scientific data.",
    "arxiv_id": "http://arxiv.org/abs/2408.01362v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01362v1",
    "primary_category": "stat.ML",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "PC$^2$: Pseudo-Classification Based Pseudo-Captioning for Noisy Correspondence Learning in Cross-Modal Retrieval",
    "authors": "Yue Duan, Zhangxuan Gu, Zhenzhe Ying, Lei Qi, Changhua Meng, Yinghuan Shi",
    "abstract": "In the realm of cross-modal retrieval, seamlessly integrating diverse\nmodalities within multimedia remains a formidable challenge, especially given\nthe complexities introduced by noisy correspondence learning (NCL). Such noise\noften stems from mismatched data pairs, which is a significant obstacle\ndistinct from traditional noisy labels. This paper introduces\nPseudo-Classification based Pseudo-Captioning (PC$^2$) framework to address\nthis challenge. PC$^2$ offers a threefold strategy: firstly, it establishes an\nauxiliary \"pseudo-classification\" task that interprets captions as categorical\nlabels, steering the model to learn image-text semantic similarity through a\nnon-contrastive mechanism. Secondly, unlike prevailing margin-based techniques,\ncapitalizing on PC$^2$'s pseudo-classification capability, we generate\npseudo-captions to provide more informative and tangible supervision for each\nmismatched pair. Thirdly, the oscillation of pseudo-classification is borrowed\nto assistant the correction of correspondence. In addition to technical\ncontributions, we develop a realistic NCL dataset called Noise of Web (NoW),\nwhich could be a new powerful NCL benchmark where noise exists naturally.\nEmpirical evaluations of PC$^2$ showcase marked improvements over existing\nstate-of-the-art robust cross-modal retrieval techniques on both simulated and\nrealistic datasets with various NCL settings. The contributed dataset and\nsource code are released at https://github.com/alipay/PC2-NoiseofWeb.",
    "arxiv_id": "http://arxiv.org/abs/2408.01349v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01349v1",
    "primary_category": "cs.MM",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "StitchFusion: Weaving Any Visual Modalities to Enhance Multimodal Semantic Segmentation",
    "authors": "Bingyu Li, Da Zhang, Zhiyuan Zhao, Junyu Gao, Xuelong Li",
    "abstract": "Multimodal semantic segmentation shows significant potential for enhancing\nsegmentation accuracy in complex scenes. However, current methods often\nincorporate specialized feature fusion modules tailored to specific modalities,\nthereby restricting input flexibility and increasing the number of training\nparameters. To address these challenges, we propose StitchFusion, a\nstraightforward yet effective modal fusion framework that integrates\nlarge-scale pre-trained models directly as encoders and feature fusers. This\napproach facilitates comprehensive multi-modal and multi-scale feature fusion,\naccommodating any visual modal inputs. Specifically, Our framework achieves\nmodal integration during encoding by sharing multi-modal visual information. To\nenhance information exchange across modalities, we introduce a\nmulti-directional adapter module (MultiAdapter) to enable cross-modal\ninformation transfer during encoding. By leveraging MultiAdapter to propagate\nmulti-scale information across pre-trained encoders during the encoding\nprocess, StitchFusion achieves multi-modal visual information integration\nduring encoding. Extensive comparative experiments demonstrate that our model\nachieves state-of-the-art performance on four multi-modal segmentation datasets\nwith minimal additional parameters. Furthermore, the experimental integration\nof MultiAdapter with existing Feature Fusion Modules (FFMs) highlights their\ncomplementary nature. Our code is available at StitchFusion_repo.",
    "arxiv_id": "http://arxiv.org/abs/2408.01343v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01343v1",
    "primary_category": "cs.CV",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "MuChoMusic: Evaluating Music Understanding in Multimodal Audio-Language Models",
    "authors": "Benno Weck, Ilaria Manco, Emmanouil Benetos, Elio Quinton, George Fazekas, Dmitry Bogdanov",
    "abstract": "Multimodal models that jointly process audio and language hold great promise\nin audio understanding and are increasingly being adopted in the music domain.\nBy allowing users to query via text and obtain information about a given audio\ninput, these models have the potential to enable a variety of music\nunderstanding tasks via language-based interfaces. However, their evaluation\nposes considerable challenges, and it remains unclear how to effectively assess\ntheir ability to correctly interpret music-related inputs with current methods.\nMotivated by this, we introduce MuChoMusic, a benchmark for evaluating music\nunderstanding in multimodal language models focused on audio. MuChoMusic\ncomprises 1,187 multiple-choice questions, all validated by human annotators,\non 644 music tracks sourced from two publicly available music datasets, and\ncovering a wide variety of genres. Questions in the benchmark are crafted to\nassess knowledge and reasoning abilities across several dimensions that cover\nfundamental musical concepts and their relation to cultural and functional\ncontexts. Through the holistic analysis afforded by the benchmark, we evaluate\nfive open-source models and identify several pitfalls, including an\nover-reliance on the language modality, pointing to a need for better\nmultimodal integration. Data and code are open-sourced.",
    "arxiv_id": "http://arxiv.org/abs/2408.01337v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01337v1",
    "primary_category": "cs.SD",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Sparse Linear Regression when Noises and Covariates are Heavy-Tailed and Contaminated by Outliers",
    "authors": "Takeyuki Sasai, Hironori Fujisawa",
    "abstract": "We investigate a problem estimating coefficients of linear regression under\nsparsity assumption when covariates and noises are sampled from heavy tailed\ndistributions. Additionally, we consider the situation where not only\ncovariates and noises are sampled from heavy tailed distributions but also\ncontaminated by outliers. Our estimators can be computed efficiently, and\nexhibit sharp error bounds.",
    "arxiv_id": "http://arxiv.org/abs/2408.01336v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01336v1",
    "primary_category": "stat.ML",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "HMDN: Hierarchical Multi-Distribution Network for Click-Through Rate Prediction",
    "authors": "Xingyu Lou, Yu Yang, Kuiyao Dong, Heyuan Huang, Wenyi Yu, Ping Wang, Xiu Li, Jun Wang",
    "abstract": "As the recommendation service needs to address increasingly diverse\ndistributions, such as multi-population, multi-scenario, multitarget, and\nmulti-interest, more and more recent works have focused on multi-distribution\nmodeling and achieved great progress. However, most of them only consider\nmodeling in a single multi-distribution manner, ignoring that mixed\nmulti-distributions often coexist and form hierarchical relationships. To\naddress these challenges, we propose a flexible modeling paradigm, named\nHierarchical Multi-Distribution Network (HMDN), which efficiently models these\nhierarchical relationships and can seamlessly integrate with existing\nmulti-distribution methods, such as Mixture of-Experts (MoE) and Dynamic-Weight\n(DW) models. Specifically, we first design a hierarchical multi-distribution\nrepresentation refinement module, employing a multi-level residual quantization\nto obtain fine-grained hierarchical representation. Then, the refined\nhierarchical representation is integrated into the existing single\nmulti-distribution models, seamlessly expanding them into mixed\nmulti-distribution models. Experimental results on both public and industrial\ndatasets validate the effectiveness and flexibility of HMDN.",
    "arxiv_id": "http://arxiv.org/abs/2408.01332v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01332v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "UnifiedNN: Efficient Neural Network Training on the Cloud",
    "authors": "Sifat Ut Taki, Arthi Padmanabhan, Spyridon Mastorakis",
    "abstract": "Nowadays, cloud-based services are widely favored over the traditional\napproach of locally training a Neural Network (NN) model. Oftentimes, a cloud\nservice processes multiple requests from users--thus training multiple NN\nmodels concurrently. However, training NN models concurrently is a challenging\nprocess, which typically requires significant amounts of available computing\nresources and takes a long time to complete. In this paper, we present\nUnifiedNN to effectively train multiple NN models concurrently on the cloud.\nUnifiedNN effectively \"combines\" multiple NN models and features several memory\nand time conservation mechanisms to train multiple NN models simultaneously\nwithout impacting the accuracy of the training process. Specifically, UnifiedNN\nmerges multiple NN models and creates a large singular unified model in order\nto efficiently train all models at once. We have implemented a prototype of\nUnifiedNN in PyTorch and we have compared its performance with relevant\nstate-of-the-art frameworks. Our experimental results demonstrate that\nUnifiedNN can reduce memory consumption by up to 53% and training time by up to\n81% when compared with vanilla PyTorch without impacting the model training and\ntesting accuracy. Finally, our results indicate that UnifiedNN can reduce\nmemory consumption by up to 52% and training time by up to 41% when compared to\nstate-of-the-art frameworks when training multiple models concurrently.",
    "arxiv_id": "http://arxiv.org/abs/2408.01331v2",
    "pdf_url": "http://arxiv.org/pdf/2408.01331v2",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Point Prediction for Streaming Data",
    "authors": "Aleena Chanda, N. V. Vinodchandran, Bertrand Clarke",
    "abstract": "We present two new approaches for point prediction with streaming data. One\nis based on the Count-Min sketch (CMS) and the other is based on Gaussian\nprocess priors with a random bias. These methods are intended for the most\ngeneral predictive problems where no true model can be usefully formulated for\nthe data stream. In statistical contexts, this is often called the\n$\\mathcal{M}$-open problem class. Under the assumption that the data consists\nof i.i.d samples from a fixed distribution function $F$, we show that the\nCMS-based estimates of the distribution function are consistent.\n  We compare our new methods with two established predictors in terms of\ncumulative $L^1$ error. One is based on the Shtarkov solution (often called the\nnormalized maximum likelihood) in the normal experts setting and the other is\nbased on Dirichlet process priors. These comparisons are for two cases. The\nfirst is one-pass meaning that the updating of the predictors is done using the\nfact that the CMS is a sketch. For predictors that are not one-pass, we use\nstreaming $K$-means to give a representative subset of fixed size that can be\nupdated as data accumulate.\n  Preliminary computational work suggests that the one-pass median version of\nthe CMS method is rarely outperformed by the other methods for sufficiently\ncomplex data. We also find that predictors based on Gaussian process priors\nwith random biases perform well. The Shtarkov predictors we use here did not\nperform as well probably because we were only using the simplest example. The\nother predictors seemed to perform well mainly when the data did not look like\nthey came from an M-open data generator.",
    "arxiv_id": "http://arxiv.org/abs/2408.01318v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01318v1",
    "primary_category": "stat.ML",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Decentralized Smoothing ADMM for Quantile Regression with Non-Convex Sparse Penalties",
    "authors": "Reza Mirzaeifard, Diyako Ghaderyan, Stefan Werner",
    "abstract": "In the rapidly evolving internet-of-things (IoT) ecosystem, effective data\nanalysis techniques are crucial for handling distributed data generated by\nsensors. Addressing the limitations of existing methods, such as the\nsub-gradient approach, which fails to distinguish between active and non-active\ncoefficients effectively, this paper introduces the decentralized smoothing\nalternating direction method of multipliers (DSAD) for penalized quantile\nregression. Our method leverages non-convex sparse penalties like the minimax\nconcave penalty (MCP) and smoothly clipped absolute deviation (SCAD), improving\nthe identification and retention of significant predictors. DSAD incorporates a\ntotal variation norm within a smoothing ADMM framework, achieving consensus\namong distributed nodes and ensuring uniform model performance across disparate\ndata sources. This approach overcomes traditional convergence challenges\nassociated with non-convex penalties in decentralized settings. We present\ntheoretical proofs and extensive simulation results to validate the\neffectiveness of the DSAD, demonstrating its superiority in achieving reliable\nconvergence and enhancing estimation accuracy compared with prior methods.",
    "arxiv_id": "http://arxiv.org/abs/2408.01307v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01307v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "A Decision-driven Methodology for Designing Uncertainty-aware AI Self-Assessment",
    "authors": "Gregory Canal, Vladimir Leung, Philip Sage, Eric Heim, I-Jeng Wang",
    "abstract": "Artificial intelligence (AI) has revolutionized decision-making processes and\nsystems throughout society and, in particular, has emerged as a significant\ntechnology in high-impact scenarios of national interest. Yet, despite AI's\nimpressive predictive capabilities in controlled settings, it still suffers\nfrom a range of practical setbacks preventing its widespread use in various\ncritical scenarios. In particular, it is generally unclear if a given AI\nsystem's predictions can be trusted by decision-makers in downstream\napplications. To address the need for more transparent, robust, and trustworthy\nAI systems, a suite of tools has been developed to quantify the uncertainty of\nAI predictions and, more generally, enable AI to \"self-assess\" the reliability\nof its predictions. In this manuscript, we categorize methods for AI\nself-assessment along several key dimensions and provide guidelines for\nselecting and designing the appropriate method for a practitioner's needs. In\nparticular, we focus on uncertainty estimation techniques that consider the\nimpact of self-assessment on the choices made by downstream decision-makers and\non the resulting costs and benefits of decision outcomes. To demonstrate the\nutility of our methodology for self-assessment design, we illustrate its use\nfor two realistic national-interest scenarios. This manuscript is a practical\nguide for machine learning engineers and AI system users to select the ideal\nself-assessment techniques for each problem.",
    "arxiv_id": "http://arxiv.org/abs/2408.01301v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01301v1",
    "primary_category": "stat.ML",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Assessing Robustness of Machine Learning Models using Covariate Perturbations",
    "authors": "Arun Prakash R, Anwesha Bhattacharyya, Joel Vaughan, Vijayan N. Nair",
    "abstract": "As machine learning models become increasingly prevalent in critical\ndecision-making models and systems in fields like finance, healthcare, etc.,\nensuring their robustness against adversarial attacks and changes in the input\ndata is paramount, especially in cases where models potentially overfit. This\npaper proposes a comprehensive framework for assessing the robustness of\nmachine learning models through covariate perturbation techniques. We explore\nvarious perturbation strategies to assess robustness and examine their impact\non model predictions, including separate strategies for numeric and non-numeric\nvariables, summaries of perturbations to assess and compare model robustness\nacross different scenarios, and local robustness diagnosis to identify any\nregions in the data where a model is particularly unstable. Through empirical\nstudies on real world dataset, we demonstrate the effectiveness of our approach\nin comparing robustness across models, identifying the instabilities in the\nmodel, and enhancing model robustness.",
    "arxiv_id": "http://arxiv.org/abs/2408.01300v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01300v1",
    "primary_category": "stat.ML",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Optimal Mixed Integer Linear Optimization Trained Multivariate Classification Trees",
    "authors": "Brandon Alston, Illya V. Hicks",
    "abstract": "Multivariate decision trees are powerful machine learning tools for\nclassification and regression that attract many researchers and industry\nprofessionals. An optimal binary tree has two types of vertices, (i) branching\nvertices which have exactly two children and where datapoints are assessed on a\nset of discrete features and (ii) leaf vertices at which datapoints are given a\nprediction, and can be obtained by solving a biobjective optimization problem\nthat seeks to (i) maximize the number of correctly classified datapoints and\n(ii) minimize the number of branching vertices. Branching vertices are linear\ncombinations of training features and therefore can be thought of as\nhyperplanes. In this paper, we propose two cut-based mixed integer linear\noptimization (MILO) formulations for designing optimal binary classification\ntrees (leaf vertices assign discrete classes). Our models leverage on-the-fly\nidentification of minimal infeasible subsystems (MISs) from which we derive\ncutting planes that hold the form of packing constraints. We show theoretical\nimprovements on the strongest flow-based MILO formulation currently in the\nliterature and conduct experiments on publicly available datasets to show our\nmodels' ability to scale, strength against traditional branch and bound\napproaches, and robustness in out-of-sample test performance. Our code and data\nare available on GitHub.",
    "arxiv_id": "http://arxiv.org/abs/2408.01297v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01297v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Feature Clock: High-Dimensional Effects in Two-Dimensional Plots",
    "authors": "Olga Ovcharenko, Rita Sevastjanova, Valentina Boeva",
    "abstract": "Humans struggle to perceive and interpret high-dimensional data. Therefore,\nhigh-dimensional data are often projected into two dimensions for\nvisualization. Many applications benefit from complex nonlinear dimensionality\nreduction techniques, but the effects of individual high-dimensional features\nare hard to explain in the two-dimensional space. Most visualization solutions\nuse multiple two-dimensional plots, each showing the effect of one\nhigh-dimensional feature in two dimensions; this approach creates a need for a\nvisual inspection of k plots for a k-dimensional input space. Our solution,\nFeature Clock, provides a novel approach that eliminates the need to inspect\nthese k plots to grasp the influence of original features on the data structure\ndepicted in two dimensions. Feature Clock enhances the explainability and\ncompactness of visualizations of embedded data and is available in an\nopen-source Python library.",
    "arxiv_id": "http://arxiv.org/abs/2408.01294v2",
    "pdf_url": "http://arxiv.org/pdf/2408.01294v2",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "A Tiny Supervised ODL Core with Auto Data Pruning for Human Activity Recognition",
    "authors": "Hiroki Matsutani, Radu Marculescu",
    "abstract": "In this paper, we introduce a low-cost and low-power tiny supervised\non-device learning (ODL) core that can address the distributional shift of\ninput data for human activity recognition. Although ODL for resource-limited\nedge devices has been studied recently, how exactly to provide the training\nlabels to these devices at runtime remains an open-issue. To address this\nproblem, we propose to combine an automatic data pruning with supervised ODL to\nreduce the number queries needed to acquire predicted labels from a nearby\nteacher device and thus save power consumption during model retraining. The\ndata pruning threshold is automatically tuned, eliminating a manual threshold\ntuning. As a tinyML solution at a few mW for the human activity recognition, we\ndesign a supervised ODL core that supports our automatic data pruning using a\n45nm CMOS process technology. We show that the required memory size for the\ncore is smaller than the same-shaped multilayer perceptron (MLP) and the power\nconsumption is only 3.39mW. Experiments using a human activity recognition\ndataset show that the proposed automatic data pruning reduces the communication\nvolume by 55.7% and power consumption accordingly with only 0.9% accuracy loss.",
    "arxiv_id": "http://arxiv.org/abs/2408.01283v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01283v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Certified Robust Invariant Polytope Training in Neural Controlled ODEs",
    "authors": "Akash Harapanahalli, Samuel Coogan",
    "abstract": "We consider a nonlinear control system modeled as an ordinary differential\nequation subject to disturbance, with a state feedback controller parameterized\nas a feedforward neural network. We propose a framework for training\ncontrollers with certified robust forward invariant polytopes, where any\ntrajectory initialized inside the polytope remains within the polytope,\nregardless of the disturbance. First, we parameterize a family of lifted\ncontrol systems in a higher dimensional space, where the original neural\ncontrolled system evolves on an invariant subspace of each lifted system. We\nuse interval analysis and neural network verifiers to further construct a\nfamily of lifted embedding systems, carefully capturing the knowledge of this\ninvariant subspace. If the vector field of any lifted embedding system\nsatisfies a sign constraint at a single point, then a certain convex polytope\nof the original system is robustly forward invariant. Treating the neural\nnetwork controller and the lifted system parameters as variables, we propose an\nalgorithm to train controllers with certified forward invariant polytopes in\nthe closed-loop control system. Through two examples, we demonstrate how the\nsimplicity of the sign constraint allows our approach to scale with system\ndimension to over $50$ states, and outperform state-of-the-art Lyapunov-based\nsampling approaches in runtime.",
    "arxiv_id": "http://arxiv.org/abs/2408.01273v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01273v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Detection and Characterization of Coordinated Online Behavior: A Survey",
    "authors": "Lorenzo Mannocci, Michele Mazza, Anna Monreale, Maurizio Tesconi, Stefano Cresci",
    "abstract": "Coordination is a fundamental aspect of life. The advent of social media has\nmade it integral also to online human interactions, such as those that\ncharacterize thriving online communities and social movements. At the same\ntime, coordination is also core to effective disinformation, manipulation, and\nhate campaigns. This survey collects, categorizes, and critically discusses the\nbody of work produced as a result of the growing interest on coordinated online\nbehavior. We reconcile industry and academic definitions, propose a\ncomprehensive framework to study coordinated online behavior, and review and\ncritically discuss the existing detection and characterization methods. Our\nanalysis identifies open challenges and promising directions of research,\nserving as a guide for scholars, practitioners, and policymakers in\nunderstanding and addressing the complexities inherent to online coordination.",
    "arxiv_id": "http://arxiv.org/abs/2408.01257v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01257v1",
    "primary_category": "cs.SI",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Deep progressive reinforcement learning-based flexible resource scheduling framework for IRS and UAV-assisted MEC system",
    "authors": "Li Dong, Feibo Jiang, Minjie Wang, Yubo Peng, Xiaolong Li",
    "abstract": "The intelligent reflection surface (IRS) and unmanned aerial vehicle\n(UAV)-assisted mobile edge computing (MEC) system is widely used in temporary\nand emergency scenarios. Our goal is to minimize the energy consumption of the\nMEC system by jointly optimizing UAV locations, IRS phase shift, task\noffloading, and resource allocation with a variable number of UAVs. To this\nend, we propose a Flexible REsource Scheduling (FRES) framework by employing a\nnovel deep progressive reinforcement learning which includes the following\ninnovations: Firstly, a novel multi-task agent is presented to deal with the\nmixed integer nonlinear programming (MINLP) problem. The multi-task agent has\ntwo output heads designed for different tasks, in which a classified head is\nemployed to make offloading decisions with integer variables while a fitting\nhead is applied to solve resource allocation with continuous variables.\nSecondly, a progressive scheduler is introduced to adapt the agent to the\nvarying number of UAVs by progressively adjusting a part of neurons in the\nagent. This structure can naturally accumulate experiences and be immune to\ncatastrophic forgetting. Finally, a light taboo search (LTS) is introduced to\nenhance the global search of the FRES. The numerical results demonstrate the\nsuperiority of the FRES framework which can make real-time and optimal resource\nscheduling even in dynamic MEC systems.",
    "arxiv_id": "http://arxiv.org/abs/2408.01248v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01248v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Automated Classification of Dry Bean Varieties Using XGBoost and SVM Models",
    "authors": "Ramtin Ardeshirifar",
    "abstract": "This paper presents a comparative study on the automated classification of\nseven different varieties of dry beans using machine learning models.\nLeveraging a dataset of 12,909 dry bean samples, reduced from an initial 13,611\nthrough outlier removal and feature extraction, we applied Principal Component\nAnalysis (PCA) for dimensionality reduction and trained two multiclass\nclassifiers: XGBoost and Support Vector Machine (SVM). The models were\nevaluated using nested cross-validation to ensure robust performance assessment\nand hyperparameter tuning. The XGBoost and SVM models achieved overall correct\nclassification rates of 94.00% and 94.39%, respectively. The results underscore\nthe efficacy of these machine learning approaches in agricultural applications,\nparticularly in enhancing the uniformity and efficiency of seed classification.\nThis study contributes to the growing body of work on precision agriculture,\ndemonstrating that automated systems can significantly support seed quality\ncontrol and crop yield optimization. Future work will explore incorporating\nmore diverse datasets and advanced algorithms to further improve classification\naccuracy.",
    "arxiv_id": "http://arxiv.org/abs/2408.01244v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01244v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Tailoring Graph Neural Network-based Flow-guided Localization to Individual Bloodstreams and Activities",
    "authors": "Pablo Galv\u00e1n, Filip Lemic, Gerard Calvo Bartra, Sergi Abadal, Xavier Costa P\u00e9rez",
    "abstract": "Flow-guided localization using in-body nanodevices in the bloodstream is\nexpected to be beneficial for early disease detection, continuous monitoring of\nbiological conditions, and targeted treatment. The nanodevices face size and\npower constraints that produce erroneous raw data for localization purposes.\nOn-body anchors receive this data, and use it to derive the locations of\ndiagnostic events of interest. Different Machine Learning (ML) approaches have\nbeen recently proposed for this task, yet they are currently restricted to a\nreference bloodstream of a resting patient. As such, they are unable to deal\nwith the physical diversity of patients' bloodstreams and cannot provide\ncontinuous monitoring due to changes in individual patient's activities. Toward\naddressing these issues for the current State-of-the-Art (SotA) flow-guided\nlocalization approach based on Graph Neural Networks (GNNs), we propose a\npipeline for GNN adaptation based on individual physiological indicators\nincluding height, weight, and heart rate. Our results indicate that the\nproposed adaptions are beneficial in reconciling the individual differences\nbetween bloodstreams and activities.",
    "arxiv_id": "http://arxiv.org/abs/2408.01239v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01239v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "HeteroMorpheus: Universal Control Based on Morphological Heterogeneity Modeling",
    "authors": "YiFan Hao, Yang Yang, Junru Song, Wei Peng, Weien Zhou, Tingsong Jiang, Wen Yao",
    "abstract": "In the field of robotic control, designing individual controllers for each\nrobot leads to high computational costs. Universal control policies, applicable\nacross diverse robot morphologies, promise to mitigate this challenge.\nPredominantly, models based on Graph Neural Networks (GNN) and Transformers are\nemployed, owing to their effectiveness in capturing relational dynamics across\na robot's limbs. However, these models typically employ homogeneous graph\nstructures that overlook the functional diversity of different limbs. To bridge\nthis gap, we introduce HeteroMorpheus, a novel method based on heterogeneous\ngraph Transformer. This method uniquely addresses limb heterogeneity, fostering\nbetter representation of robot dynamics of various morphologies. Through\nextensive experiments we demonstrate the superiority of HeteroMorpheus against\nstate-of-the-art methods in the capability of policy generalization, including\nzero-shot generalization and sample-efficient transfer to unfamiliar robot\nmorphologies.",
    "arxiv_id": "http://arxiv.org/abs/2408.01230v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01230v1",
    "primary_category": "cs.RO",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "ZNorm: Z-Score Gradient Normalization for Accelerating Neural Network Training",
    "authors": "Juyoung Yun, Hoyoung Kim, Suin Cho, Hangil Kang",
    "abstract": "The rapid advancements in deep learning necessitate efficient training\nmethods for deep neural networks (DNNs). As models grow in complexity,\nvanishing and exploding gradients impede convergence and performance. We\npropose Z-Score Normalization for Gradient Descent (ZNorm), an innovative\ntechnique that adjusts only the gradients to enhance training efficiency and\nimprove model performance. ZNorm normalizes the overall gradients, providing\nconsistent gradient scaling across layers, thereby reducing the risks of\nvanishing and exploding gradients. Our extensive experiments on CIFAR-10 and\nmedical datasets demonstrate that ZNorm not only accelerates convergence but\nalso enhances performance metrics. ZNorm consistently outperforms existing\nmethods, achieving superior results using the same computational settings. In\nmedical imaging applications, ZNorm improves tumor prediction and segmentation\nperformances, underscoring its practical utility. These findings highlight\nZNorm's potential as a robust and versatile tool for improving the efficiency\nand effectiveness of deep neural network training across a wide range of\narchitectures and applications.",
    "arxiv_id": "http://arxiv.org/abs/2408.01215v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01215v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "A Systematic Review of Intermediate Fusion in Multimodal Deep Learning for Biomedical Applications",
    "authors": "Valerio Guarrasi, Fatih Aksu, Camillo Maria Caruso, Francesco Di Feola, Aurora Rofena, Filippo Ruffini, Paolo Soda",
    "abstract": "Deep learning has revolutionized biomedical research by providing\nsophisticated methods to handle complex, high-dimensional data. Multimodal deep\nlearning (MDL) further enhances this capability by integrating diverse data\ntypes such as imaging, textual data, and genetic information, leading to more\nrobust and accurate predictive models. In MDL, differently from early and late\nfusion methods, intermediate fusion stands out for its ability to effectively\ncombine modality-specific features during the learning process. This systematic\nreview aims to comprehensively analyze and formalize current intermediate\nfusion methods in biomedical applications. We investigate the techniques\nemployed, the challenges faced, and potential future directions for advancing\nintermediate fusion methods. Additionally, we introduce a structured notation\nto enhance the understanding and application of these methods beyond the\nbiomedical domain. Our findings are intended to support researchers, healthcare\nprofessionals, and the broader deep learning community in developing more\nsophisticated and insightful multimodal models. Through this review, we aim to\nprovide a foundational framework for future research and practical applications\nin the dynamic field of MDL.",
    "arxiv_id": "http://arxiv.org/abs/2408.02686v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02686v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Certifiably Robust Encoding Schemes",
    "authors": "Aman Saxena, Tom Wollschl\u00e4ger, Nicola Franco, Jeanette Miriam Lorenz, Stephan G\u00fcnnemann",
    "abstract": "Quantum machine learning uses principles from quantum mechanics to process\ndata, offering potential advances in speed and performance. However, previous\nwork has shown that these models are susceptible to attacks that manipulate\ninput data or exploit noise in quantum circuits. Following this, various\nstudies have explored the robustness of these models. These works focus on the\nrobustness certification of manipulations of the quantum states. We extend this\nline of research by investigating the robustness against perturbations in the\nclassical data for a general class of data encoding schemes. We show that for\nsuch schemes, the addition of suitable noise channels is equivalent to\nevaluating the mean value of the noiseless classifier at the smoothed data,\nakin to Randomized Smoothing from classical machine learning. Using our general\nframework, we show that suitable additions of phase-damping noise channels\nimprove empirical and provable robustness for the considered class of encoding\nschemes.",
    "arxiv_id": "http://arxiv.org/abs/2408.01200v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01200v1",
    "primary_category": "quant-ph",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Optimizing Variational Quantum Circuits Using Metaheuristic Strategies in Reinforcement Learning",
    "authors": "Michael K\u00f6lle, Daniel Seidl, Maximilian Zorn, Philipp Altmann, Jonas Stein, Thomas Gabor",
    "abstract": "Quantum Reinforcement Learning (QRL) offers potential advantages over\nclassical Reinforcement Learning, such as compact state space representation\nand faster convergence in certain scenarios. However, practical benefits\nrequire further validation. QRL faces challenges like flat solution landscapes,\nwhere traditional gradient-based methods are inefficient, necessitating the use\nof gradient-free algorithms. This work explores the integration of\nmetaheuristic algorithms -- Particle Swarm Optimization, Ant Colony\nOptimization, Tabu Search, Genetic Algorithm, Simulated Annealing, and Harmony\nSearch -- into QRL. These algorithms provide flexibility and efficiency in\nparameter optimization. Evaluations in $5\\times5$ MiniGrid Reinforcement\nLearning environments show that, all algorithms yield near-optimal results,\nwith Simulated Annealing and Particle Swarm Optimization performing best. In\nthe Cart Pole environment, Simulated Annealing, Genetic Algorithms, and\nParticle Swarm Optimization achieve optimal results, while the others perform\nslightly better than random action selection. These findings demonstrate the\npotential of Particle Swarm Optimization and Simulated Annealing for efficient\nQRL learning, emphasizing the need for careful algorithm selection and\nadaptation.",
    "arxiv_id": "http://arxiv.org/abs/2408.01187v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01187v1",
    "primary_category": "quant-ph",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Nested Music Transformer: Sequentially Decoding Compound Tokens in Symbolic Music and Audio Generation",
    "authors": "Jiwoo Ryu, Hao-Wen Dong, Jongmin Jung, Dasaem Jeong",
    "abstract": "Representing symbolic music with compound tokens, where each token consists\nof several different sub-tokens representing a distinct musical feature or\nattribute, offers the advantage of reducing sequence length. While previous\nresearch has validated the efficacy of compound tokens in music sequence\nmodeling, predicting all sub-tokens simultaneously can lead to suboptimal\nresults as it may not fully capture the interdependencies between them. We\nintroduce the Nested Music Transformer (NMT), an architecture tailored for\ndecoding compound tokens autoregressively, similar to processing flattened\ntokens, but with low memory usage. The NMT consists of two transformers: the\nmain decoder that models a sequence of compound tokens and the sub-decoder for\nmodeling sub-tokens of each compound token. The experiment results showed that\napplying the NMT to compound tokens can enhance the performance in terms of\nbetter perplexity in processing various symbolic music datasets and discrete\naudio tokens from the MAESTRO dataset.",
    "arxiv_id": "http://arxiv.org/abs/2408.01180v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01180v1",
    "primary_category": "cs.SD",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Sustainable Diffusion-based Incentive Mechanism for Generative AI-driven Digital Twins in Industrial Cyber-Physical Systems",
    "authors": "Jinbo Wen, Jiawen Kang, Dusit Niyato, Yang Zhang, Shiwen Mao",
    "abstract": "Industrial Cyber-Physical Systems (ICPSs) are an integral component of modern\nmanufacturing and industries. By digitizing data throughout the product life\ncycle, Digital Twins (DTs) in ICPSs enable a shift from current industrial\ninfrastructures to intelligent and adaptive infrastructures. Thanks to data\nprocess capability, Generative Artificial Intelligence (GAI) can drive the\nconstruction and update of DTs to improve predictive accuracy and prepare for\ndiverse smart manufacturing. However, mechanisms that leverage sensing\nIndustrial Internet of Things (IIoT) devices to share data for the construction\nof DTs are susceptible to adverse selection problems. In this paper, we first\ndevelop a GAI-driven DT architecture for ICPSs. To address the adverse\nselection problem caused by information asymmetry, we propose a contract theory\nmodel and develop the sustainable diffusion-based soft actor-critic algorithm\nto identify the optimal feasible contract. Specifically, we leverage the\ndynamic structured pruning technique to reduce parameter numbers of actor\nnetworks, allowing sustainability and efficient implementation of the proposed\nalgorithm. Finally, numerical results demonstrate the effectiveness of the\nproposed scheme.",
    "arxiv_id": "http://arxiv.org/abs/2408.01173v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01173v1",
    "primary_category": "cs.NI",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Domain Adaptation-Enhanced Searchlight: Enabling brain decoding from visual perception to mental imagery",
    "authors": "Alexander Olza, David Soto, Roberto Santana",
    "abstract": "In cognitive neuroscience and brain-computer interface research, accurately\npredicting imagined stimuli is crucial. This study investigates the\neffectiveness of Domain Adaptation (DA) in enhancing imagery prediction using\nprimarily visual data from fMRI scans of 18 subjects. Initially, we train a\nbaseline model on visual stimuli to predict imagined stimuli, utilizing data\nfrom 14 brain regions. We then develop several models to improve imagery\nprediction, comparing different DA methods. Our results demonstrate that DA\nsignificantly enhances imagery prediction, especially with the Regular Transfer\napproach. We then conduct a DA-enhanced searchlight analysis using Regular\nTransfer, followed by permutation-based statistical tests to identify brain\nregions where imagery decoding is consistently above chance across subjects.\nOur DA-enhanced searchlight predicts imagery contents in a highly distributed\nset of brain regions, including the visual cortex and the frontoparietal\ncortex, thereby outperforming standard cross-domain classification methods. The\ncomplete code and data for this paper have been made openly available for the\nuse of the scientific community.",
    "arxiv_id": "http://arxiv.org/abs/2408.01163v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01163v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "TCR-GPT: Integrating Autoregressive Model and Reinforcement Learning for T-Cell Receptor Repertoires Generation",
    "authors": "Yicheng Lin, Dandan Zhang, Yun Liu",
    "abstract": "T-cell receptors (TCRs) play a crucial role in the immune system by\nrecognizing and binding to specific antigens presented by infected or cancerous\ncells. Understanding the sequence patterns of TCRs is essential for developing\ntargeted immune therapies and designing effective vaccines. Language models,\nsuch as auto-regressive transformers, offer a powerful solution to this problem\nby learning the probability distributions of TCR repertoires, enabling the\ngeneration of new TCR sequences that inherit the underlying patterns of the\nrepertoire. We introduce TCR-GPT, a probabilistic model built on a decoder-only\ntransformer architecture, designed to uncover and replicate sequence patterns\nin TCR repertoires. TCR-GPT demonstrates an accuracy of 0.953 in inferring\nsequence probability distributions measured by Pearson correlation coefficient.\nFurthermore, by leveraging Reinforcement Learning(RL), we adapted the\ndistribution of TCR sequences to generate TCRs capable of recognizing specific\npeptides, offering significant potential for advancing targeted immune\ntherapies and vaccine development. With the efficacy of RL, fine-tuned\npretrained TCR-GPT models demonstrated the ability to produce TCR repertoires\nlikely to bind specific peptides, illustrating RL's efficiency in enhancing the\nmodel's adaptability to the probability distributions of biologically relevant\nTCR sequences.",
    "arxiv_id": "http://arxiv.org/abs/2408.01156v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01156v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Enhanced Prediction of Ventilator-Associated Pneumonia in Patients with Traumatic Brain Injury Using Advanced Machine Learning Techniques",
    "authors": "Negin Ashrafi, Armin Abdollahi, Maryam Pishgar",
    "abstract": "Background: Ventilator-associated pneumonia (VAP) in traumatic brain injury\n(TBI) patients poses a significant mortality risk and imposes a considerable\nfinancial burden on patients and healthcare systems. Timely detection and\nprognostication of VAP in TBI patients are crucial to improve patient outcomes\nand alleviate the strain on healthcare resources.\n  Methods: We implemented six machine learning models using the MIMIC-III\ndatabase. Our methodology included preprocessing steps, such as feature\nselection with CatBoost and expert opinion, addressing class imbalance with the\nSynthetic Minority Oversampling Technique (SMOTE), and rigorous model tuning\nthrough 5-fold cross-validation to optimize hyperparameters. Key models\nevaluated included SVM, Logistic Regression, Random Forest, XGBoost, ANN, and\nAdaBoost. Additionally, we conducted SHAP analysis to determine feature\nimportance and performed an ablation study to assess feature impacts on model\nperformance.\n  Results: XGBoost outperformed the baseline models and the best existing\nliterature. We used metrics, including AUC, Accuracy, Specificity, Sensitivity,\nF1 Score, PPV, and NPV. XGBoost demonstrated the highest performance with an\nAUC of 0.940 and an Accuracy of 0.875, which are 23.4% and 23.5% higher than\nthe best results in the existing literature, with an AUC of 0.706 and an\nAccuracy of 0.640, respectively. This enhanced performance underscores the\nmodels' effectiveness in clinical settings.\n  Conclusions: This study enhances the predictive modeling of VAP in TBI\npatients, improving early detection and intervention potential. Refined feature\nselection and advanced ensemble techniques significantly boosted model accuracy\nand reliability, offering promising directions for future clinical applications\nand medical diagnostics research.",
    "arxiv_id": "http://arxiv.org/abs/2408.01144v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01144v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Machine learning topological energy braiding of non-Bloch bands",
    "authors": "Shuwei Shi, Shibing Chu, Yuee Xie, Yuanping Chen",
    "abstract": "Machine learning has been used to identify phase transitions in a variety of\nphysical systems. However, there is still a lack of relevant research on\nnon-Bloch energy braiding in non-Hermitian systems. In this work, we study\nnon-Bloch energy braiding in one-dimensional non-Hermitian systems using\nunsupervised and supervised methods. In unsupervised learning, we use diffusion\nmaps to successfully identify non-Bloch energy braiding without any prior\nknowledge and combine it with k-means to cluster different topological elements\ninto clusters, such as Unlink and Hopf link. In supervised learning, we train a\nConvolutional Neural Network (CNN) based on Bloch energy data to predict not\nonly Bloch energy braiding but also non-Bloch energy braiding with an accuracy\napproaching 100%. By analysing the CNN, we can ascertain that the network has\nsuccessfully acquired the ability to recognise the braiding topology of the\nenergy bands. The present study demonstrates the considerable potential of\nmachine learning in the identification of non-Hermitian topological phases and\nenergy braiding.",
    "arxiv_id": "http://arxiv.org/abs/2408.01141v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01141v1",
    "primary_category": "cond-mat.mes-hall",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "A Survey of Mamba",
    "authors": "Haohao Qu, Liangbo Ning, Rui An, Wenqi Fan, Tyler Derr, Xin Xu, Qing Li",
    "abstract": "Deep learning, as a vital technique, has sparked a notable revolution in\nartificial intelligence. As the most representative architecture, Transformers\nhave empowered numerous advanced models, especially the large language models\nthat comprise billions of parameters, becoming a cornerstone in deep learning.\nDespite the impressive achievements, Transformers still face inherent\nlimitations, particularly the time-consuming inference resulting from the\nquadratic computation complexity of attention calculation. Recently, a novel\narchitecture named Mamba, drawing inspiration from classical state space\nmodels, has emerged as a promising alternative for building foundation models,\ndelivering comparable modeling abilities to Transformers while preserving\nnear-linear scalability concerning sequence length. This has sparked an\nincreasing number of studies actively exploring Mamba's potential to achieve\nimpressive performance across diverse domains. Given such rapid evolution,\nthere is a critical need for a systematic review that consolidates existing\nMamba-empowered models, offering a comprehensive understanding of this emerging\nmodel architecture. In this survey, we therefore conduct an in-depth\ninvestigation of recent Mamba-associated studies, covering from three main\naspects: the advancements of Mamba-based models, the techniques of adapting\nMamba to diverse data, and the applications where Mamba can excel.\nSpecifically, we first recall the foundational knowledge of various\nrepresentative deep learning models and the details of Mamba as preliminaries.\nThen, to showcase the significance of Mamba, we comprehensively review the\nrelated studies focusing on Mamba models' architecture design, data\nadaptability, and applications. Finally, we present an discussion of current\nlimitations and explore various promising research directions to provide deeper\ninsights for future investigations.",
    "arxiv_id": "http://arxiv.org/abs/2408.01129v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01129v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Artificial Neural Networks for Photonic Applications: From Algorithms to Implementation",
    "authors": "Pedro Freire, Egor Manuylovich, Jaroslaw E. Prilepsky, Sergei K. Turitsy",
    "abstract": "This tutorial-review on applications of artificial neural networks in\nphotonics targets a broad audience, ranging from optical research and\nengineering communities to computer science and applied mathematics. We focus\nhere on the research areas at the interface between these disciplines,\nattempting to find the right balance between technical details specific to each\ndomain and overall clarity. First, we briefly recall key properties and\npeculiarities of some core neural network types, which we believe are the most\nrelevant to photonics, also linking the layer's theoretical design to some\nphotonics hardware realizations. After that, we elucidate the question of how\nto fine-tune the selected model's design to perform the required task with\noptimized accuracy. Then, in the review part, we discuss recent developments\nand progress for several selected applications of neural networks in photonics,\nincluding multiple aspects relevant to optical communications, imaging,\nsensing, and the design of new materials and lasers. In the following section,\nwe put a special emphasis on how to accurately evaluate the complexity of\nneural networks in the context of the transition from algorithms to hardware\nimplementation. The introduced complexity characteristics are used to analyze\nthe applications of neural networks in optical communications, as a specific,\nalbeit highly important example, comparing those with some benchmark signal\nprocessing methods. We combine the description of the well-known model\ncompression strategies used in machine learning, with some novel techniques\nintroduced recently in optical applications of neural networks. It is important\nto stress that although our focus in this tutorial-review is on photonics, we\nbelieve that the methods and techniques presented here can be handy in a much\nwider range of scientific and engineering applications.",
    "arxiv_id": "http://arxiv.org/abs/2408.02685v1",
    "pdf_url": "http://arxiv.org/pdf/2408.02685v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "An Encoding--Searching Separation Perspective on Bi-Encoder Neural Search",
    "authors": "Hung-Nghiep Tran, Akiko Aizawa, Atsuhiro Takasu",
    "abstract": "This paper reviews, analyzes, and proposes a new perspective on the\nbi-encoder architecture for neural search. While the bi-encoder architecture is\nwidely used due to its simplicity and scalability at test time, it has some\nnotable issues such as low performance on seen datasets and weak zero-shot\nperformance on new datasets. In this paper, we analyze these issues and\nsummarize two main critiques: the encoding information bottleneck problem and\nlimitations of the basic assumption of embedding search. We then construct a\nthought experiment to logically analyze the encoding and searching operations\nand challenge the basic assumption of embedding search. Building on these\nobservations, we propose a new perspective on the bi-encoder architecture\ncalled the \\textit{encoding--searching separation} perspective, which\nconceptually and practically separates the encoding and searching operations.\nThis new perspective is applied to explain the root cause of the identified\nissues and discuss ways to mitigate the problems. Finally, we discuss the\nimplications of the ideas underlying the new perspective, the design surface\nthat it exposes and the potential research directions arising from it.",
    "arxiv_id": "http://arxiv.org/abs/2408.01094v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01094v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Universality of kernel random matrices and kernel regression in the quadratic regime",
    "authors": "Parthe Pandit, Zhichao Wang, Yizhe Zhu",
    "abstract": "Kernel ridge regression (KRR) is a popular class of machine learning models\nthat has become an important tool for understanding deep learning. Much of the\nfocus has been on studying the proportional asymptotic regime, $n \\asymp d$,\nwhere $n$ is the number of training samples and $d$ is the dimension of the\ndataset. In this regime, under certain conditions on the data distribution, the\nkernel random matrix involved in KRR exhibits behavior akin to that of a linear\nkernel. In this work, we extend the study of kernel regression to the quadratic\nasymptotic regime, where $n \\asymp d^2$. In this regime, we demonstrate that a\nbroad class of inner-product kernels exhibit behavior similar to a quadratic\nkernel. Specifically, we establish an operator norm approximation bound for the\ndifference between the original kernel random matrix and a quadratic kernel\nrandom matrix with additional correction terms compared to the Taylor expansion\nof the kernel functions. The approximation works for general data distributions\nunder a Gaussian-moment-matching assumption with a covariance structure. This\nnew approximation is utilized to obtain a limiting spectral distribution of the\noriginal kernel matrix and characterize the precise asymptotic training and\ngeneralization errors for KRR in the quadratic regime when $n/d^2$ converges to\na non-zero constant. The generalization errors are obtained for both\ndeterministic and random teacher models. Our proof techniques combine moment\nmethods, Wick's formula, orthogonal polynomials, and resolvent analysis of\nrandom matrices with correlated entries.",
    "arxiv_id": "http://arxiv.org/abs/2408.01062v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01062v1",
    "primary_category": "stat.ML",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "The Impact of Hyperparameters on Large Language Model Inference Performance: An Evaluation of vLLM and HuggingFace Pipelines",
    "authors": "Matias Martinez",
    "abstract": "The recent surge of open-source large language models (LLMs) enables\ndevelopers to create AI-based solutions while maintaining control over aspects\nsuch as privacy and compliance, thereby providing governance and ownership of\nthe model deployment process. To utilize these LLMs, inference engines are\nneeded. These engines load the model's weights onto available resources, such\nas GPUs, and process queries to generate responses. The speed of inference, or\nperformance, of the LLM, is critical for real-time applications, as it computes\nmillions or billions of floating point operations per inference. Recently,\nadvanced inference engines such as vLLM have emerged, incorporating novel\nmechanisms such as efficient memory management to achieve state-of-the-art\nperformance. In this paper, we analyze the performance, particularly the\nthroughput (tokens generated per unit of time), of 20 LLMs using two inference\nlibraries: vLLM and HuggingFace's pipelines. We investigate how various\nhyperparameters, which developers must configure, influence inference\nperformance. Our results reveal that throughput landscapes are irregular, with\ndistinct peaks, highlighting the importance of hyperparameter optimization to\nachieve maximum performance. We also show that applying hyperparameter\noptimization when upgrading or downgrading the GPU model used for inference can\nimprove throughput from HuggingFace pipelines by an average of 9.16% and 13.7%,\nrespectively.",
    "arxiv_id": "http://arxiv.org/abs/2408.01050v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01050v1",
    "primary_category": "cs.SE",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Privacy-Preserving Split Learning with Vision Transformers using Patch-Wise Random and Noisy CutMix",
    "authors": "Seungeun Oh, Sihun Baek, Jihong Park, Hyelin Nam, Praneeth Vepakomma, Ramesh Raskar, Mehdi Bennis, Seong-Lyun Kim",
    "abstract": "In computer vision, the vision transformer (ViT) has increasingly superseded\nthe convolutional neural network (CNN) for improved accuracy and robustness.\nHowever, ViT's large model sizes and high sample complexity make it difficult\nto train on resource-constrained edge devices. Split learning (SL) emerges as a\nviable solution, leveraging server-side resources to train ViTs while utilizing\nprivate data from distributed devices. However, SL requires additional\ninformation exchange for weight updates between the device and the server,\nwhich can be exposed to various attacks on private training data. To mitigate\nthe risk of data breaches in classification tasks, inspired from the CutMix\nregularization, we propose a novel privacy-preserving SL framework that injects\nGaussian noise into smashed data and mixes randomly chosen patches of smashed\ndata across clients, coined DP-CutMixSL. Our analysis demonstrates that\nDP-CutMixSL is a differentially private (DP) mechanism that strengthens privacy\nprotection against membership inference attacks during forward propagation.\nThrough simulations, we show that DP-CutMixSL improves privacy protection\nagainst membership inference attacks, reconstruction attacks, and label\ninference attacks, while also improving accuracy compared to DP-SL and\nDP-MixSL.",
    "arxiv_id": "http://arxiv.org/abs/2408.01040v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01040v1",
    "primary_category": "cs.DC",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Distilling interpretable causal trees from causal forests",
    "authors": "Patrick Rehill",
    "abstract": "Machine learning methods for estimating treatment effect heterogeneity\npromise greater flexibility than existing methods that test a few pre-specified\nhypotheses. However, one problem these methods can have is that it can be\nchallenging to extract insights from complicated machine learning models. A\nhigh-dimensional distribution of conditional average treatment effects may give\naccurate, individual-level estimates, but it can be hard to understand the\nunderlying patterns; hard to know what the implications of the analysis are.\nThis paper proposes the Distilled Causal Tree, a method for distilling a\nsingle, interpretable causal tree from a causal forest. This compares well to\nexisting methods of extracting a single tree, particularly in noisy data or\nhigh-dimensional data where there are many correlated features. Here it even\noutperforms the base causal forest in most simulations. Its estimates are\ndoubly robust and asymptotically normal just as those of the causal forest are.",
    "arxiv_id": "http://arxiv.org/abs/2408.01023v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01023v1",
    "primary_category": "econ.EM",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "A Family of Distributions of Random Subsets for Controlling Positive and Negative Dependence",
    "authors": "Takahiro Kawashima, Hideitsu Hino",
    "abstract": "Positive and negative dependence are fundamental concepts that characterize\nthe attractive and repulsive behavior of random subsets. Although some\nprobabilistic models are known to exhibit positive or negative dependence, it\nis challenging to seamlessly bridge them with a practicable probabilistic\nmodel. In this study, we introduce a new family of distributions, named the\ndiscrete kernel point process (DKPP), which includes determinantal point\nprocesses and parts of Boltzmann machines. We also develop some computational\nmethods for probabilistic operations and inference with DKPPs, such as\ncalculating marginal and conditional probabilities and learning the parameters.\nOur numerical experiments demonstrate the controllability of positive and\nnegative dependence and the effectiveness of the computational methods for\nDKPPs.",
    "arxiv_id": "http://arxiv.org/abs/2408.01022v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01022v1",
    "primary_category": "stat.ML",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "GNN-MolKAN: Harnessing the Power of KAN to Advance Molecular Representation Learning with GNNs",
    "authors": "Ruifeng Li",
    "abstract": "Effective molecular representation learning is crucial for molecular property\nprediction and drug design. However, existing approaches struggle with\nlimitations in insufficient annotations and suboptimal architecture design. For\ninstance, Graph Neural Networks (GNNs) suffer from over-squashing, causing the\nloss of important structural details in molecules, thus impairing molecular\nrepresentations. In this work, we propose a new class of GNNs, GNN-MolKAN and\nits augmented variant, GNN-MolKAN+, that integrate the Kolmogorov-Arnold\nNetworks (KAN) architecture from AI + Science into GNNs to address these\nchallenges. Additionally, we introduce Adaptive FastKAN (AdFastKAN), an\nadvanced KAN that offers increased stability and speed, further enhancing the\nperformance of standard GNNs. Notably, our approach holds three key benefits:\n1) Superior Performance: GNN-MolKAN and GNN-MolKAN+ demonstrate superior\nprediction ability, robust generalization to unseen scaffolds, and versatile\ntransferability across different GNN architectures. 2) Efficiency: These models\nrequire less computational time and fewer parameters while matching or\nsurpassing the state-of-the-art (SOTA) self-supervised methods. 3) Few-shot\nLearning Ability: GNN-MolKAN demonstrates great potential in few-shot learning\nscenarios, achieving an average improvement of 6.97% across few-shot\nbenchmarks. Overall, we validate our architecture on 6 classification datasets,\n6 regression datasets, and 4 few-shot learning datasets, consistently achieving\nhighly competitive results across all of them.",
    "arxiv_id": "http://arxiv.org/abs/2408.01018v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01018v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "IBB Traffic Graph Data: Benchmarking and Road Traffic Prediction Model",
    "authors": "Eren Olug, Kiymet Kaya, Resul Tugay, Sule Gunduz Oguducu",
    "abstract": "Road traffic congestion prediction is a crucial component of intelligent\ntransportation systems, since it enables proactive traffic management, enhances\nsuburban experience, reduces environmental impact, and improves overall safety\nand efficiency. Although there are several public datasets, especially for\nmetropolitan areas, these datasets may not be applicable to practical scenarios\ndue to insufficiency in the scale of data (i.e. number of sensors and road\nlinks) and several external factors like different characteristics of the\ntarget area such as urban, highways and the data collection location. To\naddress this, this paper introduces a novel IBB Traffic graph dataset as an\nalternative benchmark dataset to mitigate these limitations and enrich the\nliterature with new geographical characteristics. IBB Traffic graph dataset\ncovers the sensor data collected at 2451 distinct locations. Moreover, we\npropose a novel Road Traffic Prediction Model that strengthens temporal links\nthrough feature engineering, node embedding with GLEE to represent\ninter-related relationships within the traffic network, and traffic prediction\nwith ExtraTrees. The results indicate that the proposed model consistently\noutperforms the baseline models, demonstrating an average accuracy improvement\nof 4%.",
    "arxiv_id": "http://arxiv.org/abs/2408.01016v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01016v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Tensor Train Low-rank Approximation (TT-LoRA): Democratizing AI with Accelerated LLMs",
    "authors": "Afia Anjum, Maksim E. Eren, Ismael Boureima, Boian Alexandrov, Manish Bhattarai",
    "abstract": "In recent years, Large Language Models (LLMs) have demonstrated remarkable\ncapabilities across a wide range of natural language processing (NLP) tasks,\nsuch as question-answering, sentiment analysis, text summarization, and machine\ntranslation. However, the ever-growing complexity of LLMs demands immense\ncomputational resources, hindering the broader research and application of\nthese models. To address this, various parameter-efficient fine-tuning\nstrategies, such as Low-Rank Approximation (LoRA) and Adapters, have been\ndeveloped. Despite their potential, these methods often face limitations in\ncompressibility. Specifically, LoRA struggles to scale effectively with the\nincreasing number of trainable parameters in modern large scale LLMs.\nAdditionally, Low-Rank Economic Tensor-Train Adaptation (LoRETTA), which\nutilizes tensor train decomposition, has not yet achieved the level of\ncompression necessary for fine-tuning very large scale models with limited\nresources. This paper introduces Tensor Train Low-Rank Approximation (TT-LoRA),\na novel parameter-efficient fine-tuning (PEFT) approach that extends LoRETTA\nwith optimized tensor train (TT) decomposition integration. By eliminating\nAdapters and traditional LoRA-based structures, TT-LoRA achieves greater model\ncompression without compromising downstream task performance, along with\nreduced inference latency and computational overhead. We conduct an exhaustive\nparameter search to establish benchmarks that highlight the trade-off between\nmodel compression and performance. Our results demonstrate significant\ncompression of LLMs while maintaining comparable performance to larger models,\nfacilitating their deployment on resource-constraint platforms.",
    "arxiv_id": "http://arxiv.org/abs/2408.01008v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01008v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Enhancing Financial Market Predictions: Causality-Driven Feature Selection",
    "authors": "Wenhao Liang, Zhengyang Li, Weitong Chen",
    "abstract": "This paper introduces the FinSen dataset that revolutionizes financial market\nanalysis by integrating economic and financial news articles from 197 countries\nwith stock market data. The dataset's extensive coverage spans 15 years from\n2007 to 2023 with temporal information, offering a rich, global perspective\nwith 160,000 records on financial market news. Our study leverages causally\nvalidated sentiment scores and LSTM models to enhance market forecast accuracy\nand reliability. Utilizing the FinSen dataset, we introduce an innovative Focal\nCalibration Loss, reducing Expected Calibration Error (ECE) to 3.34 percent\nwith the DAN 3 model. This not only improves prediction accuracy but also\naligns probabilistic forecasts closely with real outcomes, crucial for the\nfinancial sector where predicted probability is paramount. Our approach\ndemonstrates the effectiveness of combining sentiment analysis with precise\ncalibration techniques for trustworthy financial forecasting where the cost of\nmisinterpretation can be high. Finsen Data can be found at [this github\nURL](https://github.com/EagleAdelaide/FinSen_Dataset.git).",
    "arxiv_id": "http://arxiv.org/abs/2408.01005v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01005v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Adaptive Two-Stage Cloud Resource Scaling via Hierarchical Multi-Indicator Forecasting and Bayesian Decision-Making",
    "authors": "Yang Luo, Shiyu Wang, Zhemeng Yu, Wei Lu, Xiaofeng Gao, Lintao Ma, Guihai Chen",
    "abstract": "The surging demand for cloud computing resources, driven by the rapid growth\nof sophisticated large-scale models and data centers, underscores the critical\nimportance of efficient and adaptive resource allocation. As major tech\nenterprises deploy massive infrastructures with thousands of GPUs, existing\ncloud platforms still struggle with low resource utilization due to key\nchallenges: capturing hierarchical indicator structures, modeling non-Gaussian\ndistributions, and decision-making under uncertainty. To address these\nchallenges, we propose HRAMONY, an adaptive Hierarchical Attention-based\nResource Modeling and Decision-Making System. HARMONY combines hierarchical\nmulti-indicator distribution forecasting and uncertainty-aware Bayesian\ndecision-making. It introduces a novel hierarchical attention mechanism that\ncomprehensively models complex inter-indicator dependencies, enabling accurate\npredictions that can adapt to evolving environment states. By transforming\nGaussian projections into adaptive non-Gaussian distributions via Normalizing\nFlows. Crucially, HARMONY leverages the full predictive distributions in an\nadaptive Bayesian process, proactively incorporating uncertainties to optimize\nresource allocation while robustly meeting SLA constraints under varying\nconditions. Extensive evaluations across four large-scale cloud datasets\ndemonstrate HARMONY's state-of-the-art performance, significantly outperforming\nnine established methods. A month-long real-world deployment validated\nHARMONY's substantial practical impact, realizing over 35,000 GPU hours in\nsavings and translating to $100K+ in cost reduction, showcasing its remarkable\neconomic value through adaptive, uncertainty-aware scaling. Our code is\navailable at https://github.com/Floating-LY/HARMONY1.",
    "arxiv_id": "http://arxiv.org/abs/2408.01000v1",
    "pdf_url": "http://arxiv.org/pdf/2408.01000v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "IncidentNet: Traffic Incident Detection, Localization and Severity Estimation with Sparse Sensing",
    "authors": "Sai Shashank Peddiraju, Kaustubh Harapanahalli, Edward Andert, Aviral Shrivastava",
    "abstract": "Prior art in traffic incident detection relies on high sensor coverage and is\nprimarily based on decision-tree and random forest models that have limited\nrepresentation capacity and, as a result, cannot detect incidents with high\naccuracy. This paper presents IncidentNet - a novel approach for classifying,\nlocalizing, and estimating the severity of traffic incidents using deep\nlearning models trained on data captured from sparsely placed sensors in urban\nenvironments. Our model works on microscopic traffic data that can be collected\nusing cameras installed at traffic intersections. Due to the unavailability of\ndatasets that provide microscopic traffic details and traffic incident details\nsimultaneously, we also present a methodology to generate a synthetic\nmicroscopic traffic dataset that matches given macroscopic traffic data.\nIncidentNet achieves a traffic incident detection rate of 98%, with false alarm\nrates of less than 7% in 197 seconds on average in urban environments with\ncameras on less than 20% of the traffic intersections.",
    "arxiv_id": "http://arxiv.org/abs/2408.00996v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00996v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Fairness in Large Language Models in Three Hour",
    "authors": "Thang Doan Viet, Zichong Wang, Minh Nhat Nguyen, Wenbin Zhang",
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable success across\nvarious domains but often lack fairness considerations, potentially leading to\ndiscriminatory outcomes against marginalized populations. Unlike fairness in\ntraditional machine learning, fairness in LLMs involves unique backgrounds,\ntaxonomies, and fulfillment techniques. This tutorial provides a systematic\noverview of recent advances in the literature concerning fair LLMs, beginning\nwith real-world case studies to introduce LLMs, followed by an analysis of bias\ncauses therein. The concept of fairness in LLMs is then explored, summarizing\nthe strategies for evaluating bias and the algorithms designed to promote\nfairness. Additionally, resources for assessing bias in LLMs, including\ntoolkits and datasets, are compiled, and current research challenges and open\nquestions in the field are discussed. The repository is available at\n\\url{https://github.com/LavinWong/Fairness-in-Large-Language-Models}.",
    "arxiv_id": "http://arxiv.org/abs/2408.00992v2",
    "pdf_url": "http://arxiv.org/pdf/2408.00992v2",
    "primary_category": "cs.CL",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Reconstructing Richtmyer-Meshkov instabilities from noisy radiographs using low dimensional features and attention-based neural networks",
    "authors": "Daniel A. Serino, Marc L. Klasky, Balasubramanya T. Nadiga, Xiaojian Xu, Trevor Wilcox",
    "abstract": "A trained attention-based transformer network can robustly recover the\ncomplex topologies given by the Richtmyer-Meshkoff instability from a sequence\nof hydrodynamic features derived from radiographic images corrupted with blur,\nscatter, and noise. This approach is demonstrated on ICF-like double shell\nhydrodynamic simulations. The key component of this network is a transformer\nencoder that acts on a sequence of features extracted from noisy radiographs.\nThis encoder includes numerous self-attention layers that act to learn temporal\ndependencies in the input sequences and increase the expressiveness of the\nmodel. This approach is demonstrated to exhibit an excellent ability to\naccurately recover the Richtmyer-Meshkov instability growth rates, even despite\nthe gas-metal interface being greatly obscured by radiographic noise.",
    "arxiv_id": "http://arxiv.org/abs/2408.00985v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00985v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "META-ANOVA: Screening interactions for interpretable machine learning",
    "authors": "Yongchan Choi, Seokhun Park, Chanmoo Park, Dongha Kim, Yongdai Kim",
    "abstract": "There are two things to be considered when we evaluate predictive models. One\nis prediction accuracy,and the other is interpretability. Over the recent\ndecades, many prediction models of high performance, such as ensemble-based\nmodels and deep neural networks, have been developed. However, these models are\noften too complex, making it difficult to intuitively interpret their\npredictions. This complexity in interpretation limits their use in many\nreal-world fields that require accountability, such as medicine, finance, and\ncollege admissions. In this study, we develop a novel method called Meta-ANOVA\nto provide an interpretable model for any given prediction model. The basic\nidea of Meta-ANOVA is to transform a given black-box prediction model to the\nfunctional ANOVA model. A novel technical contribution of Meta-ANOVA is a\nprocedure of screening out unnecessary interaction before transforming a given\nblack-box model to the functional ANOVA model. This screening procedure allows\nthe inclusion of higher order interactions in the transformed functional ANOVA\nmodel without computational difficulties. We prove that the screening procedure\nis asymptotically consistent. Through various experiments with synthetic and\nreal-world datasets, we empirically demonstrate the superiority of Meta-ANOVA",
    "arxiv_id": "http://arxiv.org/abs/2408.00973v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00973v1",
    "primary_category": "stat.ML",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "MIS-ME: A Multi-modal Framework for Soil Moisture Estimation",
    "authors": "Mohammed Rakib, Adil Aman Mohammed, Cole Diggins, Sumit Sharma, Jeff Michael Sadler, Tyson Ochsner, Arun Bagavathi",
    "abstract": "Soil moisture estimation is an important task to enable precision agriculture\nin creating optimal plans for irrigation, fertilization, and harvest. It is\ncommon to utilize statistical and machine learning models to estimate soil\nmoisture from traditional data sources such as weather forecasts, soil\nproperties, and crop properties. However, there is a growing interest in\nutilizing aerial and geospatial imagery to estimate soil moisture. Although\nthese images capture high-resolution crop details, they are expensive to curate\nand challenging to interpret. Imagine, an AI-enhanced software tool that\npredicts soil moisture using visual cues captured by smartphones and\nstatistical data given by weather forecasts. This work is a first step towards\nthat goal of developing a multi-modal approach for soil moisture estimation. In\nparticular, we curate a dataset consisting of real-world images taken from\nground stations and their corresponding weather data. We also propose MIS-ME -\nMeteorological & Image based Soil Moisture Estimator, a multi-modal framework\nfor soil moisture estimation. Our extensive analysis shows that MIS-ME achieves\na MAPE of 10.79%, outperforming traditional unimodal approaches with a\nreduction of 2.6% in MAPE for meteorological data and 1.5% in MAPE for image\ndata, highlighting the effectiveness of tailored multi-modal approaches.",
    "arxiv_id": "http://arxiv.org/abs/2408.00963v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00963v1",
    "primary_category": "cs.CV",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Aggregation Models with Optimal Weights for Distributed Gaussian Processes",
    "authors": "Haoyuan Chen, Rui Tuo",
    "abstract": "Gaussian process (GP) models have received increasingly attentions in recent\nyears due to their superb prediction accuracy and modeling flexibility. To\naddress the computational burdens of GP models for large-scale datasets,\ndistributed learning for GPs are often adopted. Current aggregation models for\ndistributed GPs are not time-efficient when incorporating correlations between\nGP experts. In this work, we propose a novel approach for aggregated prediction\nin distributed GPs. The technique is suitable for both the exact and sparse\nvariational GPs. The proposed method incorporates correlations among experts,\nleading to better prediction accuracy with manageable computational\nrequirements. As demonstrated by empirical studies, the proposed approach\nresults in more stable predictions in less time than state-of-the-art\nconsistent aggregation models.",
    "arxiv_id": "http://arxiv.org/abs/2408.00955v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00955v1",
    "primary_category": "stat.ML",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Equivariant neural networks and piecewise linear representation theory",
    "authors": "Joel Gibson, Daniel Tubbenhauer, Geordie Williamson",
    "abstract": "Equivariant neural networks are neural networks with symmetry. Motivated by\nthe theory of group representations, we decompose the layers of an equivariant\nneural network into simple representations. The nonlinear activation functions\nlead to interesting nonlinear equivariant maps between simple representations.\nFor example, the rectified linear unit (ReLU) gives rise to piecewise linear\nmaps. We show that these considerations lead to a filtration of equivariant\nneural networks, generalizing Fourier series. This observation might provide a\nuseful tool for interpreting equivariant neural networks.",
    "arxiv_id": "http://arxiv.org/abs/2408.00949v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00949v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Generalisation of Total Uncertainty in AI: A Theoretical Study",
    "authors": "Keivan Shariatmadar",
    "abstract": "AI has been dealing with uncertainty to have highly accurate results. This\nbecomes even worse with reasonably small data sets or a variation in the data\nsets. This has far-reaching effects on decision-making, forecasting and\nlearning mechanisms. This study seeks to unpack the nature of uncertainty that\nexists within AI by drawing ideas from established works, the latest\ndevelopments and practical applications and provide a novel total uncertainty\ndefinition in AI.\n  From inception theories up to current methodologies, this paper provides an\nintegrated view of dealing with better total uncertainty as well as\ncomplexities of uncertainty in AI that help us understand its meaning and value\nacross different domains.",
    "arxiv_id": "http://arxiv.org/abs/2408.00946v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00946v1",
    "primary_category": "cs.AI",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Enabling High Data Throughput Reinforcement Learning on GPUs: A Domain Agnostic Framework for Data-Driven Scientific Research",
    "authors": "Tian Lan, Huan Wang, Caiming Xiong, Silvio Savarese",
    "abstract": "We introduce WarpSci, a domain agnostic framework designed to overcome\ncrucial system bottlenecks encountered in the application of reinforcement\nlearning to intricate environments with vast datasets featuring\nhigh-dimensional observation or action spaces. Notably, our framework\neliminates the need for data transfer between the CPU and GPU, enabling the\nconcurrent execution of thousands of simulations on a single or multiple GPUs.\nThis high data throughput architecture proves particularly advantageous for\ndata-driven scientific research, where intricate environment models are\ncommonly essential.",
    "arxiv_id": "http://arxiv.org/abs/2408.00930v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00930v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Verification of Machine Unlearning is Fragile",
    "authors": "Binchi Zhang, Zihan Chen, Cong Shen, Jundong Li",
    "abstract": "As privacy concerns escalate in the realm of machine learning, data owners\nnow have the option to utilize machine unlearning to remove their data from\nmachine learning models, following recent legislation. To enhance transparency\nin machine unlearning and avoid potential dishonesty by model providers,\nvarious verification strategies have been proposed. These strategies enable\ndata owners to ascertain whether their target data has been effectively\nunlearned from the model. However, our understanding of the safety issues of\nmachine unlearning verification remains nascent. In this paper, we explore the\nnovel research question of whether model providers can circumvent verification\nstrategies while retaining the information of data supposedly unlearned. Our\ninvestigation leads to a pessimistic answer: \\textit{the verification of\nmachine unlearning is fragile}. Specifically, we categorize the current\nverification strategies regarding potential dishonesty among model providers\ninto two types. Subsequently, we introduce two novel adversarial unlearning\nprocesses capable of circumventing both types. We validate the efficacy of our\nmethods through theoretical analysis and empirical experiments using real-world\ndatasets. This study highlights the vulnerabilities and limitations in machine\nunlearning verification, paving the way for further research into the safety of\nmachine unlearning.",
    "arxiv_id": "http://arxiv.org/abs/2408.00929v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00929v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Automatic Pull Request Description Generation Using LLMs: A T5 Model Approach",
    "authors": "Md Nazmus Sakib, Md Athikul Islam, Md Mashrur Arifin",
    "abstract": "Developers create pull request (PR) descriptions to provide an overview of\ntheir changes and explain the motivations behind them. These descriptions help\nreviewers and fellow developers quickly understand the updates. Despite their\nimportance, some developers omit these descriptions. To tackle this problem, we\npropose an automated method for generating PR descriptions based on commit\nmessages and source code comments. This method frames the task as a text\nsummarization problem, for which we utilized the T5 text-to-text transfer\nmodel. We fine-tuned a pre-trained T5 model using a dataset containing 33,466\nPRs. The model's effectiveness was assessed using ROUGE metrics, which are\nrecognized for their strong alignment with human evaluations. Our findings\nreveal that the T5 model significantly outperforms LexRank, which served as our\nbaseline for comparison.",
    "arxiv_id": "http://arxiv.org/abs/2408.00921v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00921v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Towards Certified Unlearning for Deep Neural Networks",
    "authors": "Binchi Zhang, Yushun Dong, Tianhao Wang, Jundong Li",
    "abstract": "In the field of machine unlearning, certified unlearning has been extensively\nstudied in convex machine learning models due to its high efficiency and strong\ntheoretical guarantees. However, its application to deep neural networks\n(DNNs), known for their highly nonconvex nature, still poses challenges. To\nbridge the gap between certified unlearning and DNNs, we propose several simple\ntechniques to extend certified unlearning methods to nonconvex objectives. To\nreduce the time complexity, we develop an efficient computation method by\ninverse Hessian approximation without compromising certification guarantees. In\naddition, we extend our discussion of certification to nonconvergence training\nand sequential unlearning, considering that real-world users can send\nunlearning requests at different time points. Extensive experiments on three\nreal-world datasets demonstrate the efficacy of our method and the advantages\nof certified unlearning in DNNs.",
    "arxiv_id": "http://arxiv.org/abs/2408.00920v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00920v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Distance-Preserving Generative Modeling of Spatial Transcriptomics",
    "authors": "Wenbin Zhou, Jin-Hong Du",
    "abstract": "Spatial transcriptomics data is invaluable for understanding the spatial\norganization of gene expression in tissues. There have been consistent efforts\nin studying how to effectively utilize the associated spatial information for\nrefining gene expression modeling. We introduce a class of distance-preserving\ngenerative models for spatial transcriptomics, which utilizes the provided\nspatial information to regularize the learned representation space of gene\nexpressions to have a similar pair-wise distance structure. This helps the\nlatent space to capture meaningful encodings of genes in spatial proximity. We\ncarry out theoretical analysis over a tractable loss function for this purpose\nand formalize the overall learning objective as a regularized evidence lower\nbound. Our framework grants compatibility with any variational-inference-based\ngenerative models for gene expression modeling. Empirically, we validate our\nproposed method on the mouse brain tissues Visium dataset and observe improved\nperformance with variational autoencoders and scVI used as backbone models.",
    "arxiv_id": "http://arxiv.org/abs/2408.00911v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00911v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Early Stopping Based on Repeated Significance",
    "authors": "Eric Bax, Arundhyoti Sarkar, Alex Shtoff",
    "abstract": "For a bucket test with a single criterion for success and a fixed number of\nsamples or testing period, requiring a $p$-value less than a specified value of\n$\\alpha$ for the success criterion produces statistical confidence at level $1\n- \\alpha$. For multiple criteria, a Bonferroni correction that partitions\n$\\alpha$ among the criteria produces statistical confidence, at the cost of\nrequiring lower $p$-values for each criterion. The same concept can be applied\nto decisions about early stopping, but that can lead to strict requirements for\n$p$-values. We show how to address that challenge by requiring criteria to be\nsuccessful at multiple decision points.",
    "arxiv_id": "http://arxiv.org/abs/2408.00908v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00908v1",
    "primary_category": "stat.ME",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Parkinson's Disease Detection from Resting State EEG using Multi-Head Graph Structure Learning with Gradient Weighted Graph Attention Explanations",
    "authors": "Christopher Neves, Yong Zeng, Yiming Xiao",
    "abstract": "Parkinson's disease (PD) is a debilitating neurodegenerative disease that has\nsevere impacts on an individual's quality of life. Compared with structural and\nfunctional MRI-based biomarkers for the disease, electroencephalography (EEG)\ncan provide more accessible alternatives for clinical insights. While deep\nlearning (DL) techniques have provided excellent outcomes, many techniques fail\nto model spatial information and dynamic brain connectivity, and face\nchallenges in robust feature learning, limited data sizes, and poor\nexplainability. To address these issues, we proposed a novel graph neural\nnetwork (GNN) technique for explainable PD detection using resting state EEG.\nSpecifically, we employ structured global convolutions with contrastive\nlearning to better model complex features with limited data, a novel multi-head\ngraph structure learner to capture the non-Euclidean structure of EEG data, and\na head-wise gradient-weighted graph attention explainer to offer neural\nconnectivity insights. We developed and evaluated our method using the UC San\nDiego Parkinson's disease EEG dataset, and achieved 69.40% detection accuracy\nin subject-wise leave-one-out cross-validation while generating intuitive\nexplanations for the learnt graph topology.",
    "arxiv_id": "http://arxiv.org/abs/2408.00906v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00906v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Discrete Randomized Smoothing Meets Quantum Computing",
    "authors": "Tom Wollschl\u00e4ger, Aman Saxena, Nicola Franco, Jeanette Miriam Lorenz, Stephan G\u00fcnnemann",
    "abstract": "Breakthroughs in machine learning (ML) and advances in quantum computing (QC)\ndrive the interdisciplinary field of quantum machine learning to new levels.\nHowever, due to the susceptibility of ML models to adversarial attacks,\npractical use raises safety-critical concerns. Existing Randomized Smoothing\n(RS) certification methods for classical machine learning models are\ncomputationally intensive. In this paper, we propose the combination of QC and\nthe concept of discrete randomized smoothing to speed up the stochastic\ncertification of ML models for discrete data. We show how to encode all the\nperturbations of the input binary data in superposition and use Quantum\nAmplitude Estimation (QAE) to obtain a quadratic reduction in the number of\ncalls to the model that are required compared to traditional randomized\nsmoothing techniques. In addition, we propose a new binary threat model to\nallow for an extensive evaluation of our approach on images, graphs, and text.",
    "arxiv_id": "http://arxiv.org/abs/2408.00895v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00895v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Peptide Sequencing Via Protein Language Models",
    "authors": "Thuong Le Hoai Pham, Jillur Rahman Saurav, Aisosa A. Omere, Calvin J. Heyl, Mohammad Sadegh Nasr, Cody Tyler Reynolds, Jai Prakash Yadav Veerla, Helen H Shang, Justyn Jaworski, Alison Ravenscraft, Joseph Anthony Buonomo, Jacob M. Luber",
    "abstract": "We introduce a protein language model for determining the complete sequence\nof a peptide based on measurement of a limited set of amino acids. To date,\nprotein sequencing relies on mass spectrometry, with some novel edman\ndegregation based platforms able to sequence non-native peptides. Current\nprotein sequencing techniques face limitations in accurately identifying all\namino acids, hindering comprehensive proteome analysis. Our method simulates\npartial sequencing data by selectively masking amino acids that are\nexperimentally difficult to identify in protein sequences from the UniRef\ndatabase. This targeted masking mimics real-world sequencing limitations. We\nthen modify and finetune a ProtBert derived transformer-based model, for a new\ndownstream task predicting these masked residues, providing an approximation of\nthe complete sequence. Evaluating on three bacterial Escherichia species, we\nachieve per-amino-acid accuracy up to 90.5% when only four amino acids ([KCYM])\nare known. Structural assessment using AlphaFold and TM-score validates the\nbiological relevance of our predictions. The model also demonstrates potential\nfor evolutionary analysis through cross-species performance. This integration\nof simulated experimental constraints with computational predictions offers a\npromising avenue for enhancing protein sequence analysis, potentially\naccelerating advancements in proteomics and structural biology by providing a\nprobabilistic reconstruction of the complete protein sequence from limited\nexperimental data.",
    "arxiv_id": "http://arxiv.org/abs/2408.00892v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00892v1",
    "primary_category": "q-bio.BM",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "On the Relationship Between Monotone and Squared Probabilistic Circuits",
    "authors": "Benjie Wang, Guy Van den Broeck",
    "abstract": "Probabilistic circuits are a unifying representation of functions as\ncomputation graphs of weighted sums and products. Their primary application is\nin probabilistic modeling, where circuits with non-negative weights (monotone\ncircuits) can be used to represent and learn density/mass functions, with\ntractable marginal inference. Recently, it was proposed to instead represent\ndensities as the square of the circuit function (squared circuits); this allows\nthe use of negative weights while retaining tractability, and can be\nexponentially more compact than monotone circuits. Unfortunately, we show the\nreverse also holds, meaning that monotone circuits and squared circuits are\nincomparable in general. This raises the question of whether we can reconcile,\nand indeed improve upon the two modeling approaches. We answer in the positive\nby proposing InceptionPCs, a novel type of circuit that naturally encompasses\nboth monotone circuits and squared circuits as special cases, and employs\ncomplex parameters. Empirically, we validate that InceptionPCs can outperform\nboth monotone and squared circuits on image datasets.",
    "arxiv_id": "http://arxiv.org/abs/2408.00876v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00876v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Online Detection of Anomalies in Temporal Knowledge Graphs with Interpretability",
    "authors": "Jiasheng Zhang, Jie Shao, Rex Ying",
    "abstract": "Temporal knowledge graphs (TKGs) are valuable resources for capturing\nevolving relationships among entities, yet they are often plagued by noise,\nnecessitating robust anomaly detection mechanisms. Existing dynamic graph\nanomaly detection approaches struggle to capture the rich semantics introduced\nby node and edge categories within TKGs, while TKG embedding methods lack\ninterpretability, undermining the credibility of anomaly detection. Moreover,\nthese methods falter in adapting to pattern changes and semantic drifts\nresulting from knowledge updates. To tackle these challenges, we introduce\nAnoT, an efficient TKG summarization method tailored for interpretable online\nanomaly detection in TKGs. AnoT begins by summarizing a TKG into a novel rule\ngraph, enabling flexible inference of complex patterns in TKGs. When new\nknowledge emerges, AnoT maps it onto a node in the rule graph and traverses the\nrule graph recursively to derive the anomaly score of the knowledge. The\ntraversal yields reachable nodes that furnish interpretable evidence for the\nvalidity or the anomalous of the new knowledge. Overall, AnoT embodies a\ndetector-updater-monitor architecture, encompassing a detector for offline TKG\nsummarization and online scoring, an updater for real-time rule graph updates\nbased on emerging knowledge, and a monitor for estimating the approximation\nerror of the rule graph. Experimental results on four real-world datasets\ndemonstrate that AnoT surpasses existing methods significantly in terms of\naccuracy and interoperability. All of the raw datasets and the implementation\nof AnoT are provided in https://github.com/zjs123/ANoT.",
    "arxiv_id": "http://arxiv.org/abs/2408.00872v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00872v1",
    "primary_category": "cs.AI",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "UniMoT: Unified Molecule-Text Language Model with Discrete Token Representation",
    "authors": "Juzheng Zhang, Yatao Bian, Yongqiang Chen, Quanming Yao",
    "abstract": "The remarkable success of Large Language Models (LLMs) across diverse tasks\nhas driven the research community to extend their capabilities to molecular\napplications. However, most molecular LLMs employ adapter-based architectures\nthat do not treat molecule and text modalities equally and lack a supervision\nsignal for the molecule modality. To address these issues, we introduce UniMoT,\na Unified Molecule-Text LLM adopting a tokenizer-based architecture that\nexpands the vocabulary of LLM with molecule tokens. Specifically, we introduce\na Vector Quantization-driven tokenizer that incorporates a Q-Former to bridge\nthe modality gap between molecule and text. This tokenizer transforms molecules\ninto sequences of molecule tokens with causal dependency, encapsulating\nhigh-level molecular and textual information. Equipped with this tokenizer,\nUniMoT can unify molecule and text modalities under a shared token\nrepresentation and an autoregressive training paradigm, enabling it to\ninterpret molecules as a foreign language and generate them as text. Following\na four-stage training scheme, UniMoT emerges as a multi-modal generalist\ncapable of performing both molecule-to-text and text-to-molecule tasks.\nExtensive experiments demonstrate that UniMoT achieves state-of-the-art\nperformance across a wide range of molecule comprehension and generation tasks.",
    "arxiv_id": "http://arxiv.org/abs/2408.00863v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00863v1",
    "primary_category": "cs.CL",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Deep Learning Approach for Changepoint Detection: Penalty Parameter Optimization",
    "authors": "Tung L Nguyen, Toby Dylan Hocking",
    "abstract": "Changepoint detection, a technique for identifying significant shifts within\ndata sequences, is crucial in various fields such as finance, genomics,\nmedicine, etc. Dynamic programming changepoint detection algorithms are\nemployed to identify the locations of changepoints within a sequence, which\nrely on a penalty parameter to regulate the number of changepoints. To estimate\nthis penalty parameter, previous work uses simple models such as linear models\nor decision trees. This study introduces a novel deep learning method for\npredicting penalty parameters, leading to demonstrably improved changepoint\ndetection accuracy on large benchmark supervised labeled datasets compared to\nprevious methods.",
    "arxiv_id": "http://arxiv.org/abs/2408.00856v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00856v1",
    "primary_category": "stat.ML",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "A Novel Use of Pseudospectra in Mathematical Biology: Understanding HPA Axis Sensitivity",
    "authors": "Catherine Drysdale, Matthew J. Colbrook",
    "abstract": "The Hypothalamic-Pituitary-Adrenal (HPA) axis is a major neuroendocrine\nsystem, and its dysregulation is implicated in various diseases. This system\nalso presents interesting mathematical challenges for modeling. We consider a\nnonlinear delay differential equation model and calculate pseudospectra of\nthree different linearizations: a time-dependent Jacobian, linearization around\nthe limit cycle, and dynamic mode decomposition (DMD) analysis of Koopman\noperators (global linearization). The time-dependent Jacobian provided insight\ninto experimental phenomena, explaining why rats respond differently to\nperturbations during corticosterone secretion's upward versus downward slopes.\nWe developed new mathematical techniques for the other two linearizations to\ncalculate pseudospectra on Banach spaces and apply DMD to delay differential\nequations, respectively. These methods helped establish local and global limit\ncycle stability and study transients. Additionally, we discuss using\npseudospectra to substantiate the model in experimental contexts and establish\nbio-variability via data-driven methods. This work is the first to utilize\npseudospectra to explore the HPA axis.",
    "arxiv_id": "http://arxiv.org/abs/2408.00845v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00845v1",
    "primary_category": "math.SP",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Calibrating Bayesian Generative Machine Learning for Bayesiamplification",
    "authors": "Sebastian Bieringer, Sascha Diefenbacher, Gregor Kasieczka, Mathias Trabs",
    "abstract": "Recently, combinations of generative and Bayesian machine learning have been\nintroduced in particle physics for both fast detector simulation and inference\ntasks. These neural networks aim to quantify the uncertainty on the generated\ndistribution originating from limited training statistics. The interpretation\nof a distribution-wide uncertainty however remains ill-defined. We show a clear\nscheme for quantifying the calibration of Bayesian generative machine learning\nmodels. For a Continuous Normalizing Flow applied to a low-dimensional toy\nexample, we evaluate the calibration of Bayesian uncertainties from either a\nmean-field Gaussian weight posterior, or Monte Carlo sampling network weights,\nto gauge their behaviour on unsteady distribution edges. Well calibrated\nuncertainties can then be used to roughly estimate the number of uncorrelated\ntruth samples that are equivalent to the generated sample and clearly indicate\ndata amplification for smooth features of the distribution.",
    "arxiv_id": "http://arxiv.org/abs/2408.00838v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00838v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "AgentGen: Enhancing Planning Abilities for Large Language Model based Agent via Environment and Task Generation",
    "authors": "Mengkang Hu, Pu Zhao, Can Xu, Qingfeng Sun, Jianguang Lou, Qingwei Lin, Ping Luo, Saravan Rajmohan, Dongmei Zhang",
    "abstract": "Large Language Model (LLM) based agents have garnered significant attention\nand are becoming increasingly popular. Furthermore, planning ability is a\ncrucial component of an LLM-based agent, involving interaction with the\nenvironment and executing actions to complete a planning task, which generally\nentails achieving a desired goal from an initial state. This paper investigates\nenhancing the planning abilities of LLMs through instruction tuning, referred\nto as agent training. Recent studies have demonstrated that utilizing\nexpert-level trajectory for instruction-tuning LLMs effectively enhances their\nplanning capabilities. However, existing work primarily focuses on synthesizing\ntrajectories from manually designed planning tasks and environments. The\nlabor-intensive nature of creating these environments and tasks impedes the\ngeneration of sufficiently varied and extensive trajectories. To address this\nlimitation, this paper explores the automated synthesis of diverse environments\nand a gradual range of planning tasks, from easy to difficult. We introduce a\nframework, AgentGen, that leverages LLMs first to generate environments and\nsubsequently generate planning tasks conditioned on these environments.\nSpecifically, to improve environmental diversity, we propose using an\ninspiration corpus composed of various domain-specific text segments as the\ncontext for synthesizing environments. Moreover, to increase the difficulty\ndiversity of generated planning tasks, we propose a bidirectional evolution\nmethod, Bi-Evol, that evolves planning tasks from easier and harder directions\nto synthesize a task set with a smoother difficulty curve. The evaluation\nresults derived from AgentBoard show that AgentGen greatly improves LLMs'\nplanning ability, e.g., the AgentGen instruction-tuned Llama-3 8B surpasses\nGPT-3.5 in overall performance. Moreover, in certain tasks, it even outperforms\nGPT-4.",
    "arxiv_id": "http://arxiv.org/abs/2408.00764v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00764v1",
    "primary_category": "cs.CL",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Tamper-Resistant Safeguards for Open-Weight LLMs",
    "authors": "Rishub Tamirisa, Bhrugu Bharathi, Long Phan, Andy Zhou, Alice Gatti, Tarun Suresh, Maxwell Lin, Justin Wang, Rowan Wang, Ron Arel, Andy Zou, Dawn Song, Bo Li, Dan Hendrycks, Mantas Mazeika",
    "abstract": "Rapid advances in the capabilities of large language models (LLMs) have\nraised widespread concerns regarding their potential for malicious use.\nOpen-weight LLMs present unique challenges, as existing safeguards lack\nrobustness to tampering attacks that modify model weights. For example, recent\nworks have demonstrated that refusal and unlearning safeguards can be trivially\nremoved with a few steps of fine-tuning. These vulnerabilities necessitate new\napproaches for enabling the safe release of open-weight LLMs. We develop a\nmethod, called TAR, for building tamper-resistant safeguards into open-weight\nLLMs such that adversaries cannot remove the safeguards even after thousands of\nsteps of fine-tuning. In extensive evaluations and red teaming analyses, we\nfind that our method greatly improves tamper-resistance while preserving benign\ncapabilities. Our results demonstrate that tamper-resistance is a tractable\nproblem, opening up a promising new avenue to improve the safety and security\nof open-weight LLMs.",
    "arxiv_id": "http://arxiv.org/abs/2408.00761v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00761v1",
    "primary_category": "cs.LG",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Smoothed Energy Guidance: Guiding Diffusion Models with Reduced Energy Curvature of Attention",
    "authors": "Susung Hong",
    "abstract": "Conditional diffusion models have shown remarkable success in visual content\ngeneration, producing high-quality samples across various domains, largely due\nto classifier-free guidance (CFG). Recent attempts to extend guidance to\nunconditional models have relied on heuristic techniques, resulting in\nsuboptimal generation quality and unintended effects. In this work, we propose\nSmoothed Energy Guidance (SEG), a novel training- and condition-free approach\nthat leverages the energy-based perspective of the self-attention mechanism to\nenhance image generation. By defining the energy of self-attention, we\nintroduce a method to reduce the curvature of the energy landscape of attention\nand use the output as the unconditional prediction. Practically, we control the\ncurvature of the energy landscape by adjusting the Gaussian kernel parameter\nwhile keeping the guidance scale parameter fixed. Additionally, we present a\nquery blurring method that is equivalent to blurring the entire attention\nweights without incurring quadratic complexity in the number of tokens. In our\nexperiments, SEG achieves a Pareto improvement in both quality and the\nreduction of side effects. The code is available at\n\\url{https://github.com/SusungHong/SEG-SDXL}.",
    "arxiv_id": "http://arxiv.org/abs/2408.00760v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00760v1",
    "primary_category": "cs.CV",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "Coarse Correspondence Elicit 3D Spacetime Understanding in Multimodal Language Model",
    "authors": "Benlin Liu, Yuhao Dong, Yiqin Wang, Yongming Rao, Yansong Tang, Wei-Chiu Ma, Ranjay Krishna",
    "abstract": "Multimodal language models (MLLMs) are increasingly being implemented in\nreal-world environments, necessitating their ability to interpret 3D spaces and\ncomprehend temporal dynamics. Despite their potential, current top models\nwithin our community still fall short in adequately understanding spatial and\ntemporal dimensions. We introduce Coarse Correspondence, a simple,\ntraining-free, effective, and general-purpose visual prompting method to elicit\n3D and temporal understanding in multimodal LLMs. Our method uses a lightweight\ntracking model to find object correspondences between frames in a video or\nbetween sets of image viewpoints. It selects the most frequent object instances\nand visualizes them with markers with unique IDs in the image. With this simple\napproach, we achieve state-of-the-art results on 3D understanding benchmarks\nincluding ScanQA (+20.5\\%) and a subset of OpenEQA (+9.7\\%), and on long-form\nvideo benchmarks such as EgoSchema (+6.0\\%). We also curate a small diagnostic\ndataset to evaluate whether MLLMs can reason about space from a described\nviewpoint other than the camera viewpoint. Again, Coarse Correspondence\nimproves spatial perspective-taking abilities but we highlight that MLLMs\nstruggle with this task. Together, we demonstrate that our simple prompting\nmethod can significantly aid downstream tasks that require 3D or temporal\nreasoning.",
    "arxiv_id": "http://arxiv.org/abs/2408.00754v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00754v1",
    "primary_category": "cs.CV",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  },
  {
    "title": "A Policy-Gradient Approach to Solving Imperfect-Information Games with Iterate Convergence",
    "authors": "Mingyang Liu, Gabriele Farina, Asuman Ozdaglar",
    "abstract": "Policy gradient methods have become a staple of any single-agent\nreinforcement learning toolbox, due to their combination of desirable\nproperties: iterate convergence, efficient use of stochastic trajectory\nfeedback, and theoretically-sound avoidance of importance sampling corrections.\nIn multi-agent imperfect-information settings (extensive-form games), however,\nit is still unknown whether the same desiderata can be guaranteed while\nretaining theoretical guarantees. Instead, sound methods for extensive-form\ngames rely on approximating counterfactual values (as opposed to Q values),\nwhich are incompatible with policy gradient methodologies. In this paper, we\ninvestigate whether policy gradient can be safely used in two-player zero-sum\nimperfect-information extensive-form games (EFGs). We establish positive\nresults, showing for the first time that a policy gradient method leads to\nprovable best-iterate convergence to a regularized Nash equilibrium in\nself-play.",
    "arxiv_id": "http://arxiv.org/abs/2408.00751v1",
    "pdf_url": "http://arxiv.org/pdf/2408.00751v1",
    "primary_category": "cs.GT",
    "votes": 0,
    "prompt": "I am interested in the following topics:\n- RL for LLM training\n- LLM in-context learning\n- Open-endedness applied to LLMs\n- Synthetic data generation\n- LLMs as outcome/process based reward models\n- Anything improving model output diversity/exploration\n- Scaling laws\n- LLMs for code/math reasoning in a formal framework\n- LLM agents\n- LLMs for scientific reasoning\n- Theoretical understanding of in-context learning\n- Theoretical understanding of scaling laws/approximation theory/statistical theory",
    "model": "gpt-4-turbo"
  }
]