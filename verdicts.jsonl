{"title": "Improving PINNs By Algebraic Inclusion of Boundary and Initial Conditions", "authors": "Mohan Ren, Zhihao Fang, Keren Li, Anirbit Mukherjee", "abstract": "\"AI for Science\" aims to solve fundamental scientific problems using AI\ntechniques. As most physical phenomena can be described as Partial Differential\nEquations (PDEs) , approximating their solutions using neural networks has\nevolved as a central component of scientific-ML. Physics-Informed Neural\nNetworks (PINNs) is the general method that has evolved for this task but its\ntraining is well-known to be very unstable. In this work we explore the\npossibility of changing the model being trained from being just a neural\nnetwork to being a non-linear transformation of it - one that algebraically\nincludes the boundary/initial conditions. This reduces the number of terms in\nthe loss function than the standard PINN losses. We demonstrate that our\nmodification leads to significant performance gains across a range of benchmark\ntasks, in various dimensions and without having to tweak the training\nalgorithm. Our conclusions are based on conducting hundreds of experiments, in\nthe fully unsupervised setting, over multiple linear and non-linear PDEs set to\nexactly solvable scenarios, which lends to a concrete measurement of our\nperformance gains in terms of order(s) of magnitude lower fractional errors\nbeing achieved, than by standard PINNs. The code accompanying this manuscript\nis publicly available at,\nhttps://github.com/MorganREN/Improving-PINNs-By-Algebraic-Inclusion-of-Boundary-and-Initial-Conditions", "arxiv_id": "http://arxiv.org/abs/2407.20741v1", "pdf_url": "http://arxiv.org/pdf/2407.20741v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Efficient Pareto Manifold Learning with Low-Rank Structure", "authors": "Weiyu Chen, James T. Kwok", "abstract": "Multi-task learning, which optimizes performance across multiple tasks, is\ninherently a multi-objective optimization problem. Various algorithms are\ndeveloped to provide discrete trade-off solutions on the Pareto front.\nRecently, continuous Pareto front approximations using a linear combination of\nbase networks have emerged as a compelling strategy. However, it suffers from\nscalability issues when the number of tasks is large. To address this issue, we\npropose a novel approach that integrates a main network with several low-rank\nmatrices to efficiently learn the Pareto manifold. It significantly reduces the\nnumber of parameters and facilitates the extraction of shared features. We also\nintroduce orthogonal regularization to further bolster performance. Extensive\nexperimental results demonstrate that the proposed approach outperforms\nstate-of-the-art baselines, especially on datasets with a large number of\ntasks.", "arxiv_id": "http://arxiv.org/abs/2407.20734v1", "pdf_url": "http://arxiv.org/pdf/2407.20734v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Persistent Sampling: Unleashing the Potential of Sequential Monte Carlo", "authors": "Minas Karamanis, Uro\u0161 Seljak", "abstract": "Sequential Monte Carlo (SMC) methods are powerful tools for Bayesian\ninference but suffer from requiring many particles for accurate estimates,\nleading to high computational costs. We introduce persistent sampling (PS), an\nextension of SMC that mitigates this issue by allowing particles from previous\niterations to persist. This generates a growing, weighted ensemble of particles\ndistributed across iterations. In each iteration, PS utilizes multiple\nimportance sampling and resampling from the mixture of all previous\ndistributions to produce the next generation of particles. This addresses\nparticle impoverishment and mode collapse, resulting in more accurate posterior\napproximations. Furthermore, this approach provides lower-variance marginal\nlikelihood estimates for model comparison. Additionally, the persistent\nparticles improve transition kernel adaptation for efficient exploration.\nExperiments on complex distributions show that PS consistently outperforms\nstandard methods, achieving lower squared bias in posterior moment estimation\nand significantly reduced marginal likelihood errors, all at a lower\ncomputational cost. PS offers a robust, efficient, and scalable framework for\nBayesian inference.", "arxiv_id": "http://arxiv.org/abs/2407.20722v1", "pdf_url": "http://arxiv.org/pdf/2407.20722v1", "primary_category": "stat.ML", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "PIP: Prototypes-Injected Prompt for Federated Class Incremental Learning", "authors": "Muhammad Anwar Ma'sum, Mahardhika Pratama, Savitha Ramasamy, Lin Liu, Habibullah Habibullah, Ryszard Kowalczyk", "abstract": "Federated Class Incremental Learning (FCIL) is a new direction in continual\nlearning (CL) for addressing catastrophic forgetting and non-IID data\ndistribution simultaneously. Existing FCIL methods call for high communication\ncosts and exemplars from previous classes. We propose a novel rehearsal-free\nmethod for FCIL named prototypes-injected prompt (PIP) that involves 3 main\nideas: a) prototype injection on prompt learning, b) prototype augmentation,\nand c) weighted Gaussian aggregation on the server side. Our experiment result\nshows that the proposed method outperforms the current state of the arts\n(SOTAs) with a significant improvement (up to 33%) in CIFAR100, MiniImageNet\nand TinyImageNet datasets. Our extensive analysis demonstrates the robustness\nof PIP in different task sizes, and the advantage of requiring smaller\nparticipating local clients, and smaller global rounds. For further study,\nsource codes of PIP, baseline, and experimental logs are shared publicly in\nhttps://github.com/anwarmaxsum/PIP.", "arxiv_id": "http://arxiv.org/abs/2407.20705v1", "pdf_url": "http://arxiv.org/pdf/2407.20705v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Industrial-Grade Smart Troubleshooting through Causal Technical Language Processing: a Proof of Concept", "authors": "Alexandre Trilla, Ossee Yiboe, Nenad Mijatovic, Jordi Vitri\u00e0", "abstract": "This paper describes the development of a causal diagnosis approach for\ntroubleshooting an industrial environment on the basis of the technical\nlanguage expressed in Return on Experience records. The proposed method\nleverages the vectorized linguistic knowledge contained in the distributed\nrepresentation of a Large Language Model, and the causal associations entailed\nby the embedded failure modes and mechanisms of the industrial assets. The\npaper presents the elementary but essential concepts of the solution, which is\nconceived as a causality-aware retrieval augmented generation system, and\nillustrates them experimentally on a real-world Predictive Maintenance setting.\nFinally, it discusses avenues of improvement for the maturity of the utilized\ncausal technology to meet the robustness challenges of increasingly complex\nscenarios in the industry.", "arxiv_id": "http://arxiv.org/abs/2407.20700v1", "pdf_url": "http://arxiv.org/pdf/2407.20700v1", "primary_category": "cs.AI", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "AgentGen: Enhancing Planning Abilities for Large Language Model based Agent via Environment and Task Generation", "authors": "Mengkang Hu, Pu Zhao, Can Xu, Qingfeng Sun, Jianguang Lou, Qingwei Lin, Ping Luo, Saravan Rajmohan, Dongmei Zhang", "abstract": "Large Language Model (LLM) based agents have garnered significant attention\nand are becoming increasingly popular. Furthermore, planning ability is a\ncrucial component of an LLM-based agent, involving interaction with the\nenvironment and executing actions to complete a planning task, which generally\nentails achieving a desired goal from an initial state. This paper investigates\nenhancing the planning abilities of LLMs through instruction tuning, referred\nto as agent training. Recent studies have demonstrated that utilizing\nexpert-level trajectory for instruction-tuning LLMs effectively enhances their\nplanning capabilities. However, existing work primarily focuses on synthesizing\ntrajectories from manually designed planning tasks and environments. The\nlabor-intensive nature of creating these environments and tasks impedes the\ngeneration of sufficiently varied and extensive trajectories. To address this\nlimitation, this paper explores the automated synthesis of diverse environments\nand a gradual range of planning tasks, from easy to difficult. We introduce a\nframework, AgentGen, that leverages LLMs first to generate environments and\nsubsequently generate planning tasks conditioned on these environments.\nSpecifically, to improve environmental diversity, we propose using an\ninspiration corpus composed of various domain-specific text segments as the\ncontext for synthesizing environments. Moreover, to increase the difficulty\ndiversity of generated planning tasks, we propose a bidirectional evolution\nmethod, Bi-Evol, that evolves planning tasks from easier and harder directions\nto synthesize a task set with a smoother difficulty curve. The evaluation\nresults derived from AgentBoard show that AgentGen greatly improves LLMs'\nplanning ability, e.g., the AgentGen instruction-tuned Llama-3 8B surpasses\nGPT-3.5 in overall performance. Moreover, in certain tasks, it even outperforms\nGPT-4.", "arxiv_id": "http://arxiv.org/abs/2408.00764v1", "pdf_url": "http://arxiv.org/pdf/2408.00764v1", "primary_category": "cs.CL", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Weak neural variational inference for solving Bayesian inverse problems without forward models: applications in elastography", "authors": "Vincent C. Scholz, Yaohua Zang, Phaedon-Stelios Koutsourelakis", "abstract": "In this paper, we introduce a novel, data-driven approach for solving\nhigh-dimensional Bayesian inverse problems based on partial differential\nequations (PDEs), called Weak Neural Variational Inference (WNVI). The method\ncomplements real measurements with virtual observations derived from the\nphysical model. In particular, weighted residuals are employed as probes to the\ngoverning PDE in order to formulate and solve a Bayesian inverse problem\nwithout ever formulating nor solving a forward model. The formulation treats\nthe state variables of the physical model as latent variables, inferred using\nStochastic Variational Inference (SVI), along with the usual unknowns. The\napproximate posterior employed uses neural networks to approximate the inverse\nmapping from state variables to the unknowns. We illustrate the proposed method\nin a biomedical setting where we infer spatially varying material properties\nfrom noisy tissue deformation data. We demonstrate that WNVI is not only as\naccurate and more efficient than traditional methods that rely on repeatedly\nsolving the (non)linear forward problem as a black-box, but it can also handle\nill-posed forward problems (e.g., with insufficient boundary conditions).", "arxiv_id": "http://arxiv.org/abs/2407.20697v1", "pdf_url": "http://arxiv.org/pdf/2407.20697v1", "primary_category": "stat.ML", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Tamper-Resistant Safeguards for Open-Weight LLMs", "authors": "Rishub Tamirisa, Bhrugu Bharathi, Long Phan, Andy Zhou, Alice Gatti, Tarun Suresh, Maxwell Lin, Justin Wang, Rowan Wang, Ron Arel, Andy Zou, Dawn Song, Bo Li, Dan Hendrycks, Mantas Mazeika", "abstract": "Rapid advances in the capabilities of large language models (LLMs) have\nraised widespread concerns regarding their potential for malicious use.\nOpen-weight LLMs present unique challenges, as existing safeguards lack\nrobustness to tampering attacks that modify model weights. For example, recent\nworks have demonstrated that refusal and unlearning safeguards can be trivially\nremoved with a few steps of fine-tuning. These vulnerabilities necessitate new\napproaches for enabling the safe release of open-weight LLMs. We develop a\nmethod, called TAR, for building tamper-resistant safeguards into open-weight\nLLMs such that adversaries cannot remove the safeguards even after thousands of\nsteps of fine-tuning. In extensive evaluations and red teaming analyses, we\nfind that our method greatly improves tamper-resistance while preserving benign\ncapabilities. Our results demonstrate that tamper-resistance is a tractable\nproblem, opening up a promising new avenue to improve the safety and security\nof open-weight LLMs.", "arxiv_id": "http://arxiv.org/abs/2408.00761v1", "pdf_url": "http://arxiv.org/pdf/2408.00761v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Time Series Anomaly Detection with CNN for Environmental Sensors in Healthcare-IoT", "authors": "Mirza Akhi Khatun, Mangolika Bhattacharya, Ciar\u00e1n Eising, Lubna Luxmi Dhirani", "abstract": "This research develops a new method to detect anomalies in time series data\nusing Convolutional Neural Networks (CNNs) in healthcare-IoT. The proposed\nmethod creates a Distributed Denial of Service (DDoS) attack using an IoT\nnetwork simulator, Cooja, which emulates environmental sensors such as\ntemperature and humidity. CNNs detect anomalies in time series data, resulting\nin a 92\\% accuracy in identifying possible attacks.", "arxiv_id": "http://arxiv.org/abs/2407.20695v1", "pdf_url": "http://arxiv.org/pdf/2407.20695v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "RELEVANT"}
{"title": "Smoothed Energy Guidance: Guiding Diffusion Models with Reduced Energy Curvature of Attention", "authors": "Susung Hong", "abstract": "Conditional diffusion models have shown remarkable success in visual content\ngeneration, producing high-quality samples across various domains, largely due\nto classifier-free guidance (CFG). Recent attempts to extend guidance to\nunconditional models have relied on heuristic techniques, resulting in\nsuboptimal generation quality and unintended effects. In this work, we propose\nSmoothed Energy Guidance (SEG), a novel training- and condition-free approach\nthat leverages the energy-based perspective of the self-attention mechanism to\nenhance image generation. By defining the energy of self-attention, we\nintroduce a method to reduce the curvature of the energy landscape of attention\nand use the output as the unconditional prediction. Practically, we control the\ncurvature of the energy landscape by adjusting the Gaussian kernel parameter\nwhile keeping the guidance scale parameter fixed. Additionally, we present a\nquery blurring method that is equivalent to blurring the entire attention\nweights without incurring quadratic complexity in the number of tokens. In our\nexperiments, SEG achieves a Pareto improvement in both quality and the\nreduction of side effects. The code is available at\n\\url{https://github.com/SusungHong/SEG-SDXL}.", "arxiv_id": "http://arxiv.org/abs/2408.00760v1", "pdf_url": "http://arxiv.org/pdf/2408.00760v1", "primary_category": "cs.CV", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Detecting Causality in the Frequency Domain with Cross-Mapping Coherence", "authors": "Zsigmond Benk\u0151, B\u00e1lint Varga, Marcell Stippinger, Zolt\u00e1n Somogyv\u00e1ri", "abstract": "Understanding causal relationships within a system is crucial for uncovering\nits underlying mechanisms. Causal discovery methods, which facilitate the\nconstruction of such models from time-series data, hold the potential to\nsignificantly advance scientific and engineering fields.\n  This study introduces the Cross-Mapping Coherence (CMC) method, designed to\nreveal causal connections in the frequency domain between time series. CMC\nbuilds upon nonlinear state-space reconstruction and extends the Convergent\nCross-Mapping algorithm to the frequency domain by utilizing coherence metrics\nfor evaluation. We tested the Cross-Mapping Coherence method using simulations\nof logistic maps, Lorenz systems, Kuramoto oscillators, and the Wilson-Cowan\nmodel of the visual cortex. CMC accurately identified the direction of causal\nconnections in all simulated scenarios. When applied to the Wilson-Cowan model,\nCMC yielded consistent results similar to spectral Granger causality.\n  Furthermore, CMC exhibits high sensitivity in detecting weak connections,\ndemonstrates sample efficiency, and maintains robustness in the presence of\nnoise.\n  In conclusion, the capability to determine directed causal influences across\ndifferent frequency bands allows CMC to provide valuable insights into the\ndynamics of complex, nonlinear systems.", "arxiv_id": "http://arxiv.org/abs/2407.20694v1", "pdf_url": "http://arxiv.org/pdf/2407.20694v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Coarse Correspondence Elicit 3D Spacetime Understanding in Multimodal Language Model", "authors": "Benlin Liu, Yuhao Dong, Yiqin Wang, Yongming Rao, Yansong Tang, Wei-Chiu Ma, Ranjay Krishna", "abstract": "Multimodal language models (MLLMs) are increasingly being implemented in\nreal-world environments, necessitating their ability to interpret 3D spaces and\ncomprehend temporal dynamics. Despite their potential, current top models\nwithin our community still fall short in adequately understanding spatial and\ntemporal dimensions. We introduce Coarse Correspondence, a simple,\ntraining-free, effective, and general-purpose visual prompting method to elicit\n3D and temporal understanding in multimodal LLMs. Our method uses a lightweight\ntracking model to find object correspondences between frames in a video or\nbetween sets of image viewpoints. It selects the most frequent object instances\nand visualizes them with markers with unique IDs in the image. With this simple\napproach, we achieve state-of-the-art results on 3D understanding benchmarks\nincluding ScanQA (+20.5\\%) and a subset of OpenEQA (+9.7\\%), and on long-form\nvideo benchmarks such as EgoSchema (+6.0\\%). We also curate a small diagnostic\ndataset to evaluate whether MLLMs can reason about space from a described\nviewpoint other than the camera viewpoint. Again, Coarse Correspondence\nimproves spatial perspective-taking abilities but we highlight that MLLMs\nstruggle with this task. Together, we demonstrate that our simple prompting\nmethod can significantly aid downstream tasks that require 3D or temporal\nreasoning.", "arxiv_id": "http://arxiv.org/abs/2408.00754v1", "pdf_url": "http://arxiv.org/pdf/2408.00754v1", "primary_category": "cs.CV", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "The Susceptibility of Example-Based Explainability Methods to Class Outliers", "authors": "Ikhtiyor Nematov, Dimitris Sacharidis, Tomer Sagi, Katja Hose", "abstract": "This study explores the impact of class outliers on the effectiveness of\nexample-based explainability methods for black-box machine learning models. We\nreformulate existing explainability evaluation metrics, such as correctness and\nrelevance, specifically for example-based methods, and introduce a new metric,\ndistinguishability. Using these metrics, we highlight the shortcomings of\ncurrent example-based explainability methods, including those who attempt to\nsuppress class outliers. We conduct experiments on two datasets, a text\nclassification dataset and an image classification dataset, and evaluate the\nperformance of four state-of-the-art explainability methods. Our findings\nunderscore the need for robust techniques to tackle the challenges posed by\nclass outliers.", "arxiv_id": "http://arxiv.org/abs/2407.20678v2", "pdf_url": "http://arxiv.org/pdf/2407.20678v2", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Rethinking the Function of Neurons in KANs", "authors": "Mohammed Ghaith Altarabichi", "abstract": "The neurons of Kolmogorov-Arnold Networks (KANs) perform a simple summation\nmotivated by the Kolmogorov-Arnold representation theorem, which asserts that\nsum is the only fundamental multivariate function. In this work, we investigate\nthe potential for identifying an alternative multivariate function for KAN\nneurons that may offer increased practical utility. Our empirical research\ninvolves testing various multivariate functions in KAN neurons across a range\nof benchmark Machine Learning tasks.\n  Our findings indicate that substituting the sum with the average function in\nKAN neurons results in significant performance enhancements compared to\ntraditional KANs. Our study demonstrates that this minor modification\ncontributes to the stability of training by confining the input to the spline\nwithin the effective range of the activation function. Our implementation and\nexperiments are available at: \\url{https://github.com/Ghaith81/dropkan}", "arxiv_id": "http://arxiv.org/abs/2407.20667v1", "pdf_url": "http://arxiv.org/pdf/2407.20667v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "A Policy-Gradient Approach to Solving Imperfect-Information Games with Iterate Convergence", "authors": "Mingyang Liu, Gabriele Farina, Asuman Ozdaglar", "abstract": "Policy gradient methods have become a staple of any single-agent\nreinforcement learning toolbox, due to their combination of desirable\nproperties: iterate convergence, efficient use of stochastic trajectory\nfeedback, and theoretically-sound avoidance of importance sampling corrections.\nIn multi-agent imperfect-information settings (extensive-form games), however,\nit is still unknown whether the same desiderata can be guaranteed while\nretaining theoretical guarantees. Instead, sound methods for extensive-form\ngames rely on approximating counterfactual values (as opposed to Q values),\nwhich are incompatible with policy gradient methodologies. In this paper, we\ninvestigate whether policy gradient can be safely used in two-player zero-sum\nimperfect-information extensive-form games (EFGs). We establish positive\nresults, showing for the first time that a policy gradient method leads to\nprovable best-iterate convergence to a regularized Nash equilibrium in\nself-play.", "arxiv_id": "http://arxiv.org/abs/2408.00751v1", "pdf_url": "http://arxiv.org/pdf/2408.00751v1", "primary_category": "cs.GT", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Leaf Angle Estimation using Mask R-CNN and LETR Vision Transformer", "authors": "Venkat Margapuri, Prapti Thapaliya, Trevor Rife", "abstract": "Modern day studies show a high degree of correlation between high yielding\ncrop varieties and plants with upright leaf angles. It is observed that plants\nwith upright leaf angles intercept more light than those without upright leaf\nangles, leading to a higher rate of photosynthesis. Plant scientists and\nbreeders benefit from tools that can directly measure plant parameters in the\nfield i.e. on-site phenotyping. The estimation of leaf angles by manual means\nin a field setting is tedious and cumbersome. We mitigate the tedium using a\ncombination of the Mask R-CNN instance segmentation neural network, and Line\nSegment Transformer (LETR), a vision transformer. The proposed Computer Vision\n(CV) pipeline is applied on two image datasets, Summer 2015-Ames ULA and Summer\n2015- Ames MLA, with a combined total of 1,827 plant images collected in the\nfield using FieldBook, an Android application aimed at on-site phenotyping. The\nleaf angles estimated by the proposed pipeline on the image datasets are\ncompared to two independent manual measurements using ImageJ, a Java-based\nimage processing program developed at the National Institutes of Health and the\nLaboratory for Optical and Computational Instrumentation. The results, when\ncompared for similarity using the Cosine Similarity measure, exhibit 0.98\nsimilarity scores on both independent measurements of Summer 2015-Ames ULA and\nSummer 2015-Ames MLA image datasets, demonstrating the feasibility of the\nproposed pipeline for on-site measurement of leaf angles.", "arxiv_id": "http://arxiv.org/abs/2408.00749v1", "pdf_url": "http://arxiv.org/pdf/2408.00749v1", "primary_category": "cs.CV", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "RELEVANT"}
{"title": "DocXPand-25k: a large and diverse benchmark dataset for identity documents analysis", "authors": "Julien Lerouge, Guillaume Betmont, Thomas Bres, Evgeny Stepankevich, Alexis Berg\u00e8s", "abstract": "Identity document (ID) image analysis has become essential for many online\nservices, like bank account opening or insurance subscription. In recent years,\nmuch research has been conducted on subjects like document localization, text\nrecognition and fraud detection, to achieve a level of accuracy reliable enough\nto automatize identity verification. However, there are only a few available\ndatasets to benchmark ID analysis methods, mainly because of privacy\nrestrictions, security requirements and legal reasons.\n  In this paper, we present the DocXPand-25k dataset, which consists of 24,994\nrichly labeled IDs images, generated using custom-made vectorial templates\nrepresenting nine fictitious ID designs, including four identity cards, two\nresidence permits and three passports designs. These synthetic IDs feature\nartificially generated personal information (names, dates, identifiers, faces,\nbarcodes, ...), and present a rich diversity in the visual layouts and textual\ncontents.\n  We collected about 5.8k diverse backgrounds coming from real-world photos,\nscans and screenshots of IDs to guarantee the variety of the backgrounds. The\nsoftware we wrote to generate these images has been published\n(https://github.com/QuickSign/docxpand/) under the terms of the MIT license,\nand our dataset has been published\n(https://github.com/QuickSign/docxpand/releases/tag/v1.0.0) under the terms of\nthe CC-BY-NC-SA 4.0 License.", "arxiv_id": "http://arxiv.org/abs/2407.20662v1", "pdf_url": "http://arxiv.org/pdf/2407.20662v1", "primary_category": "cs.CV", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Prompt-Driven Contrastive Learning for Transferable Adversarial Attacks", "authors": "Hunmin Yang, Jongoh Jeong, Kuk-Jin Yoon", "abstract": "Recent vision-language foundation models, such as CLIP, have demonstrated\nsuperior capabilities in learning representations that can be transferable\nacross diverse range of downstream tasks and domains. With the emergence of\nsuch powerful models, it has become crucial to effectively leverage their\ncapabilities in tackling challenging vision tasks. On the other hand, only a\nfew works have focused on devising adversarial examples that transfer well to\nboth unknown domains and model architectures. In this paper, we propose a novel\ntransfer attack method called PDCL-Attack, which leverages the CLIP model to\nenhance the transferability of adversarial perturbations generated by a\ngenerative model-based attack framework. Specifically, we formulate an\neffective prompt-driven feature guidance by harnessing the semantic\nrepresentation power of text, particularly from the ground-truth class labels\nof input images. To the best of our knowledge, we are the first to introduce\nprompt learning to enhance the transferable generative attacks. Extensive\nexperiments conducted across various cross-domain and cross-model settings\nempirically validate our approach, demonstrating its superiority over\nstate-of-the-art methods.", "arxiv_id": "http://arxiv.org/abs/2407.20657v1", "pdf_url": "http://arxiv.org/pdf/2407.20657v1", "primary_category": "cs.CV", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "AgentGen: Enhancing Planning Abilities for Large Language Model based Agent via Environment and Task Generation", "authors": "Mengkang Hu, Pu Zhao, Can Xu, Qingfeng Sun, Jianguang Lou, Qingwei Lin, Ping Luo, Saravan Rajmohan, Dongmei Zhang", "abstract": "Large Language Model (LLM) based agents have garnered significant attention\nand are becoming increasingly popular. Furthermore, planning ability is a\ncrucial component of an LLM-based agent, involving interaction with the\nenvironment and executing actions to complete a planning task, which generally\nentails achieving a desired goal from an initial state. This paper investigates\nenhancing the planning abilities of LLMs through instruction tuning, referred\nto as agent training. Recent studies have demonstrated that utilizing\nexpert-level trajectory for instruction-tuning LLMs effectively enhances their\nplanning capabilities. However, existing work primarily focuses on synthesizing\ntrajectories from manually designed planning tasks and environments. The\nlabor-intensive nature of creating these environments and tasks impedes the\ngeneration of sufficiently varied and extensive trajectories. To address this\nlimitation, this paper explores the automated synthesis of diverse environments\nand a gradual range of planning tasks, from easy to difficult. We introduce a\nframework, AgentGen, that leverages LLMs first to generate environments and\nsubsequently generate planning tasks conditioned on these environments.\nSpecifically, to improve environmental diversity, we propose using an\ninspiration corpus composed of various domain-specific text segments as the\ncontext for synthesizing environments. Moreover, to increase the difficulty\ndiversity of generated planning tasks, we propose a bidirectional evolution\nmethod, Bi-Evol, that evolves planning tasks from easier and harder directions\nto synthesize a task set with a smoother difficulty curve. The evaluation\nresults derived from AgentBoard show that AgentGen greatly improves LLMs'\nplanning ability, e.g., the AgentGen instruction-tuned Llama-3 8B surpasses\nGPT-3.5 in overall performance. Moreover, in certain tasks, it even outperforms\nGPT-4.", "arxiv_id": "http://arxiv.org/abs/2408.00764v1", "pdf_url": "http://arxiv.org/pdf/2408.00764v1", "primary_category": "cs.CL", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Tamper-Resistant Safeguards for Open-Weight LLMs", "authors": "Rishub Tamirisa, Bhrugu Bharathi, Long Phan, Andy Zhou, Alice Gatti, Tarun Suresh, Maxwell Lin, Justin Wang, Rowan Wang, Ron Arel, Andy Zou, Dawn Song, Bo Li, Dan Hendrycks, Mantas Mazeika", "abstract": "Rapid advances in the capabilities of large language models (LLMs) have\nraised widespread concerns regarding their potential for malicious use.\nOpen-weight LLMs present unique challenges, as existing safeguards lack\nrobustness to tampering attacks that modify model weights. For example, recent\nworks have demonstrated that refusal and unlearning safeguards can be trivially\nremoved with a few steps of fine-tuning. These vulnerabilities necessitate new\napproaches for enabling the safe release of open-weight LLMs. We develop a\nmethod, called TAR, for building tamper-resistant safeguards into open-weight\nLLMs such that adversaries cannot remove the safeguards even after thousands of\nsteps of fine-tuning. In extensive evaluations and red teaming analyses, we\nfind that our method greatly improves tamper-resistance while preserving benign\ncapabilities. Our results demonstrate that tamper-resistance is a tractable\nproblem, opening up a promising new avenue to improve the safety and security\nof open-weight LLMs.", "arxiv_id": "http://arxiv.org/abs/2408.00761v1", "pdf_url": "http://arxiv.org/pdf/2408.00761v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Smoothed Energy Guidance: Guiding Diffusion Models with Reduced Energy Curvature of Attention", "authors": "Susung Hong", "abstract": "Conditional diffusion models have shown remarkable success in visual content\ngeneration, producing high-quality samples across various domains, largely due\nto classifier-free guidance (CFG). Recent attempts to extend guidance to\nunconditional models have relied on heuristic techniques, resulting in\nsuboptimal generation quality and unintended effects. In this work, we propose\nSmoothed Energy Guidance (SEG), a novel training- and condition-free approach\nthat leverages the energy-based perspective of the self-attention mechanism to\nenhance image generation. By defining the energy of self-attention, we\nintroduce a method to reduce the curvature of the energy landscape of attention\nand use the output as the unconditional prediction. Practically, we control the\ncurvature of the energy landscape by adjusting the Gaussian kernel parameter\nwhile keeping the guidance scale parameter fixed. Additionally, we present a\nquery blurring method that is equivalent to blurring the entire attention\nweights without incurring quadratic complexity in the number of tokens. In our\nexperiments, SEG achieves a Pareto improvement in both quality and the\nreduction of side effects. The code is available at\n\\url{https://github.com/SusungHong/SEG-SDXL}.", "arxiv_id": "http://arxiv.org/abs/2408.00760v1", "pdf_url": "http://arxiv.org/pdf/2408.00760v1", "primary_category": "cs.CV", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Coarse Correspondence Elicit 3D Spacetime Understanding in Multimodal Language Model", "authors": "Benlin Liu, Yuhao Dong, Yiqin Wang, Yongming Rao, Yansong Tang, Wei-Chiu Ma, Ranjay Krishna", "abstract": "Multimodal language models (MLLMs) are increasingly being implemented in\nreal-world environments, necessitating their ability to interpret 3D spaces and\ncomprehend temporal dynamics. Despite their potential, current top models\nwithin our community still fall short in adequately understanding spatial and\ntemporal dimensions. We introduce Coarse Correspondence, a simple,\ntraining-free, effective, and general-purpose visual prompting method to elicit\n3D and temporal understanding in multimodal LLMs. Our method uses a lightweight\ntracking model to find object correspondences between frames in a video or\nbetween sets of image viewpoints. It selects the most frequent object instances\nand visualizes them with markers with unique IDs in the image. With this simple\napproach, we achieve state-of-the-art results on 3D understanding benchmarks\nincluding ScanQA (+20.5\\%) and a subset of OpenEQA (+9.7\\%), and on long-form\nvideo benchmarks such as EgoSchema (+6.0\\%). We also curate a small diagnostic\ndataset to evaluate whether MLLMs can reason about space from a described\nviewpoint other than the camera viewpoint. Again, Coarse Correspondence\nimproves spatial perspective-taking abilities but we highlight that MLLMs\nstruggle with this task. Together, we demonstrate that our simple prompting\nmethod can significantly aid downstream tasks that require 3D or temporal\nreasoning.", "arxiv_id": "http://arxiv.org/abs/2408.00754v1", "pdf_url": "http://arxiv.org/pdf/2408.00754v1", "primary_category": "cs.CV", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "A Policy-Gradient Approach to Solving Imperfect-Information Games with Iterate Convergence", "authors": "Mingyang Liu, Gabriele Farina, Asuman Ozdaglar", "abstract": "Policy gradient methods have become a staple of any single-agent\nreinforcement learning toolbox, due to their combination of desirable\nproperties: iterate convergence, efficient use of stochastic trajectory\nfeedback, and theoretically-sound avoidance of importance sampling corrections.\nIn multi-agent imperfect-information settings (extensive-form games), however,\nit is still unknown whether the same desiderata can be guaranteed while\nretaining theoretical guarantees. Instead, sound methods for extensive-form\ngames rely on approximating counterfactual values (as opposed to Q values),\nwhich are incompatible with policy gradient methodologies. In this paper, we\ninvestigate whether policy gradient can be safely used in two-player zero-sum\nimperfect-information extensive-form games (EFGs). We establish positive\nresults, showing for the first time that a policy gradient method leads to\nprovable best-iterate convergence to a regularized Nash equilibrium in\nself-play.", "arxiv_id": "http://arxiv.org/abs/2408.00751v1", "pdf_url": "http://arxiv.org/pdf/2408.00751v1", "primary_category": "cs.GT", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Leaf Angle Estimation using Mask R-CNN and LETR Vision Transformer", "authors": "Venkat Margapuri, Prapti Thapaliya, Trevor Rife", "abstract": "Modern day studies show a high degree of correlation between high yielding\ncrop varieties and plants with upright leaf angles. It is observed that plants\nwith upright leaf angles intercept more light than those without upright leaf\nangles, leading to a higher rate of photosynthesis. Plant scientists and\nbreeders benefit from tools that can directly measure plant parameters in the\nfield i.e. on-site phenotyping. The estimation of leaf angles by manual means\nin a field setting is tedious and cumbersome. We mitigate the tedium using a\ncombination of the Mask R-CNN instance segmentation neural network, and Line\nSegment Transformer (LETR), a vision transformer. The proposed Computer Vision\n(CV) pipeline is applied on two image datasets, Summer 2015-Ames ULA and Summer\n2015- Ames MLA, with a combined total of 1,827 plant images collected in the\nfield using FieldBook, an Android application aimed at on-site phenotyping. The\nleaf angles estimated by the proposed pipeline on the image datasets are\ncompared to two independent manual measurements using ImageJ, a Java-based\nimage processing program developed at the National Institutes of Health and the\nLaboratory for Optical and Computational Instrumentation. The results, when\ncompared for similarity using the Cosine Similarity measure, exhibit 0.98\nsimilarity scores on both independent measurements of Summer 2015-Ames ULA and\nSummer 2015-Ames MLA image datasets, demonstrating the feasibility of the\nproposed pipeline for on-site measurement of leaf angles.", "arxiv_id": "http://arxiv.org/abs/2408.00749v1", "pdf_url": "http://arxiv.org/pdf/2408.00749v1", "primary_category": "cs.CV", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "RELEVANT"}
{"title": "CERT-ED: Certifiably Robust Text Classification for Edit Distance", "authors": "Zhuoqun Huang, Neil G Marchant, Olga Ohrimenko, Benjamin I. P. Rubinstein", "abstract": "With the growing integration of AI in daily life, ensuring the robustness of\nsystems to inference-time attacks is crucial. Among the approaches for\ncertifying robustness to such adversarial examples, randomized smoothing has\nemerged as highly promising due to its nature as a wrapper around arbitrary\nblack-box models. Previous work on randomized smoothing in natural language\nprocessing has primarily focused on specific subsets of edit distance\noperations, such as synonym substitution or word insertion, without exploring\nthe certification of all edit operations. In this paper, we adapt Randomized\nDeletion (Huang et al., 2023) and propose, CERTified Edit Distance defense\n(CERT-ED) for natural language classification. Through comprehensive\nexperiments, we demonstrate that CERT-ED outperforms the existing Hamming\ndistance method RanMASK (Zeng et al., 2023) in 4 out of 5 datasets in terms of\nboth accuracy and the cardinality of the certificate. By covering various\nthreat models, including 5 direct and 5 transfer attacks, our method improves\nempirical robustness in 38 out of 50 settings.", "arxiv_id": "http://arxiv.org/abs/2408.00728v1", "pdf_url": "http://arxiv.org/pdf/2408.00728v1", "primary_category": "cs.CL", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "A Natural Language Processing Framework for Hotel Recommendation Based on Users' Text Reviews", "authors": "Lavrentia Aravani, Emmanuel Pintelas, Christos Pierrakeas, Panagiotis Pintelas", "abstract": "Recently, the application of Artificial Intelligence algorithms in hotel\nrecommendation systems has become an increasingly popular topic. One such\nmethod that has proven to be effective in this field is Deep Learning,\nespecially Natural Language processing models, which are able to extract\nsemantic knowledge from user's text reviews to create more efficient\nrecommendation systems. This can lead to the development of intelligent models\nthat can classify a user's preferences and emotions based on their feedback in\nthe form of text reviews about their hotel stay experience. In this study, we\npropose a Natural Language Processing framework that utilizes customer text\nreviews to provide personalized recommendations for the most appropriate hotel\nbased on their preferences. The framework is based on Bidirectional Encoder\nRepresentations from Transformers (BERT) and a fine-tuning/validation pipeline\nthat categorizes customer hotel review texts into \"Bad,\" \"Good,\" or \"Excellent\"\nrecommended hotels. Our findings indicate that the hotel recommendation system\nwe propose can significantly enhance the user experience of booking\naccommodations by providing personalized recommendations based on user\npreferences and previous booking history.", "arxiv_id": "http://arxiv.org/abs/2408.00716v1", "pdf_url": "http://arxiv.org/pdf/2408.00716v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "SAM 2: Segment Anything in Images and Videos", "authors": "Nikhila Ravi, Valentin Gabeur, Yuan-Ting Hu, Ronghang Hu, Chaitanya Ryali, Tengyu Ma, Haitham Khedr, Roman R\u00e4dle, Chloe Rolland, Laura Gustafson, Eric Mintun, Junting Pan, Kalyan Vasudev Alwala, Nicolas Carion, Chao-Yuan Wu, Ross Girshick, Piotr Doll\u00e1r, Christoph Feichtenhofer", "abstract": "We present Segment Anything Model 2 (SAM 2), a foundation model towards\nsolving promptable visual segmentation in images and videos. We build a data\nengine, which improves model and data via user interaction, to collect the\nlargest video segmentation dataset to date. Our model is a simple transformer\narchitecture with streaming memory for real-time video processing. SAM 2\ntrained on our data provides strong performance across a wide range of tasks.\nIn video segmentation, we observe better accuracy, using 3x fewer interactions\nthan prior approaches. In image segmentation, our model is more accurate and 6x\nfaster than the Segment Anything Model (SAM). We believe that our data, model,\nand insights will serve as a significant milestone for video segmentation and\nrelated perception tasks. We are releasing a version of our model, the dataset\nand an interactive demo.", "arxiv_id": "http://arxiv.org/abs/2408.00714v1", "pdf_url": "http://arxiv.org/pdf/2408.00714v1", "primary_category": "cs.CV", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Insurance Portfolio Pursuit with Reinforcement Learning", "authors": "Edward James Young, Alistair Rogers, Elliott Tong, James Jordon", "abstract": "When faced with a new customer, many factors contribute to an insurance\nfirm's decision of what offer to make to that customer. In addition to the\nexpected cost of providing the insurance, the firm must consider the other\noffers likely to be made to the customer, and how sensitive the customer is to\ndifferences in price. Moreover, firms often target a specific portfolio of\ncustomers that could depend on, e.g., age, location, and occupation. Given such\na target portfolio, firms may choose to modulate an individual customer's offer\nbased on whether the firm desires the customer within their portfolio. Given a\ntarget portfolio, we term the problem of modulating offers to achieve this\ntarget portfolio the portfolio pursuit problem. We give a formulation of\nportfolio pursuit as a sequential decision making problem, and devise a novel\nreinforcement learning algorithm for its solution. We test our method on a\ncomplex synthetic market environment, and demonstrate that it outperforms a\nbaseline method which mimics current industry approaches to portfolio pursuit.", "arxiv_id": "http://arxiv.org/abs/2408.00713v1", "pdf_url": "http://arxiv.org/pdf/2408.00713v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "AgentGen: Enhancing Planning Abilities for Large Language Model based Agent via Environment and Task Generation", "authors": "Mengkang Hu, Pu Zhao, Can Xu, Qingfeng Sun, Jianguang Lou, Qingwei Lin, Ping Luo, Saravan Rajmohan, Dongmei Zhang", "abstract": "Large Language Model (LLM) based agents have garnered significant attention\nand are becoming increasingly popular. Furthermore, planning ability is a\ncrucial component of an LLM-based agent, involving interaction with the\nenvironment and executing actions to complete a planning task, which generally\nentails achieving a desired goal from an initial state. This paper investigates\nenhancing the planning abilities of LLMs through instruction tuning, referred\nto as agent training. Recent studies have demonstrated that utilizing\nexpert-level trajectory for instruction-tuning LLMs effectively enhances their\nplanning capabilities. However, existing work primarily focuses on synthesizing\ntrajectories from manually designed planning tasks and environments. The\nlabor-intensive nature of creating these environments and tasks impedes the\ngeneration of sufficiently varied and extensive trajectories. To address this\nlimitation, this paper explores the automated synthesis of diverse environments\nand a gradual range of planning tasks, from easy to difficult. We introduce a\nframework, AgentGen, that leverages LLMs first to generate environments and\nsubsequently generate planning tasks conditioned on these environments.\nSpecifically, to improve environmental diversity, we propose using an\ninspiration corpus composed of various domain-specific text segments as the\ncontext for synthesizing environments. Moreover, to increase the difficulty\ndiversity of generated planning tasks, we propose a bidirectional evolution\nmethod, Bi-Evol, that evolves planning tasks from easier and harder directions\nto synthesize a task set with a smoother difficulty curve. The evaluation\nresults derived from AgentBoard show that AgentGen greatly improves LLMs'\nplanning ability, e.g., the AgentGen instruction-tuned Llama-3 8B surpasses\nGPT-3.5 in overall performance. Moreover, in certain tasks, it even outperforms\nGPT-4.", "arxiv_id": "http://arxiv.org/abs/2408.00764v1", "pdf_url": "http://arxiv.org/pdf/2408.00764v1", "primary_category": "cs.CL", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Tamper-Resistant Safeguards for Open-Weight LLMs", "authors": "Rishub Tamirisa, Bhrugu Bharathi, Long Phan, Andy Zhou, Alice Gatti, Tarun Suresh, Maxwell Lin, Justin Wang, Rowan Wang, Ron Arel, Andy Zou, Dawn Song, Bo Li, Dan Hendrycks, Mantas Mazeika", "abstract": "Rapid advances in the capabilities of large language models (LLMs) have\nraised widespread concerns regarding their potential for malicious use.\nOpen-weight LLMs present unique challenges, as existing safeguards lack\nrobustness to tampering attacks that modify model weights. For example, recent\nworks have demonstrated that refusal and unlearning safeguards can be trivially\nremoved with a few steps of fine-tuning. These vulnerabilities necessitate new\napproaches for enabling the safe release of open-weight LLMs. We develop a\nmethod, called TAR, for building tamper-resistant safeguards into open-weight\nLLMs such that adversaries cannot remove the safeguards even after thousands of\nsteps of fine-tuning. In extensive evaluations and red teaming analyses, we\nfind that our method greatly improves tamper-resistance while preserving benign\ncapabilities. Our results demonstrate that tamper-resistance is a tractable\nproblem, opening up a promising new avenue to improve the safety and security\nof open-weight LLMs.", "arxiv_id": "http://arxiv.org/abs/2408.00761v1", "pdf_url": "http://arxiv.org/pdf/2408.00761v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Smoothed Energy Guidance: Guiding Diffusion Models with Reduced Energy Curvature of Attention", "authors": "Susung Hong", "abstract": "Conditional diffusion models have shown remarkable success in visual content\ngeneration, producing high-quality samples across various domains, largely due\nto classifier-free guidance (CFG). Recent attempts to extend guidance to\nunconditional models have relied on heuristic techniques, resulting in\nsuboptimal generation quality and unintended effects. In this work, we propose\nSmoothed Energy Guidance (SEG), a novel training- and condition-free approach\nthat leverages the energy-based perspective of the self-attention mechanism to\nenhance image generation. By defining the energy of self-attention, we\nintroduce a method to reduce the curvature of the energy landscape of attention\nand use the output as the unconditional prediction. Practically, we control the\ncurvature of the energy landscape by adjusting the Gaussian kernel parameter\nwhile keeping the guidance scale parameter fixed. Additionally, we present a\nquery blurring method that is equivalent to blurring the entire attention\nweights without incurring quadratic complexity in the number of tokens. In our\nexperiments, SEG achieves a Pareto improvement in both quality and the\nreduction of side effects. The code is available at\n\\url{https://github.com/SusungHong/SEG-SDXL}.", "arxiv_id": "http://arxiv.org/abs/2408.00760v1", "pdf_url": "http://arxiv.org/pdf/2408.00760v1", "primary_category": "cs.CV", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Coarse Correspondence Elicit 3D Spacetime Understanding in Multimodal Language Model", "authors": "Benlin Liu, Yuhao Dong, Yiqin Wang, Yongming Rao, Yansong Tang, Wei-Chiu Ma, Ranjay Krishna", "abstract": "Multimodal language models (MLLMs) are increasingly being implemented in\nreal-world environments, necessitating their ability to interpret 3D spaces and\ncomprehend temporal dynamics. Despite their potential, current top models\nwithin our community still fall short in adequately understanding spatial and\ntemporal dimensions. We introduce Coarse Correspondence, a simple,\ntraining-free, effective, and general-purpose visual prompting method to elicit\n3D and temporal understanding in multimodal LLMs. Our method uses a lightweight\ntracking model to find object correspondences between frames in a video or\nbetween sets of image viewpoints. It selects the most frequent object instances\nand visualizes them with markers with unique IDs in the image. With this simple\napproach, we achieve state-of-the-art results on 3D understanding benchmarks\nincluding ScanQA (+20.5\\%) and a subset of OpenEQA (+9.7\\%), and on long-form\nvideo benchmarks such as EgoSchema (+6.0\\%). We also curate a small diagnostic\ndataset to evaluate whether MLLMs can reason about space from a described\nviewpoint other than the camera viewpoint. Again, Coarse Correspondence\nimproves spatial perspective-taking abilities but we highlight that MLLMs\nstruggle with this task. Together, we demonstrate that our simple prompting\nmethod can significantly aid downstream tasks that require 3D or temporal\nreasoning.", "arxiv_id": "http://arxiv.org/abs/2408.00754v1", "pdf_url": "http://arxiv.org/pdf/2408.00754v1", "primary_category": "cs.CV", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "A Policy-Gradient Approach to Solving Imperfect-Information Games with Iterate Convergence", "authors": "Mingyang Liu, Gabriele Farina, Asuman Ozdaglar", "abstract": "Policy gradient methods have become a staple of any single-agent\nreinforcement learning toolbox, due to their combination of desirable\nproperties: iterate convergence, efficient use of stochastic trajectory\nfeedback, and theoretically-sound avoidance of importance sampling corrections.\nIn multi-agent imperfect-information settings (extensive-form games), however,\nit is still unknown whether the same desiderata can be guaranteed while\nretaining theoretical guarantees. Instead, sound methods for extensive-form\ngames rely on approximating counterfactual values (as opposed to Q values),\nwhich are incompatible with policy gradient methodologies. In this paper, we\ninvestigate whether policy gradient can be safely used in two-player zero-sum\nimperfect-information extensive-form games (EFGs). We establish positive\nresults, showing for the first time that a policy gradient method leads to\nprovable best-iterate convergence to a regularized Nash equilibrium in\nself-play.", "arxiv_id": "http://arxiv.org/abs/2408.00751v1", "pdf_url": "http://arxiv.org/pdf/2408.00751v1", "primary_category": "cs.GT", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Leaf Angle Estimation using Mask R-CNN and LETR Vision Transformer", "authors": "Venkat Margapuri, Prapti Thapaliya, Trevor Rife", "abstract": "Modern day studies show a high degree of correlation between high yielding\ncrop varieties and plants with upright leaf angles. It is observed that plants\nwith upright leaf angles intercept more light than those without upright leaf\nangles, leading to a higher rate of photosynthesis. Plant scientists and\nbreeders benefit from tools that can directly measure plant parameters in the\nfield i.e. on-site phenotyping. The estimation of leaf angles by manual means\nin a field setting is tedious and cumbersome. We mitigate the tedium using a\ncombination of the Mask R-CNN instance segmentation neural network, and Line\nSegment Transformer (LETR), a vision transformer. The proposed Computer Vision\n(CV) pipeline is applied on two image datasets, Summer 2015-Ames ULA and Summer\n2015- Ames MLA, with a combined total of 1,827 plant images collected in the\nfield using FieldBook, an Android application aimed at on-site phenotyping. The\nleaf angles estimated by the proposed pipeline on the image datasets are\ncompared to two independent manual measurements using ImageJ, a Java-based\nimage processing program developed at the National Institutes of Health and the\nLaboratory for Optical and Computational Instrumentation. The results, when\ncompared for similarity using the Cosine Similarity measure, exhibit 0.98\nsimilarity scores on both independent measurements of Summer 2015-Ames ULA and\nSummer 2015-Ames MLA image datasets, demonstrating the feasibility of the\nproposed pipeline for on-site measurement of leaf angles.", "arxiv_id": "http://arxiv.org/abs/2408.00749v1", "pdf_url": "http://arxiv.org/pdf/2408.00749v1", "primary_category": "cs.CV", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "RELEVANT"}
{"title": "CERT-ED: Certifiably Robust Text Classification for Edit Distance", "authors": "Zhuoqun Huang, Neil G Marchant, Olga Ohrimenko, Benjamin I. P. Rubinstein", "abstract": "With the growing integration of AI in daily life, ensuring the robustness of\nsystems to inference-time attacks is crucial. Among the approaches for\ncertifying robustness to such adversarial examples, randomized smoothing has\nemerged as highly promising due to its nature as a wrapper around arbitrary\nblack-box models. Previous work on randomized smoothing in natural language\nprocessing has primarily focused on specific subsets of edit distance\noperations, such as synonym substitution or word insertion, without exploring\nthe certification of all edit operations. In this paper, we adapt Randomized\nDeletion (Huang et al., 2023) and propose, CERTified Edit Distance defense\n(CERT-ED) for natural language classification. Through comprehensive\nexperiments, we demonstrate that CERT-ED outperforms the existing Hamming\ndistance method RanMASK (Zeng et al., 2023) in 4 out of 5 datasets in terms of\nboth accuracy and the cardinality of the certificate. By covering various\nthreat models, including 5 direct and 5 transfer attacks, our method improves\nempirical robustness in 38 out of 50 settings.", "arxiv_id": "http://arxiv.org/abs/2408.00728v1", "pdf_url": "http://arxiv.org/pdf/2408.00728v1", "primary_category": "cs.CL", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "A Natural Language Processing Framework for Hotel Recommendation Based on Users' Text Reviews", "authors": "Lavrentia Aravani, Emmanuel Pintelas, Christos Pierrakeas, Panagiotis Pintelas", "abstract": "Recently, the application of Artificial Intelligence algorithms in hotel\nrecommendation systems has become an increasingly popular topic. One such\nmethod that has proven to be effective in this field is Deep Learning,\nespecially Natural Language processing models, which are able to extract\nsemantic knowledge from user's text reviews to create more efficient\nrecommendation systems. This can lead to the development of intelligent models\nthat can classify a user's preferences and emotions based on their feedback in\nthe form of text reviews about their hotel stay experience. In this study, we\npropose a Natural Language Processing framework that utilizes customer text\nreviews to provide personalized recommendations for the most appropriate hotel\nbased on their preferences. The framework is based on Bidirectional Encoder\nRepresentations from Transformers (BERT) and a fine-tuning/validation pipeline\nthat categorizes customer hotel review texts into \"Bad,\" \"Good,\" or \"Excellent\"\nrecommended hotels. Our findings indicate that the hotel recommendation system\nwe propose can significantly enhance the user experience of booking\naccommodations by providing personalized recommendations based on user\npreferences and previous booking history.", "arxiv_id": "http://arxiv.org/abs/2408.00716v1", "pdf_url": "http://arxiv.org/pdf/2408.00716v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "SAM 2: Segment Anything in Images and Videos", "authors": "Nikhila Ravi, Valentin Gabeur, Yuan-Ting Hu, Ronghang Hu, Chaitanya Ryali, Tengyu Ma, Haitham Khedr, Roman R\u00e4dle, Chloe Rolland, Laura Gustafson, Eric Mintun, Junting Pan, Kalyan Vasudev Alwala, Nicolas Carion, Chao-Yuan Wu, Ross Girshick, Piotr Doll\u00e1r, Christoph Feichtenhofer", "abstract": "We present Segment Anything Model 2 (SAM 2), a foundation model towards\nsolving promptable visual segmentation in images and videos. We build a data\nengine, which improves model and data via user interaction, to collect the\nlargest video segmentation dataset to date. Our model is a simple transformer\narchitecture with streaming memory for real-time video processing. SAM 2\ntrained on our data provides strong performance across a wide range of tasks.\nIn video segmentation, we observe better accuracy, using 3x fewer interactions\nthan prior approaches. In image segmentation, our model is more accurate and 6x\nfaster than the Segment Anything Model (SAM). We believe that our data, model,\nand insights will serve as a significant milestone for video segmentation and\nrelated perception tasks. We are releasing a version of our model, the dataset\nand an interactive demo.", "arxiv_id": "http://arxiv.org/abs/2408.00714v1", "pdf_url": "http://arxiv.org/pdf/2408.00714v1", "primary_category": "cs.CV", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Insurance Portfolio Pursuit with Reinforcement Learning", "authors": "Edward James Young, Alistair Rogers, Elliott Tong, James Jordon", "abstract": "When faced with a new customer, many factors contribute to an insurance\nfirm's decision of what offer to make to that customer. In addition to the\nexpected cost of providing the insurance, the firm must consider the other\noffers likely to be made to the customer, and how sensitive the customer is to\ndifferences in price. Moreover, firms often target a specific portfolio of\ncustomers that could depend on, e.g., age, location, and occupation. Given such\na target portfolio, firms may choose to modulate an individual customer's offer\nbased on whether the firm desires the customer within their portfolio. Given a\ntarget portfolio, we term the problem of modulating offers to achieve this\ntarget portfolio the portfolio pursuit problem. We give a formulation of\nportfolio pursuit as a sequential decision making problem, and devise a novel\nreinforcement learning algorithm for its solution. We test our method on a\ncomplex synthetic market environment, and demonstrate that it outperforms a\nbaseline method which mimics current industry approaches to portfolio pursuit.", "arxiv_id": "http://arxiv.org/abs/2408.00713v1", "pdf_url": "http://arxiv.org/pdf/2408.00713v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Synthetic dual image generation for reduction of labeling efforts in semantic segmentation of micrographs with a customized metric function", "authors": "Matias Oscar Volman Stern, Dominic Hohs, Andreas Jansche, Timo Bernthaler, Gerhard Schneider", "abstract": "Training of semantic segmentation models for material analysis requires\nmicrographs and their corresponding masks. It is quite unlikely that perfect\nmasks will be drawn, especially at the edges of objects, and sometimes the\namount of data that can be obtained is small, since only a few samples are\navailable. These aspects make it very problematic to train a robust model. We\ndemonstrate a workflow for the improvement of semantic segmentation models of\nmicrographs through the generation of synthetic microstructural images in\nconjunction with masks. The workflow only requires joining a few micrographs\nwith their respective masks to create the input for a Vector\nQuantised-Variational AutoEncoder model that includes an embedding space, which\nis trained such that a generative model (PixelCNN) learns the distribution of\neach input, transformed into discrete codes, and can be used to sample new\ncodes. The latter will eventually be decoded by VQ-VAE to generate images\nalongside corresponding masks for semantic segmentation. To evaluate the\nsynthetic data, we have trained U-Net models with different amounts of these\nsynthetic data in conjunction with real data. These models were then evaluated\nusing non-synthetic images only. Additionally, we introduce a customized metric\nderived from the mean Intersection over Union (mIoU). The proposed metric\nprevents a few falsely predicted pixels from greatly reducing the value of the\nmIoU. We have achieved a reduction in sample preparation and acquisition times,\nas well as the efforts, needed for image processing and labeling tasks, are\nless when it comes to training semantic segmentation model. The approach could\nbe generalized to various types of image data such that it serves as a\nuser-friendly solution for training models with a small number of real images.", "arxiv_id": "http://arxiv.org/abs/2408.00707v1", "pdf_url": "http://arxiv.org/pdf/2408.00707v1", "primary_category": "cs.CV", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "RELEVANT"}
{"title": "Point-supervised Brain Tumor Segmentation with Box-prompted MedSAM", "authors": "Xiaofeng Liu, Jonghye Woo, Chao Ma, Jinsong Ouyang, Georges El Fakhri", "abstract": "Delineating lesions and anatomical structure is important for image-guided\ninterventions. Point-supervised medical image segmentation (PSS) has great\npotential to alleviate costly expert delineation labeling. However, due to the\nlack of precise size and boundary guidance, the effectiveness of PSS often\nfalls short of expectations. Although recent vision foundational models, such\nas the medical segment anything model (MedSAM), have made significant\nadvancements in bounding-box-prompted segmentation, it is not straightforward\nto utilize point annotation, and is prone to semantic ambiguity. In this\npreliminary study, we introduce an iterative framework to facilitate\nsemantic-aware point-supervised MedSAM. Specifically, the semantic box-prompt\ngenerator (SBPG) module has the capacity to convert the point input into\npotential pseudo bounding box suggestions, which are explicitly refined by the\nprototype-based semantic similarity. This is then succeeded by a prompt-guided\nspatial refinement (PGSR) module that harnesses the exceptional\ngeneralizability of MedSAM to infer the segmentation mask, which also updates\nthe box proposal seed in SBPG. Performance can be progressively improved with\nadequate iterations. We conducted an evaluation on BraTS2018 for the\nsegmentation of whole brain tumors and demonstrated its superior performance\ncompared to traditional PSS methods and on par with box-supervised methods.", "arxiv_id": "http://arxiv.org/abs/2408.00706v1", "pdf_url": "http://arxiv.org/pdf/2408.00706v1", "primary_category": "cs.CV", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "You Can't Ignore Either: Unifying Structure and Feature Denoising for Robust Graph Learning", "authors": "Tianmeng Yang, Jiahao Meng, Min Zhou, Yaming Yang, Yujing Wang, Xiangtai Li, Yunhai Tong", "abstract": "Recent research on the robustness of Graph Neural Networks (GNNs) under\nnoises or attacks has attracted great attention due to its importance in\nreal-world applications. Most previous methods explore a single noise source,\nrecovering corrupt node embedding by reliable structures bias or developing\nstructure learning with reliable node features. However, the noises and attacks\nmay come from both structures and features in graphs, making the graph\ndenoising a dilemma and challenging problem. In this paper, we develop a\nunified graph denoising (UGD) framework to unravel the deadlock between\nstructure and feature denoising. Specifically, a high-order neighborhood\nproximity evaluation method is proposed to recognize noisy edges, considering\nfeatures may be perturbed simultaneously. Moreover, we propose to refine noisy\nfeatures with reconstruction based on a graph auto-encoder. An iterative\nupdating algorithm is further designed to optimize the framework and acquire a\nclean graph, thus enabling robust graph learning for downstream tasks. Our UGD\nframework is self-supervised and can be easily implemented as a plug-and-play\nmodule. We carry out extensive experiments, which proves the effectiveness and\nadvantages of our method. Code is avalaible at\nhttps://github.com/YoungTimmy/UGD.", "arxiv_id": "http://arxiv.org/abs/2408.00700v1", "pdf_url": "http://arxiv.org/pdf/2408.00700v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Granular-Balls based Fuzzy Twin Support Vector Machine for Classification", "authors": "Lixi Zhao, Weiping Ding, Duoqian Miao, Guangming Lang", "abstract": "The twin support vector machine (TWSVM) classifier has attracted increasing\nattention because of its low computational complexity. However, its performance\ntends to degrade when samples are affected by noise. The granular-ball fuzzy\nsupport vector machine (GBFSVM) classifier partly alleviates the adverse\neffects of noise, but it relies solely on the distance between the\ngranular-ball's center and the class center to design the granular-ball\nmembership function. In this paper, we first introduce the granular-ball twin\nsupport vector machine (GBTWSVM) classifier, which integrates granular-ball\ncomputing (GBC) with the twin support vector machine (TWSVM) classifier. By\nreplacing traditional point inputs with granular-balls, we demonstrate how to\nderive a pair of non-parallel hyperplanes for the GBTWSVM classifier by solving\na quadratic programming problem. Subsequently, we design the membership and\nnon-membership functions of granular-balls using Pythagorean fuzzy sets to\ndifferentiate the contributions of granular-balls in various regions.\nAdditionally, we develop the granular-ball fuzzy twin support vector machine\n(GBFTSVM) classifier by incorporating GBC with the fuzzy twin support vector\nmachine (FTSVM) classifier. We demonstrate how to derive a pair of non-parallel\nhyperplanes for the GBFTSVM classifier by solving a quadratic programming\nproblem. We also design algorithms for the GBTSVM classifier and the GBFTSVM\nclassifier. Finally, the superior classification performance of the GBTWSVM\nclassifier and the GBFTSVM classifier on 20 benchmark datasets underscores\ntheir scalability, efficiency, and robustness in tackling classification tasks.", "arxiv_id": "http://arxiv.org/abs/2408.00699v1", "pdf_url": "http://arxiv.org/pdf/2408.00699v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Accelerating Full Waveform Inversion By Transfer Learning", "authors": "Divya Shyam Singh, Leon Herrmann, Qing Sun, Tim B\u00fcrchner, Felix Dietrich, Stefan Kollmannsberger", "abstract": "Full waveform inversion (FWI) is a powerful tool for reconstructing material\nfields based on sparsely measured data obtained by wave propagation. For\nspecific problems, discretizing the material field with a neural network (NN)\nimproves the robustness and reconstruction quality of the corresponding\noptimization problem. We call this method NN-based FWI. Starting from an\ninitial guess, the weights of the NN are iteratively updated to fit the\nsimulated wave signals to the sparsely measured data set. For gradient-based\noptimization, a suitable choice of the initial guess, i.e., a suitable NN\nweight initialization, is crucial for fast and robust convergence.\n  In this paper, we introduce a novel transfer learning approach to further\nimprove NN-based FWI. This approach leverages supervised pretraining to provide\na better NN weight initialization, leading to faster convergence of the\nsubsequent optimization problem. Moreover, the inversions yield physically more\nmeaningful local minima. The network is pretrained to predict the unknown\nmaterial field using the gradient information from the first iteration of\nconventional FWI. In our computational experiments on two-dimensional domains,\nthe training data set consists of reference simulations with arbitrarily\npositioned elliptical voids of different shapes and orientations. We compare\nthe performance of the proposed transfer learning NN-based FWI with three other\nmethods: conventional FWI, NN-based FWI without pretraining and conventional\nFWI with an initial guess predicted from the pretrained NN. Our results show\nthat transfer learning NN-based FWI outperforms the other methods in terms of\nconvergence speed and reconstruction quality.", "arxiv_id": "http://arxiv.org/abs/2408.00695v1", "pdf_url": "http://arxiv.org/pdf/2408.00695v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "RELEVANT"}
{"title": "Alpha-VI DeepONet: A prior-robust variational Bayesian approach for enhancing DeepONets with uncertainty quantification", "authors": "Soban Nasir Lone, Subhayan De, Rajdip Nayek", "abstract": "We introduce a novel deep operator network (DeepONet) framework that\nincorporates generalised variational inference (GVI) using R\\'enyi's\n$\\alpha$-divergence to learn complex operators while quantifying uncertainty.\nBy incorporating Bayesian neural networks as the building blocks for the branch\nand trunk networks, our framework endows DeepONet with uncertainty\nquantification. The use of R\\'enyi's $\\alpha$-divergence, instead of the\nKullback-Leibler divergence (KLD), commonly used in standard variational\ninference, mitigates issues related to prior misspecification that are\nprevalent in Variational Bayesian DeepONets. This approach offers enhanced\nflexibility and robustness. We demonstrate that modifying the variational\nobjective function yields superior results in terms of minimising the mean\nsquared error and improving the negative log-likelihood on the test set. Our\nframework's efficacy is validated across various mechanical systems, where it\noutperforms both deterministic and standard KLD-based VI DeepONets in\npredictive accuracy and uncertainty quantification. The hyperparameter\n$\\alpha$, which controls the degree of robustness, can be tuned to optimise\nperformance for specific problems. We apply this approach to a range of\nmechanics problems, including gravity pendulum, advection-diffusion, and\ndiffusion-reaction systems. Our findings underscore the potential of\n$\\alpha$-VI DeepONet to advance the field of data-driven operator learning and\nits applications in engineering and scientific domains.", "arxiv_id": "http://arxiv.org/abs/2408.00681v1", "pdf_url": "http://arxiv.org/pdf/2408.00681v1", "primary_category": "stat.ML", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "An effect analysis of the balancing techniques on the counterfactual explanations of student success prediction models", "authors": "Mustafa Cavus, Jakub Kuzilek", "abstract": "In the past decade, we have experienced a massive boom in the usage of\ndigital solutions in higher education. Due to this boom, large amounts of data\nhave enabled advanced data analysis methods to support learners and examine\nlearning processes. One of the dominant research directions in learning\nanalytics is predictive modeling of learners' success using various machine\nlearning methods. To build learners' and teachers' trust in such methods and\nsystems, exploring the methods and methodologies that enable relevant\nstakeholders to deeply understand the underlying machine-learning models is\nnecessary. In this context, counterfactual explanations from explainable\nmachine learning tools are promising. Several counterfactual generation methods\nhold much promise, but the features must be actionable and causal to be\neffective. Thus, obtaining which counterfactual generation method suits the\nstudent success prediction models in terms of desiderata, stability, and\nrobustness is essential. Although a few studies have been published in recent\nyears on the use of counterfactual explanations in educational sciences, they\nhave yet to discuss which counterfactual generation method is more suitable for\nthis problem. This paper analyzed the effectiveness of commonly used\ncounterfactual generation methods, such as WhatIf Counterfactual Explanations,\nMulti-Objective Counterfactual Explanations, and Nearest Instance\nCounterfactual Explanations after balancing. This contribution presents a case\nstudy using the Open University Learning Analytics dataset to demonstrate the\npractical usefulness of counterfactual explanations. The results illustrate the\nmethod's effectiveness and describe concrete steps that could be taken to alter\nthe model's prediction.", "arxiv_id": "http://arxiv.org/abs/2408.00676v1", "pdf_url": "http://arxiv.org/pdf/2408.00676v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "ChordSync: Conformer-Based Alignment of Chord Annotations to Music Audio", "authors": "Andrea Poltronieri, Valentina Presutti, Mart\u00edn Rocamora", "abstract": "In the Western music tradition, chords are the main constituent components of\nharmony, a fundamental dimension of music. Despite its relevance for several\nMusic Information Retrieval (MIR) tasks, chord-annotated audio datasets are\nlimited and need more diversity. One way to improve those resources is to\nleverage the large number of chord annotations available online, but this\nrequires aligning them with music audio. However, existing audio-to-score\nalignment techniques, which typically rely on Dynamic Time Warping (DTW), fail\nto address this challenge, as they require weakly aligned data for precise\nsynchronisation. In this paper, we introduce ChordSync, a novel conformer-based\nmodel designed to seamlessly align chord annotations with audio, eliminating\nthe need for weak alignment. We also provide a pre-trained model and a\nuser-friendly library, enabling users to synchronise chord annotations with\naudio tracks effortlessly. In this way, ChordSync creates opportunities for\nharnessing crowd-sourced chord data for MIR, especially in audio chord\nestimation, thereby facilitating the generation of novel datasets.\nAdditionally, our system extends its utility to music education, enhancing\nmusic learning experiences by providing accurately aligned annotations, thus\nenabling learners to engage in synchronised musical practices.", "arxiv_id": "http://arxiv.org/abs/2408.00674v1", "pdf_url": "http://arxiv.org/pdf/2408.00674v1", "primary_category": "cs.SD", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "AutoM3L: An Automated Multimodal Machine Learning Framework with Large Language Models", "authors": "Daqin Luo, Chengjian Feng, Yuxuan Nong, Yiqing Shen", "abstract": "Automated Machine Learning (AutoML) offers a promising approach to streamline\nthe training of machine learning models. However, existing AutoML frameworks\nare often limited to unimodal scenarios and require extensive manual\nconfiguration. Recent advancements in Large Language Models (LLMs) have\nshowcased their exceptional abilities in reasoning, interaction, and code\ngeneration, presenting an opportunity to develop a more automated and\nuser-friendly framework. To this end, we introduce AutoM3L, an innovative\nAutomated Multimodal Machine Learning framework that leverages LLMs as\ncontrollers to automatically construct multimodal training pipelines. AutoM3L\ncomprehends data modalities and selects appropriate models based on user\nrequirements, providing automation and interactivity. By eliminating the need\nfor manual feature engineering and hyperparameter optimization, our framework\nsimplifies user engagement and enables customization through directives,\naddressing the limitations of previous rule-based AutoML approaches. We\nevaluate the performance of AutoM3L on six diverse multimodal datasets spanning\nclassification, regression, and retrieval tasks, as well as a comprehensive set\nof unimodal datasets. The results demonstrate that AutoM3L achieves competitive\nor superior performance compared to traditional rule-based AutoML methods.\nFurthermore, a user study highlights the user-friendliness and usability of our\nframework, compared to the rule-based AutoML methods.", "arxiv_id": "http://arxiv.org/abs/2408.00665v1", "pdf_url": "http://arxiv.org/pdf/2408.00665v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Aligning Multiple Knowledge Graphs in a Single Pass", "authors": "Yaming Yang, Zhe Wang, Ziyu Guan, Wei Zhao, Weigang Lu, Xinyan Huang", "abstract": "Entity alignment (EA) is to identify equivalent entities across different\nknowledge graphs (KGs), which can help fuse these KGs into a more comprehensive\none. Previous EA methods mainly focus on aligning a pair of KGs, and to the\nbest of our knowledge, no existing EA method considers aligning multiple (more\nthan two) KGs. To fill this research gap, in this work, we study a novel\nproblem of aligning multiple KGs and propose an effective framework named\nMultiEA to solve the problem. First, we embed the entities of all the candidate\nKGs into a common feature space by a shared KG encoder. Then, we explore three\nalignment strategies to minimize the distances among pre-aligned entities. In\nparticular, we propose an innovative inference enhancement technique to improve\nthe alignment performance by incorporating high-order similarities. Finally, to\nverify the effectiveness of MultiEA, we construct two new real-world benchmark\ndatasets and conduct extensive experiments on them. The results show that our\nMultiEA can effectively and efficiently align multiple KGs in a single pass.", "arxiv_id": "http://arxiv.org/abs/2408.00662v1", "pdf_url": "http://arxiv.org/pdf/2408.00662v1", "primary_category": "cs.CL", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Disentangling Dense Embeddings with Sparse Autoencoders", "authors": "Charles O'Neill, Christine Ye, Kartheik Iyer, John F. Wu", "abstract": "Sparse autoencoders (SAEs) have shown promise in extracting interpretable\nfeatures from complex neural networks. We present one of the first applications\nof SAEs to dense text embeddings from large language models, demonstrating\ntheir effectiveness in disentangling semantic concepts. By training SAEs on\nembeddings of over 420,000 scientific paper abstracts from computer science and\nastronomy, we show that the resulting sparse representations maintain semantic\nfidelity while offering interpretability. We analyse these learned features,\nexploring their behaviour across different model capacities and introducing a\nnovel method for identifying ``feature families'' that represent related\nconcepts at varying levels of abstraction. To demonstrate the practical utility\nof our approach, we show how these interpretable features can be used to\nprecisely steer semantic search, allowing for fine-grained control over query\nsemantics. This work bridges the gap between the semantic richness of dense\nembeddings and the interpretability of sparse representations. We open source\nour embeddings, trained sparse autoencoders, and interpreted features, as well\nas a web app for exploring them.", "arxiv_id": "http://arxiv.org/abs/2408.00657v1", "pdf_url": "http://arxiv.org/pdf/2408.00657v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Enhancing Multistep Prediction of Multivariate Market Indices Using Weighted Optical Reservoir Computing", "authors": "Fang Wang, Ting Bu, Yuping Huang", "abstract": "We propose and experimentally demonstrate an innovative stock index\nprediction method using a weighted optical reservoir computing system. We\nconstruct fundamental market data combined with macroeconomic data and\ntechnical indicators to capture the broader behavior of the stock market. Our\napproach shows significant higher performance than state-of-the-art methods\nsuch as linear regression, decision trees, and neural network architectures\nincluding long short-term memory. It captures well the market's high volatility\nand nonlinear behaviors despite limited data, demonstrating great potential for\nreal-time, parallel, multi-dimensional data processing and predictions.", "arxiv_id": "http://arxiv.org/abs/2408.00652v1", "pdf_url": "http://arxiv.org/pdf/2408.00652v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Enhancing Ethereum Fraud Detection via Generative and Contrastive Self-supervision", "authors": "Chenxiang Jin, Jiajun Zhou, Chenxuan Xie, Shanqing Yu, Qi Xuan, Xiaoniu Yang", "abstract": "The rampant fraudulent activities on Ethereum hinder the healthy development\nof the blockchain ecosystem, necessitating the reinforcement of regulations.\nHowever, multiple imbalances involving account interaction frequencies and\ninteraction types in the Ethereum transaction environment pose significant\nchallenges to data mining-based fraud detection research. To address this, we\nfirst propose the concept of meta-interactions to refine interaction behaviors\nin Ethereum, and based on this, we present a dual self-supervision enhanced\nEthereum fraud detection framework, named Meta-IFD. This framework initially\nintroduces a generative self-supervision mechanism to augment the interaction\nfeatures of accounts, followed by a contrastive self-supervision mechanism to\ndifferentiate various behavior patterns, and ultimately characterizes the\nbehavioral representations of accounts and mines potential fraud risks through\nmulti-view interaction feature learning. Extensive experiments on real Ethereum\ndatasets demonstrate the effectiveness and superiority of our framework in\ndetecting common Ethereum fraud behaviors such as Ponzi schemes and phishing\nscams. Additionally, the generative module can effectively alleviate the\ninteraction distribution imbalance in Ethereum data, while the contrastive\nmodule significantly enhances the framework's ability to distinguish different\nbehavior patterns. The source code will be released on GitHub soon.", "arxiv_id": "http://arxiv.org/abs/2408.00641v1", "pdf_url": "http://arxiv.org/pdf/2408.00641v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Privacy-preserving datasets by capturing feature distributions with Conditional VAEs", "authors": "Francesco Di Salvo, David Tafler, Sebastian Doerrich, Christian Ledig", "abstract": "Large and well-annotated datasets are essential for advancing deep learning\napplications, however often costly or impossible to obtain by a single entity.\nIn many areas, including the medical domain, approaches relying on data sharing\nhave become critical to address those challenges. While effective in increasing\ndataset size and diversity, data sharing raises significant privacy concerns.\nCommonly employed anonymization methods based on the k-anonymity paradigm often\nfail to preserve data diversity, affecting model robustness. This work\nintroduces a novel approach using Conditional Variational Autoencoders (CVAEs)\ntrained on feature vectors extracted from large pre-trained vision foundation\nmodels. Foundation models effectively detect and represent complex patterns\nacross diverse domains, allowing the CVAE to faithfully capture the embedding\nspace of a given data distribution to generate (sample) a diverse,\nprivacy-respecting, and potentially unbounded set of synthetic feature vectors.\nOur method notably outperforms traditional approaches in both medical and\nnatural image domains, exhibiting greater dataset diversity and higher\nrobustness against perturbations while preserving sample privacy. These results\nunderscore the potential of generative models to significantly impact deep\nlearning applications in data-scarce and privacy-sensitive environments. The\nsource code is available at\nhttps://github.com/francescodisalvo05/cvae-anonymization .", "arxiv_id": "http://arxiv.org/abs/2408.00639v1", "pdf_url": "http://arxiv.org/pdf/2408.00639v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Unlocking Fair Use in the Generative AI Supply Chain: A Systematized Literature Review", "authors": "Amruta Mahuli, Asia Biega", "abstract": "Through a systematization of generative AI (GenAI) stakeholder goals and\nexpectations, this work seeks to uncover what value different stakeholders see\nin their contributions to the GenAI supply line. This valuation enables us to\nunderstand whether fair use advocated by GenAI companies to train model\nprogresses the copyright law objective of promoting science and arts. While\nassessing the validity and efficacy of the fair use argument, we uncover\nresearch gaps and potential avenues for future works for researchers and\npolicymakers to address.", "arxiv_id": "http://arxiv.org/abs/2408.00613v1", "pdf_url": "http://arxiv.org/pdf/2408.00613v1", "primary_category": "cs.AI", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Using CSNNs to Perform Event-based Data Processing & Classification on ASL-DVS", "authors": "Ria Patel, Sujit Tripathy, Zachary Sublett, Seoyoung An, Riya Patel", "abstract": "Recent advancements in bio-inspired visual sensing and neuromorphic computing\nhave led to the development of various highly efficient bio-inspired solutions\nwith real-world applications. One notable application integrates event-based\ncameras with spiking neural networks (SNNs) to process event-based sequences\nthat are asynchronous and sparse, making them difficult to handle. In this\nproject, we develop a convolutional spiking neural network (CSNN) architecture\nthat leverages convolutional operations and recurrent properties of a spiking\nneuron to learn the spatial and temporal relations in the ASL-DVS gesture\ndataset. The ASL-DVS gesture dataset is a neuromorphic dataset containing hand\ngestures when displaying 24 letters (A to Y, excluding J and Z due to the\nnature of their symbols) from the American Sign Language (ASL). We performed\nclassification on a pre-processed subset of the full ASL-DVS dataset to\nidentify letter signs and achieved 100\\% training accuracy. Specifically, this\nwas achieved by training in the Google Cloud compute platform while using a\nlearning rate of 0.0005, batch size of 25 (total of 20 batches), 200\niterations, and 10 epochs.", "arxiv_id": "http://arxiv.org/abs/2408.00611v1", "pdf_url": "http://arxiv.org/pdf/2408.00611v1", "primary_category": "cs.NE", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "RELEVANT"}
{"title": "AutoPV: Automatically Design Your Photovoltaic Power Forecasting Model", "authors": "Dayin Chen, Xiaodan Shi, Mingkun Jiang, Haoran Zhang, Dongxiao Zhang, Yuntian Chen, Jinyue Yan", "abstract": "Photovoltaic power forecasting (PVPF) is a critical area in time series\nforecasting (TSF), enabling the efficient utilization of solar energy. With\nadvancements in machine learning and deep learning, various models have been\napplied to PVPF tasks. However, constructing an optimal predictive architecture\nfor specific PVPF tasks remains challenging, as it requires cross-domain\nknowledge and significant labor costs. To address this challenge, we introduce\nAutoPV, a novel framework for the automated search and construction of PVPF\nmodels based on neural architecture search (NAS) technology. We develop a brand\nnew NAS search space that incorporates various data processing techniques from\nstate-of-the-art (SOTA) TSF models and typical PVPF deep learning models. The\neffectiveness of AutoPV is evaluated on diverse PVPF tasks using a dataset from\nthe Daqing Photovoltaic Station in China. Experimental results demonstrate that\nAutoPV can complete the predictive architecture construction process in a\nrelatively short time, and the newly constructed architecture is superior to\nSOTA predefined models. This work bridges the gap in applying NAS to TSF\nproblems, assisting non-experts and industries in automatically designing\neffective PVPF models.", "arxiv_id": "http://arxiv.org/abs/2408.00601v1", "pdf_url": "http://arxiv.org/pdf/2408.00601v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "RELEVANT"}
{"title": "Convergence Analysis of Natural Gradient Descent for Over-parameterized Physics-Informed Neural Networks", "authors": "Xianliang Xu, Ting Du, Wang Kong, Ye Li, Zhongyi Huang", "abstract": "First-order methods, such as gradient descent (GD) and stochastic gradient\ndescent (SGD) have been proven effective in training neural networks. In the\nsetting of over-parameterization, there is a line of work demonstrating that\nrandomly initialized (stochastic) gradient descent converges to a globally\noptimal solution at a linear convergence rate for the quadratic loss function.\nHowever, the learning rate of GD in training two-layer neural networks has a\npoor dependence on the sample size and the Gram matrix, resulting in a slow\ntraining process. In this paper, we show that for the $L^2$ regression\nproblems, the learning rate can be improved from $\\mathcal{O}(\\lambda_0/n^2)$\nto $\\mathcal{O}(1/\\|\\bm{H}^{\\infty}\\|_2)$, which implies that GD enjoys a\nfaster convergence rate. Moreover, we further generalize the method for GD in\ntraining two-layer Physics-Informed Neural Networks (PINNs), showing a similar\nimprovement for the learning rate. Although the improved learning rate depends\nmildly on the Gram matrix, we still need to set it small enough in practice due\nto the agnostic eigenvalues of the Gram matrix. More importantly, the\nconvergence rate relies on the least eigenvalue of the Gram matrix, leading to\nslow convergence. In this work, we provide the convergence analysis of natural\ngradient descent (NGD) in training two-layer PINNs. We show that the learning\nrate can be $\\mathcal{O}(1)$ and at this time, the convergence rate is\nindependent of the Gram matrix.", "arxiv_id": "http://arxiv.org/abs/2408.00573v1", "pdf_url": "http://arxiv.org/pdf/2408.00573v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Analyzing the Effectiveness of Quantum Annealing with Meta-Learning", "authors": "Riccardo Pellini, Maurizio Ferrari Dacrema", "abstract": "The field of Quantum Computing has gathered significant popularity in recent\nyears and a large number of papers have studied its effectiveness in tackling\nmany tasks. We focus in particular on Quantum Annealing (QA), a meta-heuristic\nsolver for Quadratic Unconstrained Binary Optimization (QUBO) problems. It is\nknown that the effectiveness of QA is dependent on the task itself, as is the\ncase for classical solvers, but there is not yet a clear understanding of which\nare the characteristics of a problem that makes it difficult to solve with QA.\nIn this work, we propose a new methodology to study the effectiveness of QA\nbased on meta-learning models. To do so, we first build a dataset composed of\nmore than five thousand instances of ten different optimization problems. We\ndefine a set of more than a hundred features to describe their characteristics,\nand solve them with both QA and three classical solvers. We publish this\ndataset online for future research. Then, we train multiple meta-models to\npredict whether QA would solve that instance effectively and use them to probe\nwhich are the features with the strongest impact on the effectiveness of QA.\nOur results indicate that it is possible to accurately predict the\neffectiveness of QA, validating our methodology. Furthermore, we observe that\nthe distribution of the problem coefficients representing the bias and coupling\nterms is very informative to identify the probability of finding good\nsolutions, while the density of these coefficients alone is not enough. The\nmethodology we propose allows to open new research directions to further our\nunderstanding of the effectiveness of QA, by probing specific dimensions or by\ndeveloping new QUBO formulations that are better suited for the particular\nnature of QA. Furthermore, the proposed methodology is flexible and can be\nextended or used to study other quantum or classical solvers.", "arxiv_id": "http://arxiv.org/abs/2408.00570v1", "pdf_url": "http://arxiv.org/pdf/2408.00570v1", "primary_category": "quant-ph", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Learning to Embed Distributions via Maximum Kernel Entropy", "authors": "Oleksii Kachaiev, Stefano Recanatesi", "abstract": "Empirical data can often be considered as samples from a set of probability\ndistributions. Kernel methods have emerged as a natural approach for learning\nto classify these distributions. Although numerous kernels between\ndistributions have been proposed, applying kernel methods to distribution\nregression tasks remains challenging, primarily because selecting a suitable\nkernel is not straightforward. Surprisingly, the question of learning a\ndata-dependent distribution kernel has received little attention. In this\npaper, we propose a novel objective for the unsupervised learning of\ndata-dependent distribution kernel, based on the principle of entropy\nmaximization in the space of probability measure embeddings. We examine the\ntheoretical properties of the latent embedding space induced by our objective,\ndemonstrating that its geometric structure is well-suited for solving\ndownstream discriminative tasks. Finally, we demonstrate the performance of the\nlearned kernel across different modalities.", "arxiv_id": "http://arxiv.org/abs/2408.00549v1", "pdf_url": "http://arxiv.org/pdf/2408.00549v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "The Energy Cost of Artificial Intelligence of Things Lifecycle", "authors": "Shih-Kai Chou, Jernej Hribar, Mihael Mohor\u010di\u010d, Carolina Fortuna", "abstract": "Artificial intelligence (AI)coupled with existing Internet of Things (IoT)\nenables more streamlined and autonomous operations across various economic\nsectors. Consequently, the paradigm of Artificial Intelligence of Things (AIoT)\nhaving AI techniques at its core implies additional energy and carbon costs\nthat may become significant with more complex neural architectures. To better\nunderstand the energy and Carbon Footprint (CF) of some AIoT components, very\nrecent studies employ conventional metrics. However, these metrics are not\ndesigned to capture energy efficiency aspects of inference. In this paper, we\npropose a new metric, the Energy Cost of AIoT Lifecycle (eCAL) to capture the\noverall energy cost of inference over the lifecycle of an AIoT system. We\ndevise a new methodology for determining eCAL of an AIoT system by analyzing\nthe complexity of data manipulation in individual components involved in the\nAIoT lifecycle and derive the overall and per bit energy consumption. With eCAL\nwe show that the better a model is and the more it is used, the more energy\nefficient an inference is. For an example AIoT configuration, eCAL for making\n$100$ inferences is $1.43$ times higher than for $1000$ inferences. We also\nevaluate the CF of the AIoT system by calculating the equivalent CO$_{2}$\nemissions based on the energy consumption and the Carbon Intensity (CI) across\ndifferent countries. Using 2023 renewable data, our analysis reveals that\ndeploying an AIoT system in Germany results in emitting $4.62$ times higher\nCO$_2$ than in Finland, due to latter using more low-CI energy sources.", "arxiv_id": "http://arxiv.org/abs/2408.00540v1", "pdf_url": "http://arxiv.org/pdf/2408.00540v1", "primary_category": "cs.ET", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "ReSi: A Comprehensive Benchmark for Representational Similarity Measures", "authors": "Max Klabunde, Tassilo Wald, Tobias Schumacher, Klaus Maier-Hein, Markus Strohmaier, Florian Lemmerich", "abstract": "Measuring the similarity of different representations of neural architectures\nis a fundamental task and an open research challenge for the machine learning\ncommunity. This paper presents the first comprehensive benchmark for evaluating\nrepresentational similarity measures based on well-defined groundings of\nsimilarity. The representational similarity (ReSi) benchmark consists of (i)\nsix carefully designed tests for similarity measures, (ii) 23 similarity\nmeasures, (iii) eleven neural network architectures, and (iv) six datasets,\nspanning over the graph, language, and vision domains. The benchmark opens up\nseveral important avenues of research on representational similarity that\nenable novel explorations and applications of neural architectures. We\ndemonstrate the utility of the ReSi benchmark by conducting experiments on\nvarious neural network architectures, real world datasets and similarity\nmeasures. All components of the benchmark are publicly available and thereby\nfacilitate systematic reproduction and production of research results. The\nbenchmark is extensible, future research can build on and further expand it. We\nbelieve that the ReSi benchmark can serve as a sound platform catalyzing future\nresearch that aims to systematically evaluate existing and explore novel ways\nof comparing representations of neural architectures.", "arxiv_id": "http://arxiv.org/abs/2408.00531v1", "pdf_url": "http://arxiv.org/pdf/2408.00531v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Contrastive Learning with Dynamic Localized Repulsion for Brain Age Prediction on 3D Stiffness Maps", "authors": "Jakob Tr\u00e4uble, Lucy Hiscox, Curtis Johnson, Carola-Bibiane Sch\u00f6nlieb, Gabriele Kaminski Schierle, Angelica Aviles-Rivero", "abstract": "In the field of neuroimaging, accurate brain age prediction is pivotal for\nuncovering the complexities of brain aging and pinpointing early indicators of\nneurodegenerative conditions. Recent advancements in self-supervised learning,\nparticularly in contrastive learning, have demonstrated greater robustness when\ndealing with complex datasets. However, current approaches often fall short in\ngeneralizing across non-uniformly distributed data, prevalent in medical\nimaging scenarios. To bridge this gap, we introduce a novel contrastive loss\nthat adapts dynamically during the training process, focusing on the localized\nneighborhoods of samples. Moreover, we expand beyond traditional structural\nfeatures by incorporating brain stiffness, a mechanical property previously\nunderexplored yet promising due to its sensitivity to age-related changes. This\nwork presents the first application of self-supervised learning to brain\nmechanical properties, using compiled stiffness maps from various clinical\nstudies to predict brain age. Our approach, featuring dynamic localized loss,\nconsistently outperforms existing state-of-the-art methods, demonstrating\nsuperior performance and laying the way for new directions in brain aging\nresearch.", "arxiv_id": "http://arxiv.org/abs/2408.00527v1", "pdf_url": "http://arxiv.org/pdf/2408.00527v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "RELEVANT"}
{"title": "Hilbert curves for efficient exploratory landscape analysis neighbourhood sampling", "authors": "Johannes J. Pienaar, Anna S. Bosman, Katherine M. Malan", "abstract": "Landscape analysis aims to characterise optimisation problems based on their\nobjective (or fitness) function landscape properties. The problem search space\nis typically sampled, and various landscape features are estimated based on the\nsamples. One particularly salient set of features is information content, which\nrequires the samples to be sequences of neighbouring solutions, such that the\nlocal relationships between consecutive sample points are preserved. Generating\nsuch spatially correlated samples that also provide good search space coverage\nis challenging. It is therefore common to first obtain an unordered sample with\ngood search space coverage, and then apply an ordering algorithm such as the\nnearest neighbour to minimise the distance between consecutive points in the\nsample. However, the nearest neighbour algorithm becomes computationally\nprohibitive in higher dimensions, thus there is a need for more efficient\nalternatives. In this study, Hilbert space-filling curves are proposed as a\nmethod to efficiently obtain high-quality ordered samples. Hilbert curves are a\nspecial case of fractal curves, and guarantee uniform coverage of a bounded\nsearch space while providing a spatially correlated sample. We study the\neffectiveness of Hilbert curves as samplers, and discover that they are capable\nof extracting salient features at a fraction of the computational cost compared\nto Latin hypercube sampling with post-factum ordering. Further, we investigate\nthe use of Hilbert curves as an ordering strategy, and find that they order the\nsample significantly faster than the nearest neighbour ordering, without\nsacrificing the saliency of the extracted features.", "arxiv_id": "http://arxiv.org/abs/2408.00526v1", "pdf_url": "http://arxiv.org/pdf/2408.00526v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Identifying the Hierarchical Emotional Areas in the Human Brain Through Information Fusion", "authors": "Zhongyu Huang, Changde Du, Chaozhuo Li, Kaicheng Fu, Huiguang He", "abstract": "The brain basis of emotion has consistently received widespread attention,\nattracting a large number of studies to explore this cutting-edge topic.\nHowever, the methods employed in these studies typically only model the\npairwise relationship between two brain regions, while neglecting the\ninteractions and information fusion among multiple brain\nregions$\\unicode{x2014}$one of the key ideas of the psychological\nconstructionist hypothesis. To overcome the limitations of traditional methods,\nthis study provides an in-depth theoretical analysis of how to maximize\ninteractions and information fusion among brain regions. Building on the\nresults of this analysis, we propose to identify the hierarchical emotional\nareas in the human brain through multi-source information fusion and graph\nmachine learning methods. Comprehensive experiments reveal that the identified\nhierarchical emotional areas, from lower to higher levels, primarily facilitate\nthe fundamental process of emotion perception, the construction of basic\npsychological operations, and the coordination and integration of these\noperations. Overall, our findings provide unique insights into the brain\nmechanisms underlying specific emotions based on the psychological\nconstructionist hypothesis.", "arxiv_id": "http://arxiv.org/abs/2408.00525v1", "pdf_url": "http://arxiv.org/pdf/2408.00525v1", "primary_category": "cs.HC", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Jailbreaking Text-to-Image Models with LLM-Based Agents", "authors": "Yingkai Dong, Zheng Li, Xiangtao Meng, Ning Yu, Shanqing Guo", "abstract": "Recent advancements have significantly improved automated task-solving\ncapabilities using autonomous agents powered by large language models (LLMs).\nHowever, most LLM-based agents focus on dialogue, programming, or specialized\ndomains, leaving gaps in addressing generative AI safety tasks. These gaps are\nprimarily due to the challenges posed by LLM hallucinations and the lack of\nclear guidelines. In this paper, we propose Atlas, an advanced LLM-based\nmulti-agent framework that integrates an efficient fuzzing workflow to target\ngenerative AI models, specifically focusing on jailbreak attacks against\ntext-to-image (T2I) models with safety filters. Atlas utilizes a\nvision-language model (VLM) to assess whether a prompt triggers the T2I model's\nsafety filter. It then iteratively collaborates with both LLM and VLM to\ngenerate an alternative prompt that bypasses the filter. Atlas also enhances\nthe reasoning abilities of LLMs in attack scenarios by leveraging multi-agent\ncommunication, in-context learning (ICL) memory mechanisms, and the\nchain-of-thought (COT) approach. Our evaluation demonstrates that Atlas\nsuccessfully jailbreaks several state-of-the-art T2I models in a black-box\nsetting, which are equipped with multi-modal safety filters. In addition, Atlas\noutperforms existing methods in both query efficiency and the quality of the\ngenerated images.", "arxiv_id": "http://arxiv.org/abs/2408.00523v1", "pdf_url": "http://arxiv.org/pdf/2408.00523v1", "primary_category": "cs.CR", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Low-Power Vibration-Based Predictive Maintenance for Industry 4.0 using Neural Networks: A Survey", "authors": "Alexandru Vasilache, Sven Nitzsche, Daniel Floegel, Tobias Schuermann, Stefan von Dosky, Thomas Bierweiler, Marvin Mu\u00dfler, Florian K\u00e4lber, Soeren Hohmann, Juergen Becker", "abstract": "The advancements in smart sensors for Industry 4.0 offer ample opportunities\nfor low-powered predictive maintenance and condition monitoring. However,\ntraditional approaches in this field rely on processing in the cloud, which\nincurs high costs in energy and storage. This paper investigates the potential\nof neural networks for low-power on-device computation of vibration sensor data\nfor predictive maintenance. We review the literature on Spiking Neural Networks\n(SNNs) and Artificial Neuronal Networks (ANNs) for vibration-based predictive\nmaintenance by analyzing datasets, data preprocessing, network architectures,\nand hardware implementations. Our findings suggest that no satisfactory\nstandard benchmark dataset exists for evaluating neural networks in predictive\nmaintenance tasks. Furthermore frequency domain transformations are commonly\nemployed for preprocessing. SNNs mainly use shallow feed forward architectures,\nwhereas ANNs explore a wider range of models and deeper networks. Finally, we\nhighlight the need for future research on hardware implementations of neural\nnetworks for low-power predictive maintenance applications and the development\nof a standardized benchmark dataset.", "arxiv_id": "http://arxiv.org/abs/2408.00516v1", "pdf_url": "http://arxiv.org/pdf/2408.00516v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "VecAug: Unveiling Camouflaged Frauds with Cohort Augmentation for Enhanced Detection", "authors": "Fei Xiao, Shaofeng Cai, Gang Chen, H. V. Jagadish, Beng Chin Ooi, Meihui Zhang", "abstract": "Fraud detection presents a challenging task characterized by ever-evolving\nfraud patterns and scarce labeled data. Existing methods predominantly rely on\ngraph-based or sequence-based approaches. While graph-based approaches connect\nusers through shared entities to capture structural information, they remain\nvulnerable to fraudsters who can disrupt or manipulate these connections. In\ncontrast, sequence-based approaches analyze users' behavioral patterns,\noffering robustness against tampering but overlooking the interactions between\nsimilar users. Inspired by cohort analysis in retention and healthcare, this\npaper introduces VecAug, a novel cohort-augmented learning framework that\naddresses these challenges by enhancing the representation learning of target\nusers with personalized cohort information. To this end, we first propose a\nvector burn-in technique for automatic cohort identification, which retrieves a\ntask-specific cohort for each target user. Then, to fully exploit the cohort\ninformation, we introduce an attentive cohort aggregation technique for\naugmenting target user representations. To improve the robustness of such\ncohort augmentation, we also propose a novel label-aware cohort neighbor\nseparation mechanism to distance negative cohort neighbors and calibrate the\naggregated cohort information. By integrating this cohort information with\ntarget user representations, VecAug enhances the modeling capacity and\ngeneralization capabilities of the model to be augmented. Our framework is\nflexible and can be seamlessly integrated with existing fraud detection models.\nWe deploy our framework on e-commerce platforms and evaluate it on three fraud\ndetection datasets, and results show that VecAug improves the detection\nperformance of base models by up to 2.48\\% in AUC and 22.5\\% in R@P$_{0.9}$,\noutperforming state-of-the-art methods significantly.", "arxiv_id": "http://arxiv.org/abs/2408.00513v1", "pdf_url": "http://arxiv.org/pdf/2408.00513v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Block-Operations: Using Modular Routing to Improve Compositional Generalization", "authors": "Florian Dietz, Dietrich Klakow", "abstract": "We explore the hypothesis that poor compositional generalization in neural\nnetworks is caused by difficulties with learning effective routing. To solve\nthis problem, we propose the concept of block-operations, which is based on\nsplitting all activation tensors in the network into uniformly sized blocks and\nusing an inductive bias to encourage modular routing and modification of these\nblocks. Based on this concept we introduce the Multiplexer, a new architectural\ncomponent that enhances the Feed Forward Neural Network (FNN). We\nexperimentally confirm that Multiplexers exhibit strong compositional\ngeneralization. On both a synthetic and a realistic task our model was able to\nlearn the underlying process behind the task, whereas both FNNs and\nTransformers were only able to learn heuristic approximations. We propose as\nfuture work to use the principles of block-operations to improve other existing\narchitectures.", "arxiv_id": "http://arxiv.org/abs/2408.00508v1", "pdf_url": "http://arxiv.org/pdf/2408.00508v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Graph Representation Learning via Causal Diffusion for Out-of-Distribution Recommendation", "authors": "Chu Zhao, Enneng Yang, Yuliang Liang, Pengxiang Lan, Yuting Liu, Jianzhe Zhao, Guibing Guo, Xingwei Wang", "abstract": "Graph Neural Networks (GNNs)-based recommendation algorithms typically assume\nthat training and testing data are drawn from independent and identically\ndistributed (IID) spaces. However, this assumption often fails in the presence\nof out-of-distribution (OOD) data, resulting in significant performance\ndegradation. In this study, we construct a Structural Causal Model (SCM) to\nanalyze interaction data, revealing that environmental confounders (e.g., the\nCOVID-19 pandemic) lead to unstable correlations in GNN-based models, thus\nimpairing their generalization to OOD data. To address this issue, we propose a\nnovel approach, graph representation learning via causal diffusion\n(CausalDiffRec) for OOD recommendation. This method enhances the model's\ngeneralization on OOD data by eliminating environmental confounding factors and\nlearning invariant graph representations. Specifically, we use backdoor\nadjustment and variational inference to infer the real environmental\ndistribution, thereby eliminating the impact of environmental confounders. This\ninferred distribution is then used as prior knowledge to guide the\nrepresentation learning in the reverse phase of the diffusion process to learn\nthe invariant representation. In addition, we provide a theoretical derivation\nthat proves optimizing the objective function of CausalDiffRec can encourage\nthe model to learn environment-invariant graph representations, thereby\nachieving excellent generalization performance in recommendations under\ndistribution shifts. Our extensive experiments validate the effectiveness of\nCausalDiffRec in improving the generalization of OOD data, and the average\nimprovement is up to 10.69% on Food, 18.83% on KuaiRec, 22.41% on Yelp2018, and\n11.65% on Douban datasets.", "arxiv_id": "http://arxiv.org/abs/2408.00490v1", "pdf_url": "http://arxiv.org/pdf/2408.00490v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "A Systematic Review on Long-Tailed Learning", "authors": "Chongsheng Zhang, George Almpanidis, Gaojuan Fan, Binquan Deng, Yanbo Zhang, Ji Liu, Aouaidjia Kamel, Paolo Soda, Jo\u00e3o Gama", "abstract": "Long-tailed data is a special type of multi-class imbalanced data with a very\nlarge amount of minority/tail classes that have a very significant combined\ninfluence. Long-tailed learning aims to build high-performance models on\ndatasets with long-tailed distributions, which can identify all the classes\nwith high accuracy, in particular the minority/tail classes. It is a\ncutting-edge research direction that has attracted a remarkable amount of\nresearch effort in the past few years. In this paper, we present a\ncomprehensive survey of latest advances in long-tailed visual learning. We\nfirst propose a new taxonomy for long-tailed learning, which consists of eight\ndifferent dimensions, including data balancing, neural architecture, feature\nenrichment, logits adjustment, loss function, bells and whistles, network\noptimization, and post hoc processing techniques. Based on our proposed\ntaxonomy, we present a systematic review of long-tailed learning methods,\ndiscussing their commonalities and alignable differences. We also analyze the\ndifferences between imbalance learning and long-tailed learning approaches.\nFinally, we discuss prospects and future directions in this field.", "arxiv_id": "http://arxiv.org/abs/2408.00483v1", "pdf_url": "http://arxiv.org/pdf/2408.00483v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Infrequent Resolving Algorithm for Online Linear Programming", "authors": "Guokai Li, Zizhuo Wang, Jingwei Zhang", "abstract": "Online linear programming (OLP) has gained significant attention from both\nresearchers and practitioners due to its extensive applications, such as online\nauction, network revenue management and advertising. Existing OLP algorithms\nfall into two categories: LP-based algorithms and LP-free algorithms. The\nformer one typically guarantees better performance, even offering a constant\nregret, but requires solving a large number of LPs, which could be\ncomputationally expensive. In contrast, LP-free algorithm only requires\nfirst-order computations but induces a worse performance, lacking a constant\nregret bound. In this work, we bridge the gap between these two extremes by\nproposing an algorithm that achieves a constant regret while solving LPs only\n$O(\\log\\log T)$ times over the time horizon $T$. Moreover, when we are allowed\nto solve LPs only $M$ times, we propose an algorithm that can guarantee an\n$O\\left(T^{(1/2+\\epsilon)^{M-1}}\\right)$ regret. Furthermore, when the arrival\nprobabilities are known at the beginning, our algorithm can guarantee a\nconstant regret by solving LPs $O(\\log\\log T)$ times, and an\n$O\\left(T^{(1/2+\\epsilon)^{M}}\\right)$ regret by solving LPs only $M$ times.\nNumerical experiments are conducted to demonstrate the efficiency of the\nproposed algorithms.", "arxiv_id": "http://arxiv.org/abs/2408.00465v1", "pdf_url": "http://arxiv.org/pdf/2408.00465v1", "primary_category": "cs.DS", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Designing Efficient LLM Accelerators for Edge Devices", "authors": "Jude Haris, Rappy Saha, Wenhao Hu, Jos\u00e9 Cano", "abstract": "The increase in open-source availability of Large Language Models (LLMs) has\nenabled users to deploy them on more and more resource-constrained edge devices\nto reduce reliance on network connections and provide more privacy. However,\nthe high computation and memory demands of LLMs make their execution on\nresource-constrained edge devices challenging and inefficient. To address this\nissue, designing new and efficient edge accelerators for LLM inference is\ncrucial. FPGA-based accelerators are ideal for LLM acceleration due to their\nreconfigurability, as they enable model-specific optimizations and higher\nperformance per watt. However, creating and integrating FPGA-based accelerators\nfor LLMs (particularly on edge devices) has proven challenging, mainly due to\nthe limited hardware design flows for LLMs in existing FPGA platforms.\n  To tackle this issue, in this paper we first propose a new design platform,\nnamed SECDA-LLM, that utilizes the SECDA methodology to streamline the process\nof designing, integrating, and deploying efficient FPGA-based LLM accelerators\nfor the llama.cpp inference framework. We then demonstrate, through a case\nstudy, the potential benefits of SECDA-LLM by creating a new MatMul accelerator\nthat supports block floating point quantized operations for LLMs. Our initial\naccelerator design, deployed on the PYNQ-Z1 board, reduces latency 1.7 seconds\nper token or ~2 seconds per word) by 11x over the dual-core Arm NEON-based CPU\nexecution for the TinyLlama model.", "arxiv_id": "http://arxiv.org/abs/2408.00462v1", "pdf_url": "http://arxiv.org/pdf/2408.00462v1", "primary_category": "cs.AR", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Reenact Anything: Semantic Video Motion Transfer Using Motion-Textual Inversion", "authors": "Manuel Kansy, Jacek Naruniec, Christopher Schroers, Markus Gross, Romann M. Weber", "abstract": "Recent years have seen a tremendous improvement in the quality of video\ngeneration and editing approaches. While several techniques focus on editing\nappearance, few address motion. Current approaches using text, trajectories, or\nbounding boxes are limited to simple motions, so we specify motions with a\nsingle motion reference video instead. We further propose to use a pre-trained\nimage-to-video model rather than a text-to-video model. This approach allows us\nto preserve the exact appearance and position of a target object or scene and\nhelps disentangle appearance from motion. Our method, called motion-textual\ninversion, leverages our observation that image-to-video models extract\nappearance mainly from the (latent) image input, while the text/image embedding\ninjected via cross-attention predominantly controls motion. We thus represent\nmotion using text/image embedding tokens. By operating on an inflated\nmotion-text embedding containing multiple text/image embedding tokens per\nframe, we achieve a high temporal motion granularity. Once optimized on the\nmotion reference video, this embedding can be applied to various target images\nto generate videos with semantically similar motions. Our approach does not\nrequire spatial alignment between the motion reference video and target image,\ngeneralizes across various domains, and can be applied to various tasks such as\nfull-body and face reenactment, as well as controlling the motion of inanimate\nobjects and the camera. We empirically demonstrate the effectiveness of our\nmethod in the semantic video motion transfer task, significantly outperforming\nexisting methods in this context.", "arxiv_id": "http://arxiv.org/abs/2408.00458v1", "pdf_url": "http://arxiv.org/pdf/2408.00458v1", "primary_category": "cs.CV", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Rapid and Power-Aware Learned Optimization for Modular Receive Beamforming", "authors": "Ohad Levy, Nir Shlezinger", "abstract": "Multiple-input multiple-output (MIMO) systems play a key role in wireless\ncommunication technologies. A widely considered approach to realize scalable\nMIMO systems involves architectures comprised of multiple separate modules,\neach with its own beamforming capability. Such models accommodate cell-free\nmassive MIMO and partially connected hybrid MIMO architectures. A core issue\nwith the implementation of modular MIMO arises from the need to rapidly set the\nbeampatterns of the modules, while maintaining their power efficiency. This\nleads to challenging constrained optimization that should be repeatedly solved\non each coherence duration. In this work, we propose a power-oriented\noptimization algorithm for beamforming in uplink modular hybrid MIMO systems,\nwhich learns from data to operate rapidly. We derive our learned optimizer by\ntackling the rate maximization objective using projected gradient ascent steps\nwith momentum. We then leverage data to tune the hyperparameters of the\noptimizer, allowing it to operate reliably in a fixed and small number of\niterations while completely preserving its interpretable operation. We show how\npower efficient beamforming can be encouraged by the learned optimizer, via\nboosting architectures with low-resolution phase shifts and with deactivated\nanalog components. Numerical results show that our learn-to-optimize method\nnotably reduces the number of iterations and computation latency required to\nreliably tune modular MIMO receivers, and that it allows obtaining desirable\nbalances between power efficient designs and throughput.", "arxiv_id": "http://arxiv.org/abs/2408.00439v1", "pdf_url": "http://arxiv.org/pdf/2408.00439v1", "primary_category": "eess.SP", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Efficient Patient Fine-Tuned Seizure Detection with a Tensor Kernel Machine", "authors": "Seline J. S. de Rooij, Frederiek Wesel, Borb\u00e1la Hunyadi", "abstract": "Recent developments in wearable devices have made accurate and efficient\nseizure detection more important than ever. A challenge in seizure detection is\nthat patient-specific models typically outperform patient-independent models.\nHowever, in a wearable device one typically starts with a patient-independent\nmodel, until such patient-specific data is available. To avoid having to\nconstruct a new classifier with this data, as required in conventional kernel\nmachines, we propose a transfer learning approach with a tensor kernel machine.\nThis method learns the primal weights in a compressed form using the canonical\npolyadic decomposition, making it possible to efficiently update the weights of\nthe patient-independent model with patient-specific data. The results show that\nthis patient fine-tuned model reaches as high a performance as a\npatient-specific SVM model with a model size that is twice as small as the\npatient-specific model and ten times as small as the patient-independent model.", "arxiv_id": "http://arxiv.org/abs/2408.00437v1", "pdf_url": "http://arxiv.org/pdf/2408.00437v1", "primary_category": "eess.SP", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "A Cross-Domain Benchmark for Active Learning", "authors": "Thorben Werner, Johannes Burchert, Maximilian Stubbemann, Lars Schmidt-Thieme", "abstract": "Active Learning (AL) deals with identifying the most informative samples for\nlabeling to reduce data annotation costs for supervised learning tasks. AL\nresearch suffers from the fact that lifts from literature generalize poorly and\nthat only a small number of repetitions of experiments are conducted. To\novercome these obstacles, we propose \\emph{CDALBench}, the first active\nlearning benchmark which includes tasks in computer vision, natural language\nprocessing and tabular learning. Furthermore, by providing an efficient, greedy\noracle, \\emph{CDALBench} can be evaluated with 50 runs for each experiment. We\nshow, that both the cross-domain character and a large amount of repetitions\nare crucial for sophisticated evaluation of AL research. Concretely, we show\nthat the superiority of specific methods varies over the different domains,\nmaking it important to evaluate Active Learning with a cross-domain benchmark.\nAdditionally, we show that having a large amount of runs is crucial. With only\nconducting three runs as often done in the literature, the superiority of\nspecific methods can strongly vary with the specific runs. This effect is so\nstrong, that, depending on the seed, even a well-established method's\nperformance can be significantly better and significantly worse than random for\nthe same dataset.", "arxiv_id": "http://arxiv.org/abs/2408.00426v1", "pdf_url": "http://arxiv.org/pdf/2408.00426v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Towards Evolutionary-based Automated Machine Learning for Small Molecule Pharmacokinetic Prediction", "authors": "Alex G. C. de S\u00e1, David B. Ascher", "abstract": "Machine learning (ML) is revolutionising drug discovery by expediting the\nprediction of small molecule properties essential for developing new drugs.\nThese properties -- including absorption, distribution, metabolism and\nexcretion (ADME)-- are crucial in the early stages of drug development since\nthey provide an understanding of the course of the drug in the organism, i.e.,\nthe drug's pharmacokinetics. However, existing methods lack personalisation and\nrely on manually crafted ML algorithms or pipelines, which can introduce\ninefficiencies and biases into the process. To address these challenges, we\npropose a novel evolutionary-based automated ML method (AutoML) specifically\ndesigned for predicting small molecule properties, with a particular focus on\npharmacokinetics. Leveraging the advantages of grammar-based genetic\nprogramming, our AutoML method streamlines the process by automatically\nselecting algorithms and designing predictive pipelines tailored to the\nparticular characteristics of input molecular data. Results demonstrate\nAutoML's effectiveness in selecting diverse ML algorithms, resulting in\ncomparable or even improved predictive performances compared to conventional\napproaches. By offering personalised ML-driven pipelines, our method promises\nto enhance small molecule research in drug discovery, providing researchers\nwith a valuable tool for accelerating the development of novel therapeutic\ndrugs.", "arxiv_id": "http://arxiv.org/abs/2408.00421v1", "pdf_url": "http://arxiv.org/pdf/2408.00421v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Unsupervised Pairwise Causal Discovery on Heterogeneous Data using Mutual Information Measures", "authors": "Alexandre Trilla, Nenad Mijatovic", "abstract": "A fundamental task in science is to determine the underlying causal relations\nbecause it is the knowledge of this functional structure what leads to the\ncorrect interpretation of an effect given the apparent associations in the\nobserved data. In this sense, Causal Discovery is a technique that tackles this\nchallenge by analyzing the statistical properties of the constituent variables.\nIn this work, we target the generalizability of the discovery method by\nfollowing a reductionist approach that only involves two variables, i.e., the\npairwise or bi-variate setting. We question the current (possibly misleading)\nbaseline results on the basis that they were obtained through supervised\nlearning, which is arguably contrary to this genuinely exploratory endeavor. In\nconsequence, we approach this problem in an unsupervised way, using robust\nMutual Information measures, and observing the impact of the different variable\ntypes, which is oftentimes ignored in the design of solutions. Thus, we provide\na novel set of standard unbiased results that can serve as a reference to guide\nfuture discovery tasks in completely unknown environments.", "arxiv_id": "http://arxiv.org/abs/2408.00399v1", "pdf_url": "http://arxiv.org/pdf/2408.00399v1", "primary_category": "cs.AI", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "What comes after transformers? -- A selective survey connecting ideas in deep learning", "authors": "Johannes Schneider", "abstract": "Transformers have become the de-facto standard model in artificial\nintelligence since 2017 despite numerous shortcomings ranging from energy\ninefficiency to hallucinations. Research has made a lot of progress in\nimproving elements of transformers, and, more generally, deep learning\nmanifesting in many proposals for architectures, layers, optimization\nobjectives, and optimization techniques. For researchers it is difficult to\nkeep track of such developments on a broader level. We provide a comprehensive\noverview of the many important, recent works in these areas to those who\nalready have a basic understanding of deep learning. Our focus differs from\nother works, as we target specifically novel, alternative potentially\ndisruptive approaches to transformers as well as successful ideas of recent\ndeep learning. We hope that such a holistic and unified treatment of\ninfluential, recent works and novel ideas helps researchers to form new\nconnections between diverse areas of deep learning. We identify and discuss\nmultiple patterns that summarize the key strategies for successful innovations\nover the last decade as well as works that can be seen as rising stars.\nEspecially, we discuss attempts on how to improve on transformers covering\n(partially) proven methods such as state space models but also including\nfar-out ideas in deep learning that seem promising despite not achieving\nstate-of-the-art results. We also cover a discussion on recent state-of-the-art\nmodels such as OpenAI's GPT series and Meta's LLama models and, Google's Gemini\nmodel family.", "arxiv_id": "http://arxiv.org/abs/2408.00386v1", "pdf_url": "http://arxiv.org/pdf/2408.00386v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Enhancing Whole Slide Pathology Foundation Models through Stain Normalization", "authors": "Juseung Yun, Yi Hu, Jinhyung Kim, Jongseong Jang, Soonyoung Lee", "abstract": "Recent advancements in digital pathology have led to the development of\nnumerous foundational models that utilize self-supervised learning on patches\nextracted from gigapixel whole slide images (WSIs). While this approach\nleverages vast amounts of unlabeled data, we have discovered a significant\nissue: features extracted from these self-supervised models tend to cluster by\nindividual WSIs, a phenomenon we term WSI-specific feature collapse. This\nproblem can potentially limit the model's generalization ability and\nperformance on various downstream tasks. To address this issue, we introduce\nStain Normalized Pathology Foundational Model, a novel foundational model\ntrained on patches that have undergone stain normalization. Stain normalization\nhelps reduce color variability arising from different laboratories and\nscanners, enabling the model to learn more consistent features. Stain\nNormalized Pathology Foundational Model is trained using 285,153,903 patches\nextracted from a total of 34,795 WSIs, combining data from The Cancer Genome\nAtlas (TCGA) and the Genotype-Tissue Expression (GTEx) project. Our experiments\ndemonstrate that Stain Normalized Pathology Foundational Model significantly\nmitigates the feature collapse problem, indicating that the model has learned\nmore generalized features rather than overfitting to individual WSI\ncharacteristics. We compared Stain Normalized Pathology Foundational Model with\nstate-of-the-art models across six downstream task datasets, and our results\nshow that \\name{} achieves excellent performance relative to the number of WSIs\nused and the model's parameter count. This suggests that the application of\nstain normalization has substantially improved the model's efficiency and\ngeneralization capabilities.", "arxiv_id": "http://arxiv.org/abs/2408.00380v1", "pdf_url": "http://arxiv.org/pdf/2408.00380v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "On the Limitations and Prospects of Machine Unlearning for Generative AI", "authors": "Shiji Zhou, Lianzhe Wang, Jiangnan Ye, Yongliang Wu, Heng Chang", "abstract": "Generative AI (GenAI), which aims to synthesize realistic and diverse data\nsamples from latent variables or other data modalities, has achieved remarkable\nresults in various domains, such as natural language, images, audio, and\ngraphs. However, they also pose challenges and risks to data privacy, security,\nand ethics. Machine unlearning is the process of removing or weakening the\ninfluence of specific data samples or features from a trained model, without\naffecting its performance on other data or tasks. While machine unlearning has\nshown significant efficacy in traditional machine learning tasks, it is still\nunclear if it could help GenAI become safer and aligned with human desire. To\nthis end, this position paper provides an in-depth discussion of the machine\nunlearning approaches for GenAI. Firstly, we formulate the problem of machine\nunlearning tasks on GenAI and introduce the background. Subsequently, we\nsystematically examine the limitations of machine unlearning on GenAI models by\nfocusing on the two representative branches: LLMs and image generative\n(diffusion) models. Finally, we provide our prospects mainly from three\naspects: benchmark, evaluation metrics, and utility-unlearning trade-off, and\nconscientiously advocate for the future development of this field.", "arxiv_id": "http://arxiv.org/abs/2408.00376v1", "pdf_url": "http://arxiv.org/pdf/2408.00376v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Conformal Trajectory Prediction with Multi-View Data Integration in Cooperative Driving", "authors": "Xi Chen, Rahul Bhadani, Larry Head", "abstract": "Current research on trajectory prediction primarily relies on data collected\nby onboard sensors of an ego vehicle. With the rapid advancement in connected\ntechnologies, such as vehicle-to-vehicle (V2V) and vehicle-to-infrastructure\n(V2I) communication, valuable information from alternate views becomes\naccessible via wireless networks. The integration of information from\nalternative views has the potential to overcome the inherent limitations\nassociated with a single viewpoint, such as occlusions and limited field of\nview. In this work, we introduce V2INet, a novel trajectory prediction\nframework designed to model multi-view data by extending existing single-view\nmodels. Unlike previous approaches where the multi-view data is manually fused\nor formulated as a separate training stage, our model supports end-to-end\ntraining, enhancing both flexibility and performance. Moreover, the predicted\nmultimodal trajectories are calibrated by a post-hoc conformal prediction\nmodule to get valid and efficient confidence regions. We evaluated the entire\nframework using the real-world V2I dataset V2X-Seq. Our results demonstrate\nsuperior performance in terms of Final Displacement Error (FDE) and Miss Rate\n(MR) using a single GPU. The code is publicly available at:\n\\url{https://github.com/xichennn/V2I_trajectory_prediction}.", "arxiv_id": "http://arxiv.org/abs/2408.00374v1", "pdf_url": "http://arxiv.org/pdf/2408.00374v1", "primary_category": "cs.AI", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Memorization Capacity for Additive Fine-Tuning with Small ReLU Networks", "authors": "Jy-yong Sohn, Dohyun Kwon, Seoyeon An, Kangwook Lee", "abstract": "Fine-tuning large pre-trained models is a common practice in machine learning\napplications, yet its mathematical analysis remains largely unexplored. In this\npaper, we study fine-tuning through the lens of memorization capacity. Our new\nmeasure, the Fine-Tuning Capacity (FTC), is defined as the maximum number of\nsamples a neural network can fine-tune, or equivalently, as the minimum number\nof neurons ($m$) needed to arbitrarily change $N$ labels among $K$ samples\nconsidered in the fine-tuning process. In essence, FTC extends the memorization\ncapacity concept to the fine-tuning scenario. We analyze FTC for the additive\nfine-tuning scenario where the fine-tuned network is defined as the summation\nof the frozen pre-trained network $f$ and a neural network $g$ (with $m$\nneurons) designed for fine-tuning. When $g$ is a ReLU network with either 2 or\n3 layers, we obtain tight upper and lower bounds on FTC; we show that $N$\nsamples can be fine-tuned with $m=\\Theta(N)$ neurons for 2-layer networks, and\nwith $m=\\Theta(\\sqrt{N})$ neurons for 3-layer networks, no matter how large $K$\nis. Our results recover the known memorization capacity results when $N = K$ as\na special case.", "arxiv_id": "http://arxiv.org/abs/2408.00359v1", "pdf_url": "http://arxiv.org/pdf/2408.00359v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Neural Graph Matching for Video Retrieval in Large-Scale Video-driven E-commerce", "authors": "Houye Ji, Ye Tang, Zhaoxin Chen, Lixi Deng, Jun Hu, Lei Su", "abstract": "With the rapid development of the short video industry, traditional\ne-commerce has encountered a new paradigm, video-driven e-commerce, which\nleverages attractive videos for product showcases and provides both video and\nitem services for users. Benefitting from the dynamic and visualized\nintroduction of items,video-driven e-commerce has shown huge potential in\nstimulating consumer confidence and promoting sales. In this paper, we focus on\nthe video retrieval task, facing the following challenges: (1) Howto handle the\nheterogeneities among users, items, and videos? (2)How to mine the\ncomplementarity between items and videos for better user understanding? In this\npaper, we first leverage the dual graph to model the co-existing of user-video\nand user-item interactions in video-driven e-commerce and innovatively reduce\nuser preference understanding to a graph matching problem. To solve it, we\nfurther propose a novel bi-level Graph Matching Network(GMN), which mainly\nconsists of node- and preference-level graph matching. Given a user, node-level\ngraph matching aims to match videos and items, while preference-level graph\nmatching aims to match multiple user preferences extracted from both videos and\nitems. Then the proposed GMN can generate and improve user embedding by\naggregating matched nodes or preferences from the dual graph in a bi-level\nmanner. Comprehensive experiments show the superiority of the proposed GMN with\nsignificant improvements over state-of-the-art approaches (e.g., AUC+1.9% and\nCTR+7.15%). We have developed it on a well-known video-driven e-commerce\nplatform, serving hundreds of millions of users every day", "arxiv_id": "http://arxiv.org/abs/2408.00346v1", "pdf_url": "http://arxiv.org/pdf/2408.00346v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "IN-Sight: Interactive Navigation through Sight", "authors": "Philipp Schoch, Fan Yang, Yuntao Ma, Stefan Leutenegger, Marco Hutter, Quentin Leboute", "abstract": "Current visual navigation systems often treat the environment as static,\nlacking the ability to adaptively interact with obstacles. This limitation\nleads to navigation failure when encountering unavoidable obstructions. In\nresponse, we introduce IN-Sight, a novel approach to self-supervised path\nplanning, enabling more effective navigation strategies through interaction\nwith obstacles. Utilizing RGB-D observations, IN-Sight calculates\ntraversability scores and incorporates them into a semantic map, facilitating\nlong-range path planning in complex, maze-like environments. To precisely\nnavigate around obstacles, IN-Sight employs a local planner, trained\nimperatively on a differentiable costmap using representation learning\ntechniques. The entire framework undergoes end-to-end training within the\nstate-of-the-art photorealistic Intel SPEAR Simulator. We validate the\neffectiveness of IN-Sight through extensive benchmarking in a variety of\nsimulated scenarios and ablation studies. Moreover, we demonstrate the system's\nreal-world applicability with zero-shot sim-to-real transfer, deploying our\nplanner on the legged robot platform ANYmal, showcasing its practical potential\nfor interactive navigation in real environments.", "arxiv_id": "http://arxiv.org/abs/2408.00343v1", "pdf_url": "http://arxiv.org/pdf/2408.00343v1", "primary_category": "cs.RO", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "MuJoCo MPC for Humanoid Control: Evaluation on HumanoidBench", "authors": "Moritz Meser, Aditya Bhatt, Boris Belousov, Jan Peters", "abstract": "We tackle the recently introduced benchmark for whole-body humanoid control\nHumanoidBench using MuJoCo MPC. We find that sparse reward functions of\nHumanoidBench yield undesirable and unrealistic behaviors when optimized;\ntherefore, we propose a set of regularization terms that stabilize the robot\nbehavior across tasks. Current evaluations on a subset of tasks demonstrate\nthat our proposed reward function allows achieving the highest HumanoidBench\nscores while maintaining realistic posture and smooth control signals. Our code\nis publicly available and will become a part of MuJoCo MPC, enabling rapid\nprototyping of robot behaviors.", "arxiv_id": "http://arxiv.org/abs/2408.00342v1", "pdf_url": "http://arxiv.org/pdf/2408.00342v1", "primary_category": "cs.RO", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "\"Patriarchy Hurts Men Too.\" Does Your Model Agree? A Discussion on Fairness Assumptions", "authors": "Marco Favier, Toon Calders", "abstract": "The pipeline of a fair ML practitioner is generally divided into three\nphases: 1) Selecting a fairness measure. 2) Choosing a model that minimizes\nthis measure. 3) Maximizing the model's performance on the data. In the context\nof group fairness, this approach often obscures implicit assumptions about how\nbias is introduced into the data. For instance, in binary classification, it is\noften assumed that the best model, with equal fairness, is the one with better\nperformance. However, this belief already imposes specific properties on the\nprocess that introduced bias. More precisely, we are already assuming that the\nbiasing process is a monotonic function of the fair scores, dependent solely on\nthe sensitive attribute. We formally prove this claim regarding several\nimplicit fairness assumptions. This leads, in our view, to two possible\nconclusions: either the behavior of the biasing process is more complex than\nmere monotonicity, which means we need to identify and reject our implicit\nassumptions in order to develop models capable of tackling more complex\nsituations; or the bias introduced in the data behaves predictably, implying\nthat many of the developed models are superfluous.", "arxiv_id": "http://arxiv.org/abs/2408.00330v1", "pdf_url": "http://arxiv.org/pdf/2408.00330v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "OTAD: An Optimal Transport-Induced Robust Model for Agnostic Adversarial Attack", "authors": "Kuo Gai, Sicong Wang, Shihua Zhang", "abstract": "Deep neural networks (DNNs) are vulnerable to small adversarial perturbations\nof the inputs, posing a significant challenge to their reliability and\nrobustness. Empirical methods such as adversarial training can defend against\nparticular attacks but remain vulnerable to more powerful attacks.\nAlternatively, Lipschitz networks provide certified robustness to unseen\nperturbations but lack sufficient expressive power. To harness the advantages\nof both approaches, we design a novel two-step Optimal Transport induced\nAdversarial Defense (OTAD) model that can fit the training data accurately\nwhile preserving the local Lipschitz continuity. First, we train a DNN with a\nregularizer derived from optimal transport theory, yielding a discrete optimal\ntransport map linking data to its features. By leveraging the map's inherent\nregularity, we interpolate the map by solving the convex integration problem\n(CIP) to guarantee the local Lipschitz property. OTAD is extensible to diverse\narchitectures of ResNet and Transformer, making it suitable for complex data.\nFor efficient computation, the CIP can be solved through training neural\nnetworks. OTAD opens a novel avenue for developing reliable and secure deep\nlearning systems through the regularity of optimal transport maps. Empirical\nresults demonstrate that OTAD can outperform other robust models on diverse\ndatasets.", "arxiv_id": "http://arxiv.org/abs/2408.00329v1", "pdf_url": "http://arxiv.org/pdf/2408.00329v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "RELEVANT"}
{"title": "Exploiting Preferences in Loss Functions for Sequential Recommendation via Weak Transitivity", "authors": "Hyunsoo Chung, Jungtaek Kim, Hyungeun Jo, Hyungwon Choi", "abstract": "A choice of optimization objective is immensely pivotal in the design of a\nrecommender system as it affects the general modeling process of a user's\nintent from previous interactions. Existing approaches mainly adhere to three\ncategories of loss functions: pairwise, pointwise, and setwise loss functions.\nDespite their effectiveness, a critical and common drawback of such objectives\nis viewing the next observed item as a unique positive while considering all\nremaining items equally negative. Such a binary label assignment is generally\nlimited to assuring a higher recommendation score of the positive item,\nneglecting potential structures induced by varying preferences between other\nunobserved items. To alleviate this issue, we propose a novel method that\nextends original objectives to explicitly leverage the different levels of\npreferences as relative orders between their scores. Finally, we demonstrate\nthe superior performance of our method compared to baseline objectives.", "arxiv_id": "http://arxiv.org/abs/2408.00326v1", "pdf_url": "http://arxiv.org/pdf/2408.00326v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "ADBM: Adversarial diffusion bridge model for reliable adversarial purification", "authors": "Xiao Li, Wenxuan Sun, Huanran Chen, Qiongxiu Li, Yining Liu, Yingzhe He, Jie Shi, Xiaolin Hu", "abstract": "Recently Diffusion-based Purification (DiffPure) has been recognized as an\neffective defense method against adversarial examples. However, we find\nDiffPure which directly employs the original pre-trained diffusion models for\nadversarial purification, to be suboptimal. This is due to an inherent\ntrade-off between noise purification performance and data recovery quality.\nAdditionally, the reliability of existing evaluations for DiffPure is\nquestionable, as they rely on weak adaptive attacks. In this work, we propose a\nnovel Adversarial Diffusion Bridge Model, termed ADBM. ADBM directly constructs\na reverse bridge from the diffused adversarial data back to its original clean\nexamples, enhancing the purification capabilities of the original diffusion\nmodels. Through theoretical analysis and experimental validation across various\nscenarios, ADBM has proven to be a superior and robust defense mechanism,\noffering significant promise for practical applications.", "arxiv_id": "http://arxiv.org/abs/2408.00315v1", "pdf_url": "http://arxiv.org/pdf/2408.00315v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Adversarial Text Rewriting for Text-aware Recommender Systems", "authors": "Sejoon Oh, Gaurav Verma, Srijan Kumar", "abstract": "Text-aware recommender systems incorporate rich textual features, such as\ntitles and descriptions, to generate item recommendations for users. The use of\ntextual features helps mitigate cold-start problems, and thus, such recommender\nsystems have attracted increased attention. However, we argue that the\ndependency on item descriptions makes the recommender system vulnerable to\nmanipulation by adversarial sellers on e-commerce platforms. In this paper, we\nexplore the possibility of such manipulation by proposing a new text rewriting\nframework to attack text-aware recommender systems. We show that the rewriting\nattack can be exploited by sellers to unfairly uprank their products, even\nthough the adversarially rewritten descriptions are perceived as realistic by\nhuman evaluators. Methodologically, we investigate two different variations to\ncarry out text rewriting attacks: (1) two-phase fine-tuning for greater attack\nperformance, and (2) in-context learning for higher text rewriting quality.\nExperiments spanning 3 different datasets and 4 existing approaches demonstrate\nthat recommender systems exhibit vulnerability against the proposed text\nrewriting attack. Our work adds to the existing literature around the\nrobustness of recommender systems, while highlighting a new dimension of\nvulnerability in the age of large-scale automated text generation.", "arxiv_id": "http://arxiv.org/abs/2408.00312v1", "pdf_url": "http://arxiv.org/pdf/2408.00312v1", "primary_category": "cs.IR", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Online Linear Programming with Batching", "authors": "Haoran Xu, Peter W. Glynn, Yinyu Ye", "abstract": "We study Online Linear Programming (OLP) with batching. The planning horizon\nis cut into $K$ batches, and the decisions on customers arriving within a batch\ncan be delayed to the end of their associated batch. Compared with OLP without\nbatching, the ability to delay decisions brings better operational performance,\nas measured by regret. Two research questions of interest are: (1) What is a\nlower bound of the regret as a function of $K$? (2) What algorithms can achieve\nthe regret lower bound? These questions have been analyzed in the literature\nwhen the distribution of the reward and the resource consumption of the\ncustomers have finite support. By contrast, this paper analyzes these questions\nwhen the conditional distribution of the reward given the resource consumption\nis continuous, and we show the answers are different under this setting. When\nthere is only a single type of resource and the decision maker knows the total\nnumber of customers, we propose an algorithm with a $O(\\log K)$ regret upper\nbound and provide a $\\Omega(\\log K)$ regret lower bound. We also propose\nalgorithms with $O(\\log K)$ regret upper bound for the setting in which there\nare multiple types of resource and the setting in which customers arrive\nfollowing a Poisson process. All these regret upper and lower bounds are\nindependent of the length of the planning horizon, and all the proposed\nalgorithms delay decisions on customers arriving in only the first and the last\nbatch. We also take customer impatience into consideration and establish a way\nof selecting an appropriate batch size.", "arxiv_id": "http://arxiv.org/abs/2408.00310v1", "pdf_url": "http://arxiv.org/pdf/2408.00310v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Discretizing Continuous Action Space with Unimodal Probability Distributions for On-Policy Reinforcement Learning", "authors": "Yuanyang Zhu, Zhi Wang, Yuanheng Zhu, Chunlin Chen, Dongbin Zhao", "abstract": "For on-policy reinforcement learning, discretizing action space for\ncontinuous control can easily express multiple modes and is straightforward to\noptimize. However, without considering the inherent ordering between the\ndiscrete atomic actions, the explosion in the number of discrete actions can\npossess undesired properties and induce a higher variance for the policy\ngradient estimator. In this paper, we introduce a straightforward architecture\nthat addresses this issue by constraining the discrete policy to be unimodal\nusing Poisson probability distributions. This unimodal architecture can better\nleverage the continuity in the underlying continuous action space using\nexplicit unimodal probability distributions. We conduct extensive experiments\nto show that the discrete policy with the unimodal probability distribution\nprovides significantly faster convergence and higher performance for on-policy\nreinforcement learning algorithms in challenging control tasks, especially in\nhighly complex tasks such as Humanoid. We provide theoretical analysis on the\nvariance of the policy gradient estimator, which suggests that our attentively\ndesigned unimodal discrete policy can retain a lower variance and yield a\nstable learning process.", "arxiv_id": "http://arxiv.org/abs/2408.00309v1", "pdf_url": "http://arxiv.org/pdf/2408.00309v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "ABC Align: Large Language Model Alignment for Safety & Accuracy", "authors": "Gareth Seneque, Lap-Hang Ho, Ariel Kuperman, Nafise Erfanian Saeedi, Jeffrey Molendijk", "abstract": "Alignment of Large Language Models (LLMs) remains an unsolved problem. Human\npreferences are highly distributed and can be captured at multiple levels of\nabstraction, from the individual to diverse populations. Organisational\npreferences, represented by standards and principles, are defined to mitigate\nreputational risk or meet legislative obligations. In this paper, we present\nABC Align, a novel alignment methodology for LLMs that enables integration of\nthe standards and preferences of a large media organisation into the LLM\nitself. We combine a set of data and methods that build on recent breakthroughs\nin synthetic data generation, preference optimisation, and post-training model\nquantisation. Our unified approach mitigates bias and improves accuracy, while\npreserving reasoning capability, as measured against standard benchmarks.", "arxiv_id": "http://arxiv.org/abs/2408.00307v1", "pdf_url": "http://arxiv.org/pdf/2408.00307v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Contrastive Graph Representation Learning with Adversarial Cross-view Reconstruction and Information Bottleneck", "authors": "Yuntao Shou, Haozhi Lan, Xiangyong Cao", "abstract": "Graph Neural Networks (GNNs) have received extensive research attention due\nto their powerful information aggregation capabilities. Despite the success of\nGNNs, most of them suffer from the popularity bias issue in a graph caused by a\nsmall number of popular categories. Additionally, real graph datasets always\ncontain incorrect node labels, which hinders GNNs from learning effective node\nrepresentations. Graph contrastive learning (GCL) has been shown to be\neffective in solving the above problems for node classification tasks. Most\nexisting GCL methods are implemented by randomly removing edges and nodes to\ncreate multiple contrasting views, and then maximizing the mutual information\n(MI) between these contrasting views to improve the node feature\nrepresentation. However, maximizing the mutual information between multiple\ncontrasting views may lead the model to learn some redundant information\nirrelevant to the node classification task. To tackle this issue, we propose an\neffective Contrastive Graph Representation Learning with Adversarial Cross-view\nReconstruction and Information Bottleneck (CGRL) for node classification, which\ncan adaptively learn to mask the nodes and edges in the graph to obtain the\noptimal graph structure representation. Furthermore, we innovatively introduce\nthe information bottleneck theory into GCLs to remove redundant information in\nmultiple contrasting views while retaining as much information as possible\nabout node classification. Moreover, we add noise perturbations to the original\nviews and reconstruct the augmented views by constructing adversarial views to\nimprove the robustness of node feature representation. Extensive experiments on\nreal-world public datasets demonstrate that our method significantly\noutperforms existing state-of-the-art algorithms.", "arxiv_id": "http://arxiv.org/abs/2408.00295v1", "pdf_url": "http://arxiv.org/pdf/2408.00295v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Gradient Harmonization in Unsupervised Domain Adaptation", "authors": "Fuxiang Huang, Suqi Song, Lei Zhang", "abstract": "Unsupervised domain adaptation (UDA) intends to transfer knowledge from a\nlabeled source domain to an unlabeled target domain. Many current methods focus\non learning feature representations that are both discriminative for\nclassification and invariant across domains by simultaneously optimizing domain\nalignment and classification tasks. However, these methods often overlook a\ncrucial challenge: the inherent conflict between these two tasks during\ngradient-based optimization. In this paper, we delve into this issue and\nintroduce two effective solutions known as Gradient Harmonization, including GH\nand GH++, to mitigate the conflict between domain alignment and classification\ntasks. GH operates by altering the gradient angle between different tasks from\nan obtuse angle to an acute angle, thus resolving the conflict and trade-offing\nthe two tasks in a coordinated manner. Yet, this would cause both tasks to\ndeviate from their original optimization directions. We thus further propose an\nimproved version, GH++, which adjusts the gradient angle between tasks from an\nobtuse angle to a vertical angle. This not only eliminates the conflict but\nalso minimizes deviation from the original gradient directions. Finally, for\noptimization convenience and efficiency, we evolve the gradient harmonization\nstrategies into a dynamically weighted loss function using an integral operator\non the harmonized gradient. Notably, GH/GH++ are orthogonal to UDA and can be\nseamlessly integrated into most existing UDA models. Theoretical insights and\nexperimental analyses demonstrate that the proposed approaches not only enhance\npopular UDA baselines but also improve recent state-of-the-art models.", "arxiv_id": "http://arxiv.org/abs/2408.00288v1", "pdf_url": "http://arxiv.org/pdf/2408.00288v1", "primary_category": "cs.CV", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "High Performance Im2win and Direct Convolutions using Three Tensor Layouts on SIMD Architectures", "authors": "Xiang Fu, Xinpeng Zhang, Jixiang Ma, Peng Zhao, Shuai Lu, Xu T. Liu", "abstract": "Convolution is the core component within deep neural networks and it is\ncomputationally intensive and time consuming. Tensor data layouts significantly\nimpact convolution operations in terms of memory access and computational\nefficiency. Yet, there is still a lack of comprehensive performance\ncharacterization on data layouts on SIMD architectures concerning convolution\nmethods. This paper proposes three novel data layouts for im2win convolution:\nNHWC, CHWN, and CHWN8, and introduces a set of general optimization techniques\nfor both direct and im2win convolutions. We compare the optimized im2win\nconvolution with the direct convolution and PyTorch's im2col-based convolution\nacross the aforementioned layouts on SIMD machines. The experiments\ndemonstrated that the im2win convolution with the new NHWC layout achieved up\nto 355% performance speedup over NCHW layout. Our optimizations also\nsignificantly improve the performance of both im2win and direct convolutions.\nOur optimized im2win and direct convolutions achieved up to 95% and 94% of\nmachine's theoretical peak performance, respectively.", "arxiv_id": "http://arxiv.org/abs/2408.00278v1", "pdf_url": "http://arxiv.org/pdf/2408.00278v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "RELEVANT"}
{"title": "Clover-2: Accurate Inference for Regressive Lightweight Speculative Decoding", "authors": "Bin Xiao, Lujun Gui, Lei Su, Weipeng Chen", "abstract": "Large Language Models (LLMs) frequently suffer from inefficiencies, largely\nattributable to the discord between the requirements of auto-regressive\ndecoding and the architecture of contemporary GPUs. Recently, regressive\nlightweight speculative decoding has garnered attention for its notable\nefficiency improvements in text generation tasks. This approach utilizes a\nlightweight regressive draft model, like a Recurrent Neural Network (RNN) or a\nsingle transformer decoder layer, leveraging sequential information to\niteratively predict potential tokens. Specifically, RNN draft models are\ncomputationally economical but tend to deliver lower accuracy, while attention\ndecoder layer models exhibit the opposite traits. This paper presents Clover-2,\nan advanced iteration of Clover, an RNN-based draft model designed to achieve\ncomparable accuracy to that of attention decoder layer models while maintaining\nminimal computational overhead. Clover-2 enhances the model architecture and\nincorporates knowledge distillation to increase Clover's accuracy and improve\noverall efficiency. We conducted experiments using the open-source Vicuna 7B\nand LLaMA3-Instruct 8B models. The results demonstrate that Clover-2 surpasses\nexisting methods across various model architectures, showcasing its efficacy\nand robustness.", "arxiv_id": "http://arxiv.org/abs/2408.00264v1", "pdf_url": "http://arxiv.org/pdf/2408.00264v1", "primary_category": "cs.CL", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Mobility-Aware Federated Self-supervised Learning in Vehicular Network", "authors": "Xueying Gu, Qiong Wu, Pingyi Fan, Qiang Fan", "abstract": "Federated Learning (FL) is an advanced distributed machine learning approach,\nthat protects the privacy of each vehicle by allowing the model to be trained\non multiple devices simultaneously without the need to upload all data to a\nroad side unit (RSU). This enables FL to handle scenarios with sensitive or\nwidely distributed data. However, in these fields, it is well known that the\nlabeling costs can be a significant expense, and models relying on labels are\nnot suitable for these rapidly evolving fields especially in vehicular\nnetworks, or mobile internet of things (MIoT), where new data emerges\nconstantly. To handle this issue, the self-supervised learning paves the way\nfor training without labels. Additionally, for vehicles with high velocity,\nowing to blurred images, simple aggregation not only impacts the accuracy of\nthe aggregated model but also reduces the convergence speed of FL. This paper\nproposes a FL algorithm based on image blur level to aggregation, called\nFLSimCo, which does not require labels and serves as a pre-training stage for\nself-supervised learning in the vehicular environment. Simulation results\ndemonstrate that the proposed algorithm exhibits fast and stable convergence.", "arxiv_id": "http://arxiv.org/abs/2408.00256v1", "pdf_url": "http://arxiv.org/pdf/2408.00256v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Discovering Car-following Dynamics from Trajectory Data through Deep Learning", "authors": "Ohay Angah, James Enouen, Xuegang, Ban, Yan Liu", "abstract": "This study aims to discover the governing mathematical expressions of\ncar-following dynamics from trajectory data directly using deep learning\ntechniques. We propose an expression exploration framework based on deep\nsymbolic regression (DSR) integrated with a variable intersection selection\n(VIS) method to find variable combinations that encourage interpretable and\nparsimonious mathematical expressions. In the exploration learning process, two\npenalty terms are added to improve the reward function: (i) a complexity\npenalty to regulate the complexity of the explored expressions to be\nparsimonious, and (ii) a variable interaction penalty to encourage the\nexpression exploration to focus on variable combinations that can best describe\nthe data. We show the performance of the proposed method to learn several\ncar-following dynamics models and discuss its limitations and future research\ndirections.", "arxiv_id": "http://arxiv.org/abs/2408.00251v1", "pdf_url": "http://arxiv.org/pdf/2408.00251v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Enhanced Structured State Space Models via Grouped FIR Filtering and Attention Sink Mechanisms", "authors": "Tian Meng, Yang Tao, Wuliang Yin", "abstract": "Structured State Space Models (SSMs) have emerged as compelling alternatives\nto Transformer architectures, offering linear-time complexity and superior\nperformance in various sequence modeling tasks. Despite their advantages, SSMs\nlike the original Mamba-2 face training difficulties due to the sensitivities\nintroduced by the extended series of recurrent matrix multiplications. In this\npaper, we propose an advanced architecture that mitigates these challenges by\ndecomposing A-multiplications into multiple groups and optimizing positional\nencoding through Grouped Finite Impulse Response (FIR) filtering. This new\nstructure, denoted as Grouped FIR-enhanced SSM (GFSSM), employs semiseparable\nmatrices for efficient computation. Furthermore, inspired by the \"attention\nsink\" phenomenon identified in streaming language models, we incorporate a\nsimilar mechanism to enhance the stability and performance of our model over\nextended sequences. Our approach further bridges the gap between SSMs and\nTransformer architectures, offering a viable path forward for scalable and\nhigh-performing sequence modeling.", "arxiv_id": "http://arxiv.org/abs/2408.00244v1", "pdf_url": "http://arxiv.org/pdf/2408.00244v1", "primary_category": "cs.CL", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Empirical Bayes Linked Matrix Decomposition", "authors": "Eric F. Lock", "abstract": "Data for several applications in diverse fields can be represented as\nmultiple matrices that are linked across rows or columns. This is particularly\ncommon in molecular biomedical research, in which multiple molecular \"omics\"\ntechnologies may capture different feature sets (e.g., corresponding to rows in\na matrix) and/or different sample populations (corresponding to columns). This\nhas motivated a large body of work on integrative matrix factorization\napproaches that identify and decompose low-dimensional signal that is shared\nacross multiple matrices or specific to a given matrix. We propose an empirical\nvariational Bayesian approach to this problem that has several advantages over\nexisting techniques, including the flexibility to accommodate shared signal\nover any number of row or column sets (i.e., bidimensional integration), an\nintuitive model-based objective function that yields appropriate shrinkage for\nthe inferred signals, and a relatively efficient estimation algorithm with no\ntuning parameters. A general result establishes conditions for the uniqueness\nof the underlying decomposition for a broad family of methods that includes the\nproposed approach. For scenarios with missing data, we describe an associated\niterative imputation approach that is novel for the single-matrix context and a\npowerful approach for \"blockwise\" imputation (in which an entire row or column\nis missing) in various linked matrix contexts. Extensive simulations show that\nthe method performs very well under different scenarios with respect to\nrecovering underlying low-rank signal, accurately decomposing shared and\nspecific signals, and accurately imputing missing data. The approach is applied\nto gene expression and miRNA data from breast cancer tissue and normal breast\ntissue, for which it gives an informative decomposition of variation and\noutperforms alternative strategies for missing data imputation.", "arxiv_id": "http://arxiv.org/abs/2408.00237v1", "pdf_url": "http://arxiv.org/pdf/2408.00237v1", "primary_category": "stat.ML", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "CDFGNN: a Systematic Design of Cache-based Distributed Full-Batch Graph Neural Network Training with Communication Reduction", "authors": "Shuai Zhang, Zite Jiang, Haihang You", "abstract": "Graph neural network training is mainly categorized into mini-batch and\nfull-batch training methods. The mini-batch training method samples subgraphs\nfrom the original graph in each iteration. This sampling operation introduces\nextra computation overhead and reduces the training accuracy. Meanwhile, the\nfull-batch training method calculates the features and corresponding gradients\nof all vertices in each iteration, and therefore has higher convergence\naccuracy. However, in the distributed cluster, frequent remote accesses of\nvertex features and gradients lead to huge communication overhead, thus\nrestricting the overall training efficiency.\n  In this paper, we introduce the cached-based distributed full-batch graph\nneural network training framework (CDFGNN). We propose the adaptive cache\nmechanism to reduce the remote vertex access by caching the historical features\nand gradients of neighbor vertices. Besides, we further optimize the\ncommunication overhead by quantifying the messages and designing the graph\npartition algorithm for the hierarchical communication architecture.\nExperiments show that the adaptive cache mechanism reduces remote vertex\naccesses by 63.14% on average. Combined with communication quantization and\nhierarchical GP algorithm, CDFGNN outperforms the state-of-the-art distributed\nfull-batch training frameworks by 30.39% in our experiments. Our results\nindicate that CDFGNN has great potential in accelerating distributed full-batch\nGNN training tasks.", "arxiv_id": "http://arxiv.org/abs/2408.00232v1", "pdf_url": "http://arxiv.org/pdf/2408.00232v1", "primary_category": "cs.DC", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Invariant Discovery of Features Across Multiple Length Scales: Applications in Microscopy and Autonomous Materials Characterization", "authors": "Aditya Raghavan, Utkarsh Pratiush, Mani Valleti, Richard Liu, Reece Emery, Hiroshi Funakubo, Yongtao Liu, Philip Rack, Sergei Kalinin", "abstract": "Physical imaging is a foundational characterization method in areas from\ncondensed matter physics and chemistry to astronomy and spans length scales\nfrom atomic to universe. Images encapsulate crucial data regarding atomic\nbonding, materials microstructures, and dynamic phenomena such as\nmicrostructural evolution and turbulence, among other phenomena. The challenge\nlies in effectively extracting and interpreting this information. Variational\nAutoencoders (VAEs) have emerged as powerful tools for identifying underlying\nfactors of variation in image data, providing a systematic approach to\ndistilling meaningful patterns from complex datasets. However, a significant\nhurdle in their application is the definition and selection of appropriate\ndescriptors reflecting local structure. Here we introduce the scale-invariant\nVAE approach (SI-VAE) based on the progressive training of the VAE with the\ndescriptors sampled at different length scales. The SI-VAE allows the discovery\nof the length scale dependent factors of variation in the system. Here, we\nillustrate this approach using the ferroelectric domain images and generalize\nit to the movies of the electron-beam induced phenomena in graphene and\ntopography evolution across combinatorial libraries. This approach can further\nbe used to initialize the decision making in automated experiments including\nstructure-property discovery and can be applied across a broad range of imaging\nmethods. This approach is universal and can be applied to any spatially\nresolved data including both experimental imaging studies and simulations, and\ncan be particularly useful for exploration of phenomena such as turbulence,\nscale-invariant transformation fronts, etc.", "arxiv_id": "http://arxiv.org/abs/2408.00229v1", "pdf_url": "http://arxiv.org/pdf/2408.00229v1", "primary_category": "physics.comp-ph", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Persistent de Rham-Hodge Laplacians in the Eulerian representation", "authors": "Zhe Su, Yiying Tong, Guo-Wei Wei", "abstract": "Recently, topological data analysis (TDA) has become a trending topic in data\nscience and engineering. However, the key technique of TDA, i.e., persistent\nhomology, is defined on point cloud data, which restricts its scope. In this\nwork, we propose persistent de Rham-Hodge Laplacian, or persistent Hodge\nLaplacian (PHL) for abbreviation, for the TDA on manifolds with boundaries, or\nvolumetric data. Specifically, we extended the evolutionary de Rham-Hodge\ntheory from the Lagrangian formulation to the Eulerian formulation via\nstructure-persevering Cartesian grids, and extended the persistent Laplacian on\npoint clouds to persistent (de Rham-)Hodge Laplacian on nested families of\nmanifolds with appropriate boundary conditions. The proposed PHL facilitates\nthe machine learning and deep learning prediction of volumetric data. For a\nproof-of-principle application of the proposed PHL, we propose a persistent\nHodge Laplacian learning (PHLL) algorithm for data on manifolds or volumetric\ndata. To this end, we showcase the PHLL prediction of protein-ligand binding\naffinities in two benchmark datasets. Our numerical experiments highlight the\npower and promise of PHLL.", "arxiv_id": "http://arxiv.org/abs/2408.00220v1", "pdf_url": "http://arxiv.org/pdf/2408.00220v1", "primary_category": "math.DG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Load Balancing in Federated Learning", "authors": "Alireza Javani, Zhiying Wang", "abstract": "Federated Learning (FL) is a decentralized machine learning framework that\nenables learning from data distributed across multiple remote devices,\nenhancing communication efficiency and data privacy. Due to limited\ncommunication resources, a scheduling policy is often applied to select a\nsubset of devices for participation in each FL round. The scheduling process\nconfronts significant challenges due to the need for fair workload\ndistribution, efficient resource utilization, scalability in environments with\nnumerous edge devices, and statistically heterogeneous data across devices.\nThis paper proposes a load metric for scheduling policies based on the Age of\nInformation and addresses the above challenges by minimizing the load metric\nvariance across the clients. Furthermore, a decentralized Markov scheduling\npolicy is presented, that ensures a balanced workload distribution while\neliminating the management overhead irrespective of the network size due to\nindependent client decision-making. We establish the optimal parameters of the\nMarkov chain model and validate our approach through simulations. The results\ndemonstrate that reducing the load metric variance not only promotes fairness\nand improves operational efficiency, but also enhances the convergence rate of\nthe learning models.", "arxiv_id": "http://arxiv.org/abs/2408.00217v1", "pdf_url": "http://arxiv.org/pdf/2408.00217v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Penzai + Treescope: A Toolkit for Interpreting, Visualizing, and Editing Models As Data", "authors": "Daniel D. Johnson", "abstract": "Much of today's machine learning research involves interpreting, modifying or\nvisualizing models after they are trained. I present Penzai, a neural network\nlibrary designed to simplify model manipulation by representing models as\nsimple data structures, and Treescope, an interactive pretty-printer and array\nvisualizer that can visualize both model inputs/outputs and the models\nthemselves. Penzai models are built using declarative combinators that expose\nthe model forward pass in the structure of the model object itself, and use\nnamed axes to ensure each operation is semantically meaningful. With Penzai's\ntree-editing selector system, users can both insert and replace model\ncomponents, allowing them to intervene on intermediate values or make other\nedits to the model structure. Users can then get immediate feedback by\nvisualizing the modified model with Treescope. I describe the motivation and\nmain features of Penzai and Treescope, and discuss how treating the model as\ndata enables a variety of analyses and interventions to be implemented as\ndata-structure transformations, without requiring model designers to add\nexplicit hooks.", "arxiv_id": "http://arxiv.org/abs/2408.00211v1", "pdf_url": "http://arxiv.org/pdf/2408.00211v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Prognosis of COVID-19 using Artificial Intelligence: A Systematic Review and Meta-analysis", "authors": "SaeedReza Motamedian, Sadra Mohaghegh, Elham Babadi Oregani, Mahrsa Amjadi, Parnian Shobeiri, Negin Cheraghi, Niusha Solouki, Nikoo Ahmadi, Hossein Mohammad-Rahimi, Yassine Bouchareb, Arman Rahmim", "abstract": "Purpose: Artificial intelligence (AI) techniques have been extensively\nutilized for diagnosing and prognosis of several diseases in recent years. This\nstudy identifies, appraises and synthesizes published studies on the use of AI\nfor the prognosis of COVID-19. Method: Electronic search was performed using\nMedline, Google Scholar, Scopus, Embase, Cochrane and ProQuest. Studies that\nexamined machine learning or deep learning methods to determine the prognosis\nof COVID-19 using CT or chest X-ray images were included. Polled sensitivity,\nspecificity area under the curve and diagnostic odds ratio were calculated.\nResult: A total of 36 articles were included; various prognosis-related issues,\nincluding disease severity, mechanical ventilation or admission to the\nintensive care unit and mortality, were investigated. Several AI models and\narchitectures were employed, such as the Siamense model, support vector\nmachine, Random Forest , eXtreme Gradient Boosting, and convolutional neural\nnetworks. The models achieved 71%, 88% and 67% sensitivity for mortality,\nseverity assessment and need for ventilation, respectively. The specificity of\n69%, 89% and 89% were reported for the aforementioned variables. Conclusion:\nBased on the included articles, machine learning and deep learning methods used\nfor the prognosis of COVID-19 patients using radiomic features from CT or CXR\nimages can help clinicians manage patients and allocate resources more\neffectively. These studies also demonstrate that combining patient demographic,\nclinical data, laboratory tests and radiomic features improves model\nperformances.", "arxiv_id": "http://arxiv.org/abs/2408.00208v1", "pdf_url": "http://arxiv.org/pdf/2408.00208v1", "primary_category": "physics.med-ph", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "RELEVANT"}
{"title": "OmniParser for Pure Vision Based GUI Agent", "authors": "Yadong Lu, Jianwei Yang, Yelong Shen, Ahmed Awadallah", "abstract": "The recent success of large vision language models shows great potential in\ndriving the agent system operating on user interfaces. However, we argue that\nthe power multimodal models like GPT-4V as a general agent on multiple\noperating systems across different applications is largely underestimated due\nto the lack of a robust screen parsing technique capable of: 1) reliably\nidentifying interactable icons within the user interface, and 2) understanding\nthe semantics of various elements in a screenshot and accurately associate the\nintended action with the corresponding region on the screen. To fill these\ngaps, we introduce \\textsc{OmniParser}, a comprehensive method for parsing user\ninterface screenshots into structured elements, which significantly enhances\nthe ability of GPT-4V to generate actions that can be accurately grounded in\nthe corresponding regions of the interface. We first curated an interactable\nicon detection dataset using popular webpages and an icon description dataset.\nThese datasets were utilized to fine-tune specialized models: a detection model\nto parse interactable regions on the screen and a caption model to extract the\nfunctional semantics of the detected elements. \\textsc{OmniParser}\nsignificantly improves GPT-4V's performance on ScreenSpot benchmark. And on\nMind2Web and AITW benchmark, \\textsc{OmniParser} with screenshot only input\noutperforms the GPT-4V baselines requiring additional information outside of\nscreenshot.", "arxiv_id": "http://arxiv.org/abs/2408.00203v1", "pdf_url": "http://arxiv.org/pdf/2408.00203v1", "primary_category": "cs.CV", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "UnPaSt: unsupervised patient stratification by differentially expressed biclusters in omics data", "authors": "Michael Hartung, Andreas Maier, Fernando Delgado-Chaves, Yuliya Burankova, Olga I. Isaeva, F\u00e1bio Malta de S\u00e1 Patroni, Daniel He, Casey Shannon, Katharina Kaufmann, Jens Lohmann, Alexey Savchik, Anne Hartebrodt, Zoe Chervontseva, Farzaneh Firoozbakht, Niklas Probul, Evgenia Zotova, Olga Tsoy, David B. Blumenthal, Martin Ester, Tanja Laske, Jan Baumbach, Olga Zolotareva", "abstract": "Most complex diseases, including cancer and non-malignant diseases like\nasthma, have distinct molecular subtypes that require distinct clinical\napproaches. However, existing computational patient stratification methods have\nbeen benchmarked almost exclusively on cancer omics data and only perform well\nwhen mutually exclusive subtypes can be characterized by many biomarkers. Here,\nwe contribute with a massive evaluation attempt, quantitatively exploring the\npower of 22 unsupervised patient stratification methods using both, simulated\nand real transcriptome data. From this experience, we developed UnPaSt\n(https://apps.cosy.bio/unpast/) optimizing unsupervised patient stratification,\nworking even with only a limited number of subtype-predictive biomarkers. We\nevaluated all 23 methods on real-world breast cancer and asthma transcriptomics\ndata. Although many methods reliably detected major breast cancer subtypes,\nonly few identified Th2-high asthma, and UnPaSt significantly outperformed its\nclosest competitors in both test datasets. Essentially, we showed that UnPaSt\ncan detect many biologically insightful and reproducible patterns in omic\ndatasets.", "arxiv_id": "http://arxiv.org/abs/2408.00200v1", "pdf_url": "http://arxiv.org/pdf/2408.00200v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Automated Software Vulnerability Static Code Analysis Using Generative Pre-Trained Transformer Models", "authors": "Elijah Pelofske, Vincent Urias, Lorie M. Liebrock", "abstract": "Generative Pre-Trained Transformer models have been shown to be surprisingly\neffective at a variety of natural language processing tasks -- including\ngenerating computer code. We evaluate the effectiveness of open source GPT\nmodels for the task of automatic identification of the presence of vulnerable\ncode syntax (specifically targeting C and C++ source code). This task is\nevaluated on a selection of 36 source code examples from the NIST SARD dataset,\nwhich are specifically curated to not contain natural English that indicates\nthe presence, or lack thereof, of a particular vulnerability. The NIST SARD\nsource code dataset contains identified vulnerable lines of source code that\nare examples of one out of the 839 distinct Common Weakness Enumerations (CWE),\nallowing for exact quantification of the GPT output classification error rate.\nA total of 5 GPT models are evaluated, using 10 different inference\ntemperatures and 100 repetitions at each setting, resulting in 5,000 GPT\nqueries per vulnerable source code analyzed. Ultimately, we find that the GPT\nmodels that we evaluated are not suitable for fully automated vulnerability\nscanning because the false positive and false negative rates are too high to\nlikely be useful in practice. However, we do find that the GPT models perform\nsurprisingly well at automated vulnerability detection for some of the test\ncases, in particular surpassing random sampling, and being able to identify the\nexact lines of code that are vulnerable albeit at a low success rate. The best\nperforming GPT model result found was Llama-2-70b-chat-hf with inference\ntemperature of 0.1 applied to NIST SARD test case 149165 (which is an example\nof a buffer overflow vulnerability), which had a binary classification recall\nscore of 1.0 and a precision of 1.0 for correctly and uniquely identifying the\nvulnerable line of code and the correct CWE number.", "arxiv_id": "http://arxiv.org/abs/2408.00197v1", "pdf_url": "http://arxiv.org/pdf/2408.00197v1", "primary_category": "cs.CR", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Combining audio control and style transfer using latent diffusion", "authors": "Nils Demerl\u00e9, Philippe Esling, Guillaume Doras, David Genova", "abstract": "Deep generative models are now able to synthesize high-quality audio signals,\nshifting the critical aspect in their development from audio quality to control\ncapabilities. Although text-to-music generation is getting largely adopted by\nthe general public, explicit control and example-based style transfer are more\nadequate modalities to capture the intents of artists and musicians.\n  In this paper, we aim to unify explicit control and style transfer within a\nsingle model by separating local and global information to capture musical\nstructure and timbre respectively. To do so, we leverage the capabilities of\ndiffusion autoencoders to extract semantic features, in order to build two\nrepresentation spaces. We enforce disentanglement between those spaces using an\nadversarial criterion and a two-stage training strategy. Our resulting model\ncan generate audio matching a timbre target, while specifying structure either\nwith explicit controls or through another audio example. We evaluate our model\non one-shot timbre transfer and MIDI-to-audio tasks on instrumental recordings\nand show that we outperform existing baselines in terms of audio quality and\ntarget fidelity. Furthermore, we show that our method can generate cover\nversions of complete musical pieces by transferring rhythmic and melodic\ncontent to the style of a target audio in a different genre.", "arxiv_id": "http://arxiv.org/abs/2408.00196v1", "pdf_url": "http://arxiv.org/pdf/2408.00196v1", "primary_category": "cs.SD", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Adapting Skills to Novel Grasps: A Self-Supervised Approach", "authors": "Georgios Papagiannis, Kamil Dreczkowski, Vitalis Vosylius, Edward Johns", "abstract": "In this paper, we study the problem of adapting manipulation trajectories\ninvolving grasped objects (e.g. tools) defined for a single grasp pose to novel\ngrasp poses. A common approach to address this is to define a new trajectory\nfor each possible grasp explicitly, but this is highly inefficient. Instead, we\npropose a method to adapt such trajectories directly while only requiring a\nperiod of self-supervised data collection, during which a camera observes the\nrobot's end-effector moving with the object rigidly grasped. Importantly, our\nmethod requires no prior knowledge of the grasped object (such as a 3D CAD\nmodel), it can work with RGB images, depth images, or both, and it requires no\ncamera calibration. Through a series of real-world experiments involving 1360\nevaluations, we find that self-supervised RGB data consistently outperforms\nalternatives that rely on depth images including several state-of-the-art pose\nestimation methods. Compared to the best-performing baseline, our method\nresults in an average of 28.5% higher success rate when adapting manipulation\ntrajectories to novel grasps on several everyday tasks. Videos of the\nexperiments are available on our webpage at\nhttps://www.robot-learning.uk/adapting-skills", "arxiv_id": "http://arxiv.org/abs/2408.00178v1", "pdf_url": "http://arxiv.org/pdf/2408.00178v1", "primary_category": "cs.RO", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "CREW: Facilitating Human-AI Teaming Research", "authors": "Lingyu Zhang, Zhengran Ji, Boyuan Chen", "abstract": "With the increasing deployment of artificial intelligence (AI) technologies,\nthe potential of humans working with AI agents has been growing at a great\nspeed. Human-AI teaming is an important paradigm for studying various aspects\nwhen humans and AI agents work together. The unique aspect of Human-AI teaming\nresearch is the need to jointly study humans and AI agents, demanding\nmultidisciplinary research efforts from machine learning to human-computer\ninteraction, robotics, cognitive science, neuroscience, psychology, social\nscience, and complex systems. However, existing platforms for Human-AI teaming\nresearch are limited, often supporting oversimplified scenarios and a single\ntask, or specifically focusing on either human-teaming research or multi-agent\nAI algorithms. We introduce CREW, a platform to facilitate Human-AI teaming\nresearch and engage collaborations from multiple scientific disciplines, with a\nstrong emphasis on human involvement. It includes pre-built tasks for cognitive\nstudies and Human-AI teaming with expandable potentials from our modular\ndesign. Following conventional cognitive neuroscience research, CREW also\nsupports multimodal human physiological signal recording for behavior analysis.\nMoreover, CREW benchmarks real-time human-guided reinforcement learning agents\nusing state-of-the-art algorithms and well-tuned baselines. With CREW, we were\nable to conduct 50 human subject studies within a week to verify the\neffectiveness of our benchmark.", "arxiv_id": "http://arxiv.org/abs/2408.00170v1", "pdf_url": "http://arxiv.org/pdf/2408.00170v1", "primary_category": "cs.HC", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Strike the Balance: On-the-Fly Uncertainty based User Interactions for Long-Term Video Object Segmentation", "authors": "St\u00e9phane Vujasinovi\u0107, Stefan Becker, Sebastian Bullinger, Norbert Scherer-Negenborn, Michael Arens", "abstract": "In this paper, we introduce a variant of video object segmentation (VOS) that\nbridges interactive and semi-automatic approaches, termed Lazy Video Object\nSegmentation (ziVOS). In contrast, to both tasks, which handle video object\nsegmentation in an off-line manner (i.e., pre-recorded sequences), we propose\nthrough ziVOS to target online recorded sequences. Here, we strive to strike a\nbalance between performance and robustness for long-term scenarios by\nsoliciting user feedback's on-the-fly during the segmentation process. Hence,\nwe aim to maximize the tracking duration of an object of interest, while\nrequiring minimal user corrections to maintain tracking over an extended\nperiod. We propose a competitive baseline, i.e., Lazy-XMem, as a reference for\nfuture works in ziVOS. Our proposed approach uses an uncertainty estimation of\nthe tracking state to determine whether a user interaction is necessary to\nrefine the model's prediction. To quantitatively assess the performance of our\nmethod and the user's workload, we introduce complementary metrics alongside\nthose already established in the field. We evaluate our approach using the\nrecently introduced LVOS dataset, which offers numerous long-term videos. Our\ncode is publicly available at https://github.com/Vujas-Eteph/LazyXMem.", "arxiv_id": "http://arxiv.org/abs/2408.00169v1", "pdf_url": "http://arxiv.org/pdf/2408.00169v1", "primary_category": "cs.CV", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Review of Explainable Graph-Based Recommender Systems", "authors": "Thanet Markchom, Huizhi Liang, James Ferryman", "abstract": "Explainability of recommender systems has become essential to ensure users'\ntrust and satisfaction. Various types of explainable recommender systems have\nbeen proposed including explainable graph-based recommender systems. This\nreview paper discusses state-of-the-art approaches of these systems and\ncategorizes them based on three aspects: learning methods, explaining methods,\nand explanation types. It also explores the commonly used datasets,\nexplainability evaluation methods, and future directions of this research area.\nCompared with the existing review papers, this paper focuses on explainability\nbased on graphs and covers the topics required for developing novel explainable\ngraph-based recommender systems.", "arxiv_id": "http://arxiv.org/abs/2408.00166v1", "pdf_url": "http://arxiv.org/pdf/2408.00166v1", "primary_category": "cs.IR", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Non-convolutional Graph Neural Networks", "authors": "Yuanqing Wang, Kyunghyun Cho", "abstract": "Rethink convolution-based graph neural networks (GNN) -- they\ncharacteristically suffer from limited expressiveness, over-smoothing, and\nover-squashing, and require specialized sparse kernels for efficient\ncomputation. Here, we design a simple graph learning module entirely free of\nconvolution operators, coined \\textit{random walk with unifying memory} (RUM)\nneural network, where an RNN merges the topological and semantic graph features\nalong the random walks terminating at each node. Relating the rich literature\non RNN behavior and graph topology, we theoretically show and experimentally\nverify that RUM attenuates the aforementioned symptoms and is more expressive\nthan the Weisfeiler-Lehman (WL) isomorphism test. On a variety of node- and\ngraph-level classification and regression tasks, RUM not only achieves\ncompetitive performance, but is also robust, memory-efficient, scalable, and\nfaster than the simplest convolutional GNNs.", "arxiv_id": "http://arxiv.org/abs/2408.00165v1", "pdf_url": "http://arxiv.org/pdf/2408.00165v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "A Taxonomy of Stereotype Content in Large Language Models", "authors": "Gandalf Nicolas, Aylin Caliskan", "abstract": "This study introduces a taxonomy of stereotype content in contemporary large\nlanguage models (LLMs). We prompt ChatGPT 3.5, Llama 3, and Mixtral 8x7B, three\npowerful and widely used LLMs, for the characteristics associated with 87\nsocial categories (e.g., gender, race, occupations). We identify 14 stereotype\ndimensions (e.g., Morality, Ability, Health, Beliefs, Emotions), accounting for\n~90% of LLM stereotype associations. Warmth and Competence facets were the most\nfrequent content, but all other dimensions were significantly prevalent.\nStereotypes were more positive in LLMs (vs. humans), but there was significant\nvariability across categories and dimensions. Finally, the taxonomy predicted\nthe LLMs' internal evaluations of social categories (e.g., how\npositively/negatively the categories were represented), supporting the\nrelevance of a multidimensional taxonomy for characterizing LLM stereotypes.\nOur findings suggest that high-dimensional human stereotypes are reflected in\nLLMs and must be considered in AI auditing and debiasing to minimize\nunidentified harms from reliance in low-dimensional views of bias in LLMs.", "arxiv_id": "http://arxiv.org/abs/2408.00162v1", "pdf_url": "http://arxiv.org/pdf/2408.00162v1", "primary_category": "cs.CY", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Automatic Generation of Behavioral Test Cases For Natural Language Processing Using Clustering and Prompting", "authors": "Ying Li, Rahul Singh, Tarun Joshi, Agus Sudjianto", "abstract": "Recent work in behavioral testing for natural language processing (NLP)\nmodels, such as Checklist, is inspired by related paradigms in software\nengineering testing. They allow evaluation of general linguistic capabilities\nand domain understanding, hence can help evaluate conceptual soundness and\nidentify model weaknesses. However, a major challenge is the creation of test\ncases. The current packages rely on semi-automated approach using manual\ndevelopment which requires domain expertise and can be time consuming. This\npaper introduces an automated approach to develop test cases by exploiting the\npower of large language models and statistical techniques. It clusters the text\nrepresentations to carefully construct meaningful groups and then apply\nprompting techniques to automatically generate Minimal Functionality Tests\n(MFT). The well-known Amazon Reviews corpus is used to demonstrate our\napproach. We analyze the behavioral test profiles across four different\nclassification algorithms and discuss the limitations and strengths of those\nmodels.", "arxiv_id": "http://arxiv.org/abs/2408.00161v1", "pdf_url": "http://arxiv.org/pdf/2408.00161v1", "primary_category": "cs.CL", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Hierarchical Conditioning of Diffusion Models Using Tree-of-Life for Studying Species Evolution", "authors": "Mridul Khurana, Arka Daw, M. Maruf, Josef C. Uyeda, Wasila Dahdul, Caleb Charpentier, Yasin Bak\u0131\u015f, Henry L. Bart Jr., Paula M. Mabee, Hilmar Lapp, James P. Balhoff, Wei-Lun Chao, Charles Stewart, Tanya Berger-Wolf, Anuj Karpatne", "abstract": "A central problem in biology is to understand how organisms evolve and adapt\nto their environment by acquiring variations in the observable characteristics\nor traits of species across the tree of life. With the growing availability of\nlarge-scale image repositories in biology and recent advances in generative\nmodeling, there is an opportunity to accelerate the discovery of evolutionary\ntraits automatically from images. Toward this goal, we introduce\nPhylo-Diffusion, a novel framework for conditioning diffusion models with\nphylogenetic knowledge represented in the form of HIERarchical Embeddings\n(HIER-Embeds). We also propose two new experiments for perturbing the embedding\nspace of Phylo-Diffusion: trait masking and trait swapping, inspired by\ncounterpart experiments of gene knockout and gene editing/swapping. Our work\nrepresents a novel methodological advance in generative modeling to structure\nthe embedding space of diffusion models using tree-based knowledge. Our work\nalso opens a new chapter of research in evolutionary biology by using\ngenerative models to visualize evolutionary changes directly from images. We\nempirically demonstrate the usefulness of Phylo-Diffusion in capturing\nmeaningful trait variations for fishes and birds, revealing novel insights\nabout the biological mechanisms of their evolution.", "arxiv_id": "http://arxiv.org/abs/2408.00160v1", "pdf_url": "http://arxiv.org/pdf/2408.00160v1", "primary_category": "q-bio.PE", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Generative Learning of the Solution of Parametric Partial Differential Equations Using Guided Diffusion Models and Virtual Observations", "authors": "Han Gao, Sebastian Kaltenbach, Petros Koumoutsakos", "abstract": "We introduce a generative learning framework to model high-dimensional\nparametric systems using gradient guidance and virtual observations. We\nconsider systems described by Partial Differential Equations (PDEs) discretized\nwith structured or unstructured grids. The framework integrates multi-level\ninformation to generate high fidelity time sequences of the system dynamics. We\ndemonstrate the effectiveness and versatility of our framework with two case\nstudies in incompressible, two dimensional, low Reynolds cylinder flow on an\nunstructured mesh and incompressible turbulent channel flow on a structured\nmesh, both parameterized by the Reynolds number. Our results illustrate the\nframework's robustness and ability to generate accurate flow sequences across\nvarious parameter settings, significantly reducing computational costs allowing\nfor efficient forecasting and reconstruction of flow dynamics.", "arxiv_id": "http://arxiv.org/abs/2408.00157v1", "pdf_url": "http://arxiv.org/pdf/2408.00157v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Distributionally Robust Optimization as a Scalable Framework to Characterize Extreme Value Distributions", "authors": "Patrick Kuiper, Ali Hasan, Wenhao Yang, Yuting Ng, Hoda Bidkhori, Jose Blanchet, Vahid Tarokh", "abstract": "The goal of this paper is to develop distributionally robust optimization\n(DRO) estimators, specifically for multidimensional Extreme Value Theory (EVT)\nstatistics. EVT supports using semi-parametric models called max-stable\ndistributions built from spatial Poisson point processes. While powerful, these\nmodels are only asymptotically valid for large samples. However, since extreme\ndata is by definition scarce, the potential for model misspecification error is\ninherent to these applications, thus DRO estimators are natural. In order to\nmitigate over-conservative estimates while enhancing out-of-sample performance,\nwe study DRO estimators informed by semi-parametric max-stable constraints in\nthe space of point processes. We study both tractable convex formulations for\nsome problems of interest (e.g. CVaR) and more general neural network based\nestimators. Both approaches are validated using synthetically generated data,\nrecovering prescribed characteristics, and verifying the efficacy of the\nproposed techniques. Additionally, the proposed method is applied to a real\ndata set of financial returns for comparison to a previous analysis. We\nestablished the proposed model as a novel formulation in the multivariate EVT\ndomain, and innovative with respect to performance when compared to relevant\nalternate proposals.", "arxiv_id": "http://arxiv.org/abs/2408.00131v1", "pdf_url": "http://arxiv.org/pdf/2408.00131v1", "primary_category": "stat.ML", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Vera Verto: Multimodal Hijacking Attack", "authors": "Minxing Zhang, Ahmed Salem, Michael Backes, Yang Zhang", "abstract": "The increasing cost of training machine learning (ML) models has led to the\ninclusion of new parties to the training pipeline, such as users who contribute\ntraining data and companies that provide computing resources. This involvement\nof such new parties in the ML training process has introduced new attack\nsurfaces for an adversary to exploit. A recent attack in this domain is the\nmodel hijacking attack, whereby an adversary hijacks a victim model to\nimplement their own -- possibly malicious -- hijacking tasks. However, the\nscope of the model hijacking attack is so far limited to the\nhomogeneous-modality tasks. In this paper, we transform the model hijacking\nattack into a more general multimodal setting, where the hijacking and original\ntasks are performed on data of different modalities. Specifically, we focus on\nthe setting where an adversary implements a natural language processing (NLP)\nhijacking task into an image classification model. To mount the attack, we\npropose a novel encoder-decoder based framework, namely the Blender, which\nrelies on advanced image and language models. Experimental results show that\nour modal hijacking attack achieves strong performances in different settings.\nFor instance, our attack achieves 94%, 94%, and 95% attack success rate when\nusing the Sogou news dataset to hijack STL10, CIFAR-10, and MNIST classifiers.", "arxiv_id": "http://arxiv.org/abs/2408.00129v1", "pdf_url": "http://arxiv.org/pdf/2408.00129v1", "primary_category": "cs.CR", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Certifying Robustness of Learning-Based Keypoint Detection and Pose Estimation Methods", "authors": "Xusheng Luo, Tianhao Wei, Simin Liu, Ziwei Wang, Luis Mattei-Mendez, Taylor Loper, Joshua Neighbor, Casidhe Hutchison, Changliu Liu", "abstract": "This work addresses the certification of the local robustness of vision-based\ntwo-stage 6D object pose estimation. The two-stage method for object pose\nestimation achieves superior accuracy by first employing deep neural\nnetwork-driven keypoint regression and then applying a Perspective-n-Point\n(PnP) technique. Despite advancements, the certification of these methods'\nrobustness remains scarce. This research aims to fill this gap with a focus on\ntheir local robustness on the system level--the capacity to maintain robust\nestimations amidst semantic input perturbations. The core idea is to transform\nthe certification of local robustness into neural network verification for\nclassification tasks. The challenge is to develop model, input, and output\nspecifications that align with off-the-shelf verification tools. To facilitate\nverification, we modify the keypoint detection model by substituting nonlinear\noperations with those more amenable to the verification processes. Instead of\ninjecting random noise into images, as is common, we employ a convex hull\nrepresentation of images as input specifications to more accurately depict\nsemantic perturbations. Furthermore, by conducting a sensitivity analysis, we\npropagate the robustness criteria from pose to keypoint accuracy, and then\nformulating an optimal error threshold allocation problem that allows for the\nsetting of a maximally permissible keypoint deviation thresholds. Viewing each\npixel as an individual class, these thresholds result in linear,\nclassification-akin output specifications. Under certain conditions, we\ndemonstrate that the main components of our certification framework are both\nsound and complete, and validate its effects through extensive evaluations on\nrealistic perturbations. To our knowledge, this is the first study to certify\nthe robustness of large-scale, keypoint-based pose estimation given images in\nreal-world scenarios.", "arxiv_id": "http://arxiv.org/abs/2408.00117v1", "pdf_url": "http://arxiv.org/pdf/2408.00117v1", "primary_category": "cs.CV", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "RELEVANT"}
{"title": "Measuring Progress in Dictionary Learning for Language Model Interpretability with Board Game Models", "authors": "Adam Karvonen, Benjamin Wright, Can Rager, Rico Angell, Jannik Brinkmann, Logan Smith, Claudio Mayrink Verdun, David Bau, Samuel Marks", "abstract": "What latent features are encoded in language model (LM) representations?\nRecent work on training sparse autoencoders (SAEs) to disentangle interpretable\nfeatures in LM representations has shown significant promise. However,\nevaluating the quality of these SAEs is difficult because we lack a\nground-truth collection of interpretable features that we expect good SAEs to\nrecover. We thus propose to measure progress in interpretable dictionary\nlearning by working in the setting of LMs trained on chess and Othello\ntranscripts. These settings carry natural collections of interpretable features\n-- for example, \"there is a knight on F3\" -- which we leverage into\n$\\textit{supervised}$ metrics for SAE quality. To guide progress in\ninterpretable dictionary learning, we introduce a new SAE training technique,\n$\\textit{p-annealing}$, which improves performance on prior unsupervised\nmetrics as well as our new metrics.", "arxiv_id": "http://arxiv.org/abs/2408.00113v1", "pdf_url": "http://arxiv.org/pdf/2408.00113v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Adaptive Transit Signal Priority based on Deep Reinforcement Learning and Connected Vehicles in a Traffic Microsimulation Environment", "authors": "Dickness Kwesiga, Angshuman Guin, Michael Hunter", "abstract": "Model free reinforcement learning (RL) provides a potential alternative to\nearlier formulations of adaptive transit signal priority (TSP) algorithms based\non mathematical programming that require complex and nonlinear objective\nfunctions. This study extends RL - based traffic control to include TSP. Using\na microscopic simulation environment and connected vehicle data, the study\ndevelops and tests a TSP event-based RL agent that assumes control from another\ndeveloped RL - based general traffic signal controller. The TSP agent assumes\ncontrol when transit buses enter the dedicated short-range communication (DSRC)\nzone of the intersection. This agent is shown to reduce the bus travel time by\nabout 21%, with marginal impacts to general traffic at a saturation rate of\n0.95. The TSP agent also shows slightly better bus travel time compared to\nactuated signal control with TSP. The architecture of the agent and simulation\nis selected considering the need to improve simulation run time efficiency.", "arxiv_id": "http://arxiv.org/abs/2408.00098v1", "pdf_url": "http://arxiv.org/pdf/2408.00098v1", "primary_category": "cs.LG", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Approximating Rayleigh Scattering in Exoplanetary Atmospheres using Physics-informed Neural Networks (PINNs)", "authors": "David Dahlb\u00fcdding, Karan Molaverdikhani, Barbara Ercolano, Tommaso Grassi", "abstract": "This research introduces an innovative application of physics-informed neural\nnetworks (PINNs) to tackle the intricate challenges of radiative transfer (RT)\nmodeling in exoplanetary atmospheres, with a special focus on efficiently\nhandling scattering phenomena. Traditional RT models often simplify scattering\nas absorption, leading to inaccuracies. Our approach utilizes PINNs, noted for\ntheir ability to incorporate the governing differential equations of RT\ndirectly into their loss function, thus offering a more precise yet potentially\nfast modeling technique. The core of our method involves the development of a\nparameterized PINN tailored for a modified RT equation, enhancing its\nadaptability to various atmospheric scenarios. We focus on RT in transiting\nexoplanet atmospheres using a simplified 1D isothermal model with\npressure-dependent coefficients for absorption and Rayleigh scattering. In\nscenarios of pure absorption, the PINN demonstrates its effectiveness in\npredicting transmission spectra for diverse absorption profiles. For Rayleigh\nscattering, the network successfully computes the RT equation, addressing both\ndirect and diffuse stellar light components. While our preliminary results with\nsimplified models are promising, indicating the potential of PINNs in improving\nRT calculations, we acknowledge the errors stemming from our approximations as\nwell as the challenges in applying this technique to more complex atmospheric\nconditions. Specifically, extending our approach to atmospheres with intricate\ntemperature-pressure profiles and varying scattering properties, such as those\nintroduced by clouds and hazes, remains a significant area for future\ndevelopment.", "arxiv_id": "http://arxiv.org/abs/2408.00084v1", "pdf_url": "http://arxiv.org/pdf/2408.00084v1", "primary_category": "astro-ph.EP", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "TASI Lectures on Physics for Machine Learning", "authors": "Jim Halverson", "abstract": "These notes are based on lectures I gave at TASI 2024 on Physics for Machine\nLearning. The focus is on neural network theory, organized according to network\nexpressivity, statistics, and dynamics. I present classic results such as the\nuniversal approximation theorem and neural network / Gaussian process\ncorrespondence, and also more recent results such as the neural tangent kernel,\nfeature learning with the maximal update parameterization, and\nKolmogorov-Arnold networks. The exposition on neural network theory emphasizes\na field theoretic perspective familiar to theoretical physicists. I elaborate\non connections between the two, including a neural network approach to field\ntheory.", "arxiv_id": "http://arxiv.org/abs/2408.00082v1", "pdf_url": "http://arxiv.org/pdf/2408.00082v1", "primary_category": "hep-th", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Generalized Out-of-Distribution Detection and Beyond in Vision Language Model Era: A Survey", "authors": "Atsuyuki Miyai, Jingkang Yang, Jingyang Zhang, Yifei Ming, Yueqian Lin, Qing Yu, Go Irie, Shafiq Joty, Yixuan Li, Hai Li, Ziwei Liu, Toshihiko Yamasaki, Kiyoharu Aizawa", "abstract": "Detecting out-of-distribution (OOD) samples is crucial for ensuring the\nsafety of machine learning systems and has shaped the field of OOD detection.\nMeanwhile, several other problems are closely related to OOD detection,\nincluding anomaly detection (AD), novelty detection (ND), open set recognition\n(OSR), and outlier detection (OD). To unify these problems, a generalized OOD\ndetection framework was proposed, taxonomically categorizing these five\nproblems. However, Vision Language Models (VLMs) such as CLIP have\nsignificantly changed the paradigm and blurred the boundaries between these\nfields, again confusing researchers. In this survey, we first present a\ngeneralized OOD detection v2, encapsulating the evolution of AD, ND, OSR, OOD\ndetection, and OD in the VLM era. Our framework reveals that, with some field\ninactivity and integration, the demanding challenges have become OOD detection\nand AD. In addition, we also highlight the significant shift in the definition,\nproblem settings, and benchmarks; we thus feature a comprehensive review of the\nmethodology for OOD detection, including the discussion over other related\ntasks to clarify their relationship to OOD detection. Finally, we explore the\nadvancements in the emerging Large Vision Language Model (LVLM) era, such as\nGPT-4V. We conclude this survey with open challenges and future directions.", "arxiv_id": "http://arxiv.org/abs/2407.21794v1", "pdf_url": "http://arxiv.org/pdf/2407.21794v1", "primary_category": "cs.CV", "votes": 0, "preferences": "Convolutional Neural Network ", "response": "NOT_ENOUGH_RELATED"}
{"title": "LLaVA-OneVision: Easy Visual Task Transfer", "authors": "Bo Li, Yuanhan Zhang, Dong Guo, Renrui Zhang, Feng Li, Hao Zhang, Kaichen Zhang, Yanwei Li, Ziwei Liu, Chunyuan Li", "abstract": "We present LLaVA-OneVision, a family of open large multimodal models (LMMs)\ndeveloped by consolidating our insights into data, models, and visual\nrepresentations in the LLaVA-NeXT blog series. Our experimental results\ndemonstrate that LLaVA-OneVision is the first single model that can\nsimultaneously push the performance boundaries of open LMMs in three important\ncomputer vision scenarios: single-image, multi-image, and video scenarios.\nImportantly, the design of LLaVA-OneVision allows strong transfer learning\nacross different modalities/scenarios, yielding new emerging capabilities. In\nparticular, strong video understanding and cross-scenario capabilities are\ndemonstrated through task transfer from images to videos.", "arxiv_id": "2408.03326v1", "pdf_url": "http://arxiv.org/pdf/2408.03326v1", "abstract_url": "http://arxiv.org/abs/2408.03326v1", "primary_category": "cs.CV", "votes": 0, "preferences": "LLM ", "response": "RELEVANT"}
{"title": "ClassiFIM: An Unsupervised Method To Detect Phase Transitions", "authors": "Victor Kasatkin, Evgeny Mozgunov, Nicholas Ezzell, Utkarsh Mishra, Itay Hen, Daniel Lidar", "abstract": "Estimation of the Fisher Information Metric (FIM-estimation) is an important\ntask that arises in unsupervised learning of phase transitions, a problem\nproposed by physicists. This work completes the definition of the task by\ndefining rigorous evaluation metrics distMSE, distMSEPS, and distRE and\nintroduces ClassiFIM, a novel machine learning method designed to solve the\nFIM-estimation task. Unlike existing methods for unsupervised learning of phase\ntransitions, ClassiFIM directly estimates a well-defined quantity (the FIM),\nallowing it to be rigorously compared to any present and future other methods\nthat estimate the same. ClassiFIM transforms a dataset for the FIM-estimation\ntask into a dataset for an auxiliary binary classification task and involves\nselecting and training a model for the latter. We prove that the output of\nClassiFIM approaches the exact FIM in the limit of infinite dataset size and\nunder certain regularity conditions. We implement ClassiFIM on multiple\ndatasets, including datasets describing classical and quantum phase\ntransitions, and find that it achieves a good ground truth approximation with\nmodest computational resources. Furthermore, we independently implement two\nalternative state-of-the-art methods for unsupervised estimation of phase\ntransition locations on the same datasets and find that ClassiFIM predicts such\nlocations at least as well as these other methods. To emphasize the generality\nof our method, we also propose and generate the MNIST-CNN dataset, which\nconsists of the output of CNNs trained on MNIST for different hyperparameter\nchoices. Using ClassiFIM on this dataset suggests there is a phase transition\nin the distribution of image-prediction pairs for CNNs trained on MNIST,\ndemonstrating the broad scope of FIM-estimation beyond physics.", "arxiv_id": "2408.03323v1", "pdf_url": "http://arxiv.org/pdf/2408.03323v1", "abstract_url": "http://arxiv.org/abs/2408.03323v1", "primary_category": "cs.LG", "votes": 0, "preferences": "LLM ", "response": "RELEVANT"}
{"title": "Hedge Fund Portfolio Construction Using PolyModel Theory and iTransformer", "authors": "Siqiao Zhao, Zhikang Dong, Zeyu Cao, Raphael Douady", "abstract": "When constructing portfolios, a key problem is that a lot of financial time\nseries data are sparse, making it challenging to apply machine learning\nmethods. Polymodel theory can solve this issue and demonstrate superiority in\nportfolio construction from various aspects. To implement the PolyModel theory\nfor constructing a hedge fund portfolio, we begin by identifying an asset pool,\nutilizing over 10,000 hedge funds for the past 29 years' data. PolyModel theory\nalso involves choosing a wide-ranging set of risk factors, which includes\nvarious financial indices, currencies, and commodity prices. This comprehensive\nselection mirrors the complexities of the real-world environment. Leveraging on\nthe PolyModel theory, we create quantitative measures such as Long-term Alpha,\nLong-term Ratio, and SVaR. We also use more classical measures like the Sharpe\nratio or Morningstar's MRAR. To enhance the performance of the constructed\nportfolio, we also employ the latest deep learning techniques (iTransformer) to\ncapture the upward trend, while efficiently controlling the downside, using all\nthe features. The iTransformer model is specifically designed to address the\nchallenges in high-dimensional time series forecasting and could largely\nimprove our strategies. More precisely, our strategies achieve better Sharpe\nratio and annualized return. The above process enables us to create multiple\nportfolio strategies aiming for high returns and low risks when compared to\nvarious benchmarks.", "arxiv_id": "2408.03320v1", "pdf_url": "http://arxiv.org/pdf/2408.03320v1", "abstract_url": "http://arxiv.org/abs/2408.03320v1", "primary_category": "q-fin.PM", "votes": 0, "preferences": "LLM ", "response": "RELEVANT"}
{"title": "Training LLMs to Recognize Hedges in Spontaneous Narratives", "authors": "Amie J. Paige, Adil Soubki, John Murzaku, Owen Rambow, Susan E. Brennan", "abstract": "Hedges allow speakers to mark utterances as provisional, whether to signal\nnon-prototypicality or \"fuzziness\", to indicate a lack of commitment to an\nutterance, to attribute responsibility for a statement to someone else, to\ninvite input from a partner, or to soften critical feedback in the service of\nface-management needs. Here we focus on hedges in an experimentally\nparameterized corpus of 63 Roadrunner cartoon narratives spontaneously produced\nfrom memory by 21 speakers for co-present addressees, transcribed to text\n(Galati and Brennan, 2010). We created a gold standard of hedges annotated by\nhuman coders (the Roadrunner-Hedge corpus) and compared three LLM-based\napproaches for hedge detection: fine-tuning BERT, and zero and few-shot\nprompting with GPT-4o and LLaMA-3. The best-performing approach was a\nfine-tuned BERT model, followed by few-shot GPT-4o. After an error analysis on\nthe top performing approaches, we used an LLM-in-the-Loop approach to improve\nthe gold standard coding, as well as to highlight cases in which hedges are\nambiguous in linguistically interesting ways that will guide future research.\nThis is the first step in our research program to train LLMs to interpret and\ngenerate collateral signals appropriately and meaningfully in conversation.", "arxiv_id": "2408.03319v1", "pdf_url": "http://arxiv.org/pdf/2408.03319v1", "abstract_url": "http://arxiv.org/abs/2408.03319v1", "primary_category": "cs.CL", "votes": 0, "preferences": "LLM ", "response": "RELEVANT"}
{"title": "Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters", "authors": "Charlie Snell, Jaehoon Lee, Kelvin Xu, Aviral Kumar", "abstract": "Enabling LLMs to improve their outputs by using more test-time computation is\na critical step towards building generally self-improving agents that can\noperate on open-ended natural language. In this paper, we study the scaling of\ninference-time computation in LLMs, with a focus on answering the question: if\nan LLM is allowed to use a fixed but non-trivial amount of inference-time\ncompute, how much can it improve its performance on a challenging prompt?\nAnswering this question has implications not only on the achievable performance\nof LLMs, but also on the future of LLM pretraining and how one should tradeoff\ninference-time and pre-training compute. Despite its importance, little\nresearch attempted to understand the scaling behaviors of various test-time\ninference methods. Moreover, current work largely provides negative results for\na number of these strategies. In this work, we analyze two primary mechanisms\nto scale test-time computation: (1) searching against dense, process-based\nverifier reward models; and (2) updating the model's distribution over a\nresponse adaptively, given the prompt at test time. We find that in both cases,\nthe effectiveness of different approaches to scaling test-time compute\ncritically varies depending on the difficulty of the prompt. This observation\nmotivates applying a \"compute-optimal\" scaling strategy, which acts to most\neffectively allocate test-time compute adaptively per prompt. Using this\ncompute-optimal strategy, we can improve the efficiency of test-time compute\nscaling by more than 4x compared to a best-of-N baseline. Additionally, in a\nFLOPs-matched evaluation, we find that on problems where a smaller base model\nattains somewhat non-trivial success rates, test-time compute can be used to\noutperform a 14x larger model.", "arxiv_id": "2408.03314v1", "pdf_url": "http://arxiv.org/pdf/2408.03314v1", "abstract_url": "http://arxiv.org/abs/2408.03314v1", "primary_category": "cs.LG", "votes": 0, "preferences": "LLM ", "response": "RELEVANT"}
{"title": "Pre-training and in-context learning IS Bayesian inference a la De Finetti", "authors": "Naimeng Ye, Hanming Yang, Andrew Siah, Hongseok Namkoong", "abstract": "Accurately gauging uncertainty on the underlying environment is a\nlongstanding goal of intelligent systems. We characterize which latent concepts\npre-trained sequence models are naturally able to reason with. We go back to De\nFinetti's predictive view of Bayesian reasoning: instead of modeling latent\nparameters through priors and likelihoods like topic models do, De Finetti has\nlong advocated for modeling exchangeable (permutation invariant) sequences of\nobservables. According to this view, pre-training autoregressive models\nformulates informed beliefs based on prior observations (\"empirical Bayes\"),\nand forward generation is a simulated instantiation of an environment\n(\"posterior inference\"). This connection allows extending in-context learning\n(ICL) beyond predictive settings, highlighting sequence models' ability to\nperform explicit statistical inference. In particular, we show the sequence\nprediction loss over exchangeable documents controls performance on downstream\ntasks where uncertainty quantification is key. Empirically, we propose and\ndemonstrate several approaches for encoding exchangeability in sequence model\narchitectures: data augmentation, regularization, and causal masking.", "arxiv_id": "2408.03307v1", "pdf_url": "http://arxiv.org/pdf/2408.03307v1", "abstract_url": "http://arxiv.org/abs/2408.03307v1", "primary_category": "stat.ML", "votes": 0, "preferences": "LLM ", "response": "RELEVANT"}
{"title": "Fusing Forces: Deep-Human-Guided Refinement of Segmentation Masks", "authors": "Rafael Sterzinger, Christian Stippel, Robert Sablatnig", "abstract": "Etruscan mirrors constitute a significant category in Etruscan art,\ncharacterized by elaborate figurative illustrations featured on their backside.\nA laborious and costly aspect of their analysis and documentation is the task\nof manually tracing these illustrations. In previous work, a methodology has\nbeen proposed to automate this process, involving photometric-stereo scanning\nin combination with deep neural networks. While achieving quantitative\nperformance akin to an expert annotator, some results still lack qualitative\nprecision and, thus, require annotators for inspection and potential\ncorrection, maintaining resource intensity. In response, we propose a deep\nneural network trained to interactively refine existing annotations based on\nhuman guidance. Our human-in-the-loop approach streamlines annotation,\nachieving equal quality with up to 75% less manual input required. Moreover,\nduring the refinement process, the relative improvement of our methodology over\npure manual labeling reaches peak values of up to 26%, attaining drastically\nbetter quality quicker. By being tailored to the complex task of segmenting\nintricate lines, specifically distinguishing it from previous methods, our\napproach offers drastic improvements in efficacy, transferable to a broad\nspectrum of applications beyond Etruscan mirrors.", "arxiv_id": "2408.03304v1", "pdf_url": "http://arxiv.org/pdf/2408.03304v1", "abstract_url": "http://arxiv.org/abs/2408.03304v1", "primary_category": "cs.CV", "votes": 0, "preferences": "LLM ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Understanding How Blind Users Handle Object Recognition Errors: Strategies and Challenges", "authors": "Jonggi Hong, Hernisa Kacorri", "abstract": "Object recognition technologies hold the potential to support blind and\nlow-vision people in navigating the world around them. However, the gap between\nbenchmark performances and practical usability remains a significant challenge.\nThis paper presents a study aimed at understanding blind users' interaction\nwith object recognition systems for identifying and avoiding errors. Leveraging\na pre-existing object recognition system, URCam, fine-tuned for our experiment,\nwe conducted a user study involving 12 blind and low-vision participants.\nThrough in-depth interviews and hands-on error identification tasks, we gained\ninsights into users' experiences, challenges, and strategies for identifying\nerrors in camera-based assistive technologies and object recognition systems.\nDuring interviews, many participants preferred independent error review, while\nexpressing apprehension toward misrecognitions. In the error identification\ntask, participants varied viewpoints, backgrounds, and object sizes in their\nimages to avoid and overcome errors. Even after repeating the task,\nparticipants identified only half of the errors, and the proportion of errors\nidentified did not significantly differ from their first attempts. Based on\nthese insights, we offer implications for designing accessible interfaces\ntailored to the needs of blind and low-vision users in identifying object\nrecognition errors.", "arxiv_id": "2408.03303v1", "pdf_url": "http://arxiv.org/pdf/2408.03303v1", "abstract_url": "http://arxiv.org/abs/2408.03303v1", "primary_category": "cs.HC", "votes": 0, "preferences": "LLM ", "response": "RELEVANT"}
{"title": "KaPO: Knowledge-aware Preference Optimization for Controllable Knowledge Selection in Retrieval-Augmented Language Models", "authors": "Ruizhe Zhang, Yongxin Xu, Yuzhen Xiao, Runchuan Zhu, Xinke Jiang, Xu Chu, Junfeng Zhao, Yasha Wang", "abstract": "By integrating external knowledge, Retrieval-Augmented Generation (RAG) has\nbecome an effective strategy for mitigating the hallucination problems that\nlarge language models (LLMs) encounter when dealing with knowledge-intensive\ntasks. However, in the process of integrating external non-parametric\nsupporting evidence with internal parametric knowledge, inevitable knowledge\nconflicts may arise, leading to confusion in the model's responses. To enhance\nthe knowledge selection of LLMs in various contexts, some research has focused\non refining their behavior patterns through instruction-tuning. Nonetheless,\ndue to the absence of explicit negative signals and comparative objectives,\nmodels fine-tuned in this manner may still exhibit undesirable behaviors in the\nintricate and realistic retrieval scenarios. To this end, we propose a\nKnowledge-aware Preference Optimization, dubbed KaPO, aimed at achieving\ncontrollable knowledge selection in real retrieval scenarios. Concretely, we\nexplore and simulate error types across diverse context combinations and learn\nhow to avoid these negative signals through preference optimization methods.\nSimultaneously, by adjusting the balance between response length and the\nproportion of preference data representing different behavior patterns, we\nenhance the adherence capabilities and noise robustness of LLMs in a balanced\nmanner. Experimental results show that KaPO outperforms previous methods for\nhandling knowledge conflicts by over 37%, while also exhibiting robust\ngeneralization across various out-of-distribution datasets.", "arxiv_id": "2408.03297v1", "pdf_url": "http://arxiv.org/pdf/2408.03297v1", "abstract_url": "http://arxiv.org/abs/2408.03297v1", "primary_category": "cs.CL", "votes": 0, "preferences": "LLM ", "response": "RELEVANT"}
{"title": "Static IR Drop Prediction with Attention U-Net and Saliency-Based Explainability", "authors": "Lizi Zhang, Azadeh Davoodi", "abstract": "There has been significant recent progress to reduce the computational effort\nof static IR drop analysis using neural networks, and modeling as an\nimage-to-image translation task. A crucial issue is the lack of sufficient data\nfrom real industry designs to train these networks. Additionally, there is no\nmethodology to explain a high-drop pixel in a predicted IR drop image to its\nspecific root-causes. In this work, we first propose a U-Net neural network\nmodel with attention gates which is specifically tailored to achieve fast and\naccurate image-based static IR drop prediction. Attention gates allow selective\nemphasis on relevant parts of the input data without supervision which is\ndesired because of the often sparse nature of the IR drop map. We propose a\ntwo-phase training process which utilizes a mix of artificially-generated data\nand a limited number of points from real designs. The results are, on-average,\n18% (53%) better in MAE and 14% (113%) in F1 score compared to the winner of\nthe ICCAD 2023 contest (and U-Net only) when tested on real designs. Second, we\npropose a fast method using saliency maps which can explain a predicted IR drop\nin terms of specific input pixels contributing the most to a drop. In our\nexperiments, we show the number of high IR drop pixels can be reduced\non-average by 18% by mimicking upsize of a tiny portion of PDN's resistive\nedges.", "arxiv_id": "2408.03292v1", "pdf_url": "http://arxiv.org/pdf/2408.03292v1", "abstract_url": "http://arxiv.org/abs/2408.03292v1", "primary_category": "cs.AR", "votes": 0, "preferences": "LLM ", "response": "RELEVANT"}
{"title": "LLaVA-OneVision: Easy Visual Task Transfer", "authors": "Bo Li, Yuanhan Zhang, Dong Guo, Renrui Zhang, Feng Li, Hao Zhang, Kaichen Zhang, Yanwei Li, Ziwei Liu, Chunyuan Li", "abstract": "We present LLaVA-OneVision, a family of open large multimodal models (LMMs)\ndeveloped by consolidating our insights into data, models, and visual\nrepresentations in the LLaVA-NeXT blog series. Our experimental results\ndemonstrate that LLaVA-OneVision is the first single model that can\nsimultaneously push the performance boundaries of open LMMs in three important\ncomputer vision scenarios: single-image, multi-image, and video scenarios.\nImportantly, the design of LLaVA-OneVision allows strong transfer learning\nacross different modalities/scenarios, yielding new emerging capabilities. In\nparticular, strong video understanding and cross-scenario capabilities are\ndemonstrated through task transfer from images to videos.", "arxiv_id": "2408.03326v1", "pdf_url": "http://arxiv.org/pdf/2408.03326v1", "abstract_url": "http://arxiv.org/abs/2408.03326v1", "primary_category": "cs.CV", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM ", "response": "RELEVANT"}
{"title": "ClassiFIM: An Unsupervised Method To Detect Phase Transitions", "authors": "Victor Kasatkin, Evgeny Mozgunov, Nicholas Ezzell, Utkarsh Mishra, Itay Hen, Daniel Lidar", "abstract": "Estimation of the Fisher Information Metric (FIM-estimation) is an important\ntask that arises in unsupervised learning of phase transitions, a problem\nproposed by physicists. This work completes the definition of the task by\ndefining rigorous evaluation metrics distMSE, distMSEPS, and distRE and\nintroduces ClassiFIM, a novel machine learning method designed to solve the\nFIM-estimation task. Unlike existing methods for unsupervised learning of phase\ntransitions, ClassiFIM directly estimates a well-defined quantity (the FIM),\nallowing it to be rigorously compared to any present and future other methods\nthat estimate the same. ClassiFIM transforms a dataset for the FIM-estimation\ntask into a dataset for an auxiliary binary classification task and involves\nselecting and training a model for the latter. We prove that the output of\nClassiFIM approaches the exact FIM in the limit of infinite dataset size and\nunder certain regularity conditions. We implement ClassiFIM on multiple\ndatasets, including datasets describing classical and quantum phase\ntransitions, and find that it achieves a good ground truth approximation with\nmodest computational resources. Furthermore, we independently implement two\nalternative state-of-the-art methods for unsupervised estimation of phase\ntransition locations on the same datasets and find that ClassiFIM predicts such\nlocations at least as well as these other methods. To emphasize the generality\nof our method, we also propose and generate the MNIST-CNN dataset, which\nconsists of the output of CNNs trained on MNIST for different hyperparameter\nchoices. Using ClassiFIM on this dataset suggests there is a phase transition\nin the distribution of image-prediction pairs for CNNs trained on MNIST,\ndemonstrating the broad scope of FIM-estimation beyond physics.", "arxiv_id": "2408.03323v1", "pdf_url": "http://arxiv.org/pdf/2408.03323v1", "abstract_url": "http://arxiv.org/abs/2408.03323v1", "primary_category": "cs.LG", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM ", "response": "RELEVANT"}
{"title": "Hedge Fund Portfolio Construction Using PolyModel Theory and iTransformer", "authors": "Siqiao Zhao, Zhikang Dong, Zeyu Cao, Raphael Douady", "abstract": "When constructing portfolios, a key problem is that a lot of financial time\nseries data are sparse, making it challenging to apply machine learning\nmethods. Polymodel theory can solve this issue and demonstrate superiority in\nportfolio construction from various aspects. To implement the PolyModel theory\nfor constructing a hedge fund portfolio, we begin by identifying an asset pool,\nutilizing over 10,000 hedge funds for the past 29 years' data. PolyModel theory\nalso involves choosing a wide-ranging set of risk factors, which includes\nvarious financial indices, currencies, and commodity prices. This comprehensive\nselection mirrors the complexities of the real-world environment. Leveraging on\nthe PolyModel theory, we create quantitative measures such as Long-term Alpha,\nLong-term Ratio, and SVaR. We also use more classical measures like the Sharpe\nratio or Morningstar's MRAR. To enhance the performance of the constructed\nportfolio, we also employ the latest deep learning techniques (iTransformer) to\ncapture the upward trend, while efficiently controlling the downside, using all\nthe features. The iTransformer model is specifically designed to address the\nchallenges in high-dimensional time series forecasting and could largely\nimprove our strategies. More precisely, our strategies achieve better Sharpe\nratio and annualized return. The above process enables us to create multiple\nportfolio strategies aiming for high returns and low risks when compared to\nvarious benchmarks.", "arxiv_id": "2408.03320v1", "pdf_url": "http://arxiv.org/pdf/2408.03320v1", "abstract_url": "http://arxiv.org/abs/2408.03320v1", "primary_category": "q-fin.PM", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM ", "response": "RELEVANT"}
{"title": "Training LLMs to Recognize Hedges in Spontaneous Narratives", "authors": "Amie J. Paige, Adil Soubki, John Murzaku, Owen Rambow, Susan E. Brennan", "abstract": "Hedges allow speakers to mark utterances as provisional, whether to signal\nnon-prototypicality or \"fuzziness\", to indicate a lack of commitment to an\nutterance, to attribute responsibility for a statement to someone else, to\ninvite input from a partner, or to soften critical feedback in the service of\nface-management needs. Here we focus on hedges in an experimentally\nparameterized corpus of 63 Roadrunner cartoon narratives spontaneously produced\nfrom memory by 21 speakers for co-present addressees, transcribed to text\n(Galati and Brennan, 2010). We created a gold standard of hedges annotated by\nhuman coders (the Roadrunner-Hedge corpus) and compared three LLM-based\napproaches for hedge detection: fine-tuning BERT, and zero and few-shot\nprompting with GPT-4o and LLaMA-3. The best-performing approach was a\nfine-tuned BERT model, followed by few-shot GPT-4o. After an error analysis on\nthe top performing approaches, we used an LLM-in-the-Loop approach to improve\nthe gold standard coding, as well as to highlight cases in which hedges are\nambiguous in linguistically interesting ways that will guide future research.\nThis is the first step in our research program to train LLMs to interpret and\ngenerate collateral signals appropriately and meaningfully in conversation.", "arxiv_id": "2408.03319v1", "pdf_url": "http://arxiv.org/pdf/2408.03319v1", "abstract_url": "http://arxiv.org/abs/2408.03319v1", "primary_category": "cs.CL", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM ", "response": "RELEVANT"}
{"title": "Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters", "authors": "Charlie Snell, Jaehoon Lee, Kelvin Xu, Aviral Kumar", "abstract": "Enabling LLMs to improve their outputs by using more test-time computation is\na critical step towards building generally self-improving agents that can\noperate on open-ended natural language. In this paper, we study the scaling of\ninference-time computation in LLMs, with a focus on answering the question: if\nan LLM is allowed to use a fixed but non-trivial amount of inference-time\ncompute, how much can it improve its performance on a challenging prompt?\nAnswering this question has implications not only on the achievable performance\nof LLMs, but also on the future of LLM pretraining and how one should tradeoff\ninference-time and pre-training compute. Despite its importance, little\nresearch attempted to understand the scaling behaviors of various test-time\ninference methods. Moreover, current work largely provides negative results for\na number of these strategies. In this work, we analyze two primary mechanisms\nto scale test-time computation: (1) searching against dense, process-based\nverifier reward models; and (2) updating the model's distribution over a\nresponse adaptively, given the prompt at test time. We find that in both cases,\nthe effectiveness of different approaches to scaling test-time compute\ncritically varies depending on the difficulty of the prompt. This observation\nmotivates applying a \"compute-optimal\" scaling strategy, which acts to most\neffectively allocate test-time compute adaptively per prompt. Using this\ncompute-optimal strategy, we can improve the efficiency of test-time compute\nscaling by more than 4x compared to a best-of-N baseline. Additionally, in a\nFLOPs-matched evaluation, we find that on problems where a smaller base model\nattains somewhat non-trivial success rates, test-time compute can be used to\noutperform a 14x larger model.", "arxiv_id": "2408.03314v1", "pdf_url": "http://arxiv.org/pdf/2408.03314v1", "abstract_url": "http://arxiv.org/abs/2408.03314v1", "primary_category": "cs.LG", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM ", "response": "RELEVANT"}
{"title": "Pre-training and in-context learning IS Bayesian inference a la De Finetti", "authors": "Naimeng Ye, Hanming Yang, Andrew Siah, Hongseok Namkoong", "abstract": "Accurately gauging uncertainty on the underlying environment is a\nlongstanding goal of intelligent systems. We characterize which latent concepts\npre-trained sequence models are naturally able to reason with. We go back to De\nFinetti's predictive view of Bayesian reasoning: instead of modeling latent\nparameters through priors and likelihoods like topic models do, De Finetti has\nlong advocated for modeling exchangeable (permutation invariant) sequences of\nobservables. According to this view, pre-training autoregressive models\nformulates informed beliefs based on prior observations (\"empirical Bayes\"),\nand forward generation is a simulated instantiation of an environment\n(\"posterior inference\"). This connection allows extending in-context learning\n(ICL) beyond predictive settings, highlighting sequence models' ability to\nperform explicit statistical inference. In particular, we show the sequence\nprediction loss over exchangeable documents controls performance on downstream\ntasks where uncertainty quantification is key. Empirically, we propose and\ndemonstrate several approaches for encoding exchangeability in sequence model\narchitectures: data augmentation, regularization, and causal masking.", "arxiv_id": "2408.03307v1", "pdf_url": "http://arxiv.org/pdf/2408.03307v1", "abstract_url": "http://arxiv.org/abs/2408.03307v1", "primary_category": "stat.ML", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM ", "response": "RELEVANT"}
{"title": "Fusing Forces: Deep-Human-Guided Refinement of Segmentation Masks", "authors": "Rafael Sterzinger, Christian Stippel, Robert Sablatnig", "abstract": "Etruscan mirrors constitute a significant category in Etruscan art,\ncharacterized by elaborate figurative illustrations featured on their backside.\nA laborious and costly aspect of their analysis and documentation is the task\nof manually tracing these illustrations. In previous work, a methodology has\nbeen proposed to automate this process, involving photometric-stereo scanning\nin combination with deep neural networks. While achieving quantitative\nperformance akin to an expert annotator, some results still lack qualitative\nprecision and, thus, require annotators for inspection and potential\ncorrection, maintaining resource intensity. In response, we propose a deep\nneural network trained to interactively refine existing annotations based on\nhuman guidance. Our human-in-the-loop approach streamlines annotation,\nachieving equal quality with up to 75% less manual input required. Moreover,\nduring the refinement process, the relative improvement of our methodology over\npure manual labeling reaches peak values of up to 26%, attaining drastically\nbetter quality quicker. By being tailored to the complex task of segmenting\nintricate lines, specifically distinguishing it from previous methods, our\napproach offers drastic improvements in efficacy, transferable to a broad\nspectrum of applications beyond Etruscan mirrors.", "arxiv_id": "2408.03304v1", "pdf_url": "http://arxiv.org/pdf/2408.03304v1", "abstract_url": "http://arxiv.org/abs/2408.03304v1", "primary_category": "cs.CV", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM ", "response": "NOT_ENOUGH_RELATED"}
{"title": "Understanding How Blind Users Handle Object Recognition Errors: Strategies and Challenges", "authors": "Jonggi Hong, Hernisa Kacorri", "abstract": "Object recognition technologies hold the potential to support blind and\nlow-vision people in navigating the world around them. However, the gap between\nbenchmark performances and practical usability remains a significant challenge.\nThis paper presents a study aimed at understanding blind users' interaction\nwith object recognition systems for identifying and avoiding errors. Leveraging\na pre-existing object recognition system, URCam, fine-tuned for our experiment,\nwe conducted a user study involving 12 blind and low-vision participants.\nThrough in-depth interviews and hands-on error identification tasks, we gained\ninsights into users' experiences, challenges, and strategies for identifying\nerrors in camera-based assistive technologies and object recognition systems.\nDuring interviews, many participants preferred independent error review, while\nexpressing apprehension toward misrecognitions. In the error identification\ntask, participants varied viewpoints, backgrounds, and object sizes in their\nimages to avoid and overcome errors. Even after repeating the task,\nparticipants identified only half of the errors, and the proportion of errors\nidentified did not significantly differ from their first attempts. Based on\nthese insights, we offer implications for designing accessible interfaces\ntailored to the needs of blind and low-vision users in identifying object\nrecognition errors.", "arxiv_id": "2408.03303v1", "pdf_url": "http://arxiv.org/pdf/2408.03303v1", "abstract_url": "http://arxiv.org/abs/2408.03303v1", "primary_category": "cs.HC", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM ", "response": "NOT_ENOUGH_RELATED"}
{"title": "ClassiFIM: An Unsupervised Method To Detect Phase Transitions", "authors": "Victor Kasatkin, Evgeny Mozgunov, Nicholas Ezzell, Utkarsh Mishra, Itay Hen, Daniel Lidar", "abstract": "Estimation of the Fisher Information Metric (FIM-estimation) is an important\ntask that arises in unsupervised learning of phase transitions, a problem\nproposed by physicists. This work completes the definition of the task by\ndefining rigorous evaluation metrics distMSE, distMSEPS, and distRE and\nintroduces ClassiFIM, a novel machine learning method designed to solve the\nFIM-estimation task. Unlike existing methods for unsupervised learning of phase\ntransitions, ClassiFIM directly estimates a well-defined quantity (the FIM),\nallowing it to be rigorously compared to any present and future other methods\nthat estimate the same. ClassiFIM transforms a dataset for the FIM-estimation\ntask into a dataset for an auxiliary binary classification task and involves\nselecting and training a model for the latter. We prove that the output of\nClassiFIM approaches the exact FIM in the limit of infinite dataset size and\nunder certain regularity conditions. We implement ClassiFIM on multiple\ndatasets, including datasets describing classical and quantum phase\ntransitions, and find that it achieves a good ground truth approximation with\nmodest computational resources. Furthermore, we independently implement two\nalternative state-of-the-art methods for unsupervised estimation of phase\ntransition locations on the same datasets and find that ClassiFIM predicts such\nlocations at least as well as these other methods. To emphasize the generality\nof our method, we also propose and generate the MNIST-CNN dataset, which\nconsists of the output of CNNs trained on MNIST for different hyperparameter\nchoices. Using ClassiFIM on this dataset suggests there is a phase transition\nin the distribution of image-prediction pairs for CNNs trained on MNIST,\ndemonstrating the broad scope of FIM-estimation beyond physics.", "arxiv_id": "2408.03323v1", "pdf_url": "http://arxiv.org/pdf/2408.03323v1", "abstract_url": "http://arxiv.org/abs/2408.03323v1", "primary_category": "cs.LG", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM", "response": "RELEVANT"}
{"title": "ClassiFIM: An Unsupervised Method To Detect Phase Transitions", "authors": "Victor Kasatkin, Evgeny Mozgunov, Nicholas Ezzell, Utkarsh Mishra, Itay Hen, Daniel Lidar", "abstract": "Estimation of the Fisher Information Metric (FIM-estimation) is an important\ntask that arises in unsupervised learning of phase transitions, a problem\nproposed by physicists. This work completes the definition of the task by\ndefining rigorous evaluation metrics distMSE, distMSEPS, and distRE and\nintroduces ClassiFIM, a novel machine learning method designed to solve the\nFIM-estimation task. Unlike existing methods for unsupervised learning of phase\ntransitions, ClassiFIM directly estimates a well-defined quantity (the FIM),\nallowing it to be rigorously compared to any present and future other methods\nthat estimate the same. ClassiFIM transforms a dataset for the FIM-estimation\ntask into a dataset for an auxiliary binary classification task and involves\nselecting and training a model for the latter. We prove that the output of\nClassiFIM approaches the exact FIM in the limit of infinite dataset size and\nunder certain regularity conditions. We implement ClassiFIM on multiple\ndatasets, including datasets describing classical and quantum phase\ntransitions, and find that it achieves a good ground truth approximation with\nmodest computational resources. Furthermore, we independently implement two\nalternative state-of-the-art methods for unsupervised estimation of phase\ntransition locations on the same datasets and find that ClassiFIM predicts such\nlocations at least as well as these other methods. To emphasize the generality\nof our method, we also propose and generate the MNIST-CNN dataset, which\nconsists of the output of CNNs trained on MNIST for different hyperparameter\nchoices. Using ClassiFIM on this dataset suggests there is a phase transition\nin the distribution of image-prediction pairs for CNNs trained on MNIST,\ndemonstrating the broad scope of FIM-estimation beyond physics.", "arxiv_id": "2408.03323v1", "pdf_url": "http://arxiv.org/pdf/2408.03323v1", "abstract_url": "http://arxiv.org/abs/2408.03323v1", "primary_category": "cs.LG", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Accelerating Giant Impact Simulations with Machine Learning", "authors": "Caleb Lammers, Miles Cranmer, Sam Hadden, Shirley Ho, Norman Murray, Daniel Tamayo", "abstract": "Constraining planet formation models based on the observed exoplanet\npopulation requires generating large samples of synthetic planetary systems,\nwhich can be computationally prohibitive. A significant bottleneck is\nsimulating the giant impact phase, during which planetary embryos evolve\ngravitationally and combine to form planets, which may themselves experience\nlater collisions. To accelerate giant impact simulations, we present a machine\nlearning (ML) approach to predicting collisional outcomes in multiplanet\nsystems. Trained on more than 500,000 $N$-body simulations of three-planet\nsystems, we develop an ML model that can accurately predict which two planets\nwill experience a collision, along with the state of the post-collision\nplanets, from a short integration of the system's initial conditions. Our model\ngreatly improves on non-ML baselines that rely on metrics from dynamics theory,\nwhich struggle to accurately predict which pair of planets will experience a\ncollision. By combining with a model for predicting long-term stability, we\ncreate an efficient ML-based giant impact emulator, which can predict the\noutcomes of giant impact simulations with a speedup of up to four orders of\nmagnitude. We expect our model to enable analyses that would not otherwise be\ncomputationally feasible. As such, we release our full training code, along\nwith an easy-to-use API for our collision outcome model and giant impact\nemulator.", "arxiv_id": "2408.08873v1", "pdf_url": "http://arxiv.org/pdf/2408.08873v1", "abstract_url": "http://arxiv.org/abs/2408.08873v1", "primary_category": "astro-ph.EP", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Accelerating Giant Impact Simulations with Machine Learning", "response": "RELEVANT", "timestamp": "2024-08-19T13:31:21.504107"}
{"title": "PEDAL: Enhancing Greedy Decoding with Large Language Models using Diverse Exemplars", "authors": "Sumanth Prabhu", "abstract": "Self-ensembling techniques with diverse reasoning paths such as\nSelf-Consistency have demonstrated remarkable gains in accuracy for Large\nLanguage Models (LLMs). However, such techniques depend on the availability of\nan accurate answer extraction process to aggregate across multiple outputs.\nMoreover, they acquire higher inference cost, in comparison to Greedy Decoding,\ndue to generation of relatively higher number of output tokens. Research has\nshown that the free form text outputs from Self-Consistency can be aggregated\nreliably using LLMs to produce the final output. Additionally, recent\nadvancements in LLM inference have demonstrated that usage of diverse exemplars\nin prompts have the ability to induce diversity in the LLM outputs. Such proven\ntechniques can be easily extended to self-ensembling based approaches to\nachieve enhanced results in text generation. In this paper, we introduce PEDAL\n(Prompts based on Exemplar Diversity Aggregated using LLMs), a hybrid\nself-ensembling approach, that combines the strengths of diverse exemplar based\nprompts and LLM based aggregation to achieve improvement in overall\nperformance. On the publicly available SVAMP and ARC datasets, our experiments\nreveal that PEDAL can achieve better accuracy than Greedy Decoding based\nstrategies with lower inference cost compared to Self Consistency based\napproaches.", "arxiv_id": "2408.08869v1", "pdf_url": "http://arxiv.org/pdf/2408.08869v1", "abstract_url": "http://arxiv.org/abs/2408.08869v1", "primary_category": "cs.CL", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "PEDAL: Enhancing Greedy Decoding with Large Language Models using Diverse Exemplars", "response": "RELEVANT", "timestamp": "2024-08-19T13:31:22.341885"}
{"title": "A Hassle-free Algorithm for Private Learning in Practice: Don't Use Tree Aggregation, Use BLTs", "authors": "H. Brendan McMahan, Zheng Xu, Yanxiang Zhang", "abstract": "The state-of-the-art for training on-device language models for mobile\nkeyboard applications combines federated learning (FL) with differential\nprivacy (DP) via the DP-Follow-the-Regularized-Leader (DP-FTRL) algorithm. Two\nvariants of DP-FTRL are used in practice, tree aggregation and matrix\nfactorization. However, tree aggregation suffers from significantly suboptimal\nprivacy/utility tradeoffs, while matrix mechanisms require expensive\noptimization parameterized by hard-to-estimate-in-advance constants, and high\nruntime memory costs.This paper extends the recently introduced Buffered Linear\nToeplitz (BLT) mechanism to multi-participation scenarios. Our BLT-DP-FTRL\nmaintains the ease-of-use advantages of tree aggregation, while essentially\nmatching matrix factorization in terms of utility and privacy. We evaluate\nBLT-DP-FTRL on the StackOverflow dataset, serving as a re-producible simulation\nbenchmark, and across four on-device language model tasks in a production FL\nsystem. Our empirical results highlight the advantages of the BLT mechanism and\nelevate the practicality and effectiveness of DP in real-world scenarios.", "arxiv_id": "2408.08868v1", "pdf_url": "http://arxiv.org/pdf/2408.08868v1", "abstract_url": "http://arxiv.org/abs/2408.08868v1", "primary_category": "cs.LG", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "A Hassle-free Algorithm for Private Learning in Practice: Don't Use Tree Aggregation, Use BLTs", "response": "RELEVANT", "timestamp": "2024-08-19T13:31:23.070782"}
{"title": "Visual Agents as Fast and Slow Thinkers", "authors": "Guangyan Sun, Mingyu Jin, Zhenting Wang, Cheng-Long Wang, Siqi Ma, Qifan Wang, Ying Nian Wu, Yongfeng Zhang, Dongfang Liu", "abstract": "Achieving human-level intelligence requires refining cognitive distinctions\nbetween System 1 and System 2 thinking. While contemporary AI, driven by large\nlanguage models, demonstrates human-like traits, it falls short of genuine\ncognition. Transitioning from structured benchmarks to real-world scenarios\npresents challenges for visual agents, often leading to inaccurate and overly\nconfident responses. To address the challenge, we introduce FaST, which\nincorporates the Fast and Slow Thinking mechanism into visual agents. FaST\nemploys a switch adapter to dynamically select between System 1/2 modes,\ntailoring the problem-solving approach to different task complexity. It tackles\nuncertain and unseen objects by adjusting model confidence and integrating new\ncontextual data. With this novel design, we advocate a flexible system,\nhierarchical reasoning capabilities, and a transparent decision-making\npipeline, all of which contribute to its ability to emulate human-like\ncognitive processes in visual intelligence. Empirical results demonstrate that\nFaST outperforms various well-known baselines, achieving 80.8% accuracy over\nVQA^{v2} for visual question answering and 48.7% GIoU score over ReasonSeg for\nreasoning segmentation, demonstrate FaST's superior performance. Extensive\ntesting validates the efficacy and robustness of FaST's core components,\nshowcasing its potential to advance the development of cognitive visual agents\nin AI systems.", "arxiv_id": "2408.08862v1", "pdf_url": "http://arxiv.org/pdf/2408.08862v1", "abstract_url": "http://arxiv.org/abs/2408.08862v1", "primary_category": "cs.LG", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Visual Agents as Fast and Slow Thinkers", "response": "RELEVANT", "timestamp": "2024-08-19T13:31:24.040731"}
{"title": "Stochastic Bandits Robust to Adversarial Attacks", "authors": "Xuchuang Wang, Jinhang Zuo, Xutong Liu, John C. S. Lui, Mohammad Hajiesmaili", "abstract": "This paper investigates stochastic multi-armed bandit algorithms that are\nrobust to adversarial attacks, where an attacker can first observe the\nlearner's action and {then} alter their reward observation. We study two cases\nof this model, with or without the knowledge of an attack budget $C$, defined\nas an upper bound of the summation of the difference between the actual and\naltered rewards. For both cases, we devise two types of algorithms with regret\nbounds having additive or multiplicative $C$ dependence terms. For the known\nattack budget case, we prove our algorithms achieve the regret bound of\n${O}((K/\\Delta)\\log T + KC)$ and $\\tilde{O}(\\sqrt{KTC})$ for the additive and\nmultiplicative $C$ terms, respectively, where $K$ is the number of arms, $T$ is\nthe time horizon, $\\Delta$ is the gap between the expected rewards of the\noptimal arm and the second-best arm, and $\\tilde{O}$ hides the logarithmic\nfactors. For the unknown case, we prove our algorithms achieve the regret bound\nof $\\tilde{O}(\\sqrt{KT} + KC^2)$ and $\\tilde{O}(KC\\sqrt{T})$ for the additive\nand multiplicative $C$ terms, respectively. In addition to these upper bound\nresults, we provide several lower bounds showing the tightness of our bounds\nand the optimality of our algorithms. These results delineate an intrinsic\nseparation between the bandits with attacks and corruption models [Lykouris et\nal., 2018].", "arxiv_id": "2408.08859v1", "pdf_url": "http://arxiv.org/pdf/2408.08859v1", "abstract_url": "http://arxiv.org/abs/2408.08859v1", "primary_category": "cs.LG", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Stochastic Bandits Robust to Adversarial Attacks", "response": "RELEVANT", "timestamp": "2024-08-19T13:31:25.102353"}
{"title": "GeoTransformer: Enhancing Urban Forecasting with Geospatial Attention Mechanisms", "authors": "Yuhao Jia, Zile Wu, Shengao Yi, Yifei Sun", "abstract": "Recent advancements have focused on encoding urban spatial information into\nhigh-dimensional spaces, with notable efforts dedicated to integrating\nsociodemographic data and satellite imagery. These efforts have established\nfoundational models in this field. However, the effective utilization of these\nspatial representations for urban forecasting applications remains\nunder-explored. To address this gap, we introduce GeoTransformer, a novel\nstructure that synergizes the Transformer architecture with geospatial\nstatistics prior. GeoTransformer employs an innovative geospatial attention\nmechanism to incorporate extensive urban information and spatial dependencies\ninto a unified predictive model. Specifically, we compute geospatial weighted\nattention scores between the target region and surrounding regions and leverage\nthe integrated urban information for predictions. Extensive experiments on GDP\nand ride-share demand prediction tasks demonstrate that GeoTransformer\nsignificantly outperforms existing baseline models, showcasing its potential to\nenhance urban forecasting tasks.", "arxiv_id": "2408.08852v1", "pdf_url": "http://arxiv.org/pdf/2408.08852v1", "abstract_url": "http://arxiv.org/abs/2408.08852v1", "primary_category": "cs.AI", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "GeoTransformer: Enhancing Urban Forecasting with Geospatial Attention Mechanisms", "response": "RELEVANT", "timestamp": "2024-08-19T13:31:25.872205"}
{"title": "HistoGym: A Reinforcement Learning Environment for Histopathological Image Analysis", "authors": "Zhi-Bo Liu, Xiaobo Pang, Jizhao Wang, Shuai Liu, Chen Li", "abstract": "In pathological research, education, and clinical practice, the\ndecision-making process based on pathological images is critically important.\nThis significance extends to digital pathology image analysis: its adequacy is\ndemonstrated by the extensive information contained within tissue structures,\nwhich is essential for accurate cancer classification and grading.\nAdditionally, its necessity is highlighted by the inherent requirement for\ninterpretability in the conclusions generated by algorithms. For humans,\ndetermining tumor type and grade typically involves multi-scale analysis, which\npresents a significant challenge for AI algorithms. Traditional patch-based\nmethods are inadequate for modeling such complex structures, as they fail to\ncapture the intricate, multi-scale information inherent in whole slide images.\nConsequently, there is a pressing need for advanced AI techniques capable of\nefficiently and accurately replicating this complex analytical process. To\naddress this issue, we introduce HistoGym, an open-source reinforcement\nlearning environment for histopathological image analysis. Following OpenAI Gym\nAPIs, HistoGym aims to foster whole slide image diagnosis by mimicking the\nreal-life processes of doctors. Leveraging the pyramid feature of WSIs and the\nOpenSlide API, HistoGym provides a unified framework for various clinical\ntasks, including tumor detection and classification. We detail the observation,\naction, and reward specifications tailored for the histopathological image\nanalysis domain and provide an open-source Python-based interface for both\nclinicians and researchers. To accommodate different clinical demands, we offer\nvarious scenarios for different organs and cancers, including both WSI-based\nand selected region-based scenarios, showcasing several noteworthy results.", "arxiv_id": "2408.08847v1", "pdf_url": "http://arxiv.org/pdf/2408.08847v1", "abstract_url": "http://arxiv.org/abs/2408.08847v1", "primary_category": "eess.IV", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "HistoGym: A Reinforcement Learning Environment for Histopathological Image Analysis", "response": "RELEVANT", "timestamp": "2024-08-19T13:31:27.825135"}
{"title": "Shapley Marginal Surplus for Strong Models", "authors": "Daniel de Marchi, Michael Kosorok, Scott de Marchi", "abstract": "Shapley values have seen widespread use in machine learning as a way to\nexplain model predictions and estimate the importance of covariates. Accurately\nexplaining models is critical in real-world models to both aid in decision\nmaking and to infer the properties of the true data-generating process (DGP).\nIn this paper, we demonstrate that while model-based Shapley values might be\naccurate explainers of model predictions, machine learning models themselves\nare often poor explainers of the DGP even if the model is highly accurate.\nParticularly in the presence of interrelated or noisy variables, the output of\na highly predictive model may fail to account for these relationships. This\nimplies explanations of a trained model's behavior may fail to provide\nmeaningful insight into the DGP. In this paper we introduce a novel variable\nimportance algorithm, Shapley Marginal Surplus for Strong Models, that samples\nthe space of possible models to come up with an inferential measure of feature\nimportance. We compare this method to other popular feature importance methods,\nboth Shapley-based and non-Shapley based, and demonstrate significant\noutperformance in inferential capabilities relative to other methods.", "arxiv_id": "2408.08845v1", "pdf_url": "http://arxiv.org/pdf/2408.08845v1", "abstract_url": "http://arxiv.org/abs/2408.08845v1", "primary_category": "stat.ML", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Shapley Marginal Surplus for Strong Models", "response": "RELEVANT", "timestamp": "2024-08-19T13:31:28.554298"}
{"title": "Entropy Coding of Unordered Data Structures", "authors": "Julius Kunze, Daniel Severo, Giulio Zani, Jan-Willem van de Meent, James Townsend", "abstract": "We present shuffle coding, a general method for optimal compression of\nsequences of unordered objects using bits-back coding. Data structures that can\nbe compressed using shuffle coding include multisets, graphs, hypergraphs, and\nothers. We release an implementation that can easily be adapted to different\ndata types and statistical models, and demonstrate that our implementation\nachieves state-of-the-art compression rates on a range of graph datasets\nincluding molecular data.", "arxiv_id": "2408.08837v1", "pdf_url": "http://arxiv.org/pdf/2408.08837v1", "abstract_url": "http://arxiv.org/abs/2408.08837v1", "primary_category": "cs.LG", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "NOT_ENOUGH_RELATED"}
{"title": "Entropy Coding of Unordered Data Structures", "response": "NOT_ENOUGH_RELATED", "timestamp": "2024-08-19T13:31:29.403026"}
{"title": "LEVIS: Large Exact Verifiable Input Spaces for Neural Networks", "authors": "Mohamad Fares El Hajj Chehade, Brian Wesley Bell, Russell Bent, Hao Zhu, Wenting Li", "abstract": "The robustness of neural networks is paramount in safety-critical\napplications. While most current robustness verification methods assess the\nworst-case output under the assumption that the input space is known,\nidentifying a verifiable input space $\\mathcal{C}$, where no adversarial\nexamples exist, is crucial for effective model selection, robustness\nevaluation, and the development of reliable control strategies. To address this\nchallenge, we introduce a novel framework, $\\texttt{LEVIS}$, comprising\n$\\texttt{LEVIS}$-$\\alpha$ and $\\texttt{LEVIS}$-$\\beta$.\n$\\texttt{LEVIS}$-$\\alpha$ locates the largest possible verifiable ball within\nthe central region of $\\mathcal{C}$ that intersects at least two boundaries. In\ncontrast, $\\texttt{LEVIS}$-$\\beta$ integrates multiple verifiable balls to\nencapsulate the entirety of the verifiable space comprehensively. Our\ncontributions are threefold: (1) We propose $\\texttt{LEVIS}$ equipped with\nthree pioneering techniques that identify the maximum verifiable ball and the\nnearest adversarial point along collinear or orthogonal directions. (2) We\noffer a theoretical analysis elucidating the properties of the verifiable balls\nacquired through $\\texttt{LEVIS}$-$\\alpha$ and $\\texttt{LEVIS}$-$\\beta$. (3) We\nvalidate our methodology across diverse applications, including electrical\npower flow regression and image classification, showcasing performance\nenhancements and visualizations of the searching characteristics.", "arxiv_id": "2408.08824v1", "pdf_url": "http://arxiv.org/pdf/2408.08824v1", "abstract_url": "http://arxiv.org/abs/2408.08824v1", "primary_category": "cs.LG", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "LEVIS: Large Exact Verifiable Input Spaces for Neural Networks", "response": "RELEVANT", "timestamp": "2024-08-19T13:31:30.275007"}
{"title": "Optimal Symmetries in Binary Classification", "authors": "Vishal S. Ngairangbam, Michael Spannowsky", "abstract": "We explore the role of group symmetries in binary classification tasks,\npresenting a novel framework that leverages the principles of Neyman-Pearson\noptimality. Contrary to the common intuition that larger symmetry groups lead\nto improved classification performance, our findings show that selecting the\nappropriate group symmetries is crucial for optimising generalisation and\nsample efficiency. We develop a theoretical foundation for designing group\nequivariant neural networks that align the choice of symmetries with the\nunderlying probability distributions of the data. Our approach provides a\nunified methodology for improving classification accuracy across a broad range\nof applications by carefully tailoring the symmetry group to the specific\ncharacteristics of the problem. Theoretical analysis and experimental results\ndemonstrate that optimal classification performance is not always associated\nwith the largest equivariant groups possible in the domain, even when the\nlikelihood ratio is invariant under one of its proper subgroups, but rather\nwith those subgroups themselves. This work offers insights and practical\nguidelines for constructing more effective group equivariant architectures in\ndiverse machine-learning contexts.", "arxiv_id": "2408.08823v1", "pdf_url": "http://arxiv.org/pdf/2408.08823v1", "abstract_url": "http://arxiv.org/abs/2408.08823v1", "primary_category": "cs.LG", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Optimal Symmetries in Binary Classification", "response": "RELEVANT", "timestamp": "2024-08-19T13:31:31.433668"}
{"title": "An Empirical Examination of Balancing Strategy for Counterfactual Estimation on Time Series", "authors": "Qiang Huang, Chuizheng Meng, Defu Cao, Biwei Huang, Yi Chang, Yan Liu", "abstract": "Counterfactual estimation from observations represents a critical endeavor in\nnumerous application fields, such as healthcare and finance, with the primary\nchallenge being the mitigation of treatment bias. The balancing strategy aimed\nat reducing covariate disparities between different treatment groups serves as\na universal solution. However, when it comes to the time series data, the\neffectiveness of balancing strategies remains an open question, with a thorough\nanalysis of the robustness and applicability of balancing strategies still\nlacking. This paper revisits counterfactual estimation in the temporal setting\nand provides a brief overview of recent advancements in balancing strategies.\nMore importantly, we conduct a critical empirical examination for the\neffectiveness of the balancing strategies within the realm of temporal\ncounterfactual estimation in various settings on multiple datasets. Our\nfindings could be of significant interest to researchers and practitioners and\ncall for a reexamination of the balancing strategy in time series settings.", "arxiv_id": "2408.08815v1", "pdf_url": "http://arxiv.org/pdf/2408.08815v1", "abstract_url": "http://arxiv.org/abs/2408.08815v1", "primary_category": "cs.LG", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "An Empirical Examination of Balancing Strategy for Counterfactual Estimation on Time Series", "response": "RELEVANT", "timestamp": "2024-08-19T13:31:32.318316"}
{"title": "CAT: Caution Aware Transfer in Reinforcement Learning via Distributional Risk", "authors": "Mohamad Fares El Hajj Chehade, Amrit Singh Bedi, Amy Zhang, Hao Zhu", "abstract": "Transfer learning in reinforcement learning (RL) has become a pivotal\nstrategy for improving data efficiency in new, unseen tasks by utilizing\nknowledge from previously learned tasks. This approach is especially beneficial\nin real-world deployment scenarios where computational resources are\nconstrained and agents must adapt rapidly to novel environments. However,\ncurrent state-of-the-art methods often fall short in ensuring safety during the\ntransfer process, particularly when unforeseen risks emerge in the deployment\nphase. In this work, we address these limitations by introducing a novel\nCaution-Aware Transfer Learning (CAT) framework. Unlike traditional approaches\nthat limit risk considerations to mean-variance, we define \"caution\" as a more\ngeneralized and comprehensive notion of risk. Our core innovation lies in\noptimizing a weighted sum of reward return and caution-based on state-action\noccupancy measures-during the transfer process, allowing for a rich\nrepresentation of diverse risk factors. To the best of our knowledge, this is\nthe first work to explore the optimization of such a generalized risk notion\nwithin the context of transfer RL. Our contributions are threefold: (1) We\npropose a Caution-Aware Transfer (CAT) framework that evaluates source policies\nwithin the test environment and constructs a new policy that balances reward\nmaximization and caution. (2) We derive theoretical sub-optimality bounds for\nour method, providing rigorous guarantees of its efficacy. (3) We empirically\nvalidate CAT, demonstrating that it consistently outperforms existing methods\nby delivering safer policies under varying risk conditions in the test tasks.", "arxiv_id": "2408.08812v1", "pdf_url": "http://arxiv.org/pdf/2408.08812v1", "abstract_url": "http://arxiv.org/abs/2408.08812v1", "primary_category": "cs.LG", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "CAT: Caution Aware Transfer in Reinforcement Learning via Distributional Risk", "response": "RELEVANT", "timestamp": "2024-08-19T13:31:33.446282"}
{"title": "Constructing Domain-Specific Evaluation Sets for LLM-as-a-judge", "authors": "Ravi Raju, Swayambhoo Jain, Bo Li, Jonathan Li, Urmish Thakkar", "abstract": "Large Language Models (LLMs) have revolutionized the landscape of machine\nlearning, yet current benchmarks often fall short in capturing the diverse\nbehavior of these models in real-world applications. A benchmark's usefulness\nis determined by its ability to clearly differentiate between models of varying\ncapabilities (separability) and closely align with human preferences. Existing\nframeworks like Alpaca-Eval 2.0 LC\n\\cite{dubois2024lengthcontrolledalpacaevalsimpleway} and Arena-Hard v0.1\n\\cite{li2024crowdsourced} are limited by their focus on general-purpose queries\nand lack of diversity across domains such as law, medicine, and multilingual\ncontexts. In this paper, we address these limitations by introducing a novel\ndata pipeline that curates diverse, domain-specific evaluation sets tailored\nfor LLM-as-a-Judge frameworks. Our approach leverages a combination of manual\ncuration, semi-supervised learning to generate clusters, and stratified\nsampling to ensure balanced representation across a wide range of domains and\nlanguages. The resulting evaluation set, which includes 1573 samples across 14\ncategories, demonstrates high separability (84\\%) across ten top-ranked models,\nand agreement (84\\%) with Chatbot Arena and (0.915) Spearman correlation. The\nagreement values are 9\\% better than Arena Hard and 20\\% better than AlpacaEval\n2.0 LC, while the Spearman coefficient is 0.7 more than the next best\nbenchmark, showcasing a significant improvement in the usefulness of the\nbenchmark. We further provide an open-source evaluation tool that enables\nfine-grained analysis of model performance across user-defined categories,\noffering valuable insights for practitioners. This work contributes to the\nongoing effort to enhance the transparency, diversity, and effectiveness of LLM\nevaluation methodologies.", "arxiv_id": "2408.08808v1", "pdf_url": "http://arxiv.org/pdf/2408.08808v1", "abstract_url": "http://arxiv.org/abs/2408.08808v1", "primary_category": "cs.LG", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Constructing Domain-Specific Evaluation Sets for LLM-as-a-judge", "response": "RELEVANT", "timestamp": "2024-08-19T13:31:34.255084"}
{"title": "Representation Learning of Geometric Trees", "authors": "Zheng Zhang, Allen Zhang, Ruth Nelson, Giorgio Ascoli, Liang Zhao", "abstract": "Geometric trees are characterized by their tree-structured layout and\nspatially constrained nodes and edges, which significantly impacts their\ntopological attributes. This inherent hierarchical structure plays a crucial\nrole in domains such as neuron morphology and river geomorphology, but\ntraditional graph representation methods often overlook these specific\ncharacteristics of tree structures. To address this, we introduce a new\nrepresentation learning framework tailored for geometric trees. It first\nfeatures a unique message passing neural network, which is both provably\ngeometrical structure-recoverable and rotation-translation invariant. To\naddress the data label scarcity issue, our approach also includes two\ninnovative training targets that reflect the hierarchical ordering and\ngeometric structure of these geometric trees. This enables fully\nself-supervised learning without explicit labels. We validate our method's\neffectiveness on eight real-world datasets, demonstrating its capability to\nrepresent geometric trees.", "arxiv_id": "2408.08799v1", "pdf_url": "http://arxiv.org/pdf/2408.08799v1", "abstract_url": "http://arxiv.org/abs/2408.08799v1", "primary_category": "cs.LG", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Representation Learning of Geometric Trees", "response": "RELEVANT", "timestamp": "2024-08-19T13:31:35.114918"}
{"title": "Neighbor Overlay-Induced Graph Attention Network", "authors": "Tiqiao Wei, Ye Yuan", "abstract": "Graph neural networks (GNNs) have garnered significant attention due to their\nability to represent graph data. Among various GNN variants, graph attention\nnetwork (GAT) stands out since it is able to dynamically learn the importance\nof different nodes. However, present GATs heavily rely on the smoothed node\nfeatures to obtain the attention coefficients rather than graph structural\ninformation, which fails to provide crucial contextual cues for node\nrepresentations. To address this issue, this study proposes a neighbor\noverlay-induced graph attention network (NO-GAT) with the following two-fold\nideas: a) learning favorable structural information, i.e., overlaid neighbors,\noutside the node feature propagation process from an adjacency matrix; b)\ninjecting the information of overlaid neighbors into the node feature\npropagation process to compute the attention coefficient jointly. Empirical\nstudies on graph benchmark datasets indicate that the proposed NO-GAT\nconsistently outperforms state-of-the-art models.", "arxiv_id": "2408.08788v1", "pdf_url": "http://arxiv.org/pdf/2408.08788v1", "abstract_url": "http://arxiv.org/abs/2408.08788v1", "primary_category": "cs.LG", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Neighbor Overlay-Induced Graph Attention Network", "response": "RELEVANT", "timestamp": "2024-08-19T13:31:35.905374"}
{"title": "A Transparency Paradox? Investigating the Impact of Explanation Specificity and Autonomous Vehicle Perceptual Inaccuracies on Passengers", "authors": "Daniel Omeiza, Raunak Bhattacharyya, Marina Jirotka, Nick Hawes, Lars Kunze", "abstract": "Transparency in automated systems could be afforded through the provision of\nintelligible explanations. While transparency is desirable, might it lead to\ncatastrophic outcomes (such as anxiety), that could outweigh its benefits? It's\nquite unclear how the specificity of explanations (level of transparency)\ninfluences recipients, especially in autonomous driving (AD). In this work, we\nexamined the effects of transparency mediated through varying levels of\nexplanation specificity in AD. We first extended a data-driven explainer model\nby adding a rule-based option for explanation generation in AD, and then\nconducted a within-subject lab study with 39 participants in an immersive\ndriving simulator to study the effect of the resulting explanations.\nSpecifically, our investigation focused on: (1) how different types of\nexplanations (specific vs. abstract) affect passengers' perceived safety,\nanxiety, and willingness to take control of the vehicle when the vehicle\nperception system makes erroneous predictions; and (2) the relationship between\npassengers' behavioural cues and their feelings during the autonomous drives.\nOur findings showed that passengers felt safer with specific explanations when\nthe vehicle's perception system had minimal errors, while abstract explanations\nthat hid perception errors led to lower feelings of safety. Anxiety levels\nincreased when specific explanations revealed perception system errors (high\ntransparency). We found no significant link between passengers' visual patterns\nand their anxiety levels. Our study suggests that passengers prefer clear and\nspecific explanations (high transparency) when they originate from autonomous\nvehicles (AVs) with optimal perceptual accuracy.", "arxiv_id": "2408.08785v1", "pdf_url": "http://arxiv.org/pdf/2408.08785v1", "abstract_url": "http://arxiv.org/abs/2408.08785v1", "primary_category": "cs.HC", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "A Transparency Paradox? Investigating the Impact of Explanation Specificity and Autonomous Vehicle Perceptual Inaccuracies on Passengers", "response": "RELEVANT", "timestamp": "2024-08-19T13:31:36.871873"}
{"title": "NEAR: A Training-Free Pre-Estimator of Machine Learning Model Performance", "authors": "Raphael T. Husistein, Markus Reiher, Marco Eckhoff", "abstract": "Artificial neural networks have been shown to be state-of-the-art machine\nlearning models in a wide variety of applications, including natural language\nprocessing and image recognition. However, building a performant neural network\nis a laborious task and requires substantial computing power. Neural\nArchitecture Search (NAS) addresses this issue by an automatic selection of the\noptimal network from a set of potential candidates. While many NAS methods\nstill require training of (some) neural networks, zero-cost proxies promise to\nidentify the optimal network without training. In this work, we propose the\nzero-cost proxy Network Expressivity by Activation Rank (NEAR). It is based on\nthe effective rank of the pre- and post-activation matrix, i.e., the values of\na neural network layer before and after applying its activation function. We\ndemonstrate the cutting-edge correlation between this network score and the\nmodel accuracy on NAS-Bench-101 and NATS-Bench-SSS/TSS. In addition, we present\na simple approach to estimate the optimal layer sizes in multi-layer\nperceptrons. Furthermore, we show that this score can be utilized to select\nhyperparameters such as the activation function and the neural network weight\ninitialization scheme.", "arxiv_id": "2408.08776v1", "pdf_url": "http://arxiv.org/pdf/2408.08776v1", "abstract_url": "http://arxiv.org/abs/2408.08776v1", "primary_category": "cs.LG", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "NEAR: A Training-Free Pre-Estimator of Machine Learning Model Performance", "response": "RELEVANT", "timestamp": "2024-08-19T13:31:37.965656"}
{"title": "Speckle Noise Analysis for Synthetic Aperture Radar (SAR) Space Data", "authors": "Sanjjushri Varshini R, Rohith Mahadevan, Bagiya Lakshmi S, Mathivanan Periasamy, Raja CSP Raman, Lokesh M", "abstract": "This research tackles the challenge of speckle noise in Synthetic Aperture\nRadar (SAR) space data, a prevalent issue that hampers the clarity and utility\nof SAR images. The study presents a comparative analysis of six distinct\nspeckle noise reduction techniques: Lee Filtering, Frost Filtering, Kuan\nFiltering, Gaussian Filtering, Median Filtering, and Bilateral Filtering. These\nmethods, selected for their unique approaches to noise reduction and image\npreservation, were applied to SAR datasets sourced from the Alaska Satellite\nFacility (ASF). The performance of each technique was evaluated using a\ncomprehensive set of metrics, including Peak Signal-to-Noise Ratio (PSNR), Mean\nSquared Error (MSE), Structural Similarity Index (SSIM), Equivalent Number of\nLooks (ENL), and Speckle Suppression Index (SSI). The study concludes that both\nthe Lee and Kuan Filters are effective, with the choice of filter depending on\nthe specific application requirements for image quality and noise suppression.\nThis work provides valuable insights into optimizing SAR image processing, with\nsignificant implications for remote sensing, environmental monitoring, and\ngeological surveying.", "arxiv_id": "2408.08774v1", "pdf_url": "http://arxiv.org/pdf/2408.08774v1", "abstract_url": "http://arxiv.org/abs/2408.08774v1", "primary_category": "cs.LG", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Speckle Noise Analysis for Synthetic Aperture Radar (SAR) Space Data", "response": "RELEVANT", "timestamp": "2024-08-19T13:31:38.774446"}
{"title": "Pessimistic Iterative Planning for Robust POMDPs", "authors": "Maris F. L. Galesloot, Marnix Suilen, Thiago D. Sim\u00e3o, Steven Carr, Matthijs T. J. Spaan, Ufuk Topcu, Nils Jansen", "abstract": "Robust partially observable Markov decision processes (robust POMDPs) extend\nclassical POMDPs to handle additional uncertainty on the transition and\nobservation probabilities via so-called uncertainty sets. Policies for robust\nPOMDPs must not only be memory-based to account for partial observability but\nalso robust against model uncertainty to account for the worst-case instances\nfrom the uncertainty sets. We propose the pessimistic iterative planning (PIP)\nframework, which finds robust memory-based policies for robust POMDPs. PIP\nalternates between two main steps: (1) selecting an adversarial (non-robust)\nPOMDP via worst-case probability instances from the uncertainty sets; and (2)\ncomputing a finite-state controller (FSC) for this adversarial POMDP. We\nevaluate the performance of this FSC on the original robust POMDP and use this\nevaluation in step (1) to select the next adversarial POMDP. Within PIP, we\npropose the rFSCNet algorithm. In each iteration, rFSCNet finds an FSC through\na recurrent neural network trained using supervision policies optimized for the\nadversarial POMDP. The empirical evaluation in four benchmark environments\nshowcases improved robustness against a baseline method in an ablation study\nand competitive performance compared to a state-of-the-art robust POMDP solver.", "arxiv_id": "2408.08770v1", "pdf_url": "http://arxiv.org/pdf/2408.08770v1", "abstract_url": "http://arxiv.org/abs/2408.08770v1", "primary_category": "cs.AI", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Pessimistic Iterative Planning for Robust POMDPs", "response": "RELEVANT", "timestamp": "2024-08-19T13:31:40.000561"}
{"title": "SYMPOL: Symbolic Tree-Based On-Policy Reinforcement Learning", "authors": "Sascha Marton, Tim Grams, Florian Vogt, Stefan L\u00fcdtke, Christian Bartelt, Heiner Stuckenschmidt", "abstract": "Reinforcement learning (RL) has seen significant success across various\ndomains, but its adoption is often limited by the black-box nature of neural\nnetwork policies, making them difficult to interpret. In contrast, symbolic\npolicies allow representing decision-making strategies in a compact and\ninterpretable way. However, learning symbolic policies directly within\non-policy methods remains challenging. In this paper, we introduce SYMPOL, a\nnovel method for SYMbolic tree-based on-POLicy RL. SYMPOL employs a tree-based\nmodel integrated with a policy gradient method, enabling the agent to learn and\nadapt its actions while maintaining a high level of interpretability. We\nevaluate SYMPOL on a set of benchmark RL tasks, demonstrating its superiority\nover alternative tree-based RL approaches in terms of performance and\ninterpretability. To the best of our knowledge, this is the first method, that\nallows a gradient-based end-to-end learning of interpretable, axis-aligned\ndecision trees on-policy. Therefore, SYMPOL can become the foundation for a new\nclass of interpretable RL based on decision trees. Our implementation is\navailable under: https://github.com/s-marton/SYMPOL", "arxiv_id": "2408.08761v1", "pdf_url": "http://arxiv.org/pdf/2408.08761v1", "abstract_url": "http://arxiv.org/abs/2408.08761v1", "primary_category": "cs.LG", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "SYMPOL: Symbolic Tree-Based On-Policy Reinforcement Learning", "response": "RELEVANT", "timestamp": "2024-08-19T13:31:40.824204"}
{"title": "SE-SGformer: A Self-Explainable Signed Graph Transformer for Link Sign Prediction", "authors": "Lu Li, Jiale Liu, Xingyu Ji, Maojun Wang, Zeyu Zhang", "abstract": "Signed Graph Neural Networks (SGNNs) have been shown to be effective in\nanalyzing complex patterns in real-world situations where positive and negative\nlinks coexist. However, SGNN models suffer from poor explainability, which\nlimit their adoptions in critical scenarios that require understanding the\nrationale behind predictions. To the best of our knowledge, there is currently\nno research work on the explainability of the SGNN models. Our goal is to\naddress the explainability of decision-making for the downstream task of link\nsign prediction specific to signed graph neural networks. Since post-hoc\nexplanations are not derived directly from the models, they may be biased and\nmisrepresent the true explanations. Therefore, in this paper we introduce a\nSelf-Explainable Signed Graph transformer (SE-SGformer) framework, which can\nnot only outputs explainable information while ensuring high prediction\naccuracy. Specifically, We propose a new Transformer architecture for signed\ngraphs and theoretically demonstrate that using positional encoding based on\nsigned random walks has greater expressive power than current SGNN methods and\nother positional encoding graph Transformer-based approaches. We constructs a\nnovel explainable decision process by discovering the $K$-nearest (farthest)\npositive (negative) neighbors of a node to replace the neural network-based\ndecoder for predicting edge signs. These $K$ positive (negative) neighbors\nrepresent crucial information about the formation of positive (negative) edges\nbetween nodes and thus can serve as important explanatory information in the\ndecision-making process. We conducted experiments on several real-world\ndatasets to validate the effectiveness of SE-SGformer, which outperforms the\nstate-of-the-art methods by improving 2.2\\% prediction accuracy and 73.1\\%\nexplainablity accuracy in the best-case scenario.", "arxiv_id": "2408.08754v1", "pdf_url": "http://arxiv.org/pdf/2408.08754v1", "abstract_url": "http://arxiv.org/abs/2408.08754v1", "primary_category": "cs.LG", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "SE-SGformer: A Self-Explainable Signed Graph Transformer for Link Sign Prediction", "response": "RELEVANT", "timestamp": "2024-08-19T13:31:41.548618"}
{"title": "ML Study of MaliciousTransactions in Ethereum", "authors": "Natan Katz", "abstract": "Smart contracts are a major tool in Ethereum transactions. Therefore hackers\ncan exploit them by adding code vulnerabilities to their sources and using\nthese vulnerabilities for performing malicious transactions. This paper\npresents two successful approaches for detecting malicious contracts: one uses\nopcode and relies on GPT2 and the other uses the Solidity source and a LORA\nfine-tuned CodeLlama. Finally, we present an XGBOOST model that combines gas\nproperties and Hexa-decimal signatures for detecting malicious transactions.\nThis approach relies on early assumptions that maliciousness is manifested by\nthe uncommon usage of the contracts' functions and the effort to pursue the\ntransaction.", "arxiv_id": "2408.08749v1", "pdf_url": "http://arxiv.org/pdf/2408.08749v1", "abstract_url": "http://arxiv.org/abs/2408.08749v1", "primary_category": "cs.CR", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "ML Study of MaliciousTransactions in Ethereum", "response": "RELEVANT", "timestamp": "2024-08-19T13:31:42.309427"}
{"title": "Beyond KAN: Introducing KarSein for Adaptive High-Order Feature Interaction Modeling in CTR Prediction", "authors": "Yunxiao Shi, Wujiang Wu, Mingyu Jin, Haimin Zhang, Qiang Wu, Yongfeng Zhang, Min Xu", "abstract": "Modeling feature interactions is crucial for click-through rate (CTR)\nprediction, particularly when it comes to high-order explicit interactions.\nTraditional methods struggle with this task because they often predefine a\nmaximum interaction order, which relies heavily on prior knowledge and can\nlimit the model's effectiveness. Additionally, modeling high-order interactions\ntypically leads to increased computational costs. Therefore, the challenge lies\nin adaptively modeling high-order feature interactions while maintaining\nefficiency. To address this issue, we introduce Kolmogorov-Arnold Represented\nSparse Efficient Interaction Network (KarSein), designed to optimize both\npredictive accuracy and computational efficiency. We firstly identify\nlimitations of directly applying Kolmogorov-Arnold Networks (KAN) to CTR and\nthen introduce KarSein to overcome these issues. It features a novel\narchitecture that reduces the computational costs of KAN and supports embedding\nvectors as feature inputs. Additionally, KarSein employs guided symbolic\nregression to address the challenge of KAN in spontaneously learning\nmultiplicative relationships. Extensive experiments demonstrate KarSein's\nsuperior performance, achieving significant predictive accuracy with minimal\ncomputational overhead. Furthermore, KarSein maintains strong global\nexplainability while enabling the removal of redundant features, resulting in a\nsparse network structure. These advantages also position KarSein as a promising\nmethod for efficient inference.", "arxiv_id": "2408.08713v1", "pdf_url": "http://arxiv.org/pdf/2408.08713v1", "abstract_url": "http://arxiv.org/abs/2408.08713v1", "primary_category": "cs.LG", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Beyond KAN: Introducing KarSein for Adaptive High-Order Feature Interaction Modeling in CTR Prediction", "response": "RELEVANT", "timestamp": "2024-08-19T13:31:43.283410"}
{"title": "Beam Prediction based on Large Language Models", "authors": "Yucheng Sheng, Kai Huang, Le Liang, Peng Liu, Shi Jin, Geoffrey Ye Li", "abstract": "Millimeter-wave (mmWave) communication is promising for next-generation\nwireless networks but suffers from significant path loss, requiring extensive\nantenna arrays and frequent beam training. Traditional deep learning models,\nsuch as long short-term memory (LSTM), enhance beam tracking accuracy however\nare limited by poor robustness and generalization. In this letter, we use large\nlanguage models (LLMs) to improve the robustness of beam prediction. By\nconverting time series data into text-based representations and employing the\nPrompt-as-Prefix (PaP) technique for contextual enrichment, our approach\nunleashes the strength of LLMs for time series forecasting. Simulation results\ndemonstrate that our LLM-based method offers superior robustness and\ngeneralization compared to LSTM-based models, showcasing the potential of LLMs\nin wireless communications.", "arxiv_id": "2408.08707v1", "pdf_url": "http://arxiv.org/pdf/2408.08707v1", "abstract_url": "http://arxiv.org/abs/2408.08707v1", "primary_category": "cs.LG", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Beam Prediction based on Large Language Models", "response": "RELEVANT", "timestamp": "2024-08-19T13:31:44.196978"}
{"title": "Efficient Multi-Policy Evaluation for Reinforcement Learning", "authors": "Shuze Liu, Yuxin Chen, Shangtong Zhang", "abstract": "To unbiasedly evaluate multiple target policies, the dominant approach among\nRL practitioners is to run and evaluate each target policy separately. However,\nthis evaluation method is far from efficient because samples are not shared\nacross policies, and running target policies to evaluate themselves is actually\nnot optimal. In this paper, we address these two weaknesses by designing a\ntailored behavior policy to reduce the variance of estimators across all target\npolicies. Theoretically, we prove that executing this behavior policy with\nmanyfold fewer samples outperforms on-policy evaluation on every target policy\nunder characterized conditions. Empirically, we show our estimator has a\nsubstantially lower variance compared with previous best methods and achieves\nstate-of-the-art performance in a broad range of environments.", "arxiv_id": "2408.08706v1", "pdf_url": "http://arxiv.org/pdf/2408.08706v1", "abstract_url": "http://arxiv.org/abs/2408.08706v1", "primary_category": "cs.LG", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Efficient Multi-Policy Evaluation for Reinforcement Learning", "response": "RELEVANT", "timestamp": "2024-08-19T13:31:44.919158"}
{"title": "RBLA: Rank-Based-LoRA-Aggregation for Fine-tuning Heterogeneous Models in FLaaS", "authors": "Shuaijun Chen, Omid Tavallaie, Niousha Nazemi, Albert Y. Zomaya", "abstract": "Federated Learning (FL) is a promising privacy-aware distributed learning\nframework that can be deployed on various devices, such as mobile phones,\ndesktops, and devices equipped with CPUs or GPUs. In the context of\nserver-based Federated Learning as a Service (FLaas), FL enables the central\nserver to coordinate the training process across multiple devices without\ndirect access to the local data, thereby enhancing privacy and data security.\nLow-Rank Adaptation (LoRA) is a method that fine-tunes models efficiently by\nfocusing on a low-dimensional subspace of the model's parameters. This approach\nsignificantly reduces computational and memory costs compared to fine-tuning\nall parameters from scratch. When integrated with FL, especially in a FLaas\nenvironment, LoRA allows for flexible and efficient deployment across diverse\nhardware with varying computational capabilities by adjusting the local model's\nrank. However, in LoRA-enabled FL, different clients may train models with\nvarying ranks, which poses a challenge for model aggregation on the server.\nCurrent methods of aggregating models of different ranks require padding\nweights to a uniform shape, which can degrade the global model's performance.\nTo address this issue, we propose Rank-Based LoRA Aggregation (RBLA), a novel\nmodel aggregation method designed for heterogeneous LoRA structures. RBLA\npreserves key features across models with different ranks. This paper analyzes\nthe issues with current padding methods that reshape models for aggregation in\na FLaas environment. Then, we introduce RBLA, a rank-based aggregation method\nthat maintains both low-rank and high-rank features. Finally, we demonstrate\nthe effectiveness of RBLA through comparative experiments with state-of-the-art\nmethods.", "arxiv_id": "2408.08699v1", "pdf_url": "http://arxiv.org/pdf/2408.08699v1", "abstract_url": "http://arxiv.org/abs/2408.08699v1", "primary_category": "cs.LG", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "RBLA: Rank-Based-LoRA-Aggregation for Fine-tuning Heterogeneous Models in FLaaS", "response": "RELEVANT", "timestamp": "2024-08-19T13:31:45.935030"}
{"title": "Turning Trash into Treasure: Accelerating Inference of Large Language Models with Token Recycling", "authors": "Xianzhen Luo, Yixuan Wang, Qingfu Zhu, Zhiming Zhang, Xuanyu Zhang, Qing Yang, Dongliang Xu, Wanxiang Che", "abstract": "The rapid growth in the parameters of large language models (LLMs) has made\ninference latency a fundamental bottleneck, limiting broader application of\nLLMs. Speculative decoding represents a lossless approach to accelerate\ninference through a guess-and-verify paradigm, leveraging the parallel\ncapabilities of modern hardware. Some speculative decoding methods rely on\nadditional structures to guess draft tokens, such as small models or\nparameter-efficient architectures, which need extra training before use.\nAlternatively, retrieval-based train-free techniques build libraries from\npre-existing corpora or by n-gram generation. However, they face challenges\nlike large storage requirements, time-consuming retrieval, and limited\nadaptability. Observing that candidate tokens generated during the decoding\nprocess are likely to reoccur in future sequences, we propose Token Recycling.\nThis approach stores candidate tokens in an adjacency matrix and employs a\nbreadth-first search (BFS)-like algorithm on the matrix to construct a draft\ntree. The tree is then validated through tree attention. New candidate tokens\nfrom the decoding process are then used to update the matrix. Token Recycling\nrequires \\textless2MB of additional storage and achieves approximately 2x\nspeedup across all sizes of LLMs. It significantly outperforms existing\ntrain-free methods by 30\\% and even a training method by 25\\%. It can be\ndirectly applied to any existing LLMs and tasks without the need for\nadaptation.", "arxiv_id": "2408.08696v1", "pdf_url": "http://arxiv.org/pdf/2408.08696v1", "abstract_url": "http://arxiv.org/abs/2408.08696v1", "primary_category": "cs.CL", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Turning Trash into Treasure: Accelerating Inference of Large Language Models with Token Recycling", "response": "RELEVANT", "timestamp": "2024-08-19T13:31:46.861341"}
{"title": "Explore-then-Commit Algorithms for Decentralized Two-Sided Matching Markets", "authors": "Tejas Pagare, Avishek Ghosh", "abstract": "Online learning in a decentralized two-sided matching markets, where the\ndemand-side (players) compete to match with the supply-side (arms), has\nreceived substantial interest because it abstracts out the complex interactions\nin matching platforms (e.g. UpWork, TaskRabbit). However, past works assume\nthat each arm knows their preference ranking over the players (one-sided\nlearning), and each player aim to learn the preference over arms through\nsuccessive interactions. Moreover, several (impractical) assumptions on the\nproblem are usually made for theoretical tractability such as broadcast\nplayer-arm match Liu et al. (2020; 2021); Kong & Li (2023) or serial\ndictatorship Sankararaman et al. (2021); Basu et al. (2021); Ghosh et al.\n(2022). In this paper, we study a decentralized two-sided matching market,\nwhere we do not assume that the preference ranking over players are known to\nthe arms apriori. Furthermore, we do not have any structural assumptions on the\nproblem. We propose a multi-phase explore-then-commit type algorithm namely\nepoch-based CA-ETC (collision avoidance explore then commit) (\\texttt{CA-ETC}\nin short) for this problem that does not require any communication across\nagents (players and arms) and hence decentralized. We show that for the initial\nepoch length of $T_{\\circ}$ and subsequent epoch-lengths of $2^{l/\\gamma}\nT_{\\circ}$ (for the $l-$th epoch with $\\gamma \\in (0,1)$ as an input parameter\nto the algorithm), \\texttt{CA-ETC} yields a player optimal expected regret of\n$\\mathcal{O}\\left(T_{\\circ} (\\frac{K \\log T}{T_{\\circ} \\Delta^2})^{1/\\gamma} +\nT_{\\circ} (\\frac{T}{T_{\\circ}})^\\gamma\\right)$ for the $i$-th player, where $T$\nis the learning horizon, $K$ is the number of arms and $\\Delta$ is an\nappropriately defined problem gap. Furthermore, we propose a blackboard\ncommunication based baseline achieving logarithmic regret in $T$.", "arxiv_id": "2408.08690v1", "pdf_url": "http://arxiv.org/pdf/2408.08690v1", "abstract_url": "http://arxiv.org/abs/2408.08690v1", "primary_category": "cs.LG", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Explore-then-Commit Algorithms for Decentralized Two-Sided Matching Markets", "response": "RELEVANT", "timestamp": "2024-08-19T13:31:48.072179"}
{"title": "Can Large Language Models Improve the Adversarial Robustness of Graph Neural Networks?", "authors": "Zhongjian Zhang, Xiao Wang, Huichi Zhou, Yue Yu, Mengmei Zhang, Cheng Yang, Chuan Shi", "abstract": "Graph neural networks (GNNs) are vulnerable to adversarial perturbations,\nespecially for topology attacks, and many methods that improve the robustness\nof GNNs have received considerable attention. Recently, we have witnessed the\nsignificant success of large language models (LLMs), leading many to explore\nthe great potential of LLMs on GNNs. However, they mainly focus on improving\nthe performance of GNNs by utilizing LLMs to enhance the node features.\nTherefore, we ask: Will the robustness of GNNs also be enhanced with the\npowerful understanding and inference capabilities of LLMs? By presenting the\nempirical results, we find that despite that LLMs can improve the robustness of\nGNNs, there is still an average decrease of 23.1% in accuracy, implying that\nthe GNNs remain extremely vulnerable against topology attack. Therefore,\nanother question is how to extend the capabilities of LLMs on graph adversarial\nrobustness. In this paper, we propose an LLM-based robust graph structure\ninference framework, LLM4RGNN, which distills the inference capabilities of\nGPT-4 into a local LLM for identifying malicious edges and an LM-based edge\npredictor for finding missing important edges, so as to recover a robust graph\nstructure. Extensive experiments demonstrate that LLM4RGNN consistently\nimproves the robustness across various GNNs. Even in some cases where the\nperturbation ratio increases to 40%, the accuracy of GNNs is still better than\nthat on the clean graph.", "arxiv_id": "2408.08685v1", "pdf_url": "http://arxiv.org/pdf/2408.08685v1", "abstract_url": "http://arxiv.org/abs/2408.08685v1", "primary_category": "cs.LG", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Can Large Language Models Improve the Adversarial Robustness of Graph Neural Networks?", "response": "RELEVANT", "timestamp": "2024-08-19T13:31:49.161076"}
{"title": "Research on Personalized Compression Algorithm for Pre-trained Models Based on Homomorphic Entropy Increase", "authors": "Yicong Li, Xing Guo, Haohua Du", "abstract": "In this article, we explore the challenges and evolution of two key\ntechnologies in the current field of AI: Vision Transformer model and Large\nLanguage Model (LLM). Vision Transformer captures global information by\nsplitting images into small pieces and leveraging Transformer's multi-head\nattention mechanism, but its high reference count and compute overhead limit\ndeployment on mobile devices. At the same time, the rapid development of LLM\nhas revolutionized natural language processing, but it also faces huge\ndeployment challenges. To address these issues, we investigate model pruning\ntechniques, with a particular focus on how to reduce redundant parameters\nwithout losing accuracy to accommodate personalized data and\nresource-constrained environments. In this paper, a new layered pruning\nstrategy is proposed to distinguish the personalized layer from the common\nlayer by compressed sensing and random sampling, thus significantly reducing\nthe model parameters. Our experimental results show that the introduced step\nbuffering mechanism further improves the accuracy of the model after pruning,\nproviding new directions and possibilities for the deployment of efficient and\npersonalized AI models on mobile devices in the future.", "arxiv_id": "2408.08684v1", "pdf_url": "http://arxiv.org/pdf/2408.08684v1", "abstract_url": "http://arxiv.org/abs/2408.08684v1", "primary_category": "cs.LG", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Research on Personalized Compression Algorithm for Pre-trained Models Based on Homomorphic Entropy Increase", "response": "RELEVANT", "timestamp": "2024-08-19T13:31:49.904568"}
{"title": "A Mean Field Ansatz for Zero-Shot Weight Transfer", "authors": "Xingyuan Chen, Wenwei Kuang, Lei Deng, Wei Han, Bo Bai, Goncalo dos Reis", "abstract": "The pre-training cost of large language models (LLMs) is prohibitive. One\ncutting-edge approach to reduce the cost is zero-shot weight transfer, also\nknown as model growth for some cases, which magically transfers the weights\ntrained in a small model to a large model. However, there are still some\ntheoretical mysteries behind the weight transfer. In this paper, inspired by\nprior applications of mean field theory to neural network dynamics, we\nintroduce a mean field ansatz to provide a theoretical explanation for weight\ntransfer. Specifically, we propose the row-column (RC) ansatz under the mean\nfield point of view, which describes the measure structure of the weights in\nthe neural network (NN) and admits a close measure dynamic. Thus, the weights\nof different sizes NN admit a common distribution under proper assumptions, and\nweight transfer methods can be viewed as sampling methods. We empirically\nvalidate the RC ansatz by exploring simple MLP examples and LLMs such as GPT-3\nand Llama-3.1. We show the mean-field point of view is adequate under suitable\nassumptions which can provide theoretical support for zero-shot weight\ntransfer.", "arxiv_id": "2408.08681v1", "pdf_url": "http://arxiv.org/pdf/2408.08681v1", "abstract_url": "http://arxiv.org/abs/2408.08681v1", "primary_category": "cs.LG", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "A Mean Field Ansatz for Zero-Shot Weight Transfer", "response": "RELEVANT", "timestamp": "2024-08-19T13:31:51.201831"}
{"title": "Neural Reward Machines", "authors": "Elena Umili, Francesco Argenziano, Roberto Capobianco", "abstract": "Non-markovian Reinforcement Learning (RL) tasks are very hard to solve,\nbecause agents must consider the entire history of state-action pairs to act\nrationally in the environment. Most works use symbolic formalisms (as Linear\nTemporal Logic or automata) to specify the temporally-extended task. These\napproaches only work in finite and discrete state environments or continuous\nproblems for which a mapping between the raw state and a symbolic\ninterpretation is known as a symbol grounding (SG) function. Here, we define\nNeural Reward Machines (NRM), an automata-based neurosymbolic framework that\ncan be used for both reasoning and learning in non-symbolic non-markovian RL\ndomains, which is based on the probabilistic relaxation of Moore Machines. We\ncombine RL with semisupervised symbol grounding (SSSG) and we show that NRMs\ncan exploit high-level symbolic knowledge in non-symbolic environments without\nany knowledge of the SG function, outperforming Deep RL methods which cannot\nincorporate prior knowledge. Moreover, we advance the research in SSSG,\nproposing an algorithm for analysing the groundability of temporal\nspecifications, which is more efficient than baseline techniques of a factor\n$10^3$.", "arxiv_id": "2408.08677v1", "pdf_url": "http://arxiv.org/pdf/2408.08677v1", "abstract_url": "http://arxiv.org/abs/2408.08677v1", "primary_category": "cs.LG", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Neural Reward Machines", "response": "RELEVANT", "timestamp": "2024-08-19T13:31:52.288514"}
{"title": "Misclassification excess risk bounds for PAC-Bayesian classification via convexified loss", "authors": "The Tien Mai", "abstract": "PAC-Bayesian bounds have proven to be a valuable tool for deriving\ngeneralization bounds and for designing new learning algorithms in machine\nlearning. However, it typically focus on providing generalization bounds with\nrespect to a chosen loss function. In classification tasks, due to the\nnon-convex nature of the 0-1 loss, a convex surrogate loss is often used, and\nthus current PAC-Bayesian bounds are primarily specified for this convex\nsurrogate. This work shifts its focus to providing misclassification excess\nrisk bounds for PAC-Bayesian classification when using a convex surrogate loss.\nOur key ingredient here is to leverage PAC-Bayesian relative bounds in\nexpectation rather than relying on PAC-Bayesian bounds in probability. We\ndemonstrate our approach in several important applications.", "arxiv_id": "2408.08675v1", "pdf_url": "http://arxiv.org/pdf/2408.08675v1", "abstract_url": "http://arxiv.org/abs/2408.08675v1", "primary_category": "stat.ML", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Misclassification excess risk bounds for PAC-Bayesian classification via convexified loss", "response": "RELEVANT", "timestamp": "2024-08-19T13:31:53.394329"}
{"title": "A Multivocal Literature Review on Privacy and Fairness in Federated Learning", "authors": "Beatrice Balbierer, Lukas Heinlein, Domenique Zipperling, Niklas K\u00fchl", "abstract": "Federated Learning presents a way to revolutionize AI applications by\neliminating the necessity for data sharing. Yet, research has shown that\ninformation can still be extracted during training, making additional\nprivacy-preserving measures such as differential privacy imperative. To\nimplement real-world federated learning applications, fairness, ranging from a\nfair distribution of performance to non-discriminative behaviour, must be\nconsidered. Particularly in high-risk applications (e.g. healthcare), avoiding\nthe repetition of past discriminatory errors is paramount. As recent research\nhas demonstrated an inherent tension between privacy and fairness, we conduct a\nmultivocal literature review to examine the current methods to integrate\nprivacy and fairness in federated learning. Our analyses illustrate that the\nrelationship between privacy and fairness has been neglected, posing a critical\nrisk for real-world applications. We highlight the need to explore the\nrelationship between privacy, fairness, and performance, advocating for the\ncreation of integrated federated learning frameworks.", "arxiv_id": "2408.08666v1", "pdf_url": "http://arxiv.org/pdf/2408.08666v1", "abstract_url": "http://arxiv.org/abs/2408.08666v1", "primary_category": "cs.LG", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "A Multivocal Literature Review on Privacy and Fairness in Federated Learning", "response": "RELEVANT", "timestamp": "2024-08-19T13:31:54.070463"}
{"title": "A new perspective on Bayesian Operational Modal Analysis", "authors": "Brandon J. O'Connell, Max D. Champneys, Timothy J. Rogers", "abstract": "In the field of operational modal analysis (OMA), obtained modal information\nis frequently used to assess the current state of aerospace, mechanical,\noffshore and civil structures. However, the stochasticity of operational\nsystems and the lack of forcing information can lead to inconsistent results.\nQuantifying the uncertainty of the recovered modal parameters through OMA is\ntherefore of significant value. In this article, a new perspective on Bayesian\nOMA is proposed: a Bayesian stochastic subspace identification (SSI) algorithm.\nDistinct from existing approaches to Bayesian OMA, a hierarchical probabilistic\nmodel is embedded at the core of covariance-driven SSI. Through substitution of\ncanonical correlation analysis with a Bayesian equivalent, posterior\ndistributions over the modal properties are obtained. Two inference schemes are\npresented for the proposed Bayesian formulation: Markov Chain Monte Carlo and\nvariational Bayes. Two case studies are then explored. The first is benchmark\nstudy using data from a simulated, multi degree-of-freedom, linear system.\nFollowing application of Bayesian SSI, it is shown that the same posterior is\ntargeted and recovered by both inference schemes, with good agreement between\nthe posterior mean and the conventional SSI result. The second study applies\nthe variational form to data obtained from an in-service structure: The Z24\nbridge. The results of this study are presented at single model orders, and\nthen using a stabilisation diagram. The recovered posterior uncertainty is\npresented and compared to the classic SSI result. It is observed that the\nposterior distributions with mean values coinciding with the natural\nfrequencies exhibit lower variance than values situated away from the natural\nfrequencies.", "arxiv_id": "2408.08664v1", "pdf_url": "http://arxiv.org/pdf/2408.08664v1", "abstract_url": "http://arxiv.org/abs/2408.08664v1", "primary_category": "stat.ML", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "A new perspective on Bayesian Operational Modal Analysis", "response": "RELEVANT", "timestamp": "2024-08-19T13:31:54.956028"}
{"title": "MIA-Tuner: Adapting Large Language Models as Pre-training Text Detector", "authors": "Wenjie Fu, Huandong Wang, Chen Gao, Guanghua Liu, Yong Li, Tao Jiang", "abstract": "The increasing parameters and expansive dataset of large language models\n(LLMs) highlight the urgent demand for a technical solution to audit the\nunderlying privacy risks and copyright issues associated with LLMs. Existing\nstudies have partially addressed this need through an exploration of the\npre-training data detection problem, which is an instance of a membership\ninference attack (MIA). This problem involves determining whether a given piece\nof text has been used during the pre-training phase of the target LLM. Although\nexisting methods have designed various sophisticated MIA score functions to\nachieve considerable detection performance in pre-trained LLMs, how to achieve\nhigh-confidence detection and how to perform MIA on aligned LLMs remain\nchallenging. In this paper, we propose MIA-Tuner, a novel instruction-based MIA\nmethod, which instructs LLMs themselves to serve as a more precise pre-training\ndata detector internally, rather than design an external MIA score function.\nFurthermore, we design two instruction-based safeguards to respectively\nmitigate the privacy risks brought by the existing methods and MIA-Tuner. To\ncomprehensively evaluate the most recent state-of-the-art LLMs, we collect a\nmore up-to-date MIA benchmark dataset, named WIKIMIA-24, to replace the widely\nadopted benchmark WIKIMIA. We conduct extensive experiments across various\naligned and unaligned LLMs over the two benchmark datasets. The results\ndemonstrate that MIA-Tuner increases the AUC of MIAs from 0.7 to a\nsignificantly high level of 0.9.", "arxiv_id": "2408.08661v1", "pdf_url": "http://arxiv.org/pdf/2408.08661v1", "abstract_url": "http://arxiv.org/abs/2408.08661v1", "primary_category": "cs.CL", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "MIA-Tuner: Adapting Large Language Models as Pre-training Text Detector", "response": "RELEVANT", "timestamp": "2024-08-19T13:31:55.873951"}
{"title": "Mitigating Backdoor Attacks in Federated Learning via Flipping Weight Updates of Low-Activation Input Neurons", "authors": "Binbin Ding, Penghui Yang, Zeqing Ge, Shengjun Huang", "abstract": "Federated learning enables multiple clients to collaboratively train machine\nlearning models under the overall planning of the server while adhering to\nprivacy requirements. However, the server cannot directly oversee the local\ntraining process, creating an opportunity for malicious clients to introduce\nbackdoors. Existing research shows that backdoor attacks activate specific\nneurons in the compromised model, which remain dormant when processing clean\ndata. Leveraging this insight, we propose a method called Flipping Weight\nUpdates of Low-Activation Input Neurons (FLAIN) to defend against backdoor\nattacks in federated learning. Specifically, after completing global training,\nwe employ an auxiliary dataset to identify low-activation input neurons and\nflip the associated weight updates. We incrementally raise the threshold for\nlow-activation inputs and flip the weight updates iteratively, until the\nperformance degradation on the auxiliary data becomes unacceptable. Extensive\nexperiments validate that our method can effectively reduce the success rate of\nbackdoor attacks to a low level in various attack scenarios including those\nwith non-IID data distribution or high MCRs, causing only minimal performance\ndegradation on clean data.", "arxiv_id": "2408.08655v1", "pdf_url": "http://arxiv.org/pdf/2408.08655v1", "abstract_url": "http://arxiv.org/abs/2408.08655v1", "primary_category": "cs.LG", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Mitigating Backdoor Attacks in Federated Learning via Flipping Weight Updates of Low-Activation Input Neurons", "response": "RELEVANT", "timestamp": "2024-08-19T13:31:56.566190"}
{"title": "TextCAVs: Debugging vision models using text", "authors": "Angus Nicolson, Yarin Gal, J. Alison Noble", "abstract": "Concept-based interpretability methods are a popular form of explanation for\ndeep learning models which provide explanations in the form of high-level human\ninterpretable concepts. These methods typically find concept activation vectors\n(CAVs) using a probe dataset of concept examples. This requires labelled data\nfor these concepts -- an expensive task in the medical domain. We introduce\nTextCAVs: a novel method which creates CAVs using vision-language models such\nas CLIP, allowing for explanations to be created solely using text descriptions\nof the concept, as opposed to image exemplars. This reduced cost in testing\nconcepts allows for many concepts to be tested and for users to interact with\nthe model, testing new ideas as they are thought of, rather than a delay caused\nby image collection and annotation. In early experimental results, we\ndemonstrate that TextCAVs produces reasonable explanations for a chest x-ray\ndataset (MIMIC-CXR) and natural images (ImageNet), and that these explanations\ncan be used to debug deep learning-based models.", "arxiv_id": "2408.08652v1", "pdf_url": "http://arxiv.org/pdf/2408.08652v1", "abstract_url": "http://arxiv.org/abs/2408.08652v1", "primary_category": "cs.LG", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "TextCAVs: Debugging vision models using text", "response": "RELEVANT", "timestamp": "2024-08-19T13:31:57.354215"}
{"title": "Modeling the Neonatal Brain Development Using Implicit Neural Representations", "authors": "Florentin Bieder, Paul Friedrich, H\u00e9l\u00e8ne Corbaz, Alicia Durrer, Julia Wolleb, Philippe C. Cattin", "abstract": "The human brain undergoes rapid development during the third trimester of\npregnancy. In this work, we model the neonatal development of the infant brain\nin this age range. As a basis, we use MR images of preterm- and term-birth\nneonates from the developing human connectome project (dHCP). We propose a\nneural network, specifically an implicit neural representation (INR), to\npredict 2D- and 3D images of varying time points. In order to model a\nsubject-specific development process, it is necessary to disentangle the age\nfrom the subjects' identity in the latent space of the INR. We propose two\nmethods, Subject Specific Latent Vectors (SSL) and Stochastic Global Latent\nAugmentation (SGLA), enabling this disentanglement. We perform an analysis of\nthe results and compare our proposed model to an age-conditioned denoising\ndiffusion model as a baseline. We also show that our method can be applied in a\nmemory-efficient way, which is especially important for 3D data.", "arxiv_id": "2408.08647v1", "pdf_url": "http://arxiv.org/pdf/2408.08647v1", "abstract_url": "http://arxiv.org/abs/2408.08647v1", "primary_category": "eess.IV", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Modeling the Neonatal Brain Development Using Implicit Neural Representations", "response": "RELEVANT", "timestamp": "2024-08-19T13:31:58.231163"}
{"title": "The Power of Bias: Optimizing Client Selection in Federated Learning with Heterogeneous Differential Privacy", "authors": "Jiating Ma, Yipeng Zhou, Qi Li, Quan Z. Sheng, Laizhong Cui, Jiangchuan Liu", "abstract": "To preserve the data privacy, the federated learning (FL) paradigm emerges in\nwhich clients only expose model gradients rather than original data for\nconducting model training. To enhance the protection of model gradients in FL,\ndifferentially private federated learning (DPFL) is proposed which incorporates\ndifferentially private (DP) noises to obfuscate gradients before they are\nexposed. Yet, an essential but largely overlooked problem in DPFL is the\nheterogeneity of clients' privacy requirement, which can vary significantly\nbetween clients and extremely complicates the client selection problem in DPFL.\nIn other words, both the data quality and the influence of DP noises should be\ntaken into account when selecting clients. To address this problem, we conduct\nconvergence analysis of DPFL under heterogeneous privacy, a generic client\nselection strategy, popular DP mechanisms and convex loss. Based on convergence\nanalysis, we formulate the client selection problem to minimize the value of\nloss function in DPFL with heterogeneous privacy, which is a convex\noptimization problem and can be solved efficiently. Accordingly, we propose the\nDPFL-BCS (biased client selection) algorithm. The extensive experiment results\nwith real datasets under both convex and non-convex loss functions indicate\nthat DPFL-BCS can remarkably improve model utility compared with the SOTA\nbaselines.", "arxiv_id": "2408.08642v1", "pdf_url": "http://arxiv.org/pdf/2408.08642v1", "abstract_url": "http://arxiv.org/abs/2408.08642v1", "primary_category": "cs.LG", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "The Power of Bias: Optimizing Client Selection in Federated Learning with Heterogeneous Differential Privacy", "response": "RELEVANT", "timestamp": "2024-08-19T13:31:58.945558"}
{"title": "Solving The Quantum Many-Body Hamiltonian Learning Problem with Neural Differential Equations", "authors": "Timothy Heightman, Edward Jiang, Antonio Ac\u00edn", "abstract": "Understanding and characterising quantum many-body dynamics remains a\nsignificant challenge due to both the exponential complexity required to\nrepresent quantum many-body Hamiltonians, and the need to accurately track\nstates in time under the action of such Hamiltonians. This inherent complexity\nlimits our ability to characterise quantum many-body systems, highlighting the\nneed for innovative approaches to unlock their full potential. To address this\nchallenge, we propose a novel method to solve the Hamiltonian Learning (HL)\nproblem-inferring quantum dynamics from many-body state trajectories-using\nNeural Differential Equations combined with an Ansatz Hamiltonian. Our method\nis reliably convergent, experimentally friendly, and interpretable, making it a\nstable solution for HL on a set of Hamiltonians previously unlearnable in the\nliterature. In addition to this, we propose a new quantitative benchmark based\non power laws, which can objectively compare the reliability and generalisation\ncapabilities of any two HL algorithms. Finally, we benchmark our method against\nstate-of-the-art HL algorithms with a 1D spin-1/2 chain proof of concept.", "arxiv_id": "2408.08639v1", "pdf_url": "http://arxiv.org/pdf/2408.08639v1", "abstract_url": "http://arxiv.org/abs/2408.08639v1", "primary_category": "quant-ph", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Solving The Quantum Many-Body Hamiltonian Learning Problem with Neural Differential Equations", "response": "RELEVANT", "timestamp": "2024-08-19T13:32:00.074032"}
{"title": "Navigating Uncertainties in Machine Learning for Structural Dynamics: A Comprehensive Review of Probabilistic and Non-Probabilistic Approaches in Forward and Inverse Problems", "authors": "Wang-Ji Yan, Lin-Feng Mei, Jiang Mo, Costas Papadimitriou, Ka-Veng Yuen, Michael Beer", "abstract": "In the era of big data, machine learning (ML) has become a powerful tool in\nvarious fields, notably impacting structural dynamics. ML algorithms offer\nadvantages by modeling physical phenomena based on data, even in the absence of\nunderlying mechanisms. However, uncertainties such as measurement noise and\nmodeling errors can compromise the reliability of ML predictions, highlighting\nthe need for effective uncertainty awareness to enhance prediction robustness.\nThis paper presents a comprehensive review on navigating uncertainties in ML,\ncategorizing uncertainty-aware approaches into probabilistic methods (including\nBayesian and frequentist perspectives) and non-probabilistic methods (such as\ninterval learning and fuzzy learning). Bayesian neural networks, known for\ntheir uncertainty quantification and nonlinear mapping capabilities, are\nemphasized for their superior performance and potential. The review covers\nvarious techniques and methodologies for addressing uncertainties in ML,\ndiscussing fundamentals and implementation procedures of each method. While\nproviding a concise overview of fundamental concepts, the paper refrains from\nin-depth critical explanations. Strengths and limitations of each approach are\nexamined, along with their applications in structural dynamic forward problems\nlike response prediction, sensitivity assessment, and reliability analysis, and\ninverse problems like system identification, model updating, and damage\nidentification. Additionally, the review identifies research gaps and suggests\nfuture directions for investigations, aiming to provide comprehensive insights\nto the research community. By offering an extensive overview of both\nprobabilistic and non-probabilistic approaches, this review aims to assist\nresearchers and practitioners in making informed decisions when utilizing ML\ntechniques to address uncertainties in structural dynamic problems.", "arxiv_id": "2408.08629v1", "pdf_url": "http://arxiv.org/pdf/2408.08629v1", "abstract_url": "http://arxiv.org/abs/2408.08629v1", "primary_category": "cs.LG", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Navigating Uncertainties in Machine Learning for Structural Dynamics: A Comprehensive Review of Probabilistic and Non-Probabilistic Approaches in Forward and Inverse Problems", "response": "RELEVANT", "timestamp": "2024-08-19T13:32:01.920514"}
{"title": "A survey on secure decentralized optimization and learning", "authors": "Changxin Liu, Nicola Bastianello, Wei Huo, Yang Shi, Karl H. Johansson", "abstract": "Decentralized optimization has become a standard paradigm for solving\nlarge-scale decision-making problems and training large machine learning models\nwithout centralizing data. However, this paradigm introduces new privacy and\nsecurity risks, with malicious agents potentially able to infer private data or\nimpair the model accuracy. Over the past decade, significant advancements have\nbeen made in developing secure decentralized optimization and learning\nframeworks and algorithms. This survey provides a comprehensive tutorial on\nthese advancements. We begin with the fundamentals of decentralized\noptimization and learning, highlighting centralized aggregation and distributed\nconsensus as key modules exposed to security risks in federated and distributed\noptimization, respectively. Next, we focus on privacy-preserving algorithms,\ndetailing three cryptographic tools and their integration into decentralized\noptimization and learning systems. Additionally, we examine resilient\nalgorithms, exploring the design and analysis of resilient aggregation and\nconsensus protocols that support these systems. We conclude the survey by\ndiscussing current trends and potential future directions.", "arxiv_id": "2408.08628v1", "pdf_url": "http://arxiv.org/pdf/2408.08628v1", "abstract_url": "http://arxiv.org/abs/2408.08628v1", "primary_category": "cs.LG", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "A survey on secure decentralized optimization and learning", "response": "RELEVANT", "timestamp": "2024-08-19T13:32:02.613500"}
{"title": "DeepDFA: Automata Learning through Neural Probabilistic Relaxations", "authors": "Elena Umili, Roberto Capobianco", "abstract": "In this work, we introduce DeepDFA, a novel approach to identifying\nDeterministic Finite Automata (DFAs) from traces, harnessing a differentiable\nyet discrete model. Inspired by both the probabilistic relaxation of DFAs and\nRecurrent Neural Networks (RNNs), our model offers interpretability\npost-training, alongside reduced complexity and enhanced training efficiency\ncompared to traditional RNNs. Moreover, by leveraging gradient-based\noptimization, our method surpasses combinatorial approaches in both scalability\nand noise resilience. Validation experiments conducted on target regular\nlanguages of varying size and complexity demonstrate that our approach is\naccurate, fast, and robust to noise in both the input symbols and the output\nlabels of training data, integrating the strengths of both logical grammar\ninduction and deep learning.", "arxiv_id": "2408.08622v1", "pdf_url": "http://arxiv.org/pdf/2408.08622v1", "abstract_url": "http://arxiv.org/abs/2408.08622v1", "primary_category": "cs.LG", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "DeepDFA: Automata Learning through Neural Probabilistic Relaxations", "response": "RELEVANT", "timestamp": "2024-08-19T13:32:03.346427"}
{"title": "Generative Dataset Distillation Based on Diffusion Model", "authors": "Duo Su, Junjie Hou, Guang Li, Ren Togo, Rui Song, Takahiro Ogawa, Miki Haseyama", "abstract": "This paper presents our method for the generative track of The First Dataset\nDistillation Challenge at ECCV 2024. Since the diffusion model has become the\nmainstay of generative models because of its high-quality generative effects,\nwe focus on distillation methods based on the diffusion model. Considering that\nthe track can only generate a fixed number of images in 10 minutes using a\ngenerative model for CIFAR-100 and Tiny-ImageNet datasets, we need to use a\ngenerative model that can generate images at high speed. In this study, we\nproposed a novel generative dataset distillation method based on Stable\nDiffusion. Specifically, we use the SDXL-Turbo model which can generate images\nat high speed and quality. Compared to other diffusion models that can only\ngenerate images per class (IPC) = 1, our method can achieve an IPC = 10 for\nTiny-ImageNet and an IPC = 20 for CIFAR-100, respectively. Additionally, to\ngenerate high-quality distilled datasets for CIFAR-100 and Tiny-ImageNet, we\nuse the class information as text prompts and post data augmentation for the\nSDXL-Turbo model. Experimental results show the effectiveness of the proposed\nmethod, and we achieved third place in the generative track of the ECCV 2024 DD\nChallenge. Codes are available at https://github.com/Guang000/BANKO.", "arxiv_id": "2408.08610v1", "pdf_url": "http://arxiv.org/pdf/2408.08610v1", "abstract_url": "http://arxiv.org/abs/2408.08610v1", "primary_category": "cs.CV", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Generative Dataset Distillation Based on Diffusion Model", "response": "RELEVANT", "timestamp": "2024-08-19T13:32:04.345192"}
{"title": "RadioDiff: An Effective Generative Diffusion Model for Sampling-Free Dynamic Radio Map Construction", "authors": "Xiucheng Wang, Keda Tao, Nan Cheng, Zhisheng Yin, Zan Li, Yuan Zhang, Xuemin Shen", "abstract": "Radio map (RM) is a promising technology that can obtain pathloss based on\nonly location, which is significant for 6G network applications to reduce the\ncommunication costs for pathloss estimation. However, the construction of RM in\ntraditional is either computationally intensive or depends on costly\nsampling-based pathloss measurements. Although the neural network (NN)-based\nmethod can efficiently construct the RM without sampling, its performance is\nstill suboptimal. This is primarily due to the misalignment between the\ngenerative characteristics of the RM construction problem and the\ndiscrimination modeling exploited by existing NN-based methods. Thus, to\nenhance RM construction performance, in this paper, the sampling-free RM\nconstruction is modeled as a conditional generative problem, where a denoised\ndiffusion-based method, named RadioDiff, is proposed to achieve high-quality RM\nconstruction. In addition, to enhance the diffusion model's capability of\nextracting features from dynamic environments, an attention U-Net with an\nadaptive fast Fourier transform module is employed as the backbone network to\nimprove the dynamic environmental features extracting capability. Meanwhile,\nthe decoupled diffusion model is utilized to further enhance the construction\nperformance of RMs. Moreover, a comprehensive theoretical analysis of why the\nRM construction is a generative problem is provided for the first time, from\nboth perspectives of data features and NN training methods. Experimental\nresults show that the proposed RadioDiff achieves state-of-the-art performance\nin all three metrics of accuracy, structural similarity, and peak\nsignal-to-noise ratio. The code is available at\nhttps://github.com/UNIC-Lab/RadioDiff.", "arxiv_id": "2408.08593v1", "pdf_url": "http://arxiv.org/pdf/2408.08593v1", "abstract_url": "http://arxiv.org/abs/2408.08593v1", "primary_category": "cs.LG", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "RadioDiff: An Effective Generative Diffusion Model for Sampling-Free Dynamic Radio Map Construction", "response": "RELEVANT", "timestamp": "2024-08-19T13:32:05.295521"}
{"title": "A Mechanistic Interpretation of Syllogistic Reasoning in Auto-Regressive Language Models", "authors": "Geonhee Kim, Marco Valentino, Andr\u00e9 Freitas", "abstract": "Recent studies on logical reasoning in auto-regressive Language Models (LMs)\nhave sparked a debate on whether such models can learn systematic reasoning\nprinciples during pre-training or merely exploit superficial patterns in the\ntraining data. This paper presents a mechanistic interpretation of syllogistic\nreasoning in LMs to further enhance our understanding of internal dynamics.\nSpecifically, we present a methodology for circuit discovery aimed at\ndisentangling content-independent reasoning mechanisms from world knowledge\nacquired during pre-training. Through two distinct intervention methods, we\nuncover a sufficient and necessary circuit involving middle-term suppression\nthat elucidates how LMs transfer information to derive valid conclusions from\npremises. Furthermore, we investigate how belief biases manifest in syllogistic\nreasoning, finding evidence of partial contamination from additional attention\nheads responsible for encoding commonsense and contextualized knowledge.\nFinally, we explore the generalization of the discovered mechanisms across\nvarious syllogistic schemes and model sizes, finding that the identified\ncircuit is sufficient and necessary for all the schemes on which the model\nachieves high downstream accuracy ($\\geq$ 60\\%). Overall, our findings suggest\nthat LMs indeed learn transferable content-independent reasoning mechanisms,\nbut that, at the same time, such mechanisms do not involve generalisable and\nabstract logical primitives, being susceptible to contamination by the same\nworld knowledge acquired during pre-training.", "arxiv_id": "2408.08590v1", "pdf_url": "http://arxiv.org/pdf/2408.08590v1", "abstract_url": "http://arxiv.org/abs/2408.08590v1", "primary_category": "cs.CL", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "A Mechanistic Interpretation of Syllogistic Reasoning in Auto-Regressive Language Models", "response": "RELEVANT", "timestamp": "2024-08-19T13:32:06.226543"}
{"title": "OptDist: Learning Optimal Distribution for Customer Lifetime Value Prediction", "authors": "Yunpeng Weng, Xing Tang, Zhenhao Xu, Fuyuan Lyu, Dugang Liu, Zexu Sun, Xiuqiang He", "abstract": "Customer Lifetime Value (CLTV) prediction is a critical task in business\napplications. Accurately predicting CLTV is challenging in real-world business\nscenarios, as the distribution of CLTV is complex and mutable. Firstly, there\nis a large number of users without any consumption consisting of a long-tailed\npart that is too complex to fit. Secondly, the small set of high-value users\nspent orders of magnitude more than a typical user leading to a wide range of\nthe CLTV distribution which is hard to capture in a single distribution.\nExisting approaches for CLTV estimation either assume a prior probability\ndistribution and fit a single group of distribution-related parameters for all\nsamples, or directly learn from the posterior distribution with manually\npredefined buckets in a heuristic manner. However, all these methods fail to\nhandle complex and mutable distributions. In this paper, we propose a novel\noptimal distribution selection model OptDist for CLTV prediction, which\nutilizes an adaptive optimal sub-distribution selection mechanism to improve\nthe accuracy of complex distribution modeling. Specifically, OptDist trains\nseveral candidate sub-distribution networks in the distribution learning module\n(DLM) for modeling the probability distribution of CLTV. Then, a distribution\nselection module (DSM) is proposed to select the sub-distribution for each\nsample, thus making the selection automatically and adaptively. Besides, we\ndesign an alignment mechanism that connects both modules, which effectively\nguides the optimization. We conduct extensive experiments on both two public\nand one private dataset to verify that OptDist outperforms state-of-the-art\nbaselines. Furthermore, OptDist has been deployed on a large-scale financial\nplatform for customer acquisition marketing campaigns and the online\nexperiments also demonstrate the effectiveness of OptDist.", "arxiv_id": "2408.08585v1", "pdf_url": "http://arxiv.org/pdf/2408.08585v1", "abstract_url": "http://arxiv.org/abs/2408.08585v1", "primary_category": "cs.IR", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "OptDist: Learning Optimal Distribution for Customer Lifetime Value Prediction", "response": "RELEVANT", "timestamp": "2024-08-19T13:32:07.061221"}
{"title": "S-RAF: A Simulation-Based Robustness Assessment Framework for Responsible Autonomous Driving", "authors": "Daniel Omeiza, Pratik Somaiya, Jo-Ann Pattinson, Carolyn Ten-Holter, Jack Stilgoe, Marina Jirotka, Lars Kunze", "abstract": "As artificial intelligence (AI) technology advances, ensuring the robustness\nand safety of AI-driven systems has become paramount. However, varying\nperceptions of robustness among AI developers create misaligned evaluation\nmetrics, complicating the assessment and certification of safety-critical and\ncomplex AI systems such as autonomous driving (AD) agents. To address this\nchallenge, we introduce Simulation-Based Robustness Assessment Framework\n(S-RAF) for autonomous driving. S-RAF leverages the CARLA Driving simulator to\nrigorously assess AD agents across diverse conditions, including faulty\nsensors, environmental changes, and complex traffic situations. By quantifying\nrobustness and its relationship with other safety-critical factors, such as\ncarbon emissions, S-RAF aids developers and stakeholders in building safe and\nresponsible driving agents, and streamlining safety certification processes.\nFurthermore, S-RAF offers significant advantages, such as reduced testing\ncosts, and the ability to explore edge cases that may be unsafe to test in the\nreal world. The code for this framework is available here:\nhttps://github.com/cognitive-robots/rai-leaderboard", "arxiv_id": "2408.08584v1", "pdf_url": "http://arxiv.org/pdf/2408.08584v1", "abstract_url": "http://arxiv.org/abs/2408.08584v1", "primary_category": "cs.RO", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "S-RAF: A Simulation-Based Robustness Assessment Framework for Responsible Autonomous Driving", "response": "RELEVANT", "timestamp": "2024-08-19T13:32:07.854612"}
{"title": "GrassNet: State Space Model Meets Graph Neural Network", "authors": "Gongpei Zhao, Tao Wang, Yi Jin, Congyan Lang, Yidong Li, Haibin Ling", "abstract": "Designing spectral convolutional networks is a formidable task in graph\nlearning. In traditional spectral graph neural networks (GNNs),\npolynomial-based methods are commonly used to design filters via the Laplacian\nmatrix. In practical applications, however, these polynomial methods encounter\ninherent limitations, which primarily arise from the the low-order truncation\nof polynomial filters and the lack of overall modeling of the graph spectrum.\nThis leads to poor performance of existing spectral approaches on real-world\ngraph data, especially when the spectrum is highly concentrated or contains\nmany numerically identical values, as they tend to apply the exact same\nmodulation to signals with the same frequencies. To overcome these issues, in\nthis paper, we propose Graph State Space Network (GrassNet), a novel graph\nneural network with theoretical support that provides a simple yet effective\nscheme for designing and learning arbitrary graph spectral filters. In\nparticular, our GrassNet introduces structured state space models (SSMs) to\nmodel the correlations of graph signals at different frequencies and derives a\nunique rectification for each frequency in the graph spectrum. To the best of\nour knowledge, our work is the first to employ SSMs for the design of GNN\nspectral filters, and it theoretically offers greater expressive power compared\nwith polynomial filters. Extensive experiments on nine public benchmarks reveal\nthat GrassNet achieves superior performance in real-world graph modeling tasks.", "arxiv_id": "2408.08583v1", "pdf_url": "http://arxiv.org/pdf/2408.08583v1", "abstract_url": "http://arxiv.org/abs/2408.08583v1", "primary_category": "cs.LG", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "GrassNet: State Space Model Meets Graph Neural Network", "response": "RELEVANT", "timestamp": "2024-08-19T13:32:08.783083"}
{"title": "S$^3$Attention: Improving Long Sequence Attention with Smoothed Skeleton Sketching", "authors": "Xue Wang, Tian Zhou, Jianqing Zhu, Jialin Liu, Kun Yuan, Tao Yao, Wotao Yin, Rong Jin, HanQin Cai", "abstract": "Attention based models have achieved many remarkable breakthroughs in\nnumerous applications. However, the quadratic complexity of Attention makes the\nvanilla Attention based models hard to apply to long sequence tasks. Various\nimproved Attention structures are proposed to reduce the computation cost by\ninducing low rankness and approximating the whole sequence by sub-sequences.\nThe most challenging part of those approaches is maintaining the proper balance\nbetween information preservation and computation reduction: the longer\nsub-sequences used, the better information is preserved, but at the price of\nintroducing more noise and computational costs. In this paper, we propose a\nsmoothed skeleton sketching based Attention structure, coined S$^3$Attention,\nwhich significantly improves upon the previous attempts to negotiate this\ntrade-off. S$^3$Attention has two mechanisms to effectively minimize the impact\nof noise while keeping the linear complexity to the sequence length: a\nsmoothing block to mix information over long sequences and a matrix sketching\nmethod that simultaneously selects columns and rows from the input matrix. We\nverify the effectiveness of S$^3$Attention both theoretically and empirically.\nExtensive studies over Long Range Arena (LRA) datasets and six time-series\nforecasting show that S$^3$Attention significantly outperforms both vanilla\nAttention and other state-of-the-art variants of Attention structures.", "arxiv_id": "2408.08567v1", "pdf_url": "http://arxiv.org/pdf/2408.08567v1", "abstract_url": "http://arxiv.org/abs/2408.08567v1", "primary_category": "cs.LG", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "S$^3$Attention: Improving Long Sequence Attention with Smoothed Skeleton Sketching", "response": "RELEVANT", "timestamp": "2024-08-19T13:32:09.821141"}
{"title": "A training regime to learn unified representations from complementary breast imaging modalities", "authors": "Umang Sharma, Jungkyu Park, Laura Heacock, Sumit Chopra, Krzysztof Geras", "abstract": "Full Field Digital Mammograms (FFDMs) and Digital Breast Tomosynthesis (DBT)\nare the two most widely used imaging modalities for breast cancer screening.\nAlthough DBT has increased cancer detection compared to FFDM, its widespread\nadoption in clinical practice has been slowed by increased interpretation times\nand a perceived decrease in the conspicuity of specific lesion types.\nSpecifically, the non-inferiority of DBT for microcalcifications remains under\ndebate. Due to concerns about the decrease in visual acuity, combined DBT-FFDM\nacquisitions remain popular, leading to overall increased exam times and\nradiation dosage. Enabling DBT to provide diagnostic information present in\nboth FFDM and DBT would reduce reliance on FFDM, resulting in a reduction in\nboth quantities. We propose a machine learning methodology that learns\nhigh-level representations leveraging the complementary diagnostic signal from\nboth DBT and FFDM. Experiments on a large-scale data set validate our claims\nand show that our representations enable more accurate breast lesion detection\nthan any DBT- or FFDM-based model.", "arxiv_id": "2408.08560v1", "pdf_url": "http://arxiv.org/pdf/2408.08560v1", "abstract_url": "http://arxiv.org/abs/2408.08560v1", "primary_category": "cs.CV", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "A training regime to learn unified representations from complementary breast imaging modalities", "response": "RELEVANT", "timestamp": "2024-08-19T13:32:22.489124"}
{"title": "Linear combinations of latents in diffusion models: interpolation and beyond", "authors": "Erik Bodin, Henry Moss, Carl Henrik Ek", "abstract": "Generative models are crucial for applications like data synthesis and\naugmentation. Diffusion, Flow Matching and Continuous Normalizing Flows have\nshown effectiveness across various modalities, and rely on Gaussian latent\nvariables for generation. As any generated object is directly associated with a\nparticular latent variable, we can manipulate the variables to exert control\nover the generation process. However, standard approaches for combining latent\nvariables, such as spherical interpolation, only apply or work well in special\ncases. Moreover, current methods for obtaining low-dimensional representations\nof the data, important for e.g. surrogate models for search and creative\napplications, are network and data modality specific. In this work we show that\nthe standard methods to combine variables do not yield intermediates following\nthe distribution the models are trained to expect. We propose Combination of\nGaussian variables (COG), a novel interpolation method that addresses this, is\neasy to implement yet matches or improves upon current methods. COG addresses\nlinear combinations in general and, as we demonstrate, also supports other\noperations including e.g. defining subspaces of the latent space, simplifying\nthe creation of expressive low-dimensional spaces of high-dimensional objects\nusing generative models based on Gaussian latents.", "arxiv_id": "2408.08558v1", "pdf_url": "http://arxiv.org/pdf/2408.08558v1", "abstract_url": "http://arxiv.org/abs/2408.08558v1", "primary_category": "stat.ML", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Linear combinations of latents in diffusion models: interpolation and beyond", "response": "RELEVANT", "timestamp": "2024-08-19T13:32:23.727330"}
{"title": "ABQ-LLM: Arbitrary-Bit Quantized Inference Acceleration for Large Language Models", "authors": "Chao Zeng, Songwei Liu, Yusheng Xie, Hong Liu, Xiaojian Wang, Miao Wei, Shu Yang, Fangmin Chen, Xing Mei", "abstract": "Large Language Models (LLMs) have revolutionized natural language processing\ntasks. However, their practical application is constrained by substantial\nmemory and computational demands. Post-training quantization (PTQ) is\nconsidered an effective method to accelerate LLM inference. Despite its growing\npopularity in LLM model compression, PTQ deployment faces two major challenges.\nFirst, low-bit quantization leads to performance degradation. Second,\nrestricted by the limited integer computing unit type on GPUs, quantized matrix\noperations with different precisions cannot be effectively accelerated. To\naddress these issues, we introduce a novel arbitrary-bit quantization algorithm\nand inference framework, ABQ-LLM. It achieves superior performance across\nvarious quantization settings and enables efficient arbitrary-precision\nquantized inference on the GPU. ABQ-LLM introduces several key innovations: (1)\na distribution correction method for transformer blocks to mitigate\ndistribution differences caused by full quantization of weights and\nactivations, improving performance at low bit-widths. (2) the bit balance\nstrategy to counteract performance degradation from asymmetric distribution\nissues at very low bit-widths (e.g., 2-bit). (3) an innovative quantization\nacceleration framework that reconstructs the quantization matrix multiplication\nof arbitrary precision combinations based on BTC (Binary TensorCore)\nequivalents, gets rid of the limitations of INT4/INT8 computing units. ABQ-LLM\ncan convert each component bit width gain into actual acceleration gain,\nmaximizing performance under mixed precision(e.g., W6A6, W2A8). Based on W2*A8\nquantization configuration on LLaMA-7B model, it achieved a WikiText2\nperplexity of 7.59 (2.17$\\downarrow $ vs 9.76 in AffineQuant). Compared to\nSmoothQuant, we realized 1.6$\\times$ acceleration improvement and 2.7$\\times$\nmemory compression gain.", "arxiv_id": "2408.08554v1", "pdf_url": "http://arxiv.org/pdf/2408.08554v1", "abstract_url": "http://arxiv.org/abs/2408.08554v1", "primary_category": "cs.LG", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "ABQ-LLM: Arbitrary-Bit Quantized Inference Acceleration for Large Language Models", "response": "RELEVANT", "timestamp": "2024-08-19T13:32:24.505376"}
{"title": "Where is the signal in tokenization space?", "authors": "Renato Lui Geh, Honghua Zhang, Kareem Ahmed, Benjie Wang, Guy Van den Broeck", "abstract": "Large Language Models (LLMs) are typically shipped with tokenizers that\ndeterministically encode text into so-called canonical token sequences, to\nwhich the LLMs assign probability values. One common assumption is that the\nprobability of a piece of text is the probability of its canonical token\nsequence. However, the tokenization of a string is not unique: e.g., the Llama2\ntokenizer encodes Tokens as [Tok,ens], but [Tok,en,s] also represents the same\ntext. In this paper, we study non-canonical tokenizations. We prove that, given\na string, it is computationally hard to find the most likely tokenization for\nan autoregressive LLM, as well as to compute the marginal probability over all\npossible tokenizations. We then show how the marginal is, in most cases,\nindistinguishable from the canonical probability. Surprisingly, we then\nempirically demonstrate the existence of a significant amount of signal hidden\nwithin tokenization space. Notably, by simply aggregating the probabilities of\nnon-canonical tokenizations, we achieve improvements across a range of LLM\nevaluation benchmarks for a variety of architectures, including transformers\nand state space models.", "arxiv_id": "2408.08541v1", "pdf_url": "http://arxiv.org/pdf/2408.08541v1", "abstract_url": "http://arxiv.org/abs/2408.08541v1", "primary_category": "cs.CL", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Where is the signal in tokenization space?", "response": "RELEVANT", "timestamp": "2024-08-19T13:32:25.669011"}
{"title": "Blockchain-Enabled Accountability in Data Supply Chain: A Data Bill of Materials Approach", "authors": "Yue Liu, Dawen Zhang, Boming Xia, Julia Anticev, Tunde Adebayo, Zhenchang Xing, Moses Machao", "abstract": "In the era of advanced artificial intelligence, highlighted by large-scale\ngenerative models like GPT-4, ensuring the traceability, verifiability, and\nreproducibility of datasets throughout their lifecycle is paramount for\nresearch institutions and technology companies. These organisations\nincreasingly rely on vast corpora to train and fine-tune advanced AI models,\nresulting in intricate data supply chains that demand effective data governance\nmechanisms. In addition, the challenge intensifies as diverse stakeholders may\nuse assorted tools, often without adequate measures to ensure the\naccountability of data and the reliability of outcomes. In this study, we adapt\nthe concept of ``Software Bill of Materials\" into the field of data governance\nand management to address the above challenges, and introduce ``Data Bill of\nMaterials\" (DataBOM) to capture the dependency relationship between different\ndatasets and stakeholders by storing specific metadata. We demonstrate a\nplatform architecture for providing blockchain-based DataBOM services, present\nthe interaction protocol for stakeholders, and discuss the minimal requirements\nfor DataBOM metadata. The proposed solution is evaluated in terms of\nfeasibility and performance via case study and quantitative analysis\nrespectively.", "arxiv_id": "2408.08536v1", "pdf_url": "http://arxiv.org/pdf/2408.08536v1", "abstract_url": "http://arxiv.org/abs/2408.08536v1", "primary_category": "cs.SE", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Blockchain-Enabled Accountability in Data Supply Chain: A Data Bill of Materials Approach", "response": "RELEVANT", "timestamp": "2024-08-19T13:32:26.468999"}
{"title": "Unsupervised Transfer Learning via Adversarial Contrastive Training", "authors": "Chenguang Duan, Yuling Jiao, Huazhen Lin, Wensen Ma, Jerry Zhijian Yang", "abstract": "Learning a data representation for downstream supervised learning tasks under\nunlabeled scenario is both critical and challenging. In this paper, we propose\na novel unsupervised transfer learning approach using adversarial contrastive\ntraining (ACT). Our experimental results demonstrate outstanding classification\naccuracy with both fine-tuned linear probe and K-NN protocol across various\ndatasets, showing competitiveness with existing state-of-the-art\nself-supervised learning methods. Moreover, we provide an end-to-end\ntheoretical guarantee for downstream classification tasks in a misspecified,\nover-parameterized setting, highlighting how a large amount of unlabeled data\ncontributes to prediction accuracy. Our theoretical findings suggest that the\ntesting error of downstream tasks depends solely on the efficiency of data\naugmentation used in ACT when the unlabeled sample size is sufficiently large.\nThis offers a theoretical understanding of learning downstream tasks with a\nsmall sample size.", "arxiv_id": "2408.08533v1", "pdf_url": "http://arxiv.org/pdf/2408.08533v1", "abstract_url": "http://arxiv.org/abs/2408.08533v1", "primary_category": "stat.ML", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Unsupervised Transfer Learning via Adversarial Contrastive Training", "response": "RELEVANT", "timestamp": "2024-08-19T13:32:27.311168"}
{"title": "Detecting Unsuccessful Students in Cybersecurity Exercises in Two Different Learning Environments", "authors": "Valdemar \u0160v\u00e1bensk\u00fd, Kristi\u00e1n Tk\u00e1\u010dik, Aubrey Birdwell, Richard Weiss, Ryan S. Baker, Pavel \u010celeda, Jan Vykopal, Jens Mache, Ankur Chattopadhyay", "abstract": "This full paper in the research track evaluates the usage of data logged from\ncybersecurity exercises in order to predict students who are potentially at\nrisk of performing poorly. Hands-on exercises are essential for learning since\nthey enable students to practice their skills. In cybersecurity, hands-on\nexercises are often complex and require knowledge of many topics. Therefore,\nstudents may miss solutions due to gaps in their knowledge and become\nfrustrated, which impedes their learning. Targeted aid by the instructor helps,\nbut since the instructor's time is limited, efficient ways to detect struggling\nstudents are needed. This paper develops automated tools to predict when a\nstudent is having difficulty. We formed a dataset with the actions of 313\nstudents from two countries and two learning environments: KYPO CRP and\nEDURange. These data are used in machine learning algorithms to predict the\nsuccess of students in exercises deployed in these environments. After\nextracting features from the data, we trained and cross-validated eight\nclassifiers for predicting the exercise outcome and evaluated their predictive\npower. The contribution of this paper is comparing two approaches to feature\nengineering, modeling, and classification performance on data from two learning\nenvironments. Using the features from either learning environment, we were able\nto detect and distinguish between successful and struggling students. A\ndecision tree classifier achieved the highest balanced accuracy and sensitivity\nwith data from both learning environments. The results show that activity data\nfrom cybersecurity exercises are suitable for predicting student success. In a\npotential application, such models can aid instructors in detecting struggling\nstudents and providing targeted help. We publish data and code for building\nthese models so that others can adopt or adapt them.", "arxiv_id": "2408.08531v1", "pdf_url": "http://arxiv.org/pdf/2408.08531v1", "abstract_url": "http://arxiv.org/abs/2408.08531v1", "primary_category": "cs.LG", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Detecting Unsuccessful Students in Cybersecurity Exercises in Two Different Learning Environments", "response": "RELEVANT", "timestamp": "2024-08-19T13:32:28.236920"}
{"title": "Inverse design with conditional cascaded diffusion models", "authors": "Milad Habibi, Mark Fuge", "abstract": "Adjoint-based design optimizations are usually computationally expensive and\nthose costs scale with resolution. To address this, researchers have proposed\nmachine learning approaches for inverse design that can predict\nhigher-resolution solutions from lower cost/resolution ones. Due to the recent\nsuccess of diffusion models over traditional generative models, we extend the\nuse of diffusion models for multi-resolution tasks by proposing the conditional\ncascaded diffusion model (cCDM). Compared to GANs, cCDM is more stable to\ntrain, and each diffusion model within the cCDM can be trained independently,\nthus each model's parameters can be tuned separately to maximize the\nperformance of the pipeline. Our study compares cCDM against a cGAN model with\ntransfer learning.\n  Our results demonstrate that the cCDM excels in capturing finer details,\npreserving volume fraction constraints, and minimizing compliance errors in\nmulti-resolution tasks when a sufficient amount of high-resolution training\ndata (more than 102 designs) is available. Furthermore, we explore the impact\nof training data size on the performance of both models. While both models show\ndecreased performance with reduced high-resolution training data, the cCDM\nloses its superiority to the cGAN model with transfer learning when training\ndata is limited (less than 102), and we show the break-even point for this\ntransition. Also, we highlight that while the diffusion model may achieve\nbetter pixel-wise performance in both low-resolution and high-resolution\nscenarios, this does not necessarily guarantee that the model produces optimal\ncompliance error or constraint satisfaction.", "arxiv_id": "2408.08526v1", "pdf_url": "http://arxiv.org/pdf/2408.08526v1", "abstract_url": "http://arxiv.org/abs/2408.08526v1", "primary_category": "cs.LG", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Inverse design with conditional cascaded diffusion models", "response": "RELEVANT", "timestamp": "2024-08-19T13:32:29.117553"}
{"title": "Mitigating Degree Bias in Signed Graph Neural Networks", "authors": "Fang He, Jinhai Deng, Ruizhan Xue, Maojun Wang, Zeyu Zhang", "abstract": "Like Graph Neural Networks (GNNs), Signed Graph Neural Networks (SGNNs) are\nalso up against fairness issues from source data and typical aggregation\nmethod. In this paper, we are pioneering to make the investigation of fairness\nin SGNNs expanded from GNNs. We identify the issue of degree bias within signed\ngraphs, offering a new perspective on the fairness issues related to SGNNs. To\nhandle the confronted bias issue, inspired by previous work on degree bias, a\nnew Model-Agnostic method is consequently proposed to enhance representation of\nnodes with different degrees, which named as Degree Debiased Signed Graph\nNeural Network (DD-SGNN) . More specifically, in each layer, we make a transfer\nfrom nodes with high degree to nodes with low degree inside a head-to-tail\ntriplet, which to supplement the underlying domain missing structure of the\ntail nodes and meanwhile maintain the positive and negative semantics specified\nby balance theory in signed graphs. We make extensive experiments on four\nreal-world datasets. The result verifies the validity of the model, that is,\nour model mitigates the degree bias issue without compromising\nperformance($\\textit{i.e.}$, AUC, F1). The code is provided in supplementary\nmaterial.", "arxiv_id": "2408.08508v1", "pdf_url": "http://arxiv.org/pdf/2408.08508v1", "abstract_url": "http://arxiv.org/abs/2408.08508v1", "primary_category": "cs.LG", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Mitigating Degree Bias in Signed Graph Neural Networks", "response": "RELEVANT", "timestamp": "2024-08-19T13:32:29.979615"}
{"title": "The Limitations of Model Retraining in the Face of Performativity", "authors": "Anmol Kabra, Kumar Kshitij Patel", "abstract": "We study stochastic optimization in the context of performative shifts, where\nthe data distribution changes in response to the deployed model. We demonstrate\nthat naive retraining can be provably suboptimal even for simple distribution\nshifts. The issue worsens when models are retrained given a finite number of\nsamples at each retraining step. We show that adding regularization to\nretraining corrects both of these issues, attaining provably optimal models in\nthe face of distribution shifts. Our work advocates rethinking how machine\nlearning models are retrained in the presence of performative effects.", "arxiv_id": "2408.08499v1", "pdf_url": "http://arxiv.org/pdf/2408.08499v1", "abstract_url": "http://arxiv.org/abs/2408.08499v1", "primary_category": "cs.LG", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "The Limitations of Model Retraining in the Face of Performativity", "response": "RELEVANT", "timestamp": "2024-08-19T13:32:30.820822"}
{"title": "Optimal Sketching for Residual Error Estimation for Matrix and Vector Norms", "authors": "Yi Li, Honghao Lin, David P. Woodruff", "abstract": "We study the problem of residual error estimation for matrix and vector norms\nusing a linear sketch. Such estimates can be used, for example, to quickly\nassess how useful a more expensive low-rank approximation computation will be.\nThe matrix case concerns the Frobenius norm and the task is to approximate the\n$k$-residual $\\|A - A_k\\|_F$ of the input matrix $A$ within a\n$(1+\\epsilon)$-factor, where $A_k$ is the optimal rank-$k$ approximation. We\nprovide a tight bound of $\\Theta(k^2/\\epsilon^4)$ on the size of bilinear\nsketches, which have the form of a matrix product $SAT$. This improves the\nprevious $O(k^2/\\epsilon^6)$ upper bound in (Andoni et al. SODA 2013) and gives\nthe first non-trivial lower bound, to the best of our knowledge. In our\nalgorithm, our sketching matrices $S$ and $T$ can both be sparse matrices,\nallowing for a very fast update time. We demonstrate that this gives a\nsubstantial advantage empirically, for roughly the same sketch size and\naccuracy as in previous work.\n  For the vector case, we consider the $\\ell_p$-norm for $p>2$, where the task\nis to approximate the $k$-residual $\\|x - x_k\\|_p$ up to a constant factor,\nwhere $x_k$ is the optimal $k$-sparse approximation to $x$. Such vector norms\nare frequently studied in the data stream literature and are useful for finding\nfrequent items or so-called heavy hitters. We establish an upper bound of\n$O(k^{2/p}n^{1-2/p}\\operatorname{poly}(\\log n))$ for constant $\\epsilon$ on the\ndimension of a linear sketch for this problem. Our algorithm can be extended to\nthe $\\ell_p$ sparse recovery problem with the same sketching dimension, which\nseems to be the first such bound for $p > 2$. We also show an\n$\\Omega(k^{2/p}n^{1-2/p})$ lower bound for the sparse recovery problem, which\nis tight up to a $\\mathrm{poly}(\\log n)$ factor.", "arxiv_id": "2408.08494v1", "pdf_url": "http://arxiv.org/pdf/2408.08494v1", "abstract_url": "http://arxiv.org/abs/2408.08494v1", "primary_category": "cs.DS", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Optimal Sketching for Residual Error Estimation for Matrix and Vector Norms", "response": "RELEVANT", "timestamp": "2024-08-19T13:32:31.712034"}
{"title": "Fishers Harvest Parallel Unlearning in Inherited Model Networks", "authors": "Xiao Liu, Mingyuan Li, Xu Wang, Guangsheng Yu, Wei Ni, Lixiang Li, Haipeng Peng, Renping Liu", "abstract": "Unlearning in various learning frameworks remains challenging, with the\ncontinuous growth and updates of models exhibiting complex inheritance\nrelationships. This paper presents a novel unlearning framework, which enables\nfully parallel unlearning among models exhibiting inheritance. A key enabler is\nthe new Unified Model Inheritance Graph (UMIG), which captures the inheritance\nusing a Directed Acyclic Graph (DAG).Central to our framework is the new Fisher\nInheritance Unlearning (FIUn) algorithm, which utilizes the Fisher Information\nMatrix (FIM) from initial unlearning models to pinpoint impacted parameters in\ninherited models. By employing FIM, the FIUn method breaks the sequential\ndependencies among the models, facilitating simultaneous unlearning and\nreducing computational overhead. We further design to merge disparate FIMs into\na single matrix, synchronizing updates across inherited models. Experiments\nconfirm the effectiveness of our unlearning framework. For single-class tasks,\nit achieves complete unlearning with 0\\% accuracy for unlearned labels while\nmaintaining 94.53\\% accuracy for retained labels on average. For multi-class\ntasks, the accuracy is 1.07\\% for unlearned labels and 84.77\\% for retained\nlabels on average. Our framework accelerates unlearning by 99\\% compared to\nalternative methods.", "arxiv_id": "2408.08493v1", "pdf_url": "http://arxiv.org/pdf/2408.08493v1", "abstract_url": "http://arxiv.org/abs/2408.08493v1", "primary_category": "cs.LG", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Fishers Harvest Parallel Unlearning in Inherited Model Networks", "response": "RELEVANT", "timestamp": "2024-08-19T13:32:32.895919"}
{"title": "Adversarial Contrastive Learning Based Physics-Informed Temporal Networks for Cuffless Blood Pressure Estimation", "authors": "Rui Wang, Mengshi Qi, Yingxia Shao, Anfu Zhou, Huadong Ma", "abstract": "Time series data mining is immensely important in extensive applications,\nsuch as traffic, medical, and e-commerce. In this paper, we focus on medical\ntemporal variation modeling, \\emph{i.e.,} cuffless blood pressure (BP)\nmonitoring which has great value in cardiovascular healthcare. Although\nproviding a comfortable user experience, such methods are suffering from the\ndemand for a significant amount of realistic data to train an individual model\nfor each subject, especially considering the invasive or obtrusive BP\nground-truth measurements. To tackle this challenge, we introduce a novel\nphysics-informed temporal network~(PITN) with adversarial contrastive learning\nto enable precise BP estimation with very limited data. Specifically, we first\nenhance the physics-informed neural network~(PINN) with the temporal block for\ninvestigating BP dynamics' multi-periodicity for personal cardiovascular cycle\nmodeling and temporal variation. We then employ adversarial training to\ngenerate extra physiological time series data, improving PITN's robustness in\nthe face of sparse subject-specific training data. Furthermore, we utilize\ncontrastive learning to capture the discriminative variations of cardiovascular\nphysiologic phenomena. This approach aggregates physiological signals with\nsimilar blood pressure values in latent space while separating clusters of\nsamples with dissimilar blood pressure values. Experiments on three\nwidely-adopted datasets with different modailties (\\emph{i.e.,} bioimpedance,\nPPG, millimeter-wave) demonstrate the superiority and effectiveness of the\nproposed methods over previous state-of-the-art approaches. The code is\navailable at~\\url{https://github.com/Zest86/ACL-PITN}.", "arxiv_id": "2408.08488v1", "pdf_url": "http://arxiv.org/pdf/2408.08488v1", "abstract_url": "http://arxiv.org/abs/2408.08488v1", "primary_category": "cs.LG", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Adversarial Contrastive Learning Based Physics-Informed Temporal Networks for Cuffless Blood Pressure Estimation", "response": "RELEVANT", "timestamp": "2024-08-19T13:32:33.978183"}
{"title": "An Unsupervised Learning Framework Combined with Heuristics for the Maximum Minimal Cut Problem", "authors": "Huaiyuan Liu, Xianzhang Liu, Donghua Yang, Hongzhi Wang, Yingchi Long, Mengtong Ji, Dongjing Miao, Zhiyu Liang", "abstract": "The Maximum Minimal Cut Problem (MMCP), a NP-hard combinatorial optimization\n(CO) problem, has not received much attention due to the demanding and\nchallenging bi-connectivity constraint. Moreover, as a CO problem, it is also a\ndaunting task for machine learning, especially without labeled instances. To\ndeal with these problems, this work proposes an unsupervised learning framework\ncombined with heuristics for MMCP that can provide valid and high-quality\nsolutions. As far as we know, this is the first work that explores machine\nlearning and heuristics to solve MMCP. The unsupervised solver is inspired by a\nrelaxation-plus-rounding approach, the relaxed solution is parameterized by\ngraph neural networks, and the cost and penalty of MMCP are explicitly written\nout, which can train the model end-to-end. A crucial observation is that each\nsolution corresponds to at least one spanning tree. Based on this finding, a\nheuristic solver that implements tree transformations by adding vertices is\nutilized to repair and improve the solution quality of the unsupervised solver.\nAlternatively, the graph is simplified while guaranteeing solution consistency,\nwhich reduces the running time. We conduct extensive experiments to evaluate\nour framework and give a specific application. The results demonstrate the\nsuperiority of our method against two techniques designed.", "arxiv_id": "2408.08484v1", "pdf_url": "http://arxiv.org/pdf/2408.08484v1", "abstract_url": "http://arxiv.org/abs/2408.08484v1", "primary_category": "cs.AI", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "An Unsupervised Learning Framework Combined with Heuristics for the Maximum Minimal Cut Problem", "response": "RELEVANT", "timestamp": "2024-08-19T13:32:34.904304"}
{"title": "Enhancing Events in Neutrino Telescopes through Deep Learning-Driven Super-Resolution", "authors": "Felix J. Yu, Nicholas Kamp, Carlos A. Arg\u00fcelles", "abstract": "Recent discoveries by neutrino telescopes, such as the IceCube Neutrino\nObservatory, relied extensively on machine learning (ML) tools to infer\nphysical quantities from the raw photon hits detected. Neutrino telescope\nreconstruction algorithms are limited by the sparse sampling of photons by the\noptical modules due to the relatively large spacing ($10-100\\,{\\rm m})$ between\nthem. In this letter, we propose a novel technique that learns photon transport\nthrough the detector medium through the use of deep learning-driven\nsuper-resolution of data events. These ``improved'' events can then be\nreconstructed using traditional or ML techniques, resulting in improved\nresolution. Our strategy arranges additional ``virtual'' optical modules within\nan existing detector geometry and trains a convolutional neural network to\npredict the hits on these virtual optical modules. We show that this technique\nimproves the angular reconstruction of muons in a generic ice-based neutrino\ntelescope. Our results readily extend to water-based neutrino telescopes and\nother event morphologies.", "arxiv_id": "2408.08474v1", "pdf_url": "http://arxiv.org/pdf/2408.08474v1", "abstract_url": "http://arxiv.org/abs/2408.08474v1", "primary_category": "hep-ex", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Enhancing Events in Neutrino Telescopes through Deep Learning-Driven Super-Resolution", "response": "RELEVANT", "timestamp": "2024-08-19T13:32:35.713126"}
{"title": "Context-Aware Assistant Selection for Improved Inference Acceleration with Large Language Models", "authors": "Jerry Huang, Prasanna Parthasarathi, Mehdi Rezagholizadeh, Sarath Chandar", "abstract": "Despite their widespread adoption, large language models (LLMs) remain\nprohibitive to use under resource constraints, with their ever growing sizes\nonly increasing the barrier for use. One noted issue is the high latency\nassociated with auto-regressive generation, rendering large LLMs use dependent\non advanced computing infrastructure. Assisted decoding, where a smaller draft\nmodel guides a larger target model's generation, has helped alleviate this, but\nremains dependent on alignment between the two models. Thus if the draft model\nis insufficiently capable on some domain relative to the target model,\nperformance can degrade. Alternatively, one can leverage multiple draft models\nto better cover the expertise of the target, but when multiple black-box draft\nmodels are available, selecting an assistant without details about its\nconstruction can be difficult. To better understand this decision making\nproblem, we observe it as a contextual bandit, where a policy must choose a\ndraft model based on a context. We show that even without prior knowledge of\nthe draft models, creating an offline dataset from only outputs of independent\ndraft/target models and training a policy over the alignment of these outputs\ncan accelerate performance on multiple domains provided the candidates are\neffective. Further results show this to hold on various settings with multiple\nassisted decoding candidates, highlighting its flexibility and the advantageous\nrole that such decision making can play.", "arxiv_id": "2408.08470v1", "pdf_url": "http://arxiv.org/pdf/2408.08470v1", "abstract_url": "http://arxiv.org/abs/2408.08470v1", "primary_category": "cs.LG", "published_date": "2024-08-16", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Context-Aware Assistant Selection for Improved Inference Acceleration with Large Language Models", "response": "RELEVANT", "timestamp": "2024-08-19T13:32:36.744611"}
{"title": "JPEG-LM: LLMs as Image Generators with Canonical Codec Representations", "authors": "Xiaochuang Han, Marjan Ghazvininejad, Pang Wei Koh, Yulia Tsvetkov", "abstract": "Recent work in image and video generation has been adopting the\nautoregressive LLM architecture due to its generality and potentially easy\nintegration into multi-modal systems. The crux of applying autoregressive\ntraining in language generation to visual generation is discretization --\nrepresenting continuous data like images and videos as discrete tokens. Common\nmethods of discretizing images and videos include modeling raw pixel values,\nwhich are prohibitively lengthy, or vector quantization, which requires\nconvoluted pre-hoc training. In this work, we propose to directly model images\nand videos as compressed files saved on computers via canonical codecs (e.g.,\nJPEG, AVC/H.264). Using the default Llama architecture without any\nvision-specific modifications, we pretrain JPEG-LM from scratch to generate\nimages (and AVC-LM to generate videos as a proof of concept), by directly\noutputting compressed file bytes in JPEG and AVC formats. Evaluation of image\ngeneration shows that this simple and straightforward approach is more\neffective than pixel-based modeling and sophisticated vector quantization\nbaselines (on which our method yields a 31% reduction in FID). Our analysis\nshows that JPEG-LM has an especial advantage over vector quantization models in\ngenerating long-tail visual elements. Overall, we show that using canonical\ncodec representations can help lower the barriers between language generation\nand visual generation, facilitating future research on multi-modal\nlanguage/image/video LLMs.", "arxiv_id": "2408.08459v1", "pdf_url": "http://arxiv.org/pdf/2408.08459v1", "abstract_url": "http://arxiv.org/abs/2408.08459v1", "primary_category": "cs.CL", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "JPEG-LM: LLMs as Image Generators with Canonical Codec Representations", "response": "RELEVANT", "timestamp": "2024-08-19T13:32:37.651633"}
{"title": "Efficient Data-Sketches and Fine-Tuning for Early Detection of Distributional Drift in Medical Imaging", "authors": "Yusen Wu, Hao Chen, Alex Pissinou Makki, Phuong Nguyen, Yelena Yesha", "abstract": "Distributional drift detection is important in medical applications as it\nhelps ensure the accuracy and reliability of models by identifying changes in\nthe underlying data distribution that could affect diagnostic or treatment\ndecisions. However, current methods have limitations in detecting drift; for\nexample, the inclusion of abnormal datasets can lead to unfair comparisons.\nThis paper presents an accurate and sensitive approach to detect distributional\ndrift in CT-scan medical images by leveraging data-sketching and fine-tuning\ntechniques. We developed a robust baseline library model for real-time anomaly\ndetection, allowing for efficient comparison of incoming images and\nidentification of anomalies. Additionally, we fine-tuned a vision transformer\npre-trained model to extract relevant features using breast cancer images as an\nexample, significantly enhancing model accuracy to 99.11\\%. Combining with\ndata-sketches and fine-tuning, our feature extraction evaluation demonstrated\nthat cosine similarity scores between similar datasets provide greater\nimprovements, from around 50\\% increased to 100\\%. Finally, the sensitivity\nevaluation shows that our solutions are highly sensitive to even 1\\%\nsalt-and-pepper and speckle noise, and it is not sensitive to lighting noise\n(e.g., lighting conditions have no impact on data drift). The proposed methods\noffer a scalable and reliable solution for maintaining the accuracy of\ndiagnostic models in dynamic clinical environments.", "arxiv_id": "2408.08456v1", "pdf_url": "http://arxiv.org/pdf/2408.08456v1", "abstract_url": "http://arxiv.org/abs/2408.08456v1", "primary_category": "eess.IV", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Efficient Data-Sketches and Fine-Tuning for Early Detection of Distributional Drift in Medical Imaging", "response": "RELEVANT", "timestamp": "2024-08-19T13:32:38.746562"}
{"title": "Beyond Uniform Query Distribution: Key-Driven Grouped Query Attention", "authors": "Zohaib Khan, Muhammad Khaquan, Omer Tafveez, Agha Ali Raza", "abstract": "The Transformer architecture has revolutionized deep learning through its\nSelf-Attention mechanism, which effectively captures contextual information.\nHowever, the memory footprint of Self-Attention presents significant challenges\nfor long-sequence tasks. Grouped Query Attention (GQA) addresses this issue by\ngrouping queries and mean-pooling the corresponding key-value heads - reducing\nthe number of overall parameters and memory requirements in a flexible manner\nwithout adversely compromising model accuracy. In this work, we introduce\nenhancements to GQA, focusing on two novel approaches that deviate from the\nstatic nature of grouping: Key-Distributed GQA (KDGQA) and Dynamic\nKey-Distributed GQA (DGQA), which leverage information from the norms of the\nkey heads to inform query allocation. Specifically, KDGQA looks at the ratios\nof the norms of the key heads during each forward pass, while DGQA examines the\nratios of the norms as they evolve through training. Additionally, we present\nPerturbed GQA (PGQA) as a case-study, which introduces variability in (static)\ngroup formation via subtracting noise from the attention maps. Our experiments\nwith up-trained Vision Transformers, for Image Classification on datasets such\nas CIFAR-10, CIFAR-100, Food101, and Tiny ImageNet, demonstrate the promise of\nthese variants in improving upon the original GQA through more informed and\nadaptive grouping mechanisms: specifically ViT-L experiences accuracy gains of\nup to 8% when utilizing DGQA in comparison to GQA and other variants. We\nfurther analyze the impact of the number of Key-Value Heads on performance,\nunderscoring the importance of utilizing query-key affinities.", "arxiv_id": "2408.08454v1", "pdf_url": "http://arxiv.org/pdf/2408.08454v1", "abstract_url": "http://arxiv.org/abs/2408.08454v1", "primary_category": "cs.CV", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Beyond Uniform Query Distribution: Key-Driven Grouped Query Attention", "response": "RELEVANT", "timestamp": "2024-08-19T13:32:39.940996"}
{"title": "Exploring Cross-model Neuronal Correlations in the Context of Predicting Model Performance and Generalizability", "authors": "Haniyeh Ehsani Oskouie, Lionel Levine, Majid Sarrafzadeh", "abstract": "As Artificial Intelligence (AI) models are increasingly integrated into\ncritical systems, the need for a robust framework to establish the\ntrustworthiness of AI is increasingly paramount. While collaborative efforts\nhave established conceptual foundations for such a framework, there remains a\nsignificant gap in developing concrete, technically robust methods for\nassessing AI model quality and performance. A critical drawback in the\ntraditional methods for assessing the validity and generalizability of models\nis their dependence on internal developer datasets, rendering it challenging to\nindependently assess and verify their performance claims. This paper introduces\na novel approach for assessing a newly trained model's performance based on\nanother known model by calculating correlation between neural networks. The\nproposed method evaluates correlations by determining if, for each neuron in\none network, there exists a neuron in the other network that produces similar\noutput. This approach has implications for memory efficiency, allowing for the\nuse of smaller networks when high correlation exists between networks of\ndifferent sizes. Additionally, the method provides insights into robustness,\nsuggesting that if two highly correlated networks are compared and one\ndemonstrates robustness when operating in production environments, the other is\nlikely to exhibit similar robustness. This contribution advances the technical\ntoolkit for responsible AI, supporting more comprehensive and nuanced\nevaluations of AI models to ensure their safe and effective deployment.", "arxiv_id": "2408.08448v1", "pdf_url": "http://arxiv.org/pdf/2408.08448v1", "abstract_url": "http://arxiv.org/abs/2408.08448v1", "primary_category": "cs.LG", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Exploring Cross-model Neuronal Correlations in the Context of Predicting Model Performance and Generalizability", "response": "RELEVANT", "timestamp": "2024-08-19T13:32:40.735474"}
{"title": "Lifelong Reinforcement Learning via Neuromodulation", "authors": "Sebastian Lee, Samuel Liebana Garcia, Claudia Clopath, Will Dabney", "abstract": "Navigating multiple tasks$\\unicode{x2014}$for instance in succession as in\ncontinual or lifelong learning, or in distributions as in meta or multi-task\nlearning$\\unicode{x2014}$requires some notion of adaptation. Evolution over\ntimescales of millennia has imbued humans and other animals with highly\neffective adaptive learning and decision-making strategies. Central to these\nfunctions are so-called neuromodulatory systems. In this work we introduce an\nabstract framework for integrating theories and evidence from neuroscience and\nthe cognitive sciences into the design of adaptive artificial reinforcement\nlearning algorithms. We give a concrete instance of this framework built on\nliterature surrounding the neuromodulators Acetylcholine (ACh) and\nNoradrenaline (NA), and empirically validate the effectiveness of the resulting\nadaptive algorithm in a non-stationary multi-armed bandit problem. We conclude\nwith a theory-based experiment proposal providing an avenue to link our\nframework back to efforts in experimental neuroscience.", "arxiv_id": "2408.08446v1", "pdf_url": "http://arxiv.org/pdf/2408.08446v1", "abstract_url": "http://arxiv.org/abs/2408.08446v1", "primary_category": "cs.LG", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Lifelong Reinforcement Learning via Neuromodulation", "response": "RELEVANT", "timestamp": "2024-08-19T13:32:41.545575"}
{"title": "W-RAG: Weakly Supervised Dense Retrieval in RAG for Open-domain Question Answering", "authors": "Jinming Nian, Zhiyuan Peng, Qifan Wang, Yi Fang", "abstract": "In knowledge-intensive tasks such as open-domain question answering (OpenQA),\nLarge Language Models (LLMs) often struggle to generate factual answers relying\nsolely on their internal (parametric) knowledge. To address this limitation,\nRetrieval-Augmented Generation (RAG) systems enhance LLMs by retrieving\nrelevant information from external sources, thereby positioning the retriever\nas a pivotal component. Although dense retrieval demonstrates state-of-the-art\nperformance, its training poses challenges due to the scarcity of ground-truth\nevidence, largely attributed to the high costs of human annotation. In this\npaper, we propose W-RAG by utilizing the ranking capabilities of LLMs to create\nweakly labeled data for training dense retrievers. Specifically, we rerank the\ntop-$K$ passages retrieved via BM25 by assessing the probability that LLMs will\ngenerate the correct answer based on the question and each passage. The\nhighest-ranking passages are then used as positive training examples for dense\nretrieval. Our comprehensive experiments across four publicly available OpenQA\ndatasets demonstrate that our approach enhances both retrieval and OpenQA\nperformance compared to baseline models.", "arxiv_id": "2408.08444v1", "pdf_url": "http://arxiv.org/pdf/2408.08444v1", "abstract_url": "http://arxiv.org/abs/2408.08444v1", "primary_category": "cs.CL", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "W-RAG: Weakly Supervised Dense Retrieval in RAG for Open-domain Question Answering", "response": "RELEVANT", "timestamp": "2024-08-19T13:32:42.442799"}
{"title": "A semi-centralized multi-agent RL framework for efficient irrigation scheduling", "authors": "Bernard T. Agyeman, Benjamin Decard-Nelson, Jinfeng Liu, Sirish L. Shah", "abstract": "This paper proposes a Semi-Centralized Multi-Agent Reinforcement Learning\n(SCMARL) approach for irrigation scheduling in spatially variable agricultural\nfields, where management zones address spatial variability. The SCMARL\nframework is hierarchical in nature, with a centralized coordinator agent at\nthe top level and decentralized local agents at the second level. The\ncoordinator agent makes daily binary irrigation decisions based on field-wide\nconditions, which are communicated to the local agents. Local agents determine\nappropriate irrigation amounts for specific management zones using local\nconditions. The framework employs state augmentation approach to handle\nnon-stationarity in the local agents' environments. An extensive evaluation on\na large-scale field in Lethbridge, Canada, compares the SCMARL approach with a\nlearning-based multi-agent model predictive control scheduling approach,\nhighlighting its enhanced performance, resulting in water conservation and\nimproved Irrigation Water Use Efficiency (IWUE). Notably, the proposed approach\nachieved a 4.0% savings in irrigation water while enhancing the IWUE by 6.3%.", "arxiv_id": "2408.08442v1", "pdf_url": "http://arxiv.org/pdf/2408.08442v1", "abstract_url": "http://arxiv.org/abs/2408.08442v1", "primary_category": "eess.SY", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "A semi-centralized multi-agent RL framework for efficient irrigation scheduling", "response": "RELEVANT", "timestamp": "2024-08-19T13:32:43.388696"}
{"title": "D5RL: Diverse Datasets for Data-Driven Deep Reinforcement Learning", "authors": "Rafael Rafailov, Kyle Hatch, Anikait Singh, Laura Smith, Aviral Kumar, Ilya Kostrikov, Philippe Hansen-Estruch, Victor Kolev, Philip Ball, Jiajun Wu, Chelsea Finn, Sergey Levine", "abstract": "Offline reinforcement learning algorithms hold the promise of enabling\ndata-driven RL methods that do not require costly or dangerous real-world\nexploration and benefit from large pre-collected datasets. This in turn can\nfacilitate real-world applications, as well as a more standardized approach to\nRL research. Furthermore, offline RL methods can provide effective\ninitializations for online finetuning to overcome challenges with exploration.\nHowever, evaluating progress on offline RL algorithms requires effective and\nchallenging benchmarks that capture properties of real-world tasks, provide a\nrange of task difficulties, and cover a range of challenges both in terms of\nthe parameters of the domain (e.g., length of the horizon, sparsity of rewards)\nand the parameters of the data (e.g., narrow demonstration data or broad\nexploratory data). While considerable progress in offline RL in recent years\nhas been enabled by simpler benchmark tasks, the most widely used datasets are\nincreasingly saturating in performance and may fail to reflect properties of\nrealistic tasks. We propose a new benchmark for offline RL that focuses on\nrealistic simulations of robotic manipulation and locomotion environments,\nbased on models of real-world robotic systems, and comprising a variety of data\nsources, including scripted data, play-style data collected by human\nteleoperators, and other data sources. Our proposed benchmark covers\nstate-based and image-based domains, and supports both offline RL and online\nfine-tuning evaluation, with some of the tasks specifically designed to require\nboth pre-training and fine-tuning. We hope that our proposed benchmark will\nfacilitate further progress on both offline RL and fine-tuning algorithms.\nWebsite with code, examples, tasks, and data is available at\n\\url{https://sites.google.com/view/d5rl/}", "arxiv_id": "2408.08441v1", "pdf_url": "http://arxiv.org/pdf/2408.08441v1", "abstract_url": "http://arxiv.org/abs/2408.08441v1", "primary_category": "cs.LG", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "D5RL: Diverse Datasets for Data-Driven Deep Reinforcement Learning", "response": "RELEVANT", "timestamp": "2024-08-19T13:32:44.207684"}
{"title": "Predictive uncertainty estimation in deep learning for lung carcinoma classification in digital pathology under real dataset shifts", "authors": "Abdur R. Fayjie, Jutika Borah, Florencia Carbone, Jan Tack, Patrick Vandewalle", "abstract": "Deep learning has shown tremendous progress in a wide range of digital\npathology and medical image classification tasks. Its integration into safe\nclinical decision-making support requires robust and reliable models. However,\nreal-world data comes with diversities that often lie outside the intended\nsource distribution. Moreover, when test samples are dramatically different,\nclinical decision-making is greatly affected. Quantifying predictive\nuncertainty in models is crucial for well-calibrated predictions and\ndetermining when (or not) to trust a model. Unfortunately, many works have\noverlooked the importance of predictive uncertainty estimation. This paper\nevaluates whether predictive uncertainty estimation adds robustness to deep\nlearning-based diagnostic decision-making systems. We investigate the effect of\nvarious carcinoma distribution shift scenarios on predictive performance and\ncalibration. We first systematically investigate three popular methods for\nimproving predictive uncertainty: Monte Carlo dropout, deep ensemble, and\nfew-shot learning on lung adenocarcinoma classification as a primary disease in\nwhole slide images. Secondly, we compare the effectiveness of the methods in\nterms of performance and calibration under clinically relevant distribution\nshifts such as in-distribution shifts comprising primary disease sub-types and\nother characterization analysis data; out-of-distribution shifts comprising\nwell-differentiated cases, different organ origin, and imaging modality shifts.\nWhile studies on uncertainty estimation exist, to our best knowledge, no\nrigorous large-scale benchmark compares predictive uncertainty estimation\nincluding these dataset shifts for lung carcinoma classification.", "arxiv_id": "2408.08432v1", "pdf_url": "http://arxiv.org/pdf/2408.08432v1", "abstract_url": "http://arxiv.org/abs/2408.08432v1", "primary_category": "eess.IV", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Predictive uncertainty estimation in deep learning for lung carcinoma classification in digital pathology under real dataset shifts", "response": "RELEVANT", "timestamp": "2024-08-19T13:32:45.129734"}
{"title": "Random Gradient Masking as a Defensive Measure to Deep Leakage in Federated Learning", "authors": "Joon Kim, Sejin Park", "abstract": "Federated Learning(FL), in theory, preserves privacy of individual clients'\ndata while producing quality machine learning models. However, attacks such as\nDeep Leakage from Gradients(DLG) severely question the practicality of FL. In\nthis paper, we empirically evaluate the efficacy of four defensive methods\nagainst DLG: Masking, Clipping, Pruning, and Noising. Masking, while only\npreviously studied as a way to compress information during parameter transfer,\nshows surprisingly robust defensive utility when compared to the other three\nestablished methods. Our experimentation is two-fold. We first evaluate the\nminimum hyperparameter threshold for each method across MNIST, CIFAR-10, and\nlfw datasets. Then, we train FL clients with each method and their minimum\nthreshold values to investigate the trade-off between DLG defense and training\nperformance. Results reveal that Masking and Clipping show near to none\ndegradation in performance while obfuscating enough information to effectively\ndefend against DLG.", "arxiv_id": "2408.08430v1", "pdf_url": "http://arxiv.org/pdf/2408.08430v1", "abstract_url": "http://arxiv.org/abs/2408.08430v1", "primary_category": "cs.LG", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Random Gradient Masking as a Defensive Measure to Deep Leakage in Federated Learning", "response": "RELEVANT", "timestamp": "2024-08-19T13:32:46.053735"}
{"title": "Phononic materials with effectively scale-separated hierarchical features using interpretable machine learning", "authors": "Mary V. Bastawrous, Zhi Chen, Alexander C. Ogren, Chiara Daraio, Cynthia Rudin, L. Catherine Brinson", "abstract": "Manipulating the dispersive characteristics of vibrational waves is\nbeneficial for many applications, e.g., high-precision instruments. architected\nhierarchical phononic materials have sparked promise tunability of\nelastodynamic waves and vibrations over multiple frequency ranges. In this\narticle, hierarchical unit-cells are obtained, where features at each length\nscale result in a band gap within a targeted frequency range. Our novel\napproach, the ``hierarchical unit-cell template method,'' is an interpretable\nmachine-learning approach that uncovers global unit-cell shape/topology\npatterns corresponding to predefined band-gap objectives. A scale-separation\neffect is observed where the coarse-scale band-gap objective is mostly\nunaffected by the fine-scale features despite the closeness of their length\nscales, thus enabling an efficient hierarchical algorithm. Moreover, the\nhierarchical patterns revealed are not predefined or self-similar hierarchies\nas common in current hierarchical phononic materials. Thus, our approach offers\na flexible and efficient method for the exploration of new regions in the\nhierarchical design space, extracting minimal effective patterns for inverse\ndesign in applications targeting multiple frequency ranges.", "arxiv_id": "2408.08428v1", "pdf_url": "http://arxiv.org/pdf/2408.08428v1", "abstract_url": "http://arxiv.org/abs/2408.08428v1", "primary_category": "physics.app-ph", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Phononic materials with effectively scale-separated hierarchical features using interpretable machine learning", "response": "RELEVANT", "timestamp": "2024-08-19T13:32:46.869690"}
{"title": "An Efficient and Explainable Transformer-Based Few-Shot Learning for Modeling Electricity Consumption Profiles Across Thousands of Domains", "authors": "Weijie Xia, Gao Peng, Chenguang Wang, Peter Palensky, Eric Pauwels, Pedro P. Vergara", "abstract": "Electricity Consumption Profiles (ECPs) are crucial for operating and\nplanning power distribution systems, especially with the increasing numbers of\nvarious low-carbon technologies such as solar panels and electric vehicles.\nTraditional ECP modeling methods typically assume the availability of\nsufficient ECP data. However, in practice, the accessibility of ECP data is\nlimited due to privacy issues or the absence of metering devices. Few-shot\nlearning (FSL) has emerged as a promising solution for ECP modeling in\ndata-scarce scenarios. Nevertheless, standard FSL methods, such as those used\nfor images, are unsuitable for ECP modeling because (1) these methods usually\nassume several source domains with sufficient data and several target domains.\nHowever, in the context of ECP modeling, there may be thousands of source\ndomains with a moderate amount of data and thousands of target domains. (2)\nStandard FSL methods usually involve cumbersome knowledge transfer mechanisms,\nsuch as pre-training and fine-tuning, whereas ECP modeling requires more\nlightweight methods. (3) Deep learning models often lack explainability,\nhindering their application in industry. This paper proposes a novel FSL method\nthat exploits Transformers and Gaussian Mixture Models (GMMs) for ECP modeling\nto address the above-described issues. Results show that our method can\naccurately restore the complex ECP distribution with a minimal amount of ECP\ndata (e.g., only 1.6\\% of the complete domain dataset) while it outperforms\nstate-of-the-art time series modeling methods, maintaining the advantages of\nbeing both lightweight and interpretable. The project is open-sourced at\nhttps://github.com/xiaweijie1996/TransformerEM-GMM.git.", "arxiv_id": "2408.08399v1", "pdf_url": "http://arxiv.org/pdf/2408.08399v1", "abstract_url": "http://arxiv.org/abs/2408.08399v1", "primary_category": "cs.LG", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "An Efficient and Explainable Transformer-Based Few-Shot Learning for Modeling Electricity Consumption Profiles Across Thousands of Domains", "response": "RELEVANT", "timestamp": "2024-08-19T13:32:48.637875"}
{"title": "Classification of High-dimensional Time Series in Spectral Domain using Explainable Features", "authors": "Sarbojit Roy, Malik Shahid Sultan, Hernando Ombao", "abstract": "Interpretable classification of time series presents significant challenges\nin high dimensions. Traditional feature selection methods in the frequency\ndomain often assume sparsity in spectral density matrices (SDMs) or their\ninverses, which can be restrictive for real-world applications. In this\narticle, we propose a model-based approach for classifying high-dimensional\nstationary time series by assuming sparsity in the difference between inverse\nSDMs. Our approach emphasizes the interpretability of model parameters, making\nit especially suitable for fields like neuroscience, where understanding\ndifferences in brain network connectivity across various states is crucial. The\nestimators for model parameters demonstrate consistency under appropriate\nconditions. We further propose using standard deep learning optimizers for\nparameter estimation, employing techniques such as mini-batching and learning\nrate scheduling. Additionally, we introduce a method to screen the most\ndiscriminatory frequencies for classification, which exhibits the sure\nscreening property under general conditions. The flexibility of the proposed\nmodel allows the significance of covariates to vary across frequencies,\nenabling nuanced inferences and deeper insights into the underlying problem.\nThe novelty of our method lies in the interpretability of the model parameters,\naddressing critical needs in neuroscience. The proposed approaches have been\nevaluated on simulated examples and the `Alert-vs-Drowsy' EEG dataset.", "arxiv_id": "2408.08388v1", "pdf_url": "http://arxiv.org/pdf/2408.08388v1", "abstract_url": "http://arxiv.org/abs/2408.08388v1", "primary_category": "stat.ML", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Classification of High-dimensional Time Series in Spectral Domain using Explainable Features", "response": "RELEVANT", "timestamp": "2024-08-19T13:32:50.671851"}
{"title": "Pre-processing and Compression: Understanding Hidden Representation Refinement Across Imaging Domains via Intrinsic Dimension", "authors": "Nicholas Konz, Maciej A. Mazurowski", "abstract": "In recent years, there has been interest in how geometric properties such as\nintrinsic dimension (ID) of a neural network's hidden representations evolve\nthrough its layers, and how such properties are predictive of important model\nbehavior such as generalization ability. However, evidence has begun to emerge\nthat such behavior can change significantly depending on the domain of the\nnetwork's training data, such as natural versus medical images. Here, we\nfurther this inquiry by exploring how the ID of a network's learned\nrepresentations evolves through its layers, in essence, characterizing how the\nnetwork successively refines the information content of input data to be used\nfor predictions. Analyzing eleven natural and medical image datasets across six\nnetwork architectures, we find that the shape of this ID evolution curve\ndiffers noticeably between natural and medical image models: medical image\nmodels peak in representation ID earlier in the network, implying a difference\nin the image features and their abstractness that are typically used for\ndownstream tasks in these domains. Additionally, we discover a strong\ncorrelation of this peak representation ID with the ID of the data in its input\nspace, implying that the intrinsic information content of a model's learned\nrepresentations is guided by that of the data it was trained on. Overall, our\nfindings emphasize notable discrepancies in network behavior between natural\nand non-natural imaging domains regarding hidden representation information\ncontent, and provide further insights into how a network's learned features are\nshaped by its training data.", "arxiv_id": "2408.08381v1", "pdf_url": "http://arxiv.org/pdf/2408.08381v1", "abstract_url": "http://arxiv.org/abs/2408.08381v1", "primary_category": "cs.CV", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Pre-processing and Compression: Understanding Hidden Representation Refinement Across Imaging Domains via Intrinsic Dimension", "response": "RELEVANT", "timestamp": "2024-08-19T13:32:51.388315"}
{"title": "Towards Realistic Synthetic User-Generated Content: A Scaffolding Approach to Generating Online Discussions", "authors": "Krisztian Balog, John Palowitch, Barbara Ikica, Filip Radlinski, Hamidreza Alvari, Mehdi Manshadi", "abstract": "The emergence of synthetic data represents a pivotal shift in modern machine\nlearning, offering a solution to satisfy the need for large volumes of data in\ndomains where real data is scarce, highly private, or difficult to obtain. We\ninvestigate the feasibility of creating realistic, large-scale synthetic\ndatasets of user-generated content, noting that such content is increasingly\nprevalent and a source of frequently sought information. Large language models\n(LLMs) offer a starting point for generating synthetic social media discussion\nthreads, due to their ability to produce diverse responses that typify online\ninteractions. However, as we demonstrate, straightforward application of LLMs\nyields limited success in capturing the complex structure of online\ndiscussions, and standard prompting mechanisms lack sufficient control. We\ntherefore propose a multi-step generation process, predicated on the idea of\ncreating compact representations of discussion threads, referred to as\nscaffolds. Our framework is generic yet adaptable to the unique characteristics\nof specific social media platforms. We demonstrate its feasibility using data\nfrom two distinct online discussion platforms. To address the fundamental\nchallenge of ensuring the representativeness and realism of synthetic data, we\npropose a portfolio of evaluation measures to compare various instantiations of\nour framework.", "arxiv_id": "2408.08379v1", "pdf_url": "http://arxiv.org/pdf/2408.08379v1", "abstract_url": "http://arxiv.org/abs/2408.08379v1", "primary_category": "cs.CL", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Towards Realistic Synthetic User-Generated Content: A Scaffolding Approach to Generating Online Discussions", "response": "RELEVANT", "timestamp": "2024-08-19T13:32:52.204194"}
{"title": "Evaluating Text Classification Robustness to Part-of-Speech Adversarial Examples", "authors": "Anahita Samadi, Allison Sullivan", "abstract": "As machine learning systems become more widely used, especially for safety\ncritical applications, there is a growing need to ensure that these systems\nbehave as intended, even in the face of adversarial examples. Adversarial\nexamples are inputs that are designed to trick the decision making process, and\nare intended to be imperceptible to humans. However, for text-based\nclassification systems, changes to the input, a string of text, are always\nperceptible. Therefore, text-based adversarial examples instead focus on trying\nto preserve semantics. Unfortunately, recent work has shown this goal is often\nnot met. To improve the quality of text-based adversarial examples, we need to\nknow what elements of the input text are worth focusing on. To address this, in\nthis paper, we explore what parts of speech have the highest impact of\ntext-based classifiers. Our experiments highlight a distinct bias in CNN\nalgorithms against certain parts of speech tokens within review datasets. This\nfinding underscores a critical vulnerability in the linguistic processing\ncapabilities of CNNs.", "arxiv_id": "2408.08374v1", "pdf_url": "http://arxiv.org/pdf/2408.08374v1", "abstract_url": "http://arxiv.org/abs/2408.08374v1", "primary_category": "cs.CL", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Evaluating Text Classification Robustness to Part-of-Speech Adversarial Examples", "response": "RELEVANT", "timestamp": "2024-08-19T13:32:53.115421"}
{"title": "Can Large Language Models Understand Symbolic Graphics Programs?", "authors": "Zeju Qiu, Weiyang Liu, Haiwen Feng, Zhen Liu, Tim Z. Xiao, Katherine M. Collins, Joshua B. Tenenbaum, Adrian Weller, Michael J. Black, Bernhard Sch\u00f6lkopf", "abstract": "Assessing the capabilities of large language models (LLMs) is often\nchallenging, in part, because it is hard to find tasks to which they have not\nbeen exposed during training. We take one step to address this challenge by\nturning to a new task: focusing on symbolic graphics programs, which are a\npopular representation for graphics content that procedurally generates visual\ndata. LLMs have shown exciting promise towards program synthesis, but do they\nunderstand symbolic graphics programs? Unlike conventional programs, symbolic\ngraphics programs can be translated to graphics content. Here, we characterize\nan LLM's understanding of symbolic programs in terms of their ability to answer\nquestions related to the graphics content. This task is challenging as the\nquestions are difficult to answer from the symbolic programs alone -- yet, they\nwould be easy to answer from the corresponding graphics content as we verify\nthrough a human experiment. To understand symbolic programs, LLMs may need to\npossess the ability to imagine how the corresponding graphics content would\nlook without directly accessing the rendered visual content. We use this task\nto evaluate LLMs by creating a large benchmark for the semantic understanding\nof symbolic graphics programs. This benchmark is built via program-graphics\ncorrespondence, hence requiring minimal human efforts. We evaluate current LLMs\non our benchmark to elucidate a preliminary assessment of their ability to\nreason about visual scenes from programs. We find that this task distinguishes\nexisting LLMs and models considered good at reasoning perform better. Lastly,\nwe introduce Symbolic Instruction Tuning (SIT) to improve this ability.\nSpecifically, we query GPT4-o with questions and images generated by symbolic\nprograms. Such data are then used to finetune an LLM. We also find that SIT\ndata can improve the general instruction following ability of LLMs.", "arxiv_id": "2408.08313v1", "pdf_url": "http://arxiv.org/pdf/2408.08313v1", "abstract_url": "http://arxiv.org/abs/2408.08313v1", "primary_category": "cs.LG", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Can Large Language Models Understand Symbolic Graphics Programs?", "response": "RELEVANT", "timestamp": "2024-08-19T13:32:53.933615"}
{"title": "Understanding the Local Geometry of Generative Model Manifolds", "authors": "Ahmed Imtiaz Humayun, Ibtihel Amara, Candice Schumann, Golnoosh Farnadi, Negar Rostamzadeh, Mohammad Havaei", "abstract": "Deep generative models learn continuous representations of complex data\nmanifolds using a finite number of samples during training. For a pre-trained\ngenerative model, the common way to evaluate the quality of the manifold\nrepresentation learned, is by computing global metrics like Fr\\'echet Inception\nDistance using a large number of generated and real samples. However,\ngenerative model performance is not uniform across the learned manifold, e.g.,\nfor \\textit{foundation models} like Stable Diffusion generation performance can\nvary significantly based on the conditioning or initial noise vector being\ndenoised. In this paper we study the relationship between the \\textit{local\ngeometry of the learned manifold} and downstream generation. Based on the\ntheory of continuous piecewise-linear (CPWL) generators, we use three geometric\ndescriptors - scaling ($\\psi$), rank ($\\nu$), and complexity ($\\delta$) - to\ncharacterize a pre-trained generative model manifold locally. We provide\nquantitative and qualitative evidence showing that for a given latent, the\nlocal descriptors are correlated with generation aesthetics, artifacts,\nuncertainty, and even memorization. Finally we demonstrate that training a\n\\textit{reward model} on the local geometry can allow controlling the\nlikelihood of a generated sample under the learned distribution.", "arxiv_id": "2408.08307v1", "pdf_url": "http://arxiv.org/pdf/2408.08307v1", "abstract_url": "http://arxiv.org/abs/2408.08307v1", "primary_category": "cs.LG", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Understanding the Local Geometry of Generative Model Manifolds", "response": "RELEVANT", "timestamp": "2024-08-19T13:32:54.990168"}
{"title": "Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors", "authors": "Usman Syed, Ethan Light, Xingang Guo, Huan Zhang, Lianhui Qin, Yanfeng Ouyang, Bin Hu", "abstract": "In this paper, we explore the capabilities of state-of-the-art large language\nmodels (LLMs) such as GPT-4, GPT-4o, Claude 3.5 Sonnet, Claude 3 Opus, Gemini\n1.5 Pro, Llama 3, and Llama 3.1 in solving some selected undergraduate-level\ntransportation engineering problems. We introduce TransportBench, a benchmark\ndataset that includes a sample of transportation engineering problems on a wide\nrange of subjects in the context of planning, design, management, and control\nof transportation systems. This dataset is used by human experts to evaluate\nthe capabilities of various commercial and open-sourced LLMs, especially their\naccuracy, consistency, and reasoning behaviors, in solving transportation\nengineering problems. Our comprehensive analysis uncovers the unique strengths\nand limitations of each LLM, e.g. our analysis shows the impressive accuracy\nand some unexpected inconsistent behaviors of Claude 3.5 Sonnet in solving\nTransportBench problems. Our study marks a thrilling first step toward\nharnessing artificial general intelligence for complex transportation\nchallenges.", "arxiv_id": "2408.08302v1", "pdf_url": "http://arxiv.org/pdf/2408.08302v1", "abstract_url": "http://arxiv.org/abs/2408.08302v1", "primary_category": "cs.AI", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors", "response": "RELEVANT", "timestamp": "2024-08-19T13:32:55.685658"}
{"title": "HELP: Hierarchical Embeddings-based Log Parsing", "authors": "Andy Xu, Arno Gau", "abstract": "Logs are a first-hand source of information for software maintenance and\nfailure diagnosis. Log parsing, which converts semi-structured log messages\ninto structured templates, is a prerequisite for automated log analysis tasks\nsuch as anomaly detection, troubleshooting, and root cause analysis. However,\nexisting log parsers fail in real-world systems for three main reasons. First,\ntraditional heuristics-based parsers require handcrafted features and domain\nknowledge, which are difficult to generalize at scale. Second, existing large\nlanguage model-based parsers rely on periodic offline processing, limiting\ntheir effectiveness in real-time use cases. Third, existing online parsing\nalgorithms are susceptible to log drift, where slight log changes create false\npositives that drown out real anomalies. To address these challenges, we\npropose HELP, a Hierarchical Embeddings-based Log Parser. HELP is the first\nonline semantic-based parser to leverage LLMs for performant and cost-effective\nlog parsing. We achieve this through a novel hierarchical embeddings module,\nwhich fine-tunes a text embedding model to cluster logs before parsing,\nreducing querying costs by multiple orders of magnitude. To combat log drift,\nwe also develop an iterative rebalancing module, which periodically updates\nexisting log groupings. We evaluate HELP extensively on 14 public large-scale\ndatasets, showing that HELP achieves significantly higher F1-weighted grouping\nand parsing accuracy than current state-of-the-art online log parsers. We also\nimplement HELP into Iudex's production observability platform, confirming\nHELP's practicality in a production environment. Our results show that HELP is\neffective and efficient for high-throughput real-world log parsing.", "arxiv_id": "2408.08300v1", "pdf_url": "http://arxiv.org/pdf/2408.08300v1", "abstract_url": "http://arxiv.org/abs/2408.08300v1", "primary_category": "cs.SE", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "HELP: Hierarchical Embeddings-based Log Parsing", "response": "RELEVANT", "timestamp": "2024-08-19T13:32:56.597882"}
{"title": "SLCA++: Unleash the Power of Sequential Fine-tuning for Continual Learning with Pre-training", "authors": "Gengwei Zhang, Liyuan Wang, Guoliang Kang, Ling Chen, Yunchao Wei", "abstract": "In recent years, continual learning with pre-training (CLPT) has received\nwidespread interest, instead of its traditional focus of training from scratch.\nThe use of strong pre-trained models (PTMs) can greatly facilitate knowledge\ntransfer and alleviate catastrophic forgetting, but also suffers from\nprogressive overfitting of pre-trained knowledge into specific downstream\ntasks. A majority of current efforts often keep the PTMs frozen and incorporate\ntask-specific prompts to instruct representation learning, coupled with a\nprompt selection process for inference. However, due to the limited capacity of\nprompt parameters, this strategy demonstrates only sub-optimal performance in\ncontinual learning. In comparison, tuning all parameters of PTMs often provides\nthe greatest potential for representation learning, making sequential\nfine-tuning (Seq FT) a fundamental baseline that has been overlooked in CLPT.\nTo this end, we present an in-depth analysis of the progressive overfitting\nproblem from the lens of Seq FT. Considering that the overly fast\nrepresentation learning and the biased classification layer constitute this\nparticular problem, we introduce the advanced Slow Learner with Classifier\nAlignment (SLCA++) framework to unleash the power of Seq FT, serving as a\nstrong baseline approach for CLPT. Our approach involves a Slow Learner to\nselectively reduce the learning rate of backbone parameters, and a Classifier\nAlignment to align the disjoint classification layers in a post-hoc fashion. We\nfurther enhance the efficacy of SL with a symmetric cross-entropy loss, as well\nas employ a parameter-efficient strategy to implement Seq FT with SLCA++.\nAcross a variety of continual learning scenarios on image classification\nbenchmarks, our approach provides substantial improvements and outperforms\nstate-of-the-art methods by a large margin. Code:\nhttps://github.com/GengDavid/SLCA.", "arxiv_id": "2408.08295v1", "pdf_url": "http://arxiv.org/pdf/2408.08295v1", "abstract_url": "http://arxiv.org/abs/2408.08295v1", "primary_category": "cs.CV", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "SLCA++: Unleash the Power of Sequential Fine-tuning for Continual Learning with Pre-training", "response": "RELEVANT", "timestamp": "2024-08-19T13:32:57.626638"}
{"title": "Aliasing and Label-Independent Decomposition of Risk: Beyond the bias-variance trade-off", "authors": "Mark K. Transtrum, Gus L. W. Hart, Tyler J. Jarvis, Jared P. Whitehead", "abstract": "A central problem in data science is to use potentially noisy samples of an\nunknown function to predict function values for unseen inputs. In classical\nstatistics, the predictive error is understood as a trade-off between the bias\nand the variance that balances model simplicity with its ability to fit complex\nfunctions. However, over-parameterized models exhibit counter-intuitive\nbehaviors, such as \"double descent\" in which models of increasing complexity\nexhibit decreasing generalization error. We introduce an alternative paradigm\ncalled the generalized aliasing decomposition. We explain the asymptotically\nsmall error of complex models as a systematic \"de-aliasing\" that occurs in the\nover-parameterized regime. In the limit of large models, the contribution due\nto aliasing vanishes, leaving an expression for the asymptotic total error we\ncall the invertibility failure of very large models on few training points.\nBecause the generalized aliasing decomposition can be explicitly calculated\nfrom the relationship between model class and samples without seeing any data\nlabels, it can answer questions related to experimental design and model\nselection before collecting data or performing experiments. We demonstrate this\napproach using several examples, including classical regression problems and a\ncluster expansion model used in materials science.", "arxiv_id": "2408.08294v1", "pdf_url": "http://arxiv.org/pdf/2408.08294v1", "abstract_url": "http://arxiv.org/abs/2408.08294v1", "primary_category": "math.ST", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Aliasing and Label-Independent Decomposition of Risk: Beyond the bias-variance trade-off", "response": "RELEVANT", "timestamp": "2024-08-19T13:32:58.329061"}
{"title": "Absence of Closed-Form Descriptions for Gradient Flow in Two-Layer Narrow Networks", "authors": "Yeachan Park", "abstract": "In the field of machine learning, comprehending the intricate training\ndynamics of neural networks poses a significant challenge. This paper explores\nthe training dynamics of neural networks, particularly whether these dynamics\ncan be expressed in a general closed-form solution. We demonstrate that the\ndynamics of the gradient flow in two-layer narrow networks is not an integrable\nsystem. Integrable systems are characterized by trajectories confined to\nsubmanifolds defined by level sets of first integrals (invariants),\nfacilitating predictable and reducible dynamics. In contrast, non-integrable\nsystems exhibit complex behaviors that are difficult to predict. To establish\nthe non-integrability, we employ differential Galois theory, which focuses on\nthe solvability of linear differential equations. We demonstrate that under\nmild conditions, the identity component of the differential Galois group of the\nvariational equations of the gradient flow is non-solvable. This result\nconfirms the system's non-integrability and implies that the training dynamics\ncannot be represented by Liouvillian functions, precluding a closed-form\nsolution for describing these dynamics. Our findings highlight the necessity of\nemploying numerical methods to tackle optimization problems within neural\nnetworks. The results contribute to a deeper understanding of neural network\ntraining dynamics and their implications for machine learning optimization\nstrategies.", "arxiv_id": "2408.08286v1", "pdf_url": "http://arxiv.org/pdf/2408.08286v1", "abstract_url": "http://arxiv.org/abs/2408.08286v1", "primary_category": "cs.LG", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Absence of Closed-Form Descriptions for Gradient Flow in Two-Layer Narrow Networks", "response": "RELEVANT", "timestamp": "2024-08-19T13:32:59.261122"}
{"title": "Accurate and efficient structure elucidation from routine one-dimensional NMR spectra using multitask machine learning", "authors": "Frank Hu, Michael S. Chen, Grant M. Rotskoff, Matthew W. Kanan, Thomas E. Markland", "abstract": "Rapid determination of molecular structures can greatly accelerate workflows\nacross many chemical disciplines. However, elucidating structure using only\none-dimensional (1D) NMR spectra, the most readily accessible data, remains an\nextremely challenging problem because of the combinatorial explosion of the\nnumber of possible molecules as the number of constituent atoms is increased.\nHere, we introduce a multitask machine learning framework that predicts the\nmolecular structure (formula and connectivity) of an unknown compound solely\nbased on its 1D 1H and/or 13C NMR spectra. First, we show how a transformer\narchitecture can be constructed to efficiently solve the task, traditionally\nperformed by chemists, of assembling large numbers of molecular fragments into\nmolecular structures. Integrating this capability with a convolutional neural\nnetwork (CNN), we build an end-to-end model for predicting structure from\nspectra that is fast and accurate. We demonstrate the effectiveness of this\nframework on molecules with up to 19 heavy (non-hydrogen) atoms, a size for\nwhich there are trillions of possible structures. Without relying on any prior\nchemical knowledge such as the molecular formula, we show that our approach\npredicts the exact molecule 69.6% of the time within the first 15 predictions,\nreducing the search space by up to 11 orders of magnitude.", "arxiv_id": "2408.08284v1", "pdf_url": "http://arxiv.org/pdf/2408.08284v1", "abstract_url": "http://arxiv.org/abs/2408.08284v1", "primary_category": "physics.chem-ph", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Accurate and efficient structure elucidation from routine one-dimensional NMR spectra using multitask machine learning", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:00.061067"}
{"title": "Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model", "authors": "Jin Wang, Arturo Laurenzi, Nikos Tsagarakis", "abstract": "Enabling humanoid robots to perform autonomously loco-manipulation in\nunstructured environments is crucial and highly challenging for achieving\nembodied intelligence. This involves robots being able to plan their actions\nand behaviors in long-horizon tasks while using multi-modality to perceive\ndeviations between task execution and high-level planning. Recently, large\nlanguage models (LLMs) have demonstrated powerful planning and reasoning\ncapabilities for comprehension and processing of semantic information through\nrobot control tasks, as well as the usability of analytical judgment and\ndecision-making for multi-modal inputs. To leverage the power of LLMs towards\nhumanoid loco-manipulation, we propose a novel language-model based framework\nthat enables robots to autonomously plan behaviors and low-level execution\nunder given textual instructions, while observing and correcting failures that\nmay occur during task execution. To systematically evaluate this framework in\ngrounding LLMs, we created the robot 'action' and 'sensing' behavior library\nfor task planning, and conducted mobile manipulation tasks and experiments in\nboth simulated and real environments using the CENTAURO robot, and verified the\neffectiveness and application of this approach in robotic tasks with autonomous\nbehavioral planning.", "arxiv_id": "2408.08282v1", "pdf_url": "http://arxiv.org/pdf/2408.08282v1", "abstract_url": "http://arxiv.org/abs/2408.08282v1", "primary_category": "cs.RO", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:00.880664"}
{"title": "BAM! Just Like That: Simple and Efficient Parameter Upcycling for Mixture of Experts", "authors": "Qizhen Zhang, Nikolas Gritsch, Dwaraknath Gnaneshwar, Simon Guo, David Cairuz, Bharat Venkitesh, Jakob Foerster, Phil Blunsom, Sebastian Ruder, Ahmet Ustun, Acyr Locatelli", "abstract": "The Mixture of Experts (MoE) framework has become a popular architecture for\nlarge language models due to its superior performance over dense models.\nHowever, training MoEs from scratch in a large-scale regime is prohibitively\nexpensive. Existing methods mitigate this by pre-training multiple dense expert\nmodels independently and using them to initialize an MoE. This is done by using\nexperts' feed-forward network (FFN) to initialize the MoE's experts while\nmerging other parameters. However, this method limits the reuse of dense model\nparameters to only the FFN layers, thereby constraining the advantages when\n\"upcycling\" these models into MoEs. We propose BAM (Branch-Attend-Mix), a\nsimple yet effective method that addresses this shortcoming. BAM makes full use\nof specialized dense models by not only using their FFN to initialize the MoE\nlayers but also leveraging experts' attention parameters fully by initializing\nthem into a soft-variant of Mixture of Attention (MoA) layers. We explore two\nmethods for upcycling attention parameters: 1) initializing separate attention\nexperts from dense models including all attention parameters for the best model\nperformance; and 2) sharing key and value parameters across all experts to\nfacilitate for better inference efficiency. To further improve efficiency, we\nadopt a parallel attention transformer architecture to MoEs, which allows the\nattention experts and FFN experts to be computed concurrently. Our experiments\non seed models ranging from 590 million to 2 billion parameters demonstrate\nthat BAM surpasses baselines in both perplexity and downstream task\nperformance, within the same computational and data constraints.", "arxiv_id": "2408.08274v1", "pdf_url": "http://arxiv.org/pdf/2408.08274v1", "abstract_url": "http://arxiv.org/abs/2408.08274v1", "primary_category": "cs.LG", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "BAM! Just Like That: Simple and Efficient Parameter Upcycling for Mixture of Experts", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:01.851977"}
{"title": "Is Knowledge Power? On the (Im)possibility of Learning from Strategic Interaction", "authors": "Nivasini Ananthakrishnan, Nika Haghtalab, Chara Podimata, Kunhe Yang", "abstract": "When learning in strategic environments, a key question is whether agents can\novercome uncertainty about their preferences to achieve outcomes they could\nhave achieved absent any uncertainty. Can they do this solely through\ninteractions with each other? We focus this question on the ability of agents\nto attain the value of their Stackelberg optimal strategy and study the impact\nof information asymmetry. We study repeated interactions in fully strategic\nenvironments where players' actions are decided based on learning algorithms\nthat take into account their observed histories and knowledge of the game. We\nstudy the pure Nash equilibria (PNE) of a meta-game where players choose these\nalgorithms as their actions. We demonstrate that if one player has perfect\nknowledge about the game, then any initial informational gap persists. That is,\nwhile there is always a PNE in which the informed agent achieves her\nStackelberg value, there is a game where no PNE of the meta-game allows the\npartially informed player to achieve her Stackelberg value. On the other hand,\nif both players start with some uncertainty about the game, the quality of\ninformation alone does not determine which agent can achieve her Stackelberg\nvalue. In this case, the concept of information asymmetry becomes nuanced and\ndepends on the game's structure. Overall, our findings suggest that repeated\nstrategic interactions alone cannot facilitate learning effectively enough to\nearn an uninformed player her Stackelberg value.", "arxiv_id": "2408.08272v1", "pdf_url": "http://arxiv.org/pdf/2408.08272v1", "abstract_url": "http://arxiv.org/abs/2408.08272v1", "primary_category": "cs.GT", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Is Knowledge Power? On the (Im)possibility of Learning from Strategic Interaction", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:02.814134"}
{"title": "InVAErt networks for amortized inference and identifiability analysis of lumped parameter hemodynamic models", "authors": "Guoxiang Grayson Tong, Carlos A. Sing Long, Daniele E. Schiavazzi", "abstract": "Estimation of cardiovascular model parameters from electronic health records\n(EHR) poses a significant challenge primarily due to lack of identifiability.\nStructural non-identifiability arises when a manifold in the space of\nparameters is mapped to a common output, while practical non-identifiability\ncan result due to limited data, model misspecification, or noise corruption. To\naddress the resulting ill-posed inverse problem, optimization-based or Bayesian\ninference approaches typically use regularization, thereby limiting the\npossibility of discovering multiple solutions. In this study, we use inVAErt\nnetworks, a neural network-based, data-driven framework for enhanced digital\ntwin analysis of stiff dynamical systems. We demonstrate the flexibility and\neffectiveness of inVAErt networks in the context of physiological inversion of\na six-compartment lumped parameter hemodynamic model from synthetic data to\nreal data with missing components.", "arxiv_id": "2408.08264v1", "pdf_url": "http://arxiv.org/pdf/2408.08264v1", "abstract_url": "http://arxiv.org/abs/2408.08264v1", "primary_category": "math.NA", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "InVAErt networks for amortized inference and identifiability analysis of lumped parameter hemodynamic models", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:03.659485"}
{"title": "GSVD-NMF: Recovering Missing Features in Non-negative Matrix Factorization", "authors": "Youdong Guo, Timothy E. Holy", "abstract": "Non-negative matrix factorization (NMF) is an important tool in signal\nprocessing and widely used to separate mixed sources into their components.\nHowever, NMF is NP-hard and thus may fail to discover the ideal factorization;\nmoreover, the number of components may not be known in advance and thus\nfeatures may be missed or incompletely separated. To recover missing components\nfrom under-complete NMF, we introduce GSVD-NMF, which proposes new components\nbased on the generalized singular value decomposition (GSVD) between\npreliminary NMF results and the SVD of the original matrix. Simulation and\nexperimental results demonstrate that GSVD-NMF often recovers missing features\nfrom under-complete NMF and helps NMF achieve better local optima.", "arxiv_id": "2408.08260v1", "pdf_url": "http://arxiv.org/pdf/2408.08260v1", "abstract_url": "http://arxiv.org/abs/2408.08260v1", "primary_category": "cs.LG", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "GSVD-NMF: Recovering Missing Features in Non-negative Matrix Factorization", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:04.482703"}
{"title": "Snuffy: Efficient Whole Slide Image Classifier", "authors": "Hossein Jafarinia, Alireza Alipanah, Danial Hamdi, Saeed Razavi, Nahal Mirzaie, Mohammad Hossein Rohban", "abstract": "Whole Slide Image (WSI) classification with multiple instance learning (MIL)\nin digital pathology faces significant computational challenges. Current\nmethods mostly rely on extensive self-supervised learning (SSL) for\nsatisfactory performance, requiring long training periods and considerable\ncomputational resources. At the same time, no pre-training affects performance\ndue to domain shifts from natural images to WSIs. We introduce\n\\textbf{\\textit{Snuffy}} architecture, a novel MIL-pooling method based on\nsparse transformers that mitigates performance loss with limited pre-training\nand enables continual few-shot pre-training as a competitive option. Our\nsparsity pattern is tailored for pathology and is theoretically proven to be a\nuniversal approximator with the tightest probabilistic sharp bound on the\nnumber of layers for sparse transformers, to date. We demonstrate Snuffy's\neffectiveness on CAMELYON16 and TCGA Lung cancer datasets, achieving superior\nWSI and patch-level accuracies. The code is available on\n\\url{https://github.com/jafarinia/snuffy}.", "arxiv_id": "2408.08258v1", "pdf_url": "http://arxiv.org/pdf/2408.08258v1", "abstract_url": "http://arxiv.org/abs/2408.08258v1", "primary_category": "cs.CV", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Snuffy: Efficient Whole Slide Image Classifier", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:05.319166"}
{"title": "Derivative-Free Guidance in Continuous and Discrete Diffusion Models with Soft Value-Based Decoding", "authors": "Xiner Li, Yulai Zhao, Chenyu Wang, Gabriele Scalia, Gokcen Eraslan, Surag Nair, Tommaso Biancalani, Aviv Regev, Sergey Levine, Masatoshi Uehara", "abstract": "Diffusion models excel at capturing the natural design spaces of images,\nmolecules, DNA, RNA, and protein sequences. However, rather than merely\ngenerating designs that are natural, we often aim to optimize downstream reward\nfunctions while preserving the naturalness of these design spaces. Existing\nmethods for achieving this goal often require ``differentiable'' proxy models\n(\\textit{e.g.}, classifier guidance or DPS) or involve computationally\nexpensive fine-tuning of diffusion models (\\textit{e.g.}, classifier-free\nguidance, RL-based fine-tuning). In our work, we propose a new method to\naddress these challenges. Our algorithm is an iterative sampling method that\nintegrates soft value functions, which looks ahead to how intermediate noisy\nstates lead to high rewards in the future, into the standard inference\nprocedure of pre-trained diffusion models. Notably, our approach avoids\nfine-tuning generative models and eliminates the need to construct\ndifferentiable models. This enables us to (1) directly utilize\nnon-differentiable features/reward feedback, commonly used in many scientific\ndomains, and (2) apply our method to recent discrete diffusion models in a\nprincipled way. Finally, we demonstrate the effectiveness of our algorithm\nacross several domains, including image generation, molecule generation, and\nDNA/RNA sequence generation. The code is available at\n\\href{https://github.com/masa-ue/SVDD}{https://github.com/masa-ue/SVDD}.", "arxiv_id": "2408.08252v1", "pdf_url": "http://arxiv.org/pdf/2408.08252v1", "abstract_url": "http://arxiv.org/abs/2408.08252v1", "primary_category": "cs.LG", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Derivative-Free Guidance in Continuous and Discrete Diffusion Models with Soft Value-Based Decoding", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:06.012654"}
{"title": "A Conflicts-free, Speed-lossless KAN-based Reinforcement Learning Decision System for Interactive Driving in Roundabouts", "authors": "Zhihao Lin, Zhen Tian, Qi Zhang, Ziyang Ye, Hanyang Zhuang, Jianglin Lan", "abstract": "Safety and efficiency are crucial for autonomous driving in roundabouts,\nespecially in the context of mixed traffic where autonomous vehicles (AVs) and\nhuman-driven vehicles coexist. This paper introduces a learning-based algorithm\ntailored to foster safe and efficient driving behaviors across varying levels\nof traffic flows in roundabouts. The proposed algorithm employs a deep\nQ-learning network to effectively learn safe and efficient driving strategies\nin complex multi-vehicle roundabouts. Additionally, a KAN (Kolmogorov-Arnold\nnetwork) enhances the AVs' ability to learn their surroundings robustly and\nprecisely. An action inspector is integrated to replace dangerous actions to\navoid collisions when the AV interacts with the environment, and a route\nplanner is proposed to enhance the driving efficiency and safety of the AVs.\nMoreover, a model predictive control is adopted to ensure stability and\nprecision of the driving actions. The results show that our proposed system\nconsistently achieves safe and efficient driving whilst maintaining a stable\ntraining process, as evidenced by the smooth convergence of the reward function\nand the low variance in the training curves across various traffic flows.\nCompared to state-of-the-art benchmarks, the proposed algorithm achieves a\nlower number of collisions and reduced travel time to destination.", "arxiv_id": "2408.08242v1", "pdf_url": "http://arxiv.org/pdf/2408.08242v1", "abstract_url": "http://arxiv.org/abs/2408.08242v1", "primary_category": "cs.RO", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "A Conflicts-free, Speed-lossless KAN-based Reinforcement Learning Decision System for Interactive Driving in Roundabouts", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:07.324414"}
{"title": "The Z-Gromov-Wasserstein Distance", "authors": "Martin Bauer, Facundo M\u00e9moli, Tom Needham, Mao Nishino", "abstract": "The Gromov-Wasserstein (GW) distance is a powerful tool for comparing metric\nmeasure spaces which has found broad applications in data science and machine\nlearning. Driven by the need to analyze datasets whose objects have\nincreasingly complex structure (such as node and edge-attributed graphs),\nseveral variants of GW distance have been introduced in the recent literature.\nWith a view toward establishing a general framework for the theory of GW-like\ndistances, this paper considers a vast generalization of the notion of a metric\nmeasure space: for an arbitrary metric space $Z$, we define a $Z$-network to be\na measure space endowed with a kernel valued in $Z$. We introduce a method for\ncomparing $Z$-networks by defining a generalization of GW distance, which we\nrefer to as $Z$-Gromov-Wasserstein ($Z$-GW) distance. This construction\nsubsumes many previously known metrics and offers a unified approach to\nunderstanding their shared properties. The paper demonstrates that the $Z$-GW\ndistance defines a metric on the space of $Z$-networks which retains desirable\nproperties of $Z$, such as separability, completeness, and geodesicity. Many of\nthese properties were unknown for existing variants of GW distance that fall\nunder our framework. Our focus is on foundational theory, but our results also\ninclude computable lower bounds and approximations of the distance which will\nbe useful for practical applications.", "arxiv_id": "2408.08233v1", "pdf_url": "http://arxiv.org/pdf/2408.08233v1", "abstract_url": "http://arxiv.org/abs/2408.08233v1", "primary_category": "math.MG", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "The Z-Gromov-Wasserstein Distance", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:08.344137"}
{"title": "Explaining an Agent's Future Beliefs through Temporally Decomposing Future Reward Estimators", "authors": "Mark Towers, Yali Du, Christopher Freeman, Timothy J. Norman", "abstract": "Future reward estimation is a core component of reinforcement learning\nagents; i.e., Q-value and state-value functions, predicting an agent's sum of\nfuture rewards. Their scalar output, however, obfuscates when or what\nindividual future rewards an agent may expect to receive. We address this by\nmodifying an agent's future reward estimator to predict their next N expected\nrewards, referred to as Temporal Reward Decomposition (TRD). This unlocks novel\nexplanations of agent behaviour. Through TRD we can: estimate when an agent may\nexpect to receive a reward, the value of the reward and the agent's confidence\nin receiving it; measure an input feature's temporal importance to the agent's\naction decisions; and predict the influence of different actions on future\nrewards. Furthermore, we show that DQN agents trained on Atari environments can\nbe efficiently retrained to incorporate TRD with minimal impact on performance.", "arxiv_id": "2408.08230v1", "pdf_url": "http://arxiv.org/pdf/2408.08230v1", "abstract_url": "http://arxiv.org/abs/2408.08230v1", "primary_category": "cs.AI", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Explaining an Agent's Future Beliefs through Temporally Decomposing Future Reward Estimators", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:09.860064"}
{"title": "Enhancing Sharpness-Aware Minimization by Learning Perturbation Radius", "authors": "Xuehao Wang, Weisen Jiang, Shuai Fu, Yu Zhang", "abstract": "Sharpness-aware minimization (SAM) is to improve model generalization by\nsearching for flat minima in the loss landscape. The SAM update consists of one\nstep for computing the perturbation and the other for computing the update\ngradient. Within the two steps, the choice of the perturbation radius is\ncrucial to the performance of SAM, but finding an appropriate perturbation\nradius is challenging. In this paper, we propose a bilevel optimization\nframework called LEarning the perTurbation radiuS (LETS) to learn the\nperturbation radius for sharpness-aware minimization algorithms. Specifically,\nin the proposed LETS method, the upper-level problem aims at seeking a good\nperturbation radius by minimizing the squared generalization gap between the\ntraining and validation losses, while the lower-level problem is the SAM\noptimization problem. Moreover, the LETS method can be combined with any\nvariant of SAM. Experimental results on various architectures and benchmark\ndatasets in computer vision and natural language processing demonstrate the\neffectiveness of the proposed LETS method in improving the performance of SAM.", "arxiv_id": "2408.08222v1", "pdf_url": "http://arxiv.org/pdf/2408.08222v1", "abstract_url": "http://arxiv.org/abs/2408.08222v1", "primary_category": "cs.LG", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Enhancing Sharpness-Aware Minimization by Learning Perturbation Radius", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:10.617525"}
{"title": "RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science", "authors": "David Farr, Nico Manzonelli, Iain Cruickshank, Jevin West", "abstract": "Large language models (LLMs) have enhanced our ability to rapidly analyze and\nclassify unstructured natural language data. However, concerns regarding cost,\nnetwork limitations, and security constraints have posed challenges for their\nintegration into work processes. In this study, we adopt a systems design\napproach to employing LLMs as imperfect data annotators for downstream\nsupervised learning tasks, introducing novel system intervention measures aimed\nat improving classification performance. Our methodology outperforms\nLLM-generated labels in seven of eight tests, demonstrating an effective\nstrategy for incorporating LLMs into the design and deployment of specialized,\nsupervised learning models present in many industry use cases.", "arxiv_id": "2408.08217v1", "pdf_url": "http://arxiv.org/pdf/2408.08217v1", "abstract_url": "http://arxiv.org/abs/2408.08217v1", "primary_category": "cs.LG", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:11.634256"}
{"title": "Moving Healthcare AI-Support Systems for Visually Detectable Diseases onto Constrained Devices", "authors": "Tess Watt, Christos Chrysoulas, Peter J Barclay", "abstract": "Image classification usually requires connectivity and access to the cloud\nwhich is often limited in many parts of the world, including hard to reach\nrural areas. TinyML aims to solve this problem by hosting AI assistants on\nconstrained devices, eliminating connectivity issues by processing data within\nthe device itself, without internet or cloud access. This pilot study explores\nthe use of tinyML to provide healthcare support with low spec devices in low\nconnectivity environments, focusing on diagnosis of skin diseases and the\nethical use of AI assistants in a healthcare setting. To investigate this,\n10,000 images of skin lesions were used to train a model for classifying\nvisually detectable diseases (VDDs). The model weights were then offloaded to a\nRaspberry Pi with a webcam attached, to be used for the classification of skin\nlesions without internet access. It was found that the developed prototype\nachieved a test accuracy of 78% and a test loss of 1.08.", "arxiv_id": "2408.08215v1", "pdf_url": "http://arxiv.org/pdf/2408.08215v1", "abstract_url": "http://arxiv.org/abs/2408.08215v1", "primary_category": "cs.LG", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Moving Healthcare AI-Support Systems for Visually Detectable Diseases onto Constrained Devices", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:12.757083"}
{"title": "Federated Fairness Analytics: Quantifying Fairness in Federated Learning", "authors": "Oscar Dilley, Juan Marcelo Parra-Ullauri, Rasheed Hussain, Dimitra Simeonidou", "abstract": "Federated Learning (FL) is a privacy-enhancing technology for distributed ML.\nBy training models locally and aggregating updates - a federation learns\ntogether, while bypassing centralised data collection. FL is increasingly\npopular in healthcare, finance and personal computing. However, it inherits\nfairness challenges from classical ML and introduces new ones, resulting from\ndifferences in data quality, client participation, communication constraints,\naggregation methods and underlying hardware. Fairness remains an unresolved\nissue in FL and the community has identified an absence of succinct definitions\nand metrics to quantify fairness; to address this, we propose Federated\nFairness Analytics - a methodology for measuring fairness. Our definition of\nfairness comprises four notions with novel, corresponding metrics. They are\nsymptomatically defined and leverage techniques originating from XAI,\ncooperative game-theory and networking engineering. We tested a range of\nexperimental settings, varying the FL approach, ML task and data settings. The\nresults show that statistical heterogeneity and client participation affect\nfairness and fairness conscious approaches such as Ditto and q-FedAvg\nmarginally improve fairness-performance trade-offs. Using our techniques, FL\npractitioners can uncover previously unobtainable insights into their system's\nfairness, at differing levels of granularity in order to address fairness\nchallenges in FL. We have open-sourced our work at:\nhttps://github.com/oscardilley/federated-fairness.", "arxiv_id": "2408.08214v1", "pdf_url": "http://arxiv.org/pdf/2408.08214v1", "abstract_url": "http://arxiv.org/abs/2408.08214v1", "primary_category": "cs.LG", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Federated Fairness Analytics: Quantifying Fairness in Federated Learning", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:13.584141"}
{"title": "Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models", "authors": "Javier Gonz\u00e1lez, Aditya V. Nori", "abstract": "Recent advances in AI have been significantly driven by the capabilities of\nlarge language models (LLMs) to solve complex problems in ways that resemble\nhuman thinking. However, there is an ongoing debate about the extent to which\nLLMs are capable of actual reasoning. Central to this debate are two key\nprobabilistic concepts that are essential for connecting causes to their\neffects: the probability of necessity (PN) and the probability of sufficiency\n(PS). This paper introduces a framework that is both theoretical and practical,\naimed at assessing how effectively LLMs are able to replicate real-world\nreasoning mechanisms using these probabilistic measures. By viewing LLMs as\nabstract machines that process information through a natural language\ninterface, we examine the conditions under which it is possible to compute\nsuitable approximations of PN and PS. Our research marks an important step\ntowards gaining a deeper understanding of when LLMs are capable of reasoning,\nas illustrated by a series of math examples.", "arxiv_id": "2408.08210v1", "pdf_url": "http://arxiv.org/pdf/2408.08210v1", "abstract_url": "http://arxiv.org/abs/2408.08210v1", "primary_category": "cs.LG", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:14.584523"}
{"title": "Stochastic Semi-Gradient Descent for Learning Mean Field Games with Population-Aware Function Approximation", "authors": "Chenyu Zhang, Xu Chen, Xuan Di", "abstract": "Mean field games (MFGs) model the interactions within a large-population\nmulti-agent system using the population distribution. Traditional learning\nmethods for MFGs are based on fixed-point iteration (FPI), which calculates\nbest responses and induced population distribution separately and sequentially.\nHowever, FPI-type methods suffer from inefficiency and instability, due to\noscillations caused by the forward-backward procedure. This paper considers an\nonline learning method for MFGs, where an agent updates its policy and\npopulation estimates simultaneously and fully asynchronously, resulting in a\nsimple stochastic gradient descent (SGD) type method called SemiSGD. Not only\ndoes SemiSGD exhibit numerical stability and efficiency, but it also provides a\nnovel perspective by treating the value function and population distribution as\na unified parameter. We theoretically show that SemiSGD directs this unified\nparameter along a descent direction to the mean field equilibrium. Motivated by\nthis perspective, we develop a linear function approximation (LFA) for both the\nvalue function and the population distribution, resulting in the first\npopulation-aware LFA for MFGs on continuous state-action space. Finite-time\nconvergence and approximation error analysis are provided for SemiSGD equipped\nwith population-aware LFA.", "arxiv_id": "2408.08192v1", "pdf_url": "http://arxiv.org/pdf/2408.08192v1", "abstract_url": "http://arxiv.org/abs/2408.08192v1", "primary_category": "cs.LG", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Stochastic Semi-Gradient Descent for Learning Mean Field Games with Population-Aware Function Approximation", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:15.624941"}
{"title": "Data-driven identification of latent port-Hamiltonian systems", "authors": "Johannes Rettberg, Jonas Kneifl, Julius Herb, Patrick Buchfink, J\u00f6rg Fehr, Bernard Haasdonk", "abstract": "Conventional physics-based modeling techniques involve high effort, e.g.,\ntime and expert knowledge, while data-driven methods often lack\ninterpretability, structure, and sometimes reliability. To mitigate this, we\npresent a data-driven system identification framework that derives models in\nthe port-Hamiltonian (pH) formulation. This formulation is suitable for\nmulti-physical systems while guaranteeing the useful system theoretical\nproperties of passivity and stability. Our framework combines linear and\nnonlinear reduction with structured, physics-motivated system identification.\nIn this process, high-dimensional state data obtained from possibly nonlinear\nsystems serves as input for an autoencoder, which then performs two tasks: (i)\nnonlinearly transforming and (ii) reducing this data onto a low-dimensional\nlatent space. In this space, a linear pH system, that satisfies the pH\nproperties per construction, is parameterized by the weights of a neural\nnetwork. The mathematical requirements are met by defining the pH matrices\nthrough Cholesky factorizations. The neural networks that define the coordinate\ntransformation and the pH system are identified in a joint optimization process\nto match the dynamics observed in the data while defining a linear pH system in\nthe latent space. The learned, low-dimensional pH system can describe even\nnonlinear systems and is rapidly computable due to its small size. The method\nis exemplified by a parametric mass-spring-damper and a nonlinear pendulum\nexample, as well as the high-dimensional model of a disc brake with linear\nthermoelastic behavior.", "arxiv_id": "2408.08185v2", "pdf_url": "http://arxiv.org/pdf/2408.08185v2", "abstract_url": "http://arxiv.org/abs/2408.08185v2", "primary_category": "math.DS", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Data-driven identification of latent port-Hamiltonian systems", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:16.691569"}
{"title": "Not Every Image is Worth a Thousand Words: Quantifying Originality in Stable Diffusion", "authors": "Adi Haviv, Shahar Sarfaty, Uri Hacohen, Niva Elkin-Koren, Roi Livni, Amit H Bermano", "abstract": "This work addresses the challenge of quantifying originality in text-to-image\n(T2I) generative diffusion models, with a focus on copyright originality. We\nbegin by evaluating T2I models' ability to innovate and generalize through\ncontrolled experiments, revealing that stable diffusion models can effectively\nrecreate unseen elements with sufficiently diverse training data. Then, our key\ninsight is that concepts and combinations of image elements the model is\nfamiliar with, and saw more during training, are more concisly represented in\nthe model's latent space. We hence propose a method that leverages textual\ninversion to measure the originality of an image based on the number of tokens\nrequired for its reconstruction by the model. Our approach is inspired by legal\ndefinitions of originality and aims to assess whether a model can produce\noriginal content without relying on specific prompts or having the training\ndata of the model. We demonstrate our method using both a pre-trained stable\ndiffusion model and a synthetic dataset, showing a correlation between the\nnumber of tokens and image originality. This work contributes to the\nunderstanding of originality in generative models and has implications for\ncopyright infringement cases.", "arxiv_id": "2408.08184v1", "pdf_url": "http://arxiv.org/pdf/2408.08184v1", "abstract_url": "http://arxiv.org/abs/2408.08184v1", "primary_category": "cs.CV", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Not Every Image is Worth a Thousand Words: Quantifying Originality in Stable Diffusion", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:17.868352"}
{"title": "Machine learning empowered Modulation detection for OFDM-based signals", "authors": "Ali Pourranjbar, Georges Kaddoum, Verdier Assoume Mba, Sahil Garg, Satinder Singh", "abstract": "We propose a blind ML-based modulation detection for OFDM-based technologies.\nUnlike previous works that assume an ideal environment with precise knowledge\nof subcarrier count and cyclic prefix location, we consider blind modulation\ndetection while accounting for realistic environmental parameters and\nimperfections. Our approach employs a ResNet network to simultaneously detect\nthe modulation type and accurately locate the cyclic prefix. Specifically,\nafter eliminating the environmental impact from the signal and accurately\nextracting the OFDM symbols, we convert these symbols into scatter plots. Due\nto their unique shapes, these scatter plots are then classified using ResNet.\nAs a result, our proposed modulation classification method can be applied to\nany OFDM-based technology without prior knowledge of the transmitted signal. We\nevaluate its performance across various modulation schemes and subcarrier\nnumbers. Simulation results show that our method achieves a modulation\ndetection accuracy exceeding $80\\%$ at an SNR of $10$ dB and $95\\%$ at an SNR\nof $25$ dB.", "arxiv_id": "2408.08179v1", "pdf_url": "http://arxiv.org/pdf/2408.08179v1", "abstract_url": "http://arxiv.org/abs/2408.08179v1", "primary_category": "cs.LG", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Machine learning empowered Modulation detection for OFDM-based signals", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:18.777776"}
{"title": "Towards flexible perception with visual memory", "authors": "Robert Geirhos, Priyank Jaini, Austin Stone, Sourabh Medapati, Xi Yi, George Toderici, Abhijit Ogale, Jonathon Shlens", "abstract": "Training a neural network is a monolithic endeavor, akin to carving knowledge\ninto stone: once the process is completed, editing the knowledge in a network\nis nearly impossible, since all information is distributed across the network's\nweights. We here explore a simple, compelling alternative by marrying the\nrepresentational power of deep neural networks with the flexibility of a\ndatabase. Decomposing the task of image classification into image similarity\n(from a pre-trained embedding) and search (via fast nearest neighbor retrieval\nfrom a knowledge database), we build a simple and flexible visual memory that\nhas the following key capabilities: (1.) The ability to flexibly add data\nacross scales: from individual samples all the way to entire classes and\nbillion-scale data; (2.) The ability to remove data through unlearning and\nmemory pruning; (3.) An interpretable decision-mechanism on which we can\nintervene to control its behavior. Taken together, these capabilities\ncomprehensively demonstrate the benefits of an explicit visual memory. We hope\nthat it might contribute to a conversation on how knowledge should be\nrepresented in deep vision models -- beyond carving it in ``stone'' weights.", "arxiv_id": "2408.08172v1", "pdf_url": "http://arxiv.org/pdf/2408.08172v1", "abstract_url": "http://arxiv.org/abs/2408.08172v1", "primary_category": "cs.CV", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Towards flexible perception with visual memory", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:19.821790"}
{"title": "DeepSeek-Prover-V1.5: Harnessing Proof Assistant Feedback for Reinforcement Learning and Monte-Carlo Tree Search", "authors": "Huajian Xin, Z. Z. Ren, Junxiao Song, Zhihong Shao, Wanjia Zhao, Haocheng Wang, Bo Liu, Liyue Zhang, Xuan Lu, Qiushi Du, Wenjun Gao, Qihao Zhu, Dejian Yang, Zhibin Gou, Z. F. Wu, Fuli Luo, Chong Ruan", "abstract": "We introduce DeepSeek-Prover-V1.5, an open-source language model designed for\ntheorem proving in Lean 4, which enhances DeepSeek-Prover-V1 by optimizing both\ntraining and inference processes. Pre-trained on DeepSeekMath-Base with\nspecialization in formal mathematical languages, the model undergoes supervised\nfine-tuning using an enhanced formal theorem proving dataset derived from\nDeepSeek-Prover-V1. Further refinement is achieved through reinforcement\nlearning from proof assistant feedback (RLPAF). Beyond the single-pass\nwhole-proof generation approach of DeepSeek-Prover-V1, we propose RMaxTS, a\nvariant of Monte-Carlo tree search that employs an intrinsic-reward-driven\nexploration strategy to generate diverse proof paths. DeepSeek-Prover-V1.5\ndemonstrates significant improvements over DeepSeek-Prover-V1, achieving new\nstate-of-the-art results on the test set of the high school level miniF2F\nbenchmark ($63.5\\%$) and the undergraduate level ProofNet benchmark ($25.3\\%$).", "arxiv_id": "2408.08152v1", "pdf_url": "http://arxiv.org/pdf/2408.08152v1", "abstract_url": "http://arxiv.org/abs/2408.08152v1", "primary_category": "cs.CL", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "DeepSeek-Prover-V1.5: Harnessing Proof Assistant Feedback for Reinforcement Learning and Monte-Carlo Tree Search", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:20.897997"}
{"title": "Exploring Latent Space for Generating Peptide Analogs Using Protein Language Models", "authors": "Po-Yu Liang, Xueting Huang, Tibo Duran, Andrew J. Wiemer, Jun Bai", "abstract": "Generating peptides with desired properties is crucial for drug discovery and\nbiotechnology. Traditional sequence-based and structure-based methods often\nrequire extensive datasets, which limits their effectiveness. In this study, we\nproposed a novel method that utilized autoencoder shaped models to explore the\nprotein embedding space, and generate novel peptide analogs by leveraging\nprotein language models. The proposed method requires only a single sequence of\ninterest, avoiding the need for large datasets. Our results show significant\nimprovements over baseline models in similarity indicators of peptide\nstructures, descriptors and bioactivities. The proposed method validated\nthrough Molecular Dynamics simulations on TIGIT inhibitors, demonstrates that\nour method produces peptide analogs with similar yet distinct properties,\nhighlighting its potential to enhance peptide screening processes.", "arxiv_id": "2408.08341v1", "pdf_url": "http://arxiv.org/pdf/2408.08341v1", "abstract_url": "http://arxiv.org/abs/2408.08341v1", "primary_category": "q-bio.QM", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Exploring Latent Space for Generating Peptide Analogs Using Protein Language Models", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:21.920054"}
{"title": "P/D-Serve: Serving Disaggregated Large Language Model at Scale", "authors": "Yibo Jin, Tao Wang, Huimin Lin, Mingyang Song, Peiyang Li, Yipeng Ma, Yicheng Shan, Zhengfan Yuan, Cailong Li, Yajing Sun, Tiandeng Wu, Xing Chu, Ruizhi Huan, Li Ma, Xiao You, Wenting Zhou, Yunpeng Ye, Wen Liu, Xiangkun Xu, Yongsheng Zhang, Tiantian Dong, Jiawei Zhu, Zhe Wang, Xijian Ju, Jianxun Song, Haoliang Cheng, Xiaojing Li, Jiandong Ding, Hefei Guo, Zhengyong Zhang", "abstract": "Serving disaggregated large language models (LLMs) over tens of thousands of\nxPU devices (GPUs or NPUs) with reliable performance faces multiple challenges.\n1) Ignoring the diversity (various prefixes and tidal requests), treating all\nthe prompts in a mixed pool is inadequate. To facilitate the similarity per\nscenario and minimize the inner mismatch on P/D (prefill and decoding)\nprocessing, fine-grained organization is required, dynamically adjusting P/D\nratios for better performance. 2) Due to inaccurate estimation on workload\n(queue status or maintained connections), the global scheduler easily incurs\nunnecessary timeouts in prefill. 3) Block-fixed device-to-device (D2D) KVCache\ntransfer over cluster-level RDMA (remote direct memory access) fails to achieve\ndesired D2D utilization as expected. To overcome previous problems, this paper\nproposes an end-to-end system P/D-Serve, complying with the paradigm of MLOps\n(machine learning operations), which models end-to-end (E2E) P/D performance\nand enables: 1) fine-grained P/D organization, mapping the service with RoCE\n(RDMA over converged ethernet) as needed, to facilitate similar processing and\ndynamic adjustments on P/D ratios; 2) on-demand forwarding upon rejections for\nidle prefill, decoupling the scheduler from regular inaccurate reports and\nlocal queues, to avoid timeouts in prefill; and 3) efficient KVCache transfer\nvia optimized D2D access. P/D-Serve is implemented upon Ascend and MindSpore,\nhas been deployed over tens of thousands of NPUs for more than eight months in\ncommercial use, and further achieves 60\\%, 42\\% and 46\\% improvements on E2E\nthroughput, time-to-first-token (TTFT) SLO (service level objective) and D2D\ntransfer time. As the E2E system with optimizations, P/D-Serve achieves 6.7x\nincrease on throughput, compared with aggregated LLMs.", "arxiv_id": "2408.08147v1", "pdf_url": "http://arxiv.org/pdf/2408.08147v1", "abstract_url": "http://arxiv.org/abs/2408.08147v1", "primary_category": "cs.DC", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "P/D-Serve: Serving Disaggregated Large Language Model at Scale", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:22.771273"}
{"title": "Impact of Comprehensive Data Preprocessing on Predictive Modelling of COVID-19 Mortality", "authors": "Sangita Das, Subhrajyoti Maji", "abstract": "Accurate predictive models are crucial for analysing COVID-19 mortality\ntrends. This study evaluates the impact of a custom data preprocessing pipeline\non ten machine learning models predicting COVID-19 mortality using data from\nOur World in Data (OWID). Our pipeline differs from a standard preprocessing\npipeline through four key steps. Firstly, it transforms weekly reported totals\ninto daily updates, correcting reporting biases and providing more accurate\nestimates. Secondly, it uses localised outlier detection and processing to\npreserve data variance and enhance accuracy. Thirdly, it utilises computational\ndependencies among columns to ensure data consistency. Finally, it incorporates\nan iterative feature selection process to optimise the feature set and improve\nmodel performance. Results show a significant improvement with the custom\npipeline: the MLP Regressor achieved a test RMSE of 66.556 and a test R-squared\nof 0.991, surpassing the DecisionTree Regressor from the standard pipeline,\nwhich had a test RMSE of 222.858 and a test R-squared of 0.817. These findings\nhighlight the importance of tailored preprocessing techniques in enhancing\npredictive modelling accuracy for COVID-19 mortality. Although specific to this\nstudy, these methodologies offer valuable insights into diverse datasets and\ndomains, improving predictive performance across various contexts.", "arxiv_id": "2408.08142v1", "pdf_url": "http://arxiv.org/pdf/2408.08142v1", "abstract_url": "http://arxiv.org/abs/2408.08142v1", "primary_category": "cs.LG", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Impact of Comprehensive Data Preprocessing on Predictive Modelling of COVID-19 Mortality", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:23.688836"}
{"title": "Normalized AOPC: Fixing Misleading Faithfulness Metrics for Feature Attribution Explainability", "authors": "Joakim Edin, Andreas Geert Motzfeldt, Casper L. Christensen, Tuukka Ruotsalo, Lars Maal\u00f8e, Maria Maistro", "abstract": "Deep neural network predictions are notoriously difficult to interpret.\nFeature attribution methods aim to explain these predictions by identifying the\ncontribution of each input feature. Faithfulness, often evaluated using the\narea over the perturbation curve (AOPC), reflects feature attributions'\naccuracy in describing the internal mechanisms of deep neural networks.\nHowever, many studies rely on AOPC to compare faithfulness across different\nmodels, which we show can lead to false conclusions about models' faithfulness.\nSpecifically, we find that AOPC is sensitive to variations in the model,\nresulting in unreliable cross-model comparisons. Moreover, AOPC scores are\ndifficult to interpret in isolation without knowing the model-specific lower\nand upper limits. To address these issues, we propose a normalization approach,\nNormalized AOPC (NAOPC), enabling consistent cross-model evaluations and more\nmeaningful interpretation of individual scores. Our experiments demonstrate\nthat this normalization can radically change AOPC results, questioning the\nconclusions of earlier studies and offering a more robust framework for\nassessing feature attribution faithfulness.", "arxiv_id": "2408.08137v1", "pdf_url": "http://arxiv.org/pdf/2408.08137v1", "abstract_url": "http://arxiv.org/abs/2408.08137v1", "primary_category": "cs.LG", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Normalized AOPC: Fixing Misleading Faithfulness Metrics for Feature Attribution Explainability", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:24.416767"}
{"title": "EXPLAIN, AGREE, LEARN: Scaling Learning for Neural Probabilistic Logic", "authors": "Victor Verreet, Lennert De Smet, Luc De Raedt, Emanuele Sansone", "abstract": "Neural probabilistic logic systems follow the neuro-symbolic (NeSy) paradigm\nby combining the perceptive and learning capabilities of neural networks with\nthe robustness of probabilistic logic. Learning corresponds to likelihood\noptimization of the neural networks. However, to obtain the likelihood exactly,\nexpensive probabilistic logic inference is required. To scale learning to more\ncomplex systems, we therefore propose to instead optimize a sampling based\nobjective. We prove that the objective has a bounded error with respect to the\nlikelihood, which vanishes when increasing the sample count. Furthermore, the\nerror vanishes faster by exploiting a new concept of sample diversity. We then\ndevelop the EXPLAIN, AGREE, LEARN (EXAL) method that uses this objective.\nEXPLAIN samples explanations for the data. AGREE reweighs each explanation in\nconcordance with the neural component. LEARN uses the reweighed explanations as\na signal for learning. In contrast to previous NeSy methods, EXAL can scale to\nlarger problem sizes while retaining theoretical guarantees on the error.\nExperimentally, our theoretical claims are verified and EXAL outperforms recent\nNeSy methods when scaling up the MNIST addition and Warcraft pathfinding\nproblems.", "arxiv_id": "2408.08133v1", "pdf_url": "http://arxiv.org/pdf/2408.08133v1", "abstract_url": "http://arxiv.org/abs/2408.08133v1", "primary_category": "cs.LG", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "EXPLAIN, AGREE, LEARN: Scaling Learning for Neural Probabilistic Logic", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:25.810855"}
{"title": "The Unreasonable Effectiveness of Solving Inverse Problems with Neural Networks", "authors": "Philipp Holl, Nils Thuerey", "abstract": "Finding model parameters from data is an essential task in science and\nengineering, from weather and climate forecasts to plasma control. Previous\nworks have employed neural networks to greatly accelerate finding solutions to\ninverse problems. Of particular interest are end-to-end models which utilize\ndifferentiable simulations in order to backpropagate feedback from the\nsimulated process to the network weights and enable roll-out of multiple time\nsteps. So far, it has been assumed that, while model inference is faster than\nclassical optimization, this comes at the cost of a decrease in solution\naccuracy. We show that this is generally not true. In fact, neural networks\ntrained to learn solutions to inverse problems can find better solutions than\nclassical optimizers even on their training set. To demonstrate this, we\nperform both a theoretical analysis as well an extensive empirical evaluation\non challenging problems involving local minima, chaos, and zero-gradient\nregions. Our findings suggest an alternative use for neural networks: rather\nthan generalizing to new data for fast inference, they can also be used to find\nbetter solutions on known data.", "arxiv_id": "2408.08119v1", "pdf_url": "http://arxiv.org/pdf/2408.08119v1", "abstract_url": "http://arxiv.org/abs/2408.08119v1", "primary_category": "cs.LG", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "The Unreasonable Effectiveness of Solving Inverse Problems with Neural Networks", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:26.695181"}
{"title": "Learned denoising with simulated and experimental low-dose CT data", "authors": "Maximilian B. Kiss, Ander Biguri, Carola-Bibiane Sch\u00f6nlieb, K. Joost Batenburg, Felix Lucka", "abstract": "Like in many other research fields, recent developments in computational\nimaging have focused on developing machine learning (ML) approaches to tackle\nits main challenges. To improve the performance of computational imaging\nalgorithms, machine learning methods are used for image processing tasks such\nas noise reduction. Generally, these ML methods heavily rely on the\navailability of high-quality data on which they are trained. This work explores\nthe application of ML methods, specifically convolutional neural networks\n(CNNs), in the context of noise reduction for computed tomography (CT) imaging.\nWe utilize a large 2D computed tomography dataset for machine learning to carry\nout for the first time a comprehensive study on the differences between the\nobserved performances of algorithms trained on simulated noisy data and on\nreal-world experimental noisy data. The study compares the performance of two\ncommon CNN architectures, U-Net and MSD-Net, that are trained and evaluated on\nboth simulated and experimental noisy data. The results show that while\nsinogram denoising performed better with simulated noisy data if evaluated in\nthe sinogram domain, the performance did not carry over to the reconstruction\ndomain where training on experimental noisy data shows a higher performance in\ndenoising experimental noisy data. Training the algorithms in an end-to-end\nfashion from sinogram to reconstruction significantly improved model\nperformance, emphasizing the importance of matching raw measurement data to\nhigh-quality CT reconstructions. The study furthermore suggests the need for\nmore sophisticated noise simulation approaches to bridge the gap between\nsimulated and real-world data in CT image denoising applications and gives\ninsights into the challenges and opportunities in leveraging simulated data for\nmachine learning in computational imaging.", "arxiv_id": "2408.08115v1", "pdf_url": "http://arxiv.org/pdf/2408.08115v1", "abstract_url": "http://arxiv.org/abs/2408.08115v1", "primary_category": "eess.IV", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Learned denoising with simulated and experimental low-dose CT data", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:27.552584"}
{"title": "METR: Image Watermarking with Large Number of Unique Messages", "authors": "Alexander Varlamov, Daria Diatlova, Egor Spirin", "abstract": "Improvements in diffusion models have boosted the quality of image\ngeneration, which has led researchers, companies, and creators to focus on\nimproving watermarking algorithms. This provision would make it possible to\nclearly identify the creators of generative art. The main challenges that\nmodern watermarking algorithms face have to do with their ability to withstand\nattacks and encrypt many unique messages, such as user IDs. In this paper, we\npresent METR: Message Enhanced Tree-Ring, which is an approach that aims to\naddress these challenges. METR is built on the Tree-Ring watermarking\nalgorithm, a technique that makes it possible to encode multiple distinct\nmessages without compromising attack resilience or image quality. This ensures\nthe suitability of this watermarking algorithm for any Diffusion Model. In\norder to surpass the limitations on the quantity of encoded messages, we\npropose METR++, an enhanced version of METR. This approach, while limited to\nthe Latent Diffusion Model architecture, is designed to inject a virtually\nunlimited number of unique messages. We demonstrate its robustness to attacks\nand ability to encrypt many unique messages while preserving image quality,\nwhich makes METR and METR++ hold great potential for practical applications in\nreal-world settings. Our code is available at https://github.com/deepvk/metr", "arxiv_id": "2408.08340v1", "pdf_url": "http://arxiv.org/pdf/2408.08340v1", "abstract_url": "http://arxiv.org/abs/2408.08340v1", "primary_category": "cs.LG", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "METR: Image Watermarking with Large Number of Unique Messages", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:28.437942"}
{"title": "Hearing Your Blood Sugar: Non-Invasive Glucose Measurement Through Simple Vocal Signals, Transforming any Speech into a Sensor with Machine Learning", "authors": "Nihat Ahmadli, Mehmet Ali Sarsil, Onur Ergen", "abstract": "Effective diabetes management relies heavily on the continuous monitoring of\nblood glucose levels, traditionally achieved through invasive and uncomfortable\nmethods. While various non-invasive techniques have been explored, such as\noptical, microwave, and electrochemical approaches, none have effectively\nsupplanted these invasive technologies due to issues related to complexity,\naccuracy, and cost. In this study, we present a transformative and\nstraightforward method that utilizes voice analysis to predict blood glucose\nlevels. Our research investigates the relationship between fluctuations in\nblood glucose and vocal characteristics, highlighting the influence of blood\nvessel dynamics during voice production. By applying advanced machine learning\nalgorithms, we analyzed vocal signal variations and established a significant\ncorrelation with blood glucose levels. We developed a predictive model using\nartificial intelligence, based on voice recordings and corresponding glucose\nmeasurements from participants, utilizing logistic regression and Ridge\nregularization. Our findings indicate that voice analysis may serve as a viable\nnon-invasive alternative for glucose monitoring. This innovative approach not\nonly has the potential to streamline and reduce the costs associated with\ndiabetes management but also aims to enhance the quality of life for\nindividuals living with diabetes by providing a painless and user-friendly\nmethod for monitoring blood sugar levels.", "arxiv_id": "2408.08109v1", "pdf_url": "http://arxiv.org/pdf/2408.08109v1", "abstract_url": "http://arxiv.org/abs/2408.08109v1", "primary_category": "cs.LG", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Hearing Your Blood Sugar: Non-Invasive Glucose Measurement Through Simple Vocal Signals, Transforming any Speech into a Sensor with Machine Learning", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:29.380380"}
{"title": "Adaptation of uncertainty-penalized Bayesian information criterion for parametric partial differential equation discovery", "authors": "Pongpisit Thanasutives, Ken-ichi Fukui", "abstract": "Data-driven discovery of partial differential equations (PDEs) has emerged as\na promising approach for deriving governing physics when domain knowledge about\nobserved data is limited. Despite recent progress, the identification of\ngoverning equations and their parametric dependencies using conventional\ninformation criteria remains challenging in noisy situations, as the criteria\ntend to select overly complex PDEs. In this paper, we introduce an extension of\nthe uncertainty-penalized Bayesian information criterion (UBIC), which is\nadapted to solve parametric PDE discovery problems efficiently without\nrequiring computationally expensive PDE simulations. This extended UBIC uses\nquantified PDE uncertainty over different temporal or spatial points to prevent\noverfitting in model selection. The UBIC is computed with data transformation\nbased on power spectral densities to discover the governing parametric PDE that\ntruly captures qualitative features in frequency space with a few significant\nterms and their parametric dependencies (i.e., the varying PDE coefficients),\nevaluated with confidence intervals. Numerical experiments on canonical PDEs\ndemonstrate that our extended UBIC can identify the true number of terms and\ntheir varying coefficients accurately, even in the presence of noise. The code\nis available at\n\\url{https://github.com/Pongpisit-Thanasutives/parametric-discovery}.", "arxiv_id": "2408.08106v1", "pdf_url": "http://arxiv.org/pdf/2408.08106v1", "abstract_url": "http://arxiv.org/abs/2408.08106v1", "primary_category": "cs.LG", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Adaptation of uncertainty-penalized Bayesian information criterion for parametric partial differential equation discovery", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:30.179314"}
{"title": "Activation Space Selectable Kolmogorov-Arnold Networks", "authors": "Zhuoqin Yang, Jiansong Zhang, Xiaoling Luo, Zheng Lu, Linlin Shen", "abstract": "The multilayer perceptron (MLP), a fundamental paradigm in current artificial\nintelligence, is widely applied in fields such as computer vision and natural\nlanguage processing. However, the recently proposed Kolmogorov-Arnold Network\n(KAN), based on nonlinear additive connections, has been proven to achieve\nperformance comparable to MLPs with significantly fewer parameters. Despite\nthis potential, the use of a single activation function space results in\nreduced performance of KAN and related works across different tasks. To address\nthis issue, we propose an activation space Selectable KAN (S-KAN). S-KAN\nemploys an adaptive strategy to choose the possible activation mode for data at\neach feedforward KAN node. Our approach outperforms baseline methods in seven\nrepresentative function fitting tasks and significantly surpasses MLP methods\nwith the same level of parameters. Furthermore, we extend the structure of\nS-KAN and propose an activation space selectable Convolutional KAN (S-ConvKAN),\nwhich achieves leading results on four general image classification datasets.\nOur method mitigates the performance variability of the original KAN across\ndifferent tasks and demonstrates through extensive experiments that feedforward\nKANs with selectable activations can achieve or even exceed the performance of\nMLP-based methods. This work contributes to the understanding of the\ndata-centric design of new AI paradigms and provides a foundational reference\nfor innovations in KAN-based network architectures.", "arxiv_id": "2408.08338v1", "pdf_url": "http://arxiv.org/pdf/2408.08338v1", "abstract_url": "http://arxiv.org/abs/2408.08338v1", "primary_category": "cs.LG", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Activation Space Selectable Kolmogorov-Arnold Networks", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:31.058858"}
{"title": "Training Large-Scale Optical Neural Networks with Two-Pass Forward Propagation", "authors": "Amirreza Ahmadnejad, Somayyeh Koohi", "abstract": "This paper addresses the limitations in Optical Neural Networks (ONNs)\nrelated to training efficiency, nonlinear function implementation, and large\ninput data processing. We introduce Two-Pass Forward Propagation, a novel\ntraining method that avoids specific nonlinear activation functions by\nmodulating and re-entering error with random noise. Additionally, we propose a\nnew way to implement convolutional neural networks using simple neural networks\nin integrated optical systems. Theoretical foundations and numerical results\ndemonstrate significant improvements in training speed, energy efficiency, and\nscalability, advancing the potential of optical computing for complex data\ntasks.", "arxiv_id": "2408.08337v1", "pdf_url": "http://arxiv.org/pdf/2408.08337v1", "abstract_url": "http://arxiv.org/abs/2408.08337v1", "primary_category": "cs.LG", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Training Large-Scale Optical Neural Networks with Two-Pass Forward Propagation", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:31.930427"}
{"title": "An Efficient Replay for Class-Incremental Learning with Pre-trained Models", "authors": "Weimin Yin, Bin Chen adn Chunzhao Xie, Zhenhao Tan", "abstract": "In general class-incremental learning, researchers typically use sample sets\nas a tool to avoid catastrophic forgetting during continuous learning. At the\nsame time, researchers have also noted the differences between\nclass-incremental learning and Oracle training and have attempted to make\ncorrections. In recent years, researchers have begun to develop\nclass-incremental learning algorithms utilizing pre-trained models, achieving\nsignificant results. This paper observes that in class-incremental learning,\nthe steady state among the weight guided by each class center is disrupted,\nwhich is significantly correlated with catastrophic forgetting. Based on this,\nwe propose a new method to overcoming forgetting . In some cases, by retaining\nonly a single sample unit of each class in memory for replay and applying\nsimple gradient constraints, very good results can be achieved. Experimental\nresults indicate that under the condition of pre-trained models, our method can\nachieve competitive performance with very low computational cost and by simply\nusing the cross-entropy loss.", "arxiv_id": "2408.08084v1", "pdf_url": "http://arxiv.org/pdf/2408.08084v1", "abstract_url": "http://arxiv.org/abs/2408.08084v1", "primary_category": "cs.LG", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "An Efficient Replay for Class-Incremental Learning with Pre-trained Models", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:32.990636"}
{"title": "Independent Policy Mirror Descent for Markov Potential Games: Scaling to Large Number of Players", "authors": "Pragnya Alatur, Anas Barakat, Niao He", "abstract": "Markov Potential Games (MPGs) form an important sub-class of Markov games,\nwhich are a common framework to model multi-agent reinforcement learning\nproblems. In particular, MPGs include as a special case the identical-interest\nsetting where all the agents share the same reward function. Scaling the\nperformance of Nash equilibrium learning algorithms to a large number of agents\nis crucial for multi-agent systems. To address this important challenge, we\nfocus on the independent learning setting where agents can only have access to\ntheir local information to update their own policy. In prior work on MPGs, the\niteration complexity for obtaining $\\epsilon$-Nash regret scales linearly with\nthe number of agents $N$. In this work, we investigate the iteration complexity\nof an independent policy mirror descent (PMD) algorithm for MPGs. We show that\nPMD with KL regularization, also known as natural policy gradient, enjoys a\nbetter $\\sqrt{N}$ dependence on the number of agents, improving over PMD with\nEuclidean regularization and prior work. Furthermore, the iteration complexity\nis also independent of the sizes of the agents' action spaces.", "arxiv_id": "2408.08075v1", "pdf_url": "http://arxiv.org/pdf/2408.08075v1", "abstract_url": "http://arxiv.org/abs/2408.08075v1", "primary_category": "cs.LG", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Independent Policy Mirror Descent for Markov Potential Games: Scaling to Large Number of Players", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:33.878589"}
{"title": "A Survey on Integrated Sensing, Communication, and Computation", "authors": "Dingzhu Wen, Yong Zhou, Xiaoyang Li, Yuanming Shi, Kaibin Huang, Khaled B. Letaief", "abstract": "The forthcoming generation of wireless technology, 6G, promises a\nrevolutionary leap beyond traditional data-centric services. It aims to usher\nin an era of ubiquitous intelligent services, where everything is\ninterconnected and intelligent. This vision requires the seamless integration\nof three fundamental modules: Sensing for information acquisition,\ncommunication for information sharing, and computation for information\nprocessing and decision-making. These modules are intricately linked,\nespecially in complex tasks such as edge learning and inference. However, the\nperformance of these modules is interdependent, creating a resource competition\nfor time, energy, and bandwidth. Existing techniques like integrated\ncommunication and computation (ICC), integrated sensing and computation (ISC),\nand integrated sensing and communication (ISAC) have made partial strides in\naddressing this challenge, but they fall short of meeting the extreme\nperformance requirements. To overcome these limitations, it is essential to\ndevelop new techniques that comprehensively integrate sensing, communication,\nand computation. This integrated approach, known as Integrated Sensing,\nCommunication, and Computation (ISCC), offers a systematic perspective for\nenhancing task performance. This paper begins with a comprehensive survey of\nhistoric and related techniques such as ICC, ISC, and ISAC, highlighting their\nstrengths and limitations. It then explores the state-of-the-art signal designs\nfor ISCC, along with network resource management strategies specifically\ntailored for ISCC. Furthermore, this paper discusses the exciting research\nopportunities that lie ahead for implementing ISCC in future advanced networks.\nBy embracing ISCC, we can unlock the full potential of intelligent\nconnectivity, paving the way for groundbreaking applications and services.", "arxiv_id": "2408.08074v1", "pdf_url": "http://arxiv.org/pdf/2408.08074v1", "abstract_url": "http://arxiv.org/abs/2408.08074v1", "primary_category": "cs.IT", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "A Survey on Integrated Sensing, Communication, and Computation", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:34.602349"}
{"title": "Extracting Sentence Embeddings from Pretrained Transformer Models", "authors": "Lukas Stankevi\u010dius, Mantas Luko\u0161evi\u010dius", "abstract": "Background/introduction: Pre-trained transformer models shine in many natural\nlanguage processing tasks and therefore are expected to bear the representation\nof the input sentence or text meaning. These sentence-level embeddings are also\nimportant in retrieval-augmented generation. But do commonly used plain\naveraging or prompt templates surface it enough?\n  Methods: Given 110M parameters BERT's hidden representations from multiple\nlayers and multiple tokens we tried various ways to extract optimal sentence\nrepresentations. We tested various token aggregation and representation\npost-processing techniques. We also tested multiple ways of using a general\nWikitext dataset to complement BERTs sentence representations. All methods were\ntested on 8 Semantic Textual Similarity (STS), 6 short text clustering, and 12\nclassification tasks. We also evaluated our representation-shaping techniques\non other static models, including random token representations.\n  Results: Proposed representation extraction methods improved the performance\non STS and clustering tasks for all models considered. Very high improvements\nfor static token-based models, especially random embeddings for STS tasks\nalmost reach the performance of BERT-derived representations.\n  Conclusions: Our work shows that for multiple tasks simple baselines with\nrepresentation shaping techniques reach or even outperform more complex\nBERT-based models or are able to contribute to their performance.", "arxiv_id": "2408.08073v1", "pdf_url": "http://arxiv.org/pdf/2408.08073v1", "abstract_url": "http://arxiv.org/abs/2408.08073v1", "primary_category": "cs.CL", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Extracting Sentence Embeddings from Pretrained Transformer Models", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:35.338415"}
{"title": "Universality of Real Minimal Complexity Reservoir", "authors": "Robert Simon Fong, Boyu Li, Peter Ti\u0148o", "abstract": "Reservoir Computing (RC) models, a subclass of recurrent neural networks, are\ndistinguished by their fixed, non-trainable input layer and dynamically coupled\nreservoir, with only the static readout layer being trained. This design\ncircumvents the issues associated with backpropagating error signals through\ntime, thereby enhancing both stability and training efficiency. RC models have\nbeen successfully applied across a broad range of application domains.\nCrucially, they have been demonstrated to be universal approximators of\ntime-invariant dynamic filters with fading memory, under various settings of\napproximation norms and input driving sources.\n  Simple Cycle Reservoirs (SCR) represent a specialized class of RC models with\na highly constrained reservoir architecture, characterized by uniform ring\nconnectivity and binary input-to-reservoir weights with an aperiodic sign\npattern. For linear reservoirs, given the reservoir size, the reservoir\nconstruction has only one degree of freedom -- the reservoir cycle weight. Such\narchitectures are particularly amenable to hardware implementations without\nsignificant performance degradation in many practical tasks. In this study we\nendow these observations with solid theoretical foundations by proving that\nSCRs operating in real domain are universal approximators of time-invariant\ndynamic filters with fading memory. Our results supplement recent research\nshowing that SCRs in the complex domain can approximate, to arbitrary\nprecision, any unrestricted linear reservoir with a non-linear readout. We\nfurthermore introduce a novel method to drastically reduce the number of SCR\nunits, making such highly constrained architectures natural candidates for\nlow-complexity hardware implementations. Our findings are supported by\nempirical studies on real-world time series datasets.", "arxiv_id": "2408.08071v1", "pdf_url": "http://arxiv.org/pdf/2408.08071v1", "abstract_url": "http://arxiv.org/abs/2408.08071v1", "primary_category": "cs.LG", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Universality of Real Minimal Complexity Reservoir", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:36.541310"}
{"title": "BINDy -- Bayesian identification of nonlinear dynamics with reversible-jump Markov-chain Monte-Carlo", "authors": "Max D. Champneys, Timothy J. Rogers", "abstract": "Model parsimony is an important \\emph{cognitive bias} in data-driven\nmodelling that aids interpretability and helps to prevent over-fitting. Sparse\nidentification of nonlinear dynamics (SINDy) methods are able to learn sparse\nrepresentations of complex dynamics directly from data, given a basis of\nlibrary functions. In this work, a novel Bayesian treatment of dictionary\nlearning system identification, as an alternative to SINDy, is envisaged. The\nproposed method -- Bayesian identification of nonlinear dynamics (BINDy) -- is\ndistinct from previous approaches in that it targets the full joint posterior\ndistribution over both the terms in the library and their parameterisation in\nthe model. This formulation confers the advantage that an arbitrary prior may\nbe placed over the model structure to produce models that are sparse in the\nmodel space rather than in parameter space. Because this posterior is defined\nover parameter vectors that can change in dimension, the inference cannot be\nperformed by standard techniques. Instead, a Gibbs sampler based on\nreversible-jump Markov-chain Monte-Carlo is proposed. BINDy is shown to compare\nfavourably to ensemble SINDy in three benchmark case-studies. In particular, it\nis seen that the proposed method is better able to assign high probability to\ncorrect model terms.", "arxiv_id": "2408.08062v1", "pdf_url": "http://arxiv.org/pdf/2408.08062v1", "abstract_url": "http://arxiv.org/abs/2408.08062v1", "primary_category": "stat.ML", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "BINDy -- Bayesian identification of nonlinear dynamics with reversible-jump Markov-chain Monte-Carlo", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:37.538977"}
{"title": "Maximally Permissive Reward Machines", "authors": "Giovanni Varricchione, Natasha Alechina, Mehdi Dastani, Brian Logan", "abstract": "Reward machines allow the definition of rewards for temporally extended tasks\nand behaviors. Specifying \"informative\" reward machines can be challenging. One\nway to address this is to generate reward machines from a high-level abstract\ndescription of the learning environment, using techniques such as AI planning.\nHowever, previous planning-based approaches generate a reward machine based on\na single (sequential or partial-order) plan, and do not allow maximum\nflexibility to the learning agent. In this paper we propose a new approach to\nsynthesising reward machines which is based on the set of partial order plans\nfor a goal. We prove that learning using such \"maximally permissive\" reward\nmachines results in higher rewards than learning using RMs based on a single\nplan. We present experimental results which support our theoretical claims by\nshowing that our approach obtains higher rewards than the single-plan approach\nin practice.", "arxiv_id": "2408.08059v1", "pdf_url": "http://arxiv.org/pdf/2408.08059v1", "abstract_url": "http://arxiv.org/abs/2408.08059v1", "primary_category": "cs.LG", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Maximally Permissive Reward Machines", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:38.356396"}
{"title": "Navigating Data Scarcity using Foundation Models: A Benchmark of Few-Shot and Zero-Shot Learning Approaches in Medical Imaging", "authors": "Stefano Woerner, Christian F. Baumgartner", "abstract": "Data scarcity is a major limiting factor for applying modern machine learning\ntechniques to clinical tasks. Although sufficient data exists for some\nwell-studied medical tasks, there remains a long tail of clinically relevant\ntasks with poor data availability. Recently, numerous foundation models have\ndemonstrated high suitability for few-shot learning (FSL) and zero-shot\nlearning (ZSL), potentially making them more accessible to practitioners.\nHowever, it remains unclear which foundation model performs best on FSL medical\nimage analysis tasks and what the optimal methods are for learning from limited\ndata. We conducted a comprehensive benchmark study of ZSL and FSL using 16\npretrained foundation models on 19 diverse medical imaging datasets. Our\nresults indicate that BiomedCLIP, a model pretrained exclusively on medical\ndata, performs best on average for very small training set sizes, while very\nlarge CLIP models pretrained on LAION-2B perform best with slightly more\ntraining samples. However, simply fine-tuning a ResNet-18 pretrained on\nImageNet performs similarly with more than five training examples per class.\nOur findings also highlight the need for further research on foundation models\nspecifically tailored for medical applications and the collection of more\ndatasets to train these models.", "arxiv_id": "2408.08058v1", "pdf_url": "http://arxiv.org/pdf/2408.08058v1", "abstract_url": "http://arxiv.org/abs/2408.08058v1", "primary_category": "cs.CV", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Navigating Data Scarcity using Foundation Models: A Benchmark of Few-Shot and Zero-Shot Learning Approaches in Medical Imaging", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:39.033514"}
{"title": "DATTA: Towards Diversity Adaptive Test-Time Adaptation in Dynamic Wild World", "authors": "Chuyang Ye, Dongyan Wei, Zhendong Liu, Yuanyi Pang, Yixi Lin, Jiarong Liao, Qinting Jiang, Xianghua Fu, Qing Li, Jingyan Jiang", "abstract": "Test-time adaptation (TTA) effectively addresses distribution shifts between\ntraining and testing data by adjusting models on test samples, which is crucial\nfor improving model inference in real-world applications. However, traditional\nTTA methods typically follow a fixed pattern to address the dynamic data\npatterns (low-diversity or high-diversity patterns) often leading to\nperformance degradation and consequently a decline in Quality of Experience\n(QoE). The primary issues we observed are:Different scenarios require different\nnormalization methods (e.g., Instance Normalization is optimal in mixed domains\nbut not in static domains). Model fine-tuning can potentially harm the model\nand waste time.Hence, it is crucial to design strategies for effectively\nmeasuring and managing distribution diversity to minimize its negative impact\non model performance. Based on these observations, this paper proposes a new\ngeneral method, named Diversity Adaptive Test-Time Adaptation (DATTA), aimed at\nimproving QoE. DATTA dynamically selects the best batch normalization methods\nand fine-tuning strategies by leveraging the Diversity Score to differentiate\nbetween high and low diversity score batches. It features three key components:\nDiversity Discrimination (DD) to assess batch diversity, Diversity Adaptive\nBatch Normalization (DABN) to tailor normalization methods based on DD\ninsights, and Diversity Adaptive Fine-Tuning (DAFT) to selectively fine-tune\nthe model. Experimental results show that our method achieves up to a 21%\nincrease in accuracy compared to state-of-the-art methodologies, indicating\nthat our method maintains good model performance while demonstrating its\nrobustness. Our code will be released soon.", "arxiv_id": "2408.08056v1", "pdf_url": "http://arxiv.org/pdf/2408.08056v1", "abstract_url": "http://arxiv.org/abs/2408.08056v1", "primary_category": "cs.LG", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "DATTA: Towards Diversity Adaptive Test-Time Adaptation in Dynamic Wild World", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:39.744181"}
{"title": "COTODE: COntinuous Trajectory neural Ordinary Differential Equations for modelling event sequences", "authors": "Ilya Kuleshov, Galina Boeva, Vladislav Zhuzhel, Evgenia Romanenkova, Evgeni Vorsin, Alexey Zaytsev", "abstract": "Observation of the underlying actors that generate event sequences reveals\nthat they often evolve continuously. Most modern methods, however, tend to\nmodel such processes through at most piecewise-continuous trajectories. To\naddress this, we adopt a way of viewing events not as standalone phenomena but\ninstead as observations of a Gaussian Process, which in turn governs the\nactor's dynamics. We propose integrating these obtained dynamics, resulting in\na continuous-trajectory modification of the widely successful Neural ODE model.\nThrough Gaussian Process theory, we were able to evaluate the uncertainty in an\nactor's representation, which arises from not observing them between events.\nThis estimate led us to develop a novel, theoretically backed negative feedback\nmechanism. Empirical studies indicate that our model with Gaussian process\ninterpolation and negative feedback achieves state-of-the-art performance, with\nimprovements up to 20% AUROC against similar architectures.", "arxiv_id": "2408.08055v1", "pdf_url": "http://arxiv.org/pdf/2408.08055v1", "abstract_url": "http://arxiv.org/abs/2408.08055v1", "primary_category": "cs.LG", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "COTODE: COntinuous Trajectory neural Ordinary Differential Equations for modelling event sequences", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:40.524965"}
{"title": "An Efficient Continuous Control Perspective for Reinforcement-Learning-based Sequential Recommendation", "authors": "Jun Wang, Likang Wu, Qi Liu, Yu Yang", "abstract": "Sequential recommendation, where user preference is dynamically inferred from\nsequential historical behaviors, is a critical task in recommender systems\n(RSs). To further optimize long-term user engagement, offline\nreinforcement-learning-based RSs have become a mainstream technique as they\nprovide an additional advantage in avoiding global explorations that may harm\nonline users' experiences. However, previous studies mainly focus on discrete\naction and policy spaces, which might have difficulties in handling\ndramatically growing items efficiently.\n  To mitigate this issue, in this paper, we aim to design an algorithmic\nframework applicable to continuous policies. To facilitate the control in the\nlow-dimensional but dense user preference space, we propose an\n\\underline{\\textbf{E}}fficient \\underline{\\textbf{Co}}ntinuous\n\\underline{\\textbf{C}}ontrol framework (ECoC). Based on a statistically tested\nassumption, we first propose the novel unified action representation abstracted\nfrom normalized user and item spaces. Then, we develop the corresponding policy\nevaluation and policy improvement procedures. During this process, strategic\nexploration and directional control in terms of unified actions are carefully\ndesigned and crucial to final recommendation decisions. Moreover, beneficial\nfrom unified actions, the conservatism regularization for policies and value\nfunctions are combined and perfectly compatible with the continuous framework.\nThe resulting dual regularization ensures the successful offline training of\nRL-based recommendation policies. Finally, we conduct extensive experiments to\nvalidate the effectiveness of our framework. The results show that compared to\nthe discrete baselines, our ECoC is trained far more efficiently. Meanwhile,\nthe final policies outperform baselines in both capturing the offline data and\ngaining long-term rewards.", "arxiv_id": "2408.08047v1", "pdf_url": "http://arxiv.org/pdf/2408.08047v1", "abstract_url": "http://arxiv.org/abs/2408.08047v1", "primary_category": "cs.LG", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "An Efficient Continuous Control Perspective for Reinforcement-Learning-based Sequential Recommendation", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:42.485394"}
{"title": "The Clever Hans Effect in Unsupervised Learning", "authors": "Jacob Kauffmann, Jonas Dippel, Lukas Ruff, Wojciech Samek, Klaus-Robert M\u00fcller, Gr\u00e9goire Montavon", "abstract": "Unsupervised learning has become an essential building block of AI systems.\nThe representations it produces, e.g. in foundation models, are critical to a\nwide variety of downstream applications. It is therefore important to carefully\nexamine unsupervised models to ensure not only that they produce accurate\npredictions, but also that these predictions are not \"right for the wrong\nreasons\", the so-called Clever Hans (CH) effect. Using specially developed\nExplainable AI techniques, we show for the first time that CH effects are\nwidespread in unsupervised learning. Our empirical findings are enriched by\ntheoretical insights, which interestingly point to inductive biases in the\nunsupervised learning machine as a primary source of CH effects. Overall, our\nwork sheds light on unexplored risks associated with practical applications of\nunsupervised learning and suggests ways to make unsupervised learning more\nrobust.", "arxiv_id": "2408.08041v1", "pdf_url": "http://arxiv.org/pdf/2408.08041v1", "abstract_url": "http://arxiv.org/abs/2408.08041v1", "primary_category": "cs.LG", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "The Clever Hans Effect in Unsupervised Learning", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:47.345244"}
{"title": "Adaptive User Journeys in Pharma E-Commerce with Reinforcement Learning: Insights from SwipeRx", "authors": "Ana Fern\u00e1ndez del R\u00edo, Michael Brennan Leong, Paulo Saraiva, Ivan Nazarov, Aditya Rastogi, Moiz Hassan, Dexian Tang, \u00c1frica Peri\u00e1\u00f1ez", "abstract": "This paper introduces a reinforcement learning (RL) platform that enhances\nend-to-end user journeys in healthcare digital tools through personalization.\nWe explore a case study with SwipeRx, the most popular all-in-one app for\npharmacists in Southeast Asia, demonstrating how the platform can be used to\npersonalize and adapt user experiences. Our RL framework is tested through a\nseries of experiments with product recommendations tailored to each pharmacy\nbased on real-time information on their purchasing history and in-app\nengagement, showing a significant increase in basket size. By integrating\nadaptive interventions into existing mobile health solutions and enriching user\njourneys, our platform offers a scalable solution to improve pharmaceutical\nsupply chain management, health worker capacity building, and clinical decision\nand patient care, ultimately contributing to better healthcare outcomes.", "arxiv_id": "2408.08024v1", "pdf_url": "http://arxiv.org/pdf/2408.08024v1", "abstract_url": "http://arxiv.org/abs/2408.08024v1", "primary_category": "cs.LG", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Adaptive User Journeys in Pharma E-Commerce with Reinforcement Learning: Insights from SwipeRx", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:48.276217"}
{"title": "Causal Discovery from Time-Series Data with Short-Term Invariance-Based Convolutional Neural Networks", "authors": "Rujia Shen, Boran Wang, Chao Zhao, Yi Guan, Jingchi Jiang", "abstract": "Causal discovery from time-series data aims to capture both intra-slice\n(contemporaneous) and inter-slice (time-lagged) causality between variables\nwithin the temporal chain, which is crucial for various scientific disciplines.\nCompared to causal discovery from non-time-series data, causal discovery from\ntime-series data necessitates more serialized samples with a larger amount of\nobserved time steps. To address the challenges, we propose a novel\ngradient-based causal discovery approach STIC, which focuses on\n\\textbf{S}hort-\\textbf{T}erm \\textbf{I}nvariance using \\textbf{C}onvolutional\nneural networks to uncover the causal relationships from time-series data.\nSpecifically, STIC leverages both the short-term time and mechanism invariance\nof causality within each window observation, which possesses the property of\nindependence, to enhance sample efficiency. Furthermore, we construct two\ncausal convolution kernels, which correspond to the short-term time and\nmechanism invariance respectively, to estimate the window causal graph. To\ndemonstrate the necessity of convolutional neural networks for causal discovery\nfrom time-series data, we theoretically derive the equivalence between\nconvolution and the underlying generative principle of time-series data under\nthe assumption that the additive noise model is identifiable. Experimental\nevaluations conducted on both synthetic and FMRI benchmark datasets demonstrate\nthat our STIC outperforms baselines significantly and achieves the\nstate-of-the-art performance, particularly when the datasets contain a limited\nnumber of observed time steps. Code is available at\n\\url{https://github.com/HITshenrj/STIC}.", "arxiv_id": "2408.08023v1", "pdf_url": "http://arxiv.org/pdf/2408.08023v1", "abstract_url": "http://arxiv.org/abs/2408.08023v1", "primary_category": "cs.LG", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Causal Discovery from Time-Series Data with Short-Term Invariance-Based Convolutional Neural Networks", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:49.024053"}
{"title": "Accelerating High-Fidelity Waveform Generation via Adversarial Flow Matching Optimization", "authors": "Sang-Hoon Lee, Ha-Yeong Choi, Seong-Whan Lee", "abstract": "This paper introduces PeriodWave-Turbo, a high-fidelity and high-efficient\nwaveform generation model via adversarial flow matching optimization. Recently,\nconditional flow matching (CFM) generative models have been successfully\nadopted for waveform generation tasks, leveraging a single vector field\nestimation objective for training. Although these models can generate\nhigh-fidelity waveform signals, they require significantly more ODE steps\ncompared to GAN-based models, which only need a single generation step.\nAdditionally, the generated samples often lack high-frequency information due\nto noisy vector field estimation, which fails to ensure high-frequency\nreproduction. To address this limitation, we enhance pre-trained CFM-based\ngenerative models by incorporating a fixed-step generator modification. We\nutilized reconstruction losses and adversarial feedback to accelerate\nhigh-fidelity waveform generation. Through adversarial flow matching\noptimization, it only requires 1,000 steps of fine-tuning to achieve\nstate-of-the-art performance across various objective metrics. Moreover, we\nsignificantly reduce inference speed from 16 steps to 2 or 4 steps.\nAdditionally, by scaling up the backbone of PeriodWave from 29M to 70M\nparameters for improved generalization, PeriodWave-Turbo achieves unprecedented\nperformance, with a perceptual evaluation of speech quality (PESQ) score of\n4.454 on the LibriTTS dataset. Audio samples, source code and checkpoints will\nbe available at https://github.com/sh-lee-prml/PeriodWave.", "arxiv_id": "2408.08019v1", "pdf_url": "http://arxiv.org/pdf/2408.08019v1", "abstract_url": "http://arxiv.org/abs/2408.08019v1", "primary_category": "cs.SD", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Accelerating High-Fidelity Waveform Generation via Adversarial Flow Matching Optimization", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:49.776074"}
{"title": "Asteroid: Resource-Efficient Hybrid Pipeline Parallelism for Collaborative DNN Training on Heterogeneous Edge Devices", "authors": "Shengyuan Ye, Liekang Zeng, Xiaowen Chu, Guoliang Xing, Xu Chen", "abstract": "On-device Deep Neural Network (DNN) training has been recognized as crucial\nfor privacy-preserving machine learning at the edge. However, the intensive\ntraining workload and limited onboard computing resources pose significant\nchallenges to the availability and efficiency of model training. While existing\nworks address these challenges through native resource management optimization,\nwe instead leverage our observation that edge environments usually comprise a\nrich set of accompanying trusted edge devices with idle resources beyond a\nsingle terminal. We propose Asteroid, a distributed edge training system that\nbreaks the resource walls across heterogeneous edge devices for efficient model\ntraining acceleration. Asteroid adopts a hybrid pipeline parallelism to\norchestrate distributed training, along with a judicious parallelism planning\nfor maximizing throughput under certain resource constraints. Furthermore, a\nfault-tolerant yet lightweight pipeline replay mechanism is developed to tame\nthe device-level dynamics for training robustness and performance stability. We\nimplement Asteroid on heterogeneous edge devices with both vision and language\nmodels, demonstrating up to 12.2x faster training than conventional parallelism\nmethods and 2.1x faster than state-of-the-art hybrid parallelism methods\nthrough evaluations. Furthermore, Asteroid can recover training pipeline 14x\nfaster than baseline methods while preserving comparable throughput despite\nunexpected device exiting and failure.", "arxiv_id": "2408.08015v1", "pdf_url": "http://arxiv.org/pdf/2408.08015v1", "abstract_url": "http://arxiv.org/abs/2408.08015v1", "primary_category": "cs.DC", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Asteroid: Resource-Efficient Hybrid Pipeline Parallelism for Collaborative DNN Training on Heterogeneous Edge Devices", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:50.871625"}
{"title": "Hessian QM9: A quantum chemistry database of molecular Hessians in implicit solvents", "authors": "Nicholas J. Williams, Lara Kabalan, Ljiljana Stojanovic, Viktor Zolyomi, Edward O. Pyzer-Knapp", "abstract": "A significant challenge in computational chemistry is developing\napproximations that accelerate \\emph{ab initio} methods while preserving\naccuracy. Machine learning interatomic potentials (MLIPs) have emerged as a\npromising solution for constructing atomistic potentials that can be\ntransferred across different molecular and crystalline systems. Most MLIPs are\ntrained only on energies and forces in vacuum, while an improved description of\nthe potential energy surface could be achieved by including the curvature of\nthe potential energy surface. We present Hessian QM9, the first database of\nequilibrium configurations and numerical Hessian matrices, consisting of 41,645\nmolecules from the QM9 dataset at the $\\omega$B97x/6-31G* level. Molecular\nHessians were calculated in vacuum, as well as water, tetrahydrofuran, and\ntoluene using an implicit solvation model. To demonstrate the utility of this\ndataset, we show that incorporating second derivatives of the potential energy\nsurface into the loss function of a MLIP significantly improves the prediction\nof vibrational frequencies in all solvent environments, thus making this\ndataset extremely useful for studying organic molecules in realistic solvent\nenvironments for experimental characterization.", "arxiv_id": "2408.08006v1", "pdf_url": "http://arxiv.org/pdf/2408.08006v1", "abstract_url": "http://arxiv.org/abs/2408.08006v1", "primary_category": "physics.chem-ph", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Hessian QM9: A quantum chemistry database of molecular Hessians in implicit solvents", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:51.690979"}
{"title": "Inversion-DeepONet: A Novel DeepONet-Based Network with Encoder-Decoder for Full Waveform Inversion", "authors": "Zekai Guo, Lihui Chai, Shengjun Huang, Ye Li", "abstract": "Full waveform inversion (FWI) plays a crucial role in the field of\ngeophysics. There has been lots of research about applying deep learning (DL)\nmethods to FWI. The success of DL-FWI relies significantly on the quantity and\ndiversity of the datasets. Nevertheless, existing FWI datasets, like OpenFWI,\nwhere sources have fixed locations or identical frequencies, provide limited\ninformation and do not represent the complex real-world scene. For instance,\nlow frequencies help in resolving larger-scale structures. High frequencies\nallow for a more detailed subsurface features. %A single source frequency is\ninsufficient to describe subsurface structural properties. We consider that\nsimultaneously using sources with different frequencies, instead of performing\ninversion using low frequencies data and then gradually introducing higher\nfrequencies data, has rationale and potential advantages. Hence, we develop\nthree enhanced datasets based on OpenFWI where each source have varying\nlocations, frequencies or both. Moreover, we propose a novel deep operator\nnetwork (DeepONet) architecture Inversion-DeepONet for FWI. We utilize\nconvolutional neural network (CNN) to extract the features from seismic data in\nbranch net. Source parameters, such as locations and frequencies, are fed to\ntrunk net. Then another CNN is employed as the decoder of DeepONet to\nreconstruct the velocity models more effectively. Through experiments, we\nconfirm the superior performance on accuracy and generalization ability of our\nnetwork, compared with existing data-driven FWI methods.", "arxiv_id": "2408.08005v1", "pdf_url": "http://arxiv.org/pdf/2408.08005v1", "abstract_url": "http://arxiv.org/abs/2408.08005v1", "primary_category": "cs.LG", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Inversion-DeepONet: A Novel DeepONet-Based Network with Encoder-Decoder for Full Waveform Inversion", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:52.579048"}
{"title": "Graph representations of 3D data for machine learning", "authors": "Tomasz Prytu\u0142a", "abstract": "We give an overview of combinatorial methods to represent 3D data, such as\ngraphs and meshes, from the viewpoint of their amenability to analysis using\nmachine learning algorithms. We highlight pros and cons of various\nrepresentations and we discuss some methods of generating/switching between the\nrepresentations. We finally present two concrete applications in life science\nand industry. Despite its theoretical nature, our discussion is in general\nmotivated by, and biased towards real-world challenges.", "arxiv_id": "2408.08336v1", "pdf_url": "http://arxiv.org/pdf/2408.08336v1", "abstract_url": "http://arxiv.org/abs/2408.08336v1", "primary_category": "cs.LG", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "NOT_ENOUGH_RELATED"}
{"title": "Graph representations of 3D data for machine learning", "response": "NOT_ENOUGH_RELATED", "timestamp": "2024-08-19T13:33:53.671515"}
{"title": "Experimental evaluation of offline reinforcement learning for HVAC control in buildings", "authors": "Jun Wang, Linyan Li, Qi Liu, Yu Yang", "abstract": "Reinforcement learning (RL) techniques have been increasingly investigated\nfor dynamic HVAC control in buildings. However, most studies focus on exploring\nsolutions in online or off-policy scenarios without discussing in detail the\nimplementation feasibility or effectiveness of dealing with purely offline\ndatasets or trajectories. The lack of these works limits the real-world\ndeployment of RL-based HVAC controllers, especially considering the abundance\nof historical data. To this end, this paper comprehensively evaluates the\nstrengths and limitations of state-of-the-art offline RL algorithms by\nconducting analytical and numerical studies. The analysis is conducted from two\nperspectives: algorithms and dataset characteristics. As a prerequisite, the\nnecessity of applying offline RL algorithms is first confirmed in two building\nenvironments. The ability of observation history modeling to reduce violations\nand enhance performance is subsequently studied. Next, the performance of\nRL-based controllers under datasets with different qualitative and quantitative\nconditions is investigated, including constraint satisfaction and power\nconsumption. Finally, the sensitivity of certain hyperparameters is also\nevaluated. The results indicate that datasets of a certain suboptimality level\nand relatively small scale can be utilized to effectively train a\nwell-performed RL-based HVAC controller. Specifically, such controllers can\nreduce at most 28.5% violation ratios of indoor temperatures and achieve at\nmost 12.1% power savings compared to the baseline controller. In summary, this\npaper presents our well-structured investigations and new findings when\napplying offline reinforcement learning to building HVAC systems.", "arxiv_id": "2408.07986v1", "pdf_url": "http://arxiv.org/pdf/2408.07986v1", "abstract_url": "http://arxiv.org/abs/2408.07986v1", "primary_category": "cs.LG", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Experimental evaluation of offline reinforcement learning for HVAC control in buildings", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:54.658552"}
{"title": "Analytical Uncertainty-Based Loss Weighting in Multi-Task Learning", "authors": "Lukas Kirchdorfer, Cathrin Elich, Simon Kutsche, Heiner Stuckenschmidt, Lukas Schott, Jan M. K\u00f6hler", "abstract": "With the rise of neural networks in various domains, multi-task learning\n(MTL) gained significant relevance. A key challenge in MTL is balancing\nindividual task losses during neural network training to improve performance\nand efficiency through knowledge sharing across tasks. To address these\nchallenges, we propose a novel task-weighting method by building on the most\nprevalent approach of Uncertainty Weighting and computing analytically optimal\nuncertainty-based weights, normalized by a softmax function with tunable\ntemperature. Our approach yields comparable results to the combinatorially\nprohibitive, brute-force approach of Scalarization while offering a more\ncost-effective yet high-performing alternative. We conduct an extensive\nbenchmark on various datasets and architectures. Our method consistently\noutperforms six other common weighting methods. Furthermore, we report\nnoteworthy experimental findings for the practical application of MTL. For\nexample, larger networks diminish the influence of weighting methods, and\ntuning the weight decay has a low impact compared to the learning rate.", "arxiv_id": "2408.07985v1", "pdf_url": "http://arxiv.org/pdf/2408.07985v1", "abstract_url": "http://arxiv.org/abs/2408.07985v1", "primary_category": "cs.LG", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Analytical Uncertainty-Based Loss Weighting in Multi-Task Learning", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:55.326890"}
{"title": "Coupling without Communication and Drafter-Invariant Speculative Decoding", "authors": "Majid Daliri, Christopher Musco, Ananda Theertha Suresh", "abstract": "Suppose Alice has a distribution $P$ and Bob has a distribution $Q$. Alice\nwants to generate a sample $a\\sim P$ and Bob a sample $b \\sim Q$ such that $a =\nb$ with has as high of probability as possible. It is well-known that, by\nsampling from an optimal coupling between the distributions, Alice and Bob can\nachieve $Pr[a = b] = 1 - D_{TV}(P,Q)$, where $D_{TV}(P,Q)$ is the total\nvariation distance. What if Alice and Bob must solve this same problem without\ncommunicating at all? Perhaps surprisingly, with access to public randomness,\nthey can still achieve $Pr[a = b] \\geq \\frac{1 - D_{TV}(P,Q)}{1 + D_{TV}(P,Q)}\n\\geq 1-2D_{TV}(P,Q)$. In fact, this bound can be obtained using a simple\nprotocol based on the Weighted MinHash algorithm. In this work, we explore the\ncommunication-free coupling in greater depth. First, we show that an equally\nsimple protocol based on Gumbel sampling matches the worst-case guarantees of\nthe Weighted MinHash approach, but tends to perform better in practice.\nConversely, we prove that both approaches are actually sharp: no\ncommunication-free protocol can achieve $Pr[a=b]>\\frac{1 - D_{TV}(P,Q)}{1 +\nD_{TV}(P,Q)}$ in the worst-case. Finally, we prove that, for distributions over\n$n$ items, there exists a scheme that uses just $O(\\log(n/\\epsilon))$ bits of\ncommunication to achieve $Pr[a = b] = 1 - D_{TV}(P,Q) - \\epsilon$, i.e. to\nessentially match optimal coupling. Beyond our theoretical results, we\ndemonstrate an application of communication-free coupling to speculative\ndecoding, a recent method for accelerating autoregressive large language models\n[Leviathan, Kalman, Matias, ICML 2023]. We show that communication-free\nprotocols yield a variant of speculative decoding that we call\nDrafter-Invariant Speculative Decoding, which has the desirable property that\nthe output of the method is fixed given a fixed random seed, regardless of what\ndrafter is used for speculation.", "arxiv_id": "2408.07978v1", "pdf_url": "http://arxiv.org/pdf/2408.07978v1", "abstract_url": "http://arxiv.org/abs/2408.07978v1", "primary_category": "cs.DS", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Coupling without Communication and Drafter-Invariant Speculative Decoding", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:56.093166"}
{"title": "Addressing Skewed Heterogeneity via Federated Prototype Rectification with Personalization", "authors": "Shunxin Guo, Hongsong Wang, Shuxia Lin, Zhiqiang Kou, Xin Geng", "abstract": "Federated learning is an efficient framework designed to facilitate\ncollaborative model training across multiple distributed devices while\npreserving user data privacy. A significant challenge of federated learning is\ndata-level heterogeneity, i.e., skewed or long-tailed distribution of private\ndata. Although various methods have been proposed to address this challenge,\nmost of them assume that the underlying global data is uniformly distributed\nacross all clients. This paper investigates data-level heterogeneity federated\nlearning with a brief review and redefines a more practical and challenging\nsetting called Skewed Heterogeneous Federated Learning (SHFL). Accordingly, we\npropose a novel Federated Prototype Rectification with Personalization which\nconsists of two parts: Federated Personalization and Federated Prototype\nRectification. The former aims to construct balanced decision boundaries\nbetween dominant and minority classes based on private data, while the latter\nexploits both inter-class discrimination and intra-class consistency to rectify\nempirical prototypes. Experiments on three popular benchmarks show that the\nproposed approach outperforms current state-of-the-art methods and achieves\nbalanced performance in both personalization and generalization.", "arxiv_id": "2408.07966v1", "pdf_url": "http://arxiv.org/pdf/2408.07966v1", "abstract_url": "http://arxiv.org/abs/2408.07966v1", "primary_category": "cs.LG", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Addressing Skewed Heterogeneity via Federated Prototype Rectification with Personalization", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:57.219674"}
{"title": "Meta SAC-Lag: Towards Deployable Safe Reinforcement Learning via MetaGradient-based Hyperparameter Tuning", "authors": "Homayoun Honari, Amir Mehdi Soufi Enayati, Mehran Ghafarian Tamizi, Homayoun Najjaran", "abstract": "Safe Reinforcement Learning (Safe RL) is one of the prevalently studied\nsubcategories of trial-and-error-based methods with the intention to be\ndeployed on real-world systems. In safe RL, the goal is to maximize reward\nperformance while minimizing constraints, often achieved by setting bounds on\nconstraint functions and utilizing the Lagrangian method. However, deploying\nLagrangian-based safe RL in real-world scenarios is challenging due to the\nnecessity of threshold fine-tuning, as imprecise adjustments may lead to\nsuboptimal policy convergence. To mitigate this challenge, we propose a unified\nLagrangian-based model-free architecture called Meta Soft Actor-Critic\nLagrangian (Meta SAC-Lag). Meta SAC-Lag uses meta-gradient optimization to\nautomatically update the safety-related hyperparameters. The proposed method is\ndesigned to address safe exploration and threshold adjustment with minimal\nhyperparameter tuning requirement. In our pipeline, the inner parameters are\nupdated through the conventional formulation and the hyperparameters are\nadjusted using the meta-objectives which are defined based on the updated\nparameters. Our results show that the agent can reliably adjust the safety\nperformance due to the relatively fast convergence rate of the safety\nthreshold. We evaluate the performance of Meta SAC-Lag in five simulated\nenvironments against Lagrangian baselines, and the results demonstrate its\ncapability to create synergy between parameters, yielding better or competitive\nresults. Furthermore, we conduct a real-world experiment involving a robotic\narm tasked with pouring coffee into a cup without spillage. Meta SAC-Lag is\nsuccessfully trained to execute the task, while minimizing effort constraints.", "arxiv_id": "2408.07962v1", "pdf_url": "http://arxiv.org/pdf/2408.07962v1", "abstract_url": "http://arxiv.org/abs/2408.07962v1", "primary_category": "cs.LG", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Meta SAC-Lag: Towards Deployable Safe Reinforcement Learning via MetaGradient-based Hyperparameter Tuning", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:57.936759"}
{"title": "RandomNet: Clustering Time Series Using Untrained Deep Neural Networks", "authors": "Xiaosheng Li, Wenjie Xi, Jessica Lin", "abstract": "Neural networks are widely used in machine learning and data mining.\nTypically, these networks need to be trained, implying the adjustment of\nweights (parameters) within the network based on the input data. In this work,\nwe propose a novel approach, RandomNet, that employs untrained deep neural\nnetworks to cluster time series. RandomNet uses different sets of random\nweights to extract diverse representations of time series and then ensembles\nthe clustering relationships derived from these different representations to\nbuild the final clustering results. By extracting diverse representations, our\nmodel can effectively handle time series with different characteristics. Since\nall parameters are randomly generated, no training is required during the\nprocess. We provide a theoretical analysis of the effectiveness of the method.\nTo validate its performance, we conduct extensive experiments on all of the 128\ndatasets in the well-known UCR time series archive and perform statistical\nanalysis of the results. These datasets have different sizes, sequence lengths,\nand they are from diverse fields. The experimental results show that the\nproposed method is competitive compared with existing state-of-the-art methods.", "arxiv_id": "2408.07956v1", "pdf_url": "http://arxiv.org/pdf/2408.07956v1", "abstract_url": "http://arxiv.org/abs/2408.07956v1", "primary_category": "cs.LG", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "RandomNet: Clustering Time Series Using Untrained Deep Neural Networks", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:58.755629"}
{"title": "Robust Offline Active Learning on Graphs", "authors": "Yuanchen Wu, Yubai Yuan", "abstract": "We consider the problem of active learning on graphs, which has crucial\napplications in many real-world networks where labeling node responses is\nexpensive. In this paper, we propose an offline active learning method that\nselects nodes to query by explicitly incorporating information from both the\nnetwork structure and node covariates. Building on graph signal recovery\ntheories and the random spectral sparsification technique, the proposed method\nadopts a two-stage biased sampling strategy that takes both informativeness and\nrepresentativeness into consideration for node querying. Informativeness refers\nto the complexity of graph signals that are learnable from the responses of\nqueried nodes, while representativeness refers to the capacity of queried nodes\nto control generalization errors given noisy node-level information. We\nestablish a theoretical relationship between generalization error and the\nnumber of nodes selected by the proposed method. Our theoretical results\ndemonstrate the trade-off between informativeness and representativeness in\nactive learning. Extensive numerical experiments show that the proposed method\nis competitive with existing graph-based active learning methods, especially\nwhen node covariates and responses contain noises. Additionally, the proposed\nmethod is applicable to both regression and classification tasks on graphs.", "arxiv_id": "2408.07941v1", "pdf_url": "http://arxiv.org/pdf/2408.07941v1", "abstract_url": "http://arxiv.org/abs/2408.07941v1", "primary_category": "stat.ML", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Robust Offline Active Learning on Graphs", "response": "RELEVANT", "timestamp": "2024-08-19T13:33:59.677045"}
{"title": "MobileMEF: Fast and Efficient Method for Multi-Exposure Fusion", "authors": "Lucas Nedel Kirsten, Zhicheng Fu, Nikhil Ambha Madhusudhana", "abstract": "Recent advances in camera design and imaging technology have enabled the\ncapture of high-quality images using smartphones. However, due to the limited\ndynamic range of digital cameras, the quality of photographs captured in\nenvironments with highly imbalanced lighting often results in poor-quality\nimages. To address this issue, most devices capture multi-exposure frames and\nthen use some multi-exposure fusion method to merge those frames into a final\nfused image. Nevertheless, most traditional and current deep learning\napproaches are unsuitable for real-time applications on mobile devices due to\ntheir heavy computational and memory requirements. We propose a new method for\nmulti-exposure fusion based on an encoder-decoder deep learning architecture\nwith efficient building blocks tailored for mobile devices. This efficient\ndesign makes our model capable of processing 4K resolution images in less than\n2 seconds on mid-range smartphones. Our method outperforms state-of-the-art\ntechniques regarding full-reference quality measures and computational\nefficiency (runtime and memory usage), making it ideal for real-time\napplications on hardware-constrained devices. Our code is available at:\nhttps://github.com/LucasKirsten/MobileMEF.", "arxiv_id": "2408.07932v1", "pdf_url": "http://arxiv.org/pdf/2408.07932v1", "abstract_url": "http://arxiv.org/abs/2408.07932v1", "primary_category": "eess.IV", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "MobileMEF: Fast and Efficient Method for Multi-Exposure Fusion", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:00.497009"}
{"title": "A Single Channel-Based Neonatal Sleep-Wake Classification using Hjorth Parameters and Improved Gradient Boosting", "authors": "Muhammad Arslan, Muhammad Mubeen, Saadullah Farooq Abbasi, Muhammad Shahbaz Khan, Wadii Boulila, Jawad Ahmad", "abstract": "Sleep plays a crucial role in neonatal development. Monitoring the sleep\npatterns in neonates in a Neonatal Intensive Care Unit (NICU) is imperative for\nunderstanding the maturation process. While polysomnography (PSG) is considered\nthe best practice for sleep classification, its expense and reliance on human\nannotation pose challenges. Existing research often relies on multichannel EEG\nsignals; however, concerns arise regarding the vulnerability of neonates and\nthe potential impact on their sleep quality. This paper introduces a novel\napproach to neonatal sleep stage classification using a single-channel gradient\nboosting algorithm with Hjorth features. The gradient boosting parameters are\nfine-tuned using random search cross-validation (randomsearchCV), achieving an\naccuracy of 82.35% for neonatal sleep-wake classification. Validation is\nconducted through 5-fold cross-validation. The proposed algorithm not only\nenhances existing neonatal sleep algorithms but also opens avenues for broader\napplications.", "arxiv_id": "2408.07925v1", "pdf_url": "http://arxiv.org/pdf/2408.07925v1", "abstract_url": "http://arxiv.org/abs/2408.07925v1", "primary_category": "cs.LG", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "A Single Channel-Based Neonatal Sleep-Wake Classification using Hjorth Parameters and Improved Gradient Boosting", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:01.213416"}
{"title": "A Deep Features-Based Approach Using Modified ResNet50 and Gradient Boosting for Visual Sentiments Classification", "authors": "Muhammad Arslan, Muhammad Mubeen, Arslan Akram, Saadullah Farooq Abbasi, Muhammad Salman Ali, Muhammad Usman Tariq", "abstract": "The versatile nature of Visual Sentiment Analysis (VSA) is one reason for its\nrising profile. It isn't easy to efficiently manage social media data with\nvisual information since previous research has concentrated on Sentiment\nAnalysis (SA) of single modalities, like textual. In addition, most visual\nsentiment studies need to adequately classify sentiment because they are mainly\nfocused on simply merging modal attributes without investigating their\nintricate relationships. This prompted the suggestion of developing a fusion of\ndeep learning and machine learning algorithms. In this research, a deep\nfeature-based method for multiclass classification has been used to extract\ndeep features from modified ResNet50. Furthermore, gradient boosting algorithm\nhas been used to classify photos containing emotional content. The approach is\nthoroughly evaluated on two benchmarked datasets, CrowdFlower and GAPED.\nFinally, cutting-edge deep learning and machine learning models were used to\ncompare the proposed strategy. When compared to state-of-the-art approaches,\nthe proposed method demonstrates exceptional performance on the datasets\npresented.", "arxiv_id": "2408.07922v1", "pdf_url": "http://arxiv.org/pdf/2408.07922v1", "abstract_url": "http://arxiv.org/abs/2408.07922v1", "primary_category": "cs.CV", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "A Deep Features-Based Approach Using Modified ResNet50 and Gradient Boosting for Visual Sentiments Classification", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:02.036289"}
{"title": "Physics-Informed Neural Network for Predicting Out-of-Training-Range TCAD Solution with Minimized Domain Expertise", "authors": "Albert Lu, Yu Foon Chau, Hiu Yung Wong", "abstract": "Machine learning (ML) is promising in assisting technology computer-aided\ndesign (TCAD) simulations to alleviate difficulty in convergence and prolonged\nsimulation time. While ML is widely used in TCAD, they either require access to\nthe internal solver, require extensive domain expertise, are only trained by\nterminal quantities such as currents and voltages, and/or lack\nout-of-training-range prediction capability. In this paper, using Si nanowire\nas an example, we demonstrate that it is possible to use a physics-informed\nneural network (PINN) to predict out-of-training-range TCAD solutions without\naccessing the internal solver and with minimal domain expertise. The machine\nnot only can predict a 2.5 times larger range than the training but also can\npredict the inversion region by only being trained with subthreshold region\ndata. The physics-informed module is also trained with data without the need\nfor human-coded equations making this easier to be extended to more\nsophisticated systems.", "arxiv_id": "2408.07921v1", "pdf_url": "http://arxiv.org/pdf/2408.07921v1", "abstract_url": "http://arxiv.org/abs/2408.07921v1", "primary_category": "cs.LG", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Physics-Informed Neural Network for Predicting Out-of-Training-Range TCAD Solution with Minimized Domain Expertise", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:02.891780"}
{"title": "CEGRL-TKGR: A Causal Enhanced Graph Representation Learning Framework for Improving Temporal Knowledge Graph Extrapolation Reasoning", "authors": "Jinze Sun, Yongpan Sheng, Lirong He", "abstract": "Temporal knowledge graph reasoning (TKGR) is increasingly gaining attention\nfor its ability to extrapolate new events from historical data, thereby\nenriching the inherently incomplete temporal knowledge graphs. Existing\ngraph-based representation learning frameworks have made significant strides in\ndeveloping evolving representations for both entities and relational\nembeddings. Despite these achievements, there's a notable tendency in these\nmodels to inadvertently learn biased data representations and mine spurious\ncorrelations, consequently failing to discern the causal relationships between\nevents. This often leads to incorrect predictions based on these false\ncorrelations. To address this, we propose an innovative causal enhanced graph\nrepresentation learning framework for TKGR (named CEGRL-TKGR). This framework\nintroduces causal structures in graph-based representation learning to unveil\nthe essential causal relationships between events, ultimately enhancing task\nperformance. Specifically, we first disentangle the evolutionary\nrepresentations of entities and relations in a temporal graph sequence into two\ndistinct components, namely causal representations and confounding\nrepresentations. Then, drawing on causal intervention theory, we advocate the\nutilization of causal representations for predictions, aiming to mitigate the\neffects of erroneous correlations caused by confounding features, thus\nachieving more robust and accurate predictions. Finally, extensive experimental\nresults on six benchmark datasets demonstrate the superior performance of our\nmodel in the link prediction task.", "arxiv_id": "2408.07911v1", "pdf_url": "http://arxiv.org/pdf/2408.07911v1", "abstract_url": "http://arxiv.org/abs/2408.07911v1", "primary_category": "cs.LG", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "CEGRL-TKGR: A Causal Enhanced Graph Representation Learning Framework for Improving Temporal Knowledge Graph Extrapolation Reasoning", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:03.585233"}
{"title": "KAN versus MLP on Irregular or Noisy Functions", "authors": "Chen Zeng, Jiahui Wang, Haoran Shen, Qiao Wang", "abstract": "In this paper, we compare the performance of Kolmogorov-Arnold Networks (KAN)\nand Multi-Layer Perceptron (MLP) networks on irregular or noisy functions. We\ncontrol the number of parameters and the size of the training samples to ensure\na fair comparison. For clarity, we categorize the functions into six types:\nregular functions, continuous functions with local non-differentiable points,\nfunctions with jump discontinuities, functions with singularities, functions\nwith coherent oscillations, and noisy functions. Our experimental results\nindicate that KAN does not always perform best. For some types of functions,\nMLP outperforms or performs comparably to KAN. Furthermore, increasing the size\nof training samples can improve performance to some extent. When noise is added\nto functions, the irregular features are often obscured by the noise, making it\nchallenging for both MLP and KAN to extract these features effectively. We hope\nthese experiments provide valuable insights for future neural network research\nand encourage further investigations to overcome these challenges.", "arxiv_id": "2408.07906v1", "pdf_url": "http://arxiv.org/pdf/2408.07906v1", "abstract_url": "http://arxiv.org/abs/2408.07906v1", "primary_category": "cs.LG", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "KAN versus MLP on Irregular or Noisy Functions", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:04.413305"}
{"title": "The Nah Bandit: Modeling User Non-compliance in Recommendation Systems", "authors": "Tianyue Zhou, Jung-Hoon Cho, Cathy Wu", "abstract": "Recommendation systems now pervade the digital world, ranging from\nadvertising to entertainment. However, it remains challenging to implement\neffective recommendation systems in the physical world, such as in mobility or\nhealth. This work focuses on a key challenge: in the physical world, it is\noften easy for the user to opt out of taking any recommendation if they are not\nto her liking, and to fall back to her baseline behavior. It is thus crucial in\ncyber-physical recommendation systems to operate with an interaction model that\nis aware of such user behavior, lest the user abandon the recommendations\naltogether. This paper thus introduces the Nah Bandit, a tongue-in-cheek\nreference to describe a Bandit problem where users can say `nah' to the\nrecommendation and opt for their preferred option instead. As such, this\nproblem lies in between a typical bandit setup and supervised learning. We\nmodel the user non-compliance by parameterizing an anchoring effect of\nrecommendations on users. We then propose the Expert with Clustering (EWC)\nalgorithm, a hierarchical approach that incorporates feedback from both\nrecommended and non-recommended options to accelerate user preference learning.\nIn a recommendation scenario with $N$ users, $T$ rounds per user, and $K$\nclusters, EWC achieves a regret bound of $O(N\\sqrt{T\\log K} + NT)$, achieving\nsuperior theoretical performance in the short term compared to LinUCB\nalgorithm. Experimental results also highlight that EWC outperforms both\nsupervised learning and traditional contextual bandit approaches. This\nadvancement reveals that effective use of non-compliance feedback can\naccelerate preference learning and improve recommendation accuracy. This work\nlays the foundation for future research in Nah Bandit, providing a robust\nframework for more effective recommendation systems.", "arxiv_id": "2408.07897v1", "pdf_url": "http://arxiv.org/pdf/2408.07897v1", "abstract_url": "http://arxiv.org/abs/2408.07897v1", "primary_category": "cs.LG", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "The Nah Bandit: Modeling User Non-compliance in Recommendation Systems", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:05.308732"}
{"title": "System States Forecasting of Microservices with Dynamic Spatio-Temporal Data", "authors": "Yifei Xu, Jingguo Ge, Haina Tang, Shuai Ding, Tong Li, Hui Li", "abstract": "In the AIOps (Artificial Intelligence for IT Operations) era, accurately\nforecasting system states is crucial. In microservices systems, this task\nencounters the challenge of dynamic and complex spatio-temporal relationships\namong microservice instances, primarily due to dynamic deployments, diverse\ncall paths, and cascading effects among instances. Current time-series\nforecasting methods, which focus mainly on intrinsic patterns, are insufficient\nin environments where spatial relationships are critical. Similarly,\nspatio-temporal graph approaches often neglect the nature of temporal trend,\nconcentrating mostly on message passing between nodes. Moreover, current\nresearch in microservices domain frequently underestimates the importance of\nnetwork metrics and topological structures in capturing the evolving dynamics\nof systems. This paper introduces STMformer, a model tailored for forecasting\nsystem states in microservices environments, capable of handling multi-node and\nmultivariate time series. Our method leverages dynamic network connection data\nand topological information to assist in modeling the intricate spatio-temporal\nrelationships within the system. Additionally, we integrate the\nPatchCrossAttention module to compute the impact of cascading effects globally.\nWe have developed a dataset based on a microservices system and conducted\ncomprehensive experiments with STMformer against leading methods. In both\nshort-term and long-term forecasting tasks, our model consistently achieved a\n8.6% reduction in MAE(Mean Absolute Error) and a 2.2% reduction in MSE (Mean\nSquared Error). The source code is available at\nhttps://github.com/xuyifeiiie/STMformer.", "arxiv_id": "2408.07894v1", "pdf_url": "http://arxiv.org/pdf/2408.07894v1", "abstract_url": "http://arxiv.org/abs/2408.07894v1", "primary_category": "cs.NI", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "System States Forecasting of Microservices with Dynamic Spatio-Temporal Data", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:06.200032"}
{"title": "Quantum-inspired Interpretable Deep Learning Architecture for Text Sentiment Analysis", "authors": "Bingyu Li, Da Zhang, Zhiyuan Zhao, Junyu Gao, Yuan Yuan", "abstract": "Text has become the predominant form of communication on social media,\nembedding a wealth of emotional nuances. Consequently, the extraction of\nemotional information from text is of paramount importance. Despite previous\nresearch making some progress, existing text sentiment analysis models still\nface challenges in integrating diverse semantic information and lack\ninterpretability. To address these issues, we propose a quantum-inspired deep\nlearning architecture that combines fundamental principles of quantum mechanics\n(QM principles) with deep learning models for text sentiment analysis.\nSpecifically, we analyze the commonalities between text representation and QM\nprinciples to design a quantum-inspired text representation method and further\ndevelop a quantum-inspired text embedding layer. Additionally, we design a\nfeature extraction layer based on long short-term memory (LSTM) networks and\nself-attention mechanisms (SAMs). Finally, we calculate the text density matrix\nusing the quantum complex numbers principle and apply 2D-convolution neural\nnetworks (CNNs) for feature condensation and dimensionality reduction. Through\na series of visualization, comparative, and ablation experiments, we\ndemonstrate that our model not only shows significant advantages in accuracy\nand efficiency compared to previous related models but also achieves a certain\nlevel of interpretability by integrating QM principles. Our code is available\nat QISA.", "arxiv_id": "2408.07891v1", "pdf_url": "http://arxiv.org/pdf/2408.07891v1", "abstract_url": "http://arxiv.org/abs/2408.07891v1", "primary_category": "cs.CV", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Quantum-inspired Interpretable Deep Learning Architecture for Text Sentiment Analysis", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:07.012261"}
{"title": "Local Causal Discovery with Background Knowledge", "authors": "Qingyuan Zheng, Yue Liu, Yangbo He", "abstract": "Causality plays a pivotal role in various fields of study. Based on the\nframework of causal graphical models, previous works have proposed identifying\nwhether a variable is a cause or non-cause of a target in every Markov\nequivalent graph solely by learning a local structure. However, the presence of\nprior knowledge, often represented as a partially known causal graph, is common\nin many causal modeling applications. Leveraging this prior knowledge allows\nfor the further identification of causal relationships. In this paper, we first\npropose a method for learning the local structure using all types of causal\nbackground knowledge, including direct causal information, non-ancestral\ninformation and ancestral information. Then we introduce criteria for\nidentifying causal relationships based solely on the local structure in the\npresence of prior knowledge. We also apply out method to fair machine learning,\nand experiments involving local structure learning, causal relationship\nidentification, and fair machine learning demonstrate that our method is both\neffective and efficient.", "arxiv_id": "2408.07890v1", "pdf_url": "http://arxiv.org/pdf/2408.07890v1", "abstract_url": "http://arxiv.org/abs/2408.07890v1", "primary_category": "stat.ML", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Local Causal Discovery with Background Knowledge", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:07.767221"}
{"title": "IReCa: Intrinsic Reward-enhanced Context-aware Reinforcement Learning for Human-AI Coordination", "authors": "Xin Hao, Bahareh Nakisa, Mohmmad Naim Rastgoo, Richard Dazeley", "abstract": "In human-AI coordination scenarios, human agents usually exhibit asymmetric\nbehaviors that are significantly sparse and unpredictable compared to those of\nAI agents. These characteristics introduce two primary challenges to human-AI\ncoordination: the effectiveness of obtaining sparse rewards and the efficiency\nof training the AI agents. To tackle these challenges, we propose an Intrinsic\nReward-enhanced Context-aware (IReCa) reinforcement learning (RL) algorithm,\nwhich leverages intrinsic rewards to facilitate the acquisition of sparse\nrewards and utilizes environmental context to enhance training efficiency. Our\nIReCa RL algorithm introduces three unique features: (i) it encourages the\nexploration of sparse rewards by incorporating intrinsic rewards that\nsupplement traditional extrinsic rewards from the environment; (ii) it improves\nthe acquisition of sparse rewards by prioritizing the corresponding sparse\nstate-action pairs; and (iii) it enhances the training efficiency by optimizing\nthe exploration and exploitation through innovative context-aware weights of\nextrinsic and intrinsic rewards. Extensive simulations executed in the\nOvercooked layouts demonstrate that our IReCa RL algorithm can increase the\naccumulated rewards by approximately 20% and reduce the epochs required for\nconvergence by approximately 67% compared to state-of-the-art baselines.", "arxiv_id": "2408.07877v1", "pdf_url": "http://arxiv.org/pdf/2408.07877v1", "abstract_url": "http://arxiv.org/abs/2408.07877v1", "primary_category": "cs.AI", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "IReCa: Intrinsic Reward-enhanced Context-aware Reinforcement Learning for Human-AI Coordination", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:08.792922"}
{"title": "Incremental Structure Discovery of Classification via Sequential Monte Carlo", "authors": "Changze Huang, Di Wang", "abstract": "Gaussian Processes (GPs) provide a powerful framework for making predictions\nand understanding uncertainty for classification with kernels and Bayesian\nnon-parametric learning. Building such models typically requires strong prior\nknowledge to define preselect kernels, which could be ineffective for online\napplications of classification that sequentially process data because features\nof data may shift during the process. To alleviate the requirement of prior\nknowledge used in GPs and learn new features from data that arrive\nsuccessively, this paper presents a novel method to automatically discover\nmodels of classification on complex data with little prior knowledge. Our\nmethod adapts a recently proposed technique for GP-based time-series structure\ndiscovery, which integrates GPs and Sequential Monte Carlo (SMC). We extend the\ntechnique to handle extra latent variables in GP classification, such that our\nmethod can effectively and adaptively learn a-priori unknown structures of\nclassification from continuous input. In addition, our method adapts new batch\nof data with updated structures of models. Our experiments show that our method\nis able to automatically incorporate various features of kernels on synthesized\ndata and real-world data for classification. In the experiments of real-world\ndata, our method outperforms various classification methods on both online and\noffline setting achieving a 10\\% accuracy improvement on one benchmark.", "arxiv_id": "2408.07875v1", "pdf_url": "http://arxiv.org/pdf/2408.07875v1", "abstract_url": "http://arxiv.org/abs/2408.07875v1", "primary_category": "cs.LG", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Incremental Structure Discovery of Classification via Sequential Monte Carlo", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:09.816115"}
{"title": "A Systematic Evaluation of Generated Time Series and Their Effects in Self-Supervised Pretraining", "authors": "Audrey Der, Chin-Chia Michael Yeh, Xin Dai, Huiyuan Chen, Yan Zheng, Yujie Fan, Zhongfang Zhuang, Vivian Lai, Junpeng Wang, Liang Wang, Wei Zhang, Eamonn Keogh", "abstract": "Self-supervised Pretrained Models (PTMs) have demonstrated remarkable\nperformance in computer vision and natural language processing tasks. These\nsuccesses have prompted researchers to design PTMs for time series data. In our\nexperiments, most self-supervised time series PTMs were surpassed by simple\nsupervised models. We hypothesize this undesired phenomenon may be caused by\ndata scarcity. In response, we test six time series generation methods, use the\ngenerated data in pretraining in lieu of the real data, and examine the effects\non classification performance. Our results indicate that replacing a real-data\npretraining set with a greater volume of only generated samples produces\nnoticeable improvement.", "arxiv_id": "2408.07869v1", "pdf_url": "http://arxiv.org/pdf/2408.07869v1", "abstract_url": "http://arxiv.org/abs/2408.07869v1", "primary_category": "cs.LG", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "A Systematic Evaluation of Generated Time Series and Their Effects in Self-Supervised Pretraining", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:10.509172"}
{"title": "Capturing the Complexity of Human Strategic Decision-Making with Machine Learning", "authors": "Jian-Qiao Zhu, Joshua C. Peterson, Benjamin Enke, Thomas L. Griffiths", "abstract": "Understanding how people behave in strategic settings--where they make\ndecisions based on their expectations about the behavior of others--is a\nlong-standing problem in the behavioral sciences. We conduct the largest study\nto date of strategic decision-making in the context of initial play in\ntwo-player matrix games, analyzing over 90,000 human decisions across more than\n2,400 procedurally generated games that span a much wider space than previous\ndatasets. We show that a deep neural network trained on these data predicts\npeople's choices better than leading theories of strategic behavior, indicating\nthat there is systematic variation that is not explained by those theories. We\nthen modify the network to produce a new, interpretable behavioral model,\nrevealing what the original network learned about people: their ability to\noptimally respond and their capacity to reason about others are dependent on\nthe complexity of individual games. This context-dependence is critical in\nexplaining deviations from the rational Nash equilibrium, response times, and\nuncertainty in strategic decisions. More broadly, our results demonstrate how\nmachine learning can be applied beyond prediction to further help generate\nnovel explanations of complex human behavior.", "arxiv_id": "2408.07865v1", "pdf_url": "http://arxiv.org/pdf/2408.07865v1", "abstract_url": "http://arxiv.org/abs/2408.07865v1", "primary_category": "econ.GN", "published_date": "2024-08-15", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Capturing the Complexity of Human Strategic Decision-Making with Machine Learning", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:11.378853"}
{"title": "CON-FOLD -- Explainable Machine Learning with Confidence", "authors": "Lachlan McGinness, Peter Baumgartner", "abstract": "FOLD-RM is an explainable machine learning classification algorithm that uses\ntraining data to create a set of classification rules. In this paper we\nintroduce CON-FOLD which extends FOLD-RM in several ways. CON-FOLD assigns\nprobability-based confidence scores to rules learned for a classification task.\nThis allows users to know how confident they should be in a prediction made by\nthe model. We present a confidence-based pruning algorithm that uses the unique\nstructure of FOLD-RM rules to efficiently prune rules and prevent overfitting.\nFurthermore, CON-FOLD enables the user to provide pre-existing knowledge in the\nform of logic program rules that are either (fixed) background knowledge or\n(modifiable) initial rule candidates. The paper describes our method in detail\nand reports on practical experiments. We demonstrate the performance of the\nalgorithm on benchmark datasets from the UCI Machine Learning Repository. For\nthat, we introduce a new metric, Inverse Brier Score, to evaluate the accuracy\nof the produced confidence scores. Finally we apply this extension to a real\nworld example that requires explainability: marking of student responses to a\nshort answer question from the Australian Physics Olympiad.", "arxiv_id": "2408.07854v1", "pdf_url": "http://arxiv.org/pdf/2408.07854v1", "abstract_url": "http://arxiv.org/abs/2408.07854v1", "primary_category": "cs.AI", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "CON-FOLD -- Explainable Machine Learning with Confidence", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:12.101414"}
{"title": "Training Language Models on the Knowledge Graph: Insights on Hallucinations and Their Detectability", "authors": "Jiri Hron, Laura Culp, Gamaleldin Elsayed, Rosanne Liu, Ben Adlam, Maxwell Bileschi, Bernd Bohnet, JD Co-Reyes, Noah Fiedel, C. Daniel Freeman, Izzeddin Gur, Kathleen Kenealy, Jaehoon Lee, Peter J. Liu, Gaurav Mishra, Igor Mordatch, Azade Nova, Roman Novak, Aaron Parisi, Jeffrey Pennington, Alex Rizkowsky, Isabelle Simpson, Hanie Sedghi, Jascha Sohl-dickstein, Kevin Swersky, Sharad Vikram, Tris Warkentin, Lechao Xiao, Kelvin Xu, Jasper Snoek, Simon Kornblith", "abstract": "While many capabilities of language models (LMs) improve with increased\ntraining budget, the influence of scale on hallucinations is not yet fully\nunderstood. Hallucinations come in many forms, and there is no universally\naccepted definition. We thus focus on studying only those hallucinations where\na correct answer appears verbatim in the training set. To fully control the\ntraining data content, we construct a knowledge graph (KG)-based dataset, and\nuse it to train a set of increasingly large LMs. We find that for a fixed\ndataset, larger and longer-trained LMs hallucinate less. However, hallucinating\non $\\leq5$% of the training data requires an order of magnitude larger model,\nand thus an order of magnitude more compute, than Hoffmann et al. (2022)\nreported was optimal. Given this costliness, we study how hallucination\ndetectors depend on scale. While we see detector size improves performance on\nfixed LM's outputs, we find an inverse relationship between the scale of the LM\nand the detectability of its hallucinations.", "arxiv_id": "2408.07852v1", "pdf_url": "http://arxiv.org/pdf/2408.07852v1", "abstract_url": "http://arxiv.org/abs/2408.07852v1", "primary_category": "cs.CL", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Training Language Models on the Knowledge Graph: Insights on Hallucinations and Their Detectability", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:12.888141"}
{"title": "Time-inversion of spatiotemporal beam dynamics using uncertainty-aware latent evolution reversal", "authors": "Mahindra Rautela, Alan Williams, Alexander Scheinker", "abstract": "Charged particle dynamics under the influence of electromagnetic fields is a\nchallenging spatiotemporal problem. Many high performance physics-based\nsimulators for predicting behavior in a charged particle beam are\ncomputationally expensive, limiting their utility for solving inverse problems\nonline. The problem of estimating upstream six-dimensional phase space given\ndownstream measurements of charged particles in an accelerator is an inverse\nproblem of growing importance. This paper introduces a reverse Latent Evolution\nModel (rLEM) designed for temporal inversion of forward beam dynamics. In this\ntwo-step self-supervised deep learning framework, we utilize a Conditional\nVariational Autoencoder (CVAE) to project 6D phase space projections of a\ncharged particle beam into a lower-dimensional latent distribution.\nSubsequently, we autoregressively learn the inverse temporal dynamics in the\nlatent space using a Long Short-Term Memory (LSTM) network. The coupled\nCVAE-LSTM framework can predict 6D phase space projections across all upstream\naccelerating sections based on single or multiple downstream phase space\nmeasurements as inputs. The proposed model also captures the aleatoric\nuncertainty of the high-dimensional input data within the latent space. This\nuncertainty, which reflects potential uncertain measurements at a given module,\nis propagated through the LSTM to estimate uncertainty bounds for all upstream\npredictions, demonstrating the robustness of the LSTM against in-distribution\nvariations in the input data.", "arxiv_id": "2408.07847v1", "pdf_url": "http://arxiv.org/pdf/2408.07847v1", "abstract_url": "http://arxiv.org/abs/2408.07847v1", "primary_category": "physics.acc-ph", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Time-inversion of spatiotemporal beam dynamics using uncertainty-aware latent evolution reversal", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:13.616229"}
{"title": "Enhancing Equitable Access to AI in Housing and Homelessness System of Care through Federated Learning", "authors": "Musa Taib, Jiajun Wu, Steve Drew, Geoffrey G. Messier", "abstract": "The top priority of a Housing and Homelessness System of Care (HHSC) is to\nconnect people experiencing homelessness to supportive housing. An HHSC\ntypically consists of many agencies serving the same population. Information\ntechnology platforms differ in type and quality between agencies, so their data\nare usually isolated from one agency to another. Larger agencies may have\nsufficient data to train and test artificial intelligence (AI) tools but\nsmaller agencies typically do not. To address this gap, we introduce a\nFederated Learning (FL) approach enabling all agencies to train a predictive\nmodel collaboratively without sharing their sensitive data. We demonstrate how\nFL can be used within an HHSC to provide all agencies equitable access to\nquality AI and further assist human decision-makers in the allocation of\nresources within HHSC. This is achieved while preserving the privacy of the\npeople within the data by not sharing identifying information between agencies\nwithout their consent. Our experimental results using real-world HHSC data from\nCalgary, Alberta, demonstrate that our FL approach offers comparable\nperformance with the idealized scenario of training the predictive model with\ndata fully shared and linked between agencies.", "arxiv_id": "2408.07845v1", "pdf_url": "http://arxiv.org/pdf/2408.07845v1", "abstract_url": "http://arxiv.org/abs/2408.07845v1", "primary_category": "cs.LG", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Enhancing Equitable Access to AI in Housing and Homelessness System of Care through Federated Learning", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:15.541640"}
{"title": "SustainDC -- Benchmarking for Sustainable Data Center Control", "authors": "Avisek Naug, Antonio Guillen, Ricardo Luna, Vineet Gundecha, Desik Rengarajan, Sahand Ghorbanpour, Sajad Mousavi, Ashwin Ramesh Babu, Dejan Markovikj, Lekhapriya D Kashyap, Soumyendu Sarkar", "abstract": "Machine learning has driven an exponential increase in computational demand,\nleading to massive data centers that consume significant amounts of energy and\ncontribute to climate change. This makes sustainable data center control a\npriority. In this paper, we introduce SustainDC, a set of Python environments\nfor benchmarking multi-agent reinforcement learning (MARL) algorithms for data\ncenters (DC). SustainDC supports custom DC configurations and tasks such as\nworkload scheduling, cooling optimization, and auxiliary battery management,\nwith multiple agents managing these operations while accounting for the effects\nof each other. We evaluate various MARL algorithms on SustainDC, showing their\nperformance across diverse DC designs, locations, weather conditions, grid\ncarbon intensity, and workload requirements. Our results highlight significant\nopportunities for improvement of data center operations using MARL algorithms.\nGiven the increasing use of DC due to AI, SustainDC provides a crucial platform\nfor the development and benchmarking of advanced algorithms essential for\nachieving sustainable computing and addressing other heterogeneous real-world\nchallenges.", "arxiv_id": "2408.07841v1", "pdf_url": "http://arxiv.org/pdf/2408.07841v1", "abstract_url": "http://arxiv.org/abs/2408.07841v1", "primary_category": "cs.LG", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "SustainDC -- Benchmarking for Sustainable Data Center Control", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:16.676132"}
{"title": "CarbonClipper: Optimal Algorithms for Carbon-Aware Spatiotemporal Workload Management", "authors": "Adam Lechowicz, Nicolas Christianson, Bo Sun, Noman Bashir, Mohammad Hajiesmaili, Adam Wierman, Prashant Shenoy", "abstract": "We study carbon-aware spatiotemporal workload management, which seeks to\naddress the growing environmental impact of data centers. We formalize this as\nan online problem called spatiotemporal online allocation with deadline\nconstraints ($\\mathsf{SOAD}$), in which an online player completes a workload\n(e.g., a batch compute job) by moving and scheduling the workload across a\nnetwork subject to a deadline $T$. At each time step, a service cost function\nis revealed, representing, e.g., the carbon intensity of servicing a workload\nat each location, and the player must irrevocably decide the current\nallocation. Furthermore, whenever the player moves the allocation, it incurs a\nmovement cost defined by a metric space $(X,d)$ that captures, e.g., the\noverhead of migrating a compute job. $\\mathsf{SOAD}$ formalizes the open\nproblem of combining general metrics and deadline constraints in the online\nalgorithms literature, unifying problems such as metrical task systems and\nonline search. We propose a competitive algorithm for $\\mathsf{SOAD}$ along\nwith a matching lower bound that proves it is optimal. Our main algorithm,\n${\\rm C{\\scriptsize ARBON}C{\\scriptsize LIPPER}}$, is a learning-augmented\nalgorithm that takes advantage of predictions (e.g., carbon intensity\nforecasts) and achieves an optimal consistency-robustness trade-off. We\nevaluate our proposed algorithms for carbon-aware spatiotemporal workload\nmanagement on a simulated global data center network, showing that ${\\rm\nC{\\scriptsize ARBON}C{\\scriptsize LIPPER}}$ significantly improves performance\ncompared to baseline methods and delivers meaningful carbon reductions.", "arxiv_id": "2408.07831v1", "pdf_url": "http://arxiv.org/pdf/2408.07831v1", "abstract_url": "http://arxiv.org/abs/2408.07831v1", "primary_category": "cs.DS", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "CarbonClipper: Optimal Algorithms for Carbon-Aware Spatiotemporal Workload Management", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:17.860892"}
{"title": "Differentiating Policies for Non-Myopic Bayesian Optimization", "authors": "Darian Nwankwo, David Bindel", "abstract": "Bayesian optimization (BO) methods choose sample points by optimizing an\nacquisition function derived from a statistical model of the objective. These\nacquisition functions are chosen to balance sampling regions with predicted\ngood objective values against exploring regions where the objective is\nuncertain. Standard acquisition functions are myopic, considering only the\nimpact of the next sample, but non-myopic acquisition functions may be more\neffective. In principle, one could model the sampling by a Markov decision\nprocess, and optimally choose the next sample by maximizing an expected reward\ncomputed by dynamic programming; however, this is infeasibly expensive. More\npractical approaches, such as rollout, consider a parametric family of sampling\npolicies. In this paper, we show how to efficiently estimate rollout\nacquisition functions and their gradients, enabling stochastic gradient-based\noptimization of sampling policies.", "arxiv_id": "2408.07812v1", "pdf_url": "http://arxiv.org/pdf/2408.07812v1", "abstract_url": "http://arxiv.org/abs/2408.07812v1", "primary_category": "cs.LG", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Differentiating Policies for Non-Myopic Bayesian Optimization", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:18.637488"}
{"title": "Kraken: Inherently Parallel Transformers For Efficient Multi-Device Inference", "authors": "Rohan Baskar Prabhakar, Hengrui Zhang, David Wentlzaff", "abstract": "Large Transformer networks are increasingly used in settings where low\ninference latency can improve the end-user experience and enable new\napplications. However, autoregressive inference is resource intensive and\nrequires parallelism for efficiency. Parallelism introduces collective\ncommunication that is both expensive and represents a phase when hardware\nresources are underutilized. Towards mitigating this, Kraken is an evolution of\nthe standard Transformer architecture that is designed to complement existing\ntensor parallelism schemes for efficient inference on multi-device systems. By\nintroducing a fixed degree of intra-layer model parallelism, the architecture\nallows collective operations to be overlapped with compute, decreasing latency\nand increasing hardware utilization. When trained on OpenWebText, Kraken models\nreach a similar perplexity as standard Transformers while also preserving their\nlanguage modeling capabilities when evaluated on the SuperGLUE benchmark.\nImportantly, when tested on multi-GPU systems using TensorRT-LLM engines,\nKraken speeds up Time To First Token by a mean of 35.6% across a range of model\nsizes, context lengths, and degrees of tensor parallelism.", "arxiv_id": "2408.07802v1", "pdf_url": "http://arxiv.org/pdf/2408.07802v1", "abstract_url": "http://arxiv.org/abs/2408.07802v1", "primary_category": "cs.LG", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Kraken: Inherently Parallel Transformers For Efficient Multi-Device Inference", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:19.544531"}
{"title": "Ranking and Combining Latent Structured Predictive Scores without Labeled Data", "authors": "Shiva Afshar, Yinghan Chen, Shizhong Han, Ying Lin", "abstract": "Combining multiple predictors obtained from distributed data sources to an\naccurate meta-learner is promising to achieve enhanced performance in lots of\nprediction problems. As the accuracy of each predictor is usually unknown,\nintegrating the predictors to achieve better performance is challenging.\nConventional ensemble learning methods assess the accuracy of predictors based\non extensive labeled data. In practical applications, however, the acquisition\nof such labeled data can prove to be an arduous task. Furthermore, the\npredictors under consideration may exhibit high degrees of correlation,\nparticularly when similar data sources or machine learning algorithms were\nemployed during their model training. In response to these challenges, this\npaper introduces a novel structured unsupervised ensemble learning model (SUEL)\nto exploit the dependency between a set of predictors with continuous\npredictive scores, rank the predictors without labeled data and combine them to\nan ensembled score with weights. Two novel correlation-based decomposition\nalgorithms are further proposed to estimate the SUEL model, constrained\nquadratic optimization (SUEL.CQO) and matrix-factorization-based (SUEL.MF)\napproaches. The efficacy of the proposed methods is rigorously assessed through\nboth simulation studies and real-world application of risk genes discovery. The\nresults compellingly demonstrate that the proposed methods can efficiently\nintegrate the dependent predictors to an ensemble model without the need of\nground truth data.", "arxiv_id": "2408.07796v1", "pdf_url": "http://arxiv.org/pdf/2408.07796v1", "abstract_url": "http://arxiv.org/abs/2408.07796v1", "primary_category": "stat.ML", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Ranking and Combining Latent Structured Predictive Scores without Labeled Data", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:20.674102"}
{"title": "An Efficient and Explanatory Image and Text Clustering System with Multimodal Autoencoder Architecture", "authors": "Tiancheng Shi, Yuanchen Wei, John R. Kender", "abstract": "We demonstrate the efficiencies and explanatory abilities of extensions to\nthe common tools of Autoencoders and LLM interpreters, in the novel context of\ncomparing different cultural approaches to the same international news event.\nWe develop a new Convolutional-Recurrent Variational Autoencoder (CRVAE) model\nthat extends the modalities of previous CVAE models, by using fully-connected\nlatent layers to embed in parallel the CNN encodings of video frames, together\nwith the LSTM encodings of their related text derived from audio. We\nincorporate the model within a larger system that includes frame-caption\nalignment, latent space vector clustering, and a novel LLM-based cluster\ninterpreter. We measure, tune, and apply this system to the task of summarizing\na video into three to five thematic clusters, with each theme described by ten\nLLM-produced phrases. We apply this system to two news topics, COVID-19 and the\nWinter Olympics, and five other topics are in progress.", "arxiv_id": "2408.07791v1", "pdf_url": "http://arxiv.org/pdf/2408.07791v1", "abstract_url": "http://arxiv.org/abs/2408.07791v1", "primary_category": "cs.MM", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "An Efficient and Explanatory Image and Text Clustering System with Multimodal Autoencoder Architecture", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:21.900146"}
{"title": "Knowledge-based Neural Ordinary Differential Equations for Cosserat Rod-based Soft Robots", "authors": "Tom Z. Jiahao, Ryan Adolf, Cynthia Sung, M. Ani Hsieh", "abstract": "Soft robots have many advantages over rigid robots thanks to their compliant\nand passive nature. However, it is generally challenging to model the dynamics\nof soft robots due to their high spatial dimensionality, making it difficult to\nuse model-based methods to accurately control soft robots. It often requires\ndirect numerical simulation of partial differential equations to simulate soft\nrobots. This not only requires an accurate numerical model, but also makes soft\nrobot modeling slow and expensive. Deep learning algorithms have shown promises\nin data-driven modeling of soft robots. However, these algorithms usually\nrequire a large amount of data, which are difficult to obtain in either\nsimulation or real-world experiments of soft robots. In this work, we propose\nKNODE-Cosserat, a framework that combines first-principle physics models and\nneural ordinary differential equations. We leverage the best from both worlds\n-- the generalization ability of physics-based models and the fast speed of\ndeep learning methods. We validate our framework in both simulation and\nreal-world experiments. In both cases, we show that the robot model\nsignificantly improves over the baseline models under different metrics.", "arxiv_id": "2408.07776v1", "pdf_url": "http://arxiv.org/pdf/2408.07776v1", "abstract_url": "http://arxiv.org/abs/2408.07776v1", "primary_category": "cs.RO", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Knowledge-based Neural Ordinary Differential Equations for Cosserat Rod-based Soft Robots", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:22.717392"}
{"title": "MedTsLLM: Leveraging LLMs for Multimodal Medical Time Series Analysis", "authors": "Nimeesha Chan, Felix Parker, William Bennett, Tianyi Wu, Mung Yao Jia, James Fackler, Kimia Ghobadi", "abstract": "The complexity and heterogeneity of data in many real-world applications pose\nsignificant challenges for traditional machine learning and signal processing\ntechniques. For instance, in medicine, effective analysis of diverse\nphysiological signals is crucial for patient monitoring and clinical\ndecision-making and yet highly challenging. We introduce MedTsLLM, a general\nmultimodal large language model (LLM) framework that effectively integrates\ntime series data and rich contextual information in the form of text to analyze\nphysiological signals, performing three tasks with clinical relevance: semantic\nsegmentation, boundary detection, and anomaly detection in time series. These\ncritical tasks enable deeper analysis of physiological signals and can provide\nactionable insights for clinicians. We utilize a reprogramming layer to align\nembeddings of time series patches with a pretrained LLM's embedding space and\nmake effective use of raw time series, in conjunction with textual context.\nGiven the multivariate nature of medical datasets, we develop methods to handle\nmultiple covariates. We additionally tailor the text prompt to include\npatient-specific information. Our model outperforms state-of-the-art baselines,\nincluding deep learning models, other LLMs, and clinical methods across\nmultiple medical domains, specifically electrocardiograms and respiratory\nwaveforms. MedTsLLM presents a promising step towards harnessing the power of\nLLMs for medical time series analysis that can elevate data-driven tools for\nclinicians and improve patient outcomes.", "arxiv_id": "2408.07773v1", "pdf_url": "http://arxiv.org/pdf/2408.07773v1", "abstract_url": "http://arxiv.org/abs/2408.07773v1", "primary_category": "cs.LG", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "MedTsLLM: Leveraging LLMs for Multimodal Medical Time Series Analysis", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:23.435316"}
{"title": "Out-of-Distribution Learning with Human Feedback", "authors": "Haoyue Bai, Xuefeng Du, Katie Rainey, Shibin Parameswaran, Yixuan Li", "abstract": "Out-of-distribution (OOD) learning often relies heavily on statistical\napproaches or predefined assumptions about OOD data distributions, hindering\ntheir efficacy in addressing multifaceted challenges of OOD generalization and\nOOD detection in real-world deployment environments. This paper presents a\nnovel framework for OOD learning with human feedback, which can provide\ninvaluable insights into the nature of OOD shifts and guide effective model\nadaptation. Our framework capitalizes on the freely available unlabeled data in\nthe wild that captures the environmental test-time OOD distributions under both\ncovariate and semantic shifts. To harness such data, our key idea is to\nselectively provide human feedback and label a small number of informative\nsamples from the wild data distribution, which are then used to train a\nmulti-class classifier and an OOD detector. By exploiting human feedback, we\nenhance the robustness and reliability of machine learning models, equipping\nthem with the capability to handle OOD scenarios with greater precision. We\nprovide theoretical insights on the generalization error bounds to justify our\nalgorithm. Extensive experiments show the superiority of our method,\noutperforming the current state-of-the-art by a significant margin.", "arxiv_id": "2408.07772v1", "pdf_url": "http://arxiv.org/pdf/2408.07772v1", "abstract_url": "http://arxiv.org/abs/2408.07772v1", "primary_category": "cs.LG", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Out-of-Distribution Learning with Human Feedback", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:24.559581"}
{"title": "Data Clustering and Visualization with Recursive Goemans-Williamson MaxCut Algorithm", "authors": "An Ly, Raj Sawhney, Marina Chugunova", "abstract": "In this article, we introduce a novel recursive modification to the classical\nGoemans-Williamson MaxCut algorithm, offering improved performance in\nvectorized data clustering tasks. Focusing on the clustering of medical\npublications, we employ recursive iterations in conjunction with a dimension\nrelaxation method to significantly enhance density of clustering results.\nFurthermore, we propose a unique vectorization technique for articles,\nleveraging conditional probabilities for more effective clustering. Our methods\nprovide advantages in both computational efficiency and clustering accuracy,\nsubstantiated through comprehensive experiments.", "arxiv_id": "2408.07763v1", "pdf_url": "http://arxiv.org/pdf/2408.07763v1", "abstract_url": "http://arxiv.org/abs/2408.07763v1", "primary_category": "math.OC", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Data Clustering and Visualization with Recursive Goemans-Williamson MaxCut Algorithm", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:25.327556"}
{"title": "How to Solve Contextual Goal-Oriented Problems with Offline Datasets?", "authors": "Ying Fan, Jingling Li, Adith Swaminathan, Aditya Modi, Ching-An Cheng", "abstract": "We present a novel method, Contextual goal-Oriented Data Augmentation (CODA),\nwhich uses commonly available unlabeled trajectories and context-goal pairs to\nsolve Contextual Goal-Oriented (CGO) problems. By carefully constructing an\naction-augmented MDP that is equivalent to the original MDP, CODA creates a\nfully labeled transition dataset under training contexts without additional\napproximation error. We conduct a novel theoretical analysis to demonstrate\nCODA's capability to solve CGO problems in the offline data setup. Empirical\nresults also showcase the effectiveness of CODA, which outperforms other\nbaseline methods across various context-goal relationships of CGO problem. This\napproach offers a promising direction to solving CGO problems using offline\ndatasets.", "arxiv_id": "2408.07753v1", "pdf_url": "http://arxiv.org/pdf/2408.07753v1", "abstract_url": "http://arxiv.org/abs/2408.07753v1", "primary_category": "cs.LG", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "How to Solve Contextual Goal-Oriented Problems with Offline Datasets?", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:26.811051"}
{"title": "TurboEdit: Instant text-based image editing", "authors": "Zongze Wu, Nicholas Kolkin, Jonathan Brandt, Richard Zhang, Eli Shechtman", "abstract": "We address the challenges of precise image inversion and disentangled image\nediting in the context of few-step diffusion models. We introduce an encoder\nbased iterative inversion technique. The inversion network is conditioned on\nthe input image and the reconstructed image from the previous step, allowing\nfor correction of the next reconstruction towards the input image. We\ndemonstrate that disentangled controls can be easily achieved in the few-step\ndiffusion model by conditioning on an (automatically generated) detailed text\nprompt. To manipulate the inverted image, we freeze the noise maps and modify\none attribute in the text prompt (either manually or via instruction based\nediting driven by an LLM), resulting in the generation of a new image similar\nto the input image with only one attribute changed. It can further control the\nediting strength and accept instructive text prompt. Our approach facilitates\nrealistic text-guided image edits in real-time, requiring only 8 number of\nfunctional evaluations (NFEs) in inversion (one-time cost) and 4 NFEs per edit.\nOur method is not only fast, but also significantly outperforms\nstate-of-the-art multi-step diffusion editing techniques.", "arxiv_id": "2408.08332v1", "pdf_url": "http://arxiv.org/pdf/2408.08332v1", "abstract_url": "http://arxiv.org/abs/2408.08332v1", "primary_category": "cs.CV", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "TurboEdit: Instant text-based image editing", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:27.497701"}
{"title": "Enhancing Model Interpretability with Local Attribution over Global Exploration", "authors": "Zhiyu Zhu, Zhibo Jin, Jiayu Zhang, Huaming Chen", "abstract": "In the field of artificial intelligence, AI models are frequently described\nas `black boxes' due to the obscurity of their internal mechanisms. It has\nignited research interest on model interpretability, especially in attribution\nmethods that offers precise explanations of model decisions. Current\nattribution algorithms typically evaluate the importance of each parameter by\nexploring the sample space. A large number of intermediate states are\nintroduced during the exploration process, which may reach the model's\nOut-of-Distribution (OOD) space. Such intermediate states will impact the\nattribution results, making it challenging to grasp the relative importance of\nfeatures. In this paper, we firstly define the local space and its relevant\nproperties, and we propose the Local Attribution (LA) algorithm that leverages\nthese properties. The LA algorithm comprises both targeted and untargeted\nexploration phases, which are designed to effectively generate intermediate\nstates for attribution that thoroughly encompass the local space. Compared to\nthe state-of-the-art attribution methods, our approach achieves an average\nimprovement of 38.21\\% in attribution effectiveness. Extensive ablation studies\nin our experiments also validate the significance of each component in our\nalgorithm. Our code is available at: https://github.com/LMBTough/LA/", "arxiv_id": "2408.07736v1", "pdf_url": "http://arxiv.org/pdf/2408.07736v1", "abstract_url": "http://arxiv.org/abs/2408.07736v1", "primary_category": "cs.LG", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Enhancing Model Interpretability with Local Attribution over Global Exploration", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:28.195730"}
{"title": "Enhancing Adversarial Attacks via Parameter Adaptive Adversarial Attack", "authors": "Zhibo Jin, Jiayu Zhang, Zhiyu Zhu, Chenyu Zhang, Jiahao Huang, Jianlong Zhou, Fang Chen", "abstract": "In recent times, the swift evolution of adversarial attacks has captured\nwidespread attention, particularly concerning their transferability and other\nperformance attributes. These techniques are primarily executed at the sample\nlevel, frequently overlooking the intrinsic parameters of models. Such neglect\nsuggests that the perturbations introduced in adversarial samples might have\nthe potential for further reduction. Given the essence of adversarial attacks\nis to impair model integrity with minimal noise on original samples, exploring\navenues to maximize the utility of such perturbations is imperative. Against\nthis backdrop, we have delved into the complexities of adversarial attack\nalgorithms, dissecting the adversarial process into two critical phases: the\nDirectional Supervision Process (DSP) and the Directional Optimization Process\n(DOP). While DSP determines the direction of updates based on the current\nsamples and model parameters, it has been observed that existing model\nparameters may not always be conducive to adversarial attacks. The impact of\nmodels on adversarial efficacy is often overlooked in current research, leading\nto the neglect of DSP. We propose that under certain conditions, fine-tuning\nmodel parameters can significantly enhance the quality of DSP. For the first\ntime, we propose that under certain conditions, fine-tuning model parameters\ncan significantly improve the quality of the DSP. We provide, for the first\ntime, rigorous mathematical definitions and proofs for these conditions, and\nintroduce multiple methods for fine-tuning model parameters within DSP. Our\nextensive experiments substantiate the effectiveness of the proposed P3A\nmethod. Our code is accessible at: https://anonymous.4open.science/r/P3A-A12C/", "arxiv_id": "2408.07733v1", "pdf_url": "http://arxiv.org/pdf/2408.07733v1", "abstract_url": "http://arxiv.org/abs/2408.07733v1", "primary_category": "cs.LG", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Enhancing Adversarial Attacks via Parameter Adaptive Adversarial Attack", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:28.972071"}
{"title": "End-to-end Semantic-centric Video-based Multimodal Affective Computing", "authors": "Ronghao Lin, Ying Zeng, Sijie Mai, Haifeng Hu", "abstract": "In the pathway toward Artificial General Intelligence (AGI), understanding\nhuman's affection is essential to enhance machine's cognition abilities. For\nachieving more sensual human-AI interaction, Multimodal Affective Computing\n(MAC) in human-spoken videos has attracted increasing attention. However,\nprevious methods are mainly devoted to designing multimodal fusion algorithms,\nsuffering from two issues: semantic imbalance caused by diverse pre-processing\noperations and semantic mismatch raised by inconsistent affection content\ncontained in different modalities comparing with the multimodal ground truth.\nBesides, the usage of manual features extractors make they fail in building\nend-to-end pipeline for multiple MAC downstream tasks. To address above\nchallenges, we propose a novel end-to-end framework named SemanticMAC to\ncompute multimodal semantic-centric affection for human-spoken videos. We\nfirstly employ pre-trained Transformer model in multimodal data pre-processing\nand design Affective Perceiver module to capture unimodal affective\ninformation. Moreover, we present a semantic-centric approach to unify\nmultimodal representation learning in three ways, including gated feature\ninteraction, multi-task pseudo label generation, and intra-/inter-sample\ncontrastive learning. Finally, SemanticMAC effectively learn specific- and\nshared-semantic representations in the guidance of semantic-centric labels.\nExtensive experimental results demonstrate that our approach surpass the\nstate-of-the-art methods on 7 public datasets in four MAC downstream tasks.", "arxiv_id": "2408.07694v1", "pdf_url": "http://arxiv.org/pdf/2408.07694v1", "abstract_url": "http://arxiv.org/abs/2408.07694v1", "primary_category": "cs.CV", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "End-to-end Semantic-centric Video-based Multimodal Affective Computing", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:29.780240"}
{"title": "A Spitting Image: Modular Superpixel Tokenization in Vision Transformers", "authors": "Marius Aasan, Odd Kolbj\u00f8rnsen, Anne Schistad Solberg, Ad\u00edn Ramirez Rivera", "abstract": "Vision Transformer (ViT) architectures traditionally employ a grid-based\napproach to tokenization independent of the semantic content of an image. We\npropose a modular superpixel tokenization strategy which decouples tokenization\nand feature extraction; a shift from contemporary approaches where these are\ntreated as an undifferentiated whole. Using on-line content-aware tokenization\nand scale- and shape-invariant positional embeddings, we perform experiments\nand ablations that contrast our approach with patch-based tokenization and\nrandomized partitions as baselines. We show that our method significantly\nimproves the faithfulness of attributions, gives pixel-level granularity on\nzero-shot unsupervised dense prediction tasks, while maintaining predictive\nperformance in classification tasks. Our approach provides a modular\ntokenization framework commensurable with standard architectures, extending the\nspace of ViTs to a larger class of semantically-rich models.", "arxiv_id": "2408.07680v2", "pdf_url": "http://arxiv.org/pdf/2408.07680v2", "abstract_url": "http://arxiv.org/abs/2408.07680v2", "primary_category": "cs.CV", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "A Spitting Image: Modular Superpixel Tokenization in Vision Transformers", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:30.513955"}
{"title": "Deep Learning: a Heuristic Three-stage Mechanism for Grid Searches to Optimize the Future Risk Prediction of Breast Cancer Metastasis Using EHR-based Clinical Data", "authors": "Xia Jiang, Yijun Zhou, Chuhan Xu, Adam Brufsky, Alan Wells", "abstract": "A grid search, at the cost of training and testing a large number of models,\nis an effective way to optimize the prediction performance of deep learning\nmodels. A challenging task concerning grid search is the time management.\nWithout a good time management scheme, a grid search can easily be set off as a\nmission that will not finish in our lifetime. In this study, we introduce a\nheuristic three-stage mechanism for managing the running time of low-budget\ngrid searches, and the sweet-spot grid search (SSGS) and randomized grid search\n(RGS) strategies for improving model prediction performance, in predicting the\n5-year, 10-year, and 15-year risk of breast cancer metastasis. We develop deep\nfeedforward neural network (DFNN) models and optimize them through grid\nsearches. We conduct eight cycles of grid searches by applying our three-stage\nmechanism and SSGS and RGS strategies. We conduct various SHAP analyses\nincluding unique ones that interpret the importance of the DFNN-model\nhyperparameters. Our results show that grid search can greatly improve model\nprediction. The grid searches we conducted improved the risk prediction of\n5-year, 10-year, and 15-year breast cancer metastasis by 18.6%, 16.3%, and\n17.3% respectively, over the average performance of all corresponding models we\ntrained using the RGS strategy. We not only demonstrate best model performance\nbut also characterize grid searches from various aspects such as their\ncapabilities of discovering decent models and the unit grid search time. The\nthree-stage mechanism worked effectively. It made our low-budget grid searches\nfeasible and manageable, and in the meantime helped improve model prediction\nperformance. Our SHAP analyses identified both clinical risk factors important\nfor the prediction of future risk of breast cancer metastasis, and DFNN-model\nhyperparameters important to the prediction of performance scores.", "arxiv_id": "2408.07673v2", "pdf_url": "http://arxiv.org/pdf/2408.07673v2", "abstract_url": "http://arxiv.org/abs/2408.07673v2", "primary_category": "cs.LG", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Deep Learning: a Heuristic Three-stage Mechanism for Grid Searches to Optimize the Future Risk Prediction of Breast Cancer Metastasis Using EHR-based Clinical Data", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:31.726329"}
{"title": "Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities", "authors": "Enneng Yang, Li Shen, Guibing Guo, Xingwei Wang, Xiaochun Cao, Jie Zhang, Dacheng Tao", "abstract": "Model merging is an efficient empowerment technique in the machine learning\ncommunity that does not require the collection of raw training data and does\nnot require expensive computation. As model merging becomes increasingly\nprevalent across various fields, it is crucial to understand the available\nmodel merging techniques comprehensively. However, there is a significant gap\nin the literature regarding a systematic and thorough review of these\ntechniques. This survey provides a comprehensive overview of model merging\nmethods and theories, their applications in various domains and settings, and\nfuture research directions. Specifically, we first propose a new taxonomic\napproach that exhaustively discusses existing model merging methods. Secondly,\nwe discuss the application of model merging techniques in large language\nmodels, multimodal large language models, and 10+ machine learning subfields,\nincluding continual learning, multi-task learning, few-shot learning, etc.\nFinally, we highlight the remaining challenges of model merging and discuss\nfuture research directions. A comprehensive list of papers about model merging\nis available at\n\\url{https://github.com/EnnengYang/Awesome-Model-Merging-Methods-Theories-Applications}.", "arxiv_id": "2408.07666v2", "pdf_url": "http://arxiv.org/pdf/2408.07666v2", "abstract_url": "http://arxiv.org/abs/2408.07666v2", "primary_category": "cs.LG", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:32.854785"}
{"title": "Interpretable Graph Neural Networks for Heterogeneous Tabular Data", "authors": "Amr Alkhatib, Henrik Bostr\u00f6m", "abstract": "Many machine learning algorithms for tabular data produce black-box models,\nwhich prevent users from understanding the rationale behind the model\npredictions. In their unconstrained form, graph neural networks fall into this\ncategory, and they have further limited abilities to handle heterogeneous data.\nTo overcome these limitations, an approach is proposed, called IGNH\n(Interpretable Graph Neural Network for Heterogeneous tabular data), which\nhandles both categorical and numerical features, while constraining the\nlearning process to generate exact feature attributions together with the\npredictions. A large-scale empirical investigation is presented, showing that\nthe feature attributions provided by IGNH align with Shapley values that are\ncomputed post hoc. Furthermore, the results show that IGNH outperforms two\npowerful machine learning algorithms for tabular data, Random Forests and\nTabNet, while reaching a similar level of performance as XGBoost.", "arxiv_id": "2408.07661v1", "pdf_url": "http://arxiv.org/pdf/2408.07661v1", "abstract_url": "http://arxiv.org/abs/2408.07661v1", "primary_category": "cs.LG", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Interpretable Graph Neural Networks for Heterogeneous Tabular Data", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:33.572007"}
{"title": "Off-Policy Reinforcement Learning with High Dimensional Reward", "authors": "Dong Neuck Lee, Michael R. Kosorok", "abstract": "Conventional off-policy reinforcement learning (RL) focuses on maximizing the\nexpected return of scalar rewards. Distributional RL (DRL), in contrast,\nstudies the distribution of returns with the distributional Bellman operator in\na Euclidean space, leading to highly flexible choices for utility. This paper\nestablishes robust theoretical foundations for DRL. We prove the contraction\nproperty of the Bellman operator even when the reward space is an\ninfinite-dimensional separable Banach space. Furthermore, we demonstrate that\nthe behavior of high- or infinite-dimensional returns can be effectively\napproximated using a lower-dimensional Euclidean space. Leveraging these\ntheoretical insights, we propose a novel DRL algorithm that tackles problems\nwhich have been previously intractable using conventional reinforcement\nlearning approaches.", "arxiv_id": "2408.07660v1", "pdf_url": "http://arxiv.org/pdf/2408.07660v1", "abstract_url": "http://arxiv.org/abs/2408.07660v1", "primary_category": "stat.ML", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Off-Policy Reinforcement Learning with High Dimensional Reward", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:34.476783"}
{"title": "Graph Triple Attention Network: A Decoupled Perspective", "authors": "Xiaotang Wang, Yun Zhu, Haizhou Shi, Yongchao Liu, Chuntao Hong", "abstract": "Graph Transformers (GTs) have recently achieved significant success in the\ngraph domain by effectively capturing both long-range dependencies and graph\ninductive biases. However, these methods face two primary challenges: (1)\nmulti-view chaos, which results from coupling multi-view information\n(positional, structural, attribute), thereby impeding flexible usage and the\ninterpretability of the propagation process. (2) local-global chaos, which\narises from coupling local message passing with global attention, leading to\nissues of overfitting and over-globalizing. To address these challenges, we\npropose a high-level decoupled perspective of GTs, breaking them down into\nthree components and two interaction levels: positional attention, structural\nattention, and attribute attention, alongside local and global interaction.\nBased on this decoupled perspective, we design a decoupled graph triple\nattention network named DeGTA, which separately computes multi-view attentions\nand adaptively integrates multi-view local and global information. This\napproach offers three key advantages: enhanced interpretability, flexible\ndesign, and adaptive integration of local and global information. Through\nextensive experiments, DeGTA achieves state-of-the-art performance across\nvarious datasets and tasks, including node classification and graph\nclassification. Comprehensive ablation studies demonstrate that decoupling is\nessential for improving performance and enhancing interpretability. Our code is\navailable at: https://github.com/wangxiaotang0906/DeGTA", "arxiv_id": "2408.07654v1", "pdf_url": "http://arxiv.org/pdf/2408.07654v1", "abstract_url": "http://arxiv.org/abs/2408.07654v1", "primary_category": "cs.LG", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Graph Triple Attention Network: A Decoupled Perspective", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:36.238892"}
{"title": "Adaptive Behavioral AI: Reinforcement Learning to Enhance Pharmacy Services", "authors": "Ana Fern\u00e1ndez del R\u00edo, Michael Brennan Leong, Paulo Saraiva, Ivan Nazarov, Aditya Rastogi, Moiz Hassan, Dexian Tang, \u00c1frica Peri\u00e1\u00f1ez", "abstract": "Pharmacies are critical in healthcare systems, particularly in low- and\nmiddle-income countries. Procuring pharmacists with the right behavioral\ninterventions or nudges can enhance their skills, public health awareness, and\npharmacy inventory management, ensuring access to essential medicines that\nultimately benefit their patients. We introduce a reinforcement learning\noperational system to deliver personalized behavioral interventions through\nmobile health applications. We illustrate its potential by discussing a series\nof initial experiments run with SwipeRx, an all-in-one app for pharmacists,\nincluding B2B e-commerce, in Indonesia. The proposed method has broader\napplications extending beyond pharmacy operations to optimize healthcare\ndelivery.", "arxiv_id": "2408.07647v1", "pdf_url": "http://arxiv.org/pdf/2408.07647v1", "abstract_url": "http://arxiv.org/abs/2408.07647v1", "primary_category": "cs.LG", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Adaptive Behavioral AI: Reinforcement Learning to Enhance Pharmacy Services", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:37.312866"}
{"title": "SigmaRL: A Sample-Efficient and Generalizable Multi-Agent Reinforcement Learning Framework for Motion Planning", "authors": "Jianye Xu, Pan Hu, Bassam Alrifaee", "abstract": "This paper introduces an open-source, decentralized framework named SigmaRL,\ndesigned to enhance both sample efficiency and generalization of multi-agent\nReinforcement Learning (RL) for motion planning of connected and automated\nvehicles. Most RL agents exhibit a limited capacity to generalize, often\nfocusing narrowly on specific scenarios, and are usually evaluated in similar\nor even the same scenarios seen during training. Various methods have been\nproposed to address these challenges, including experience replay and\nregularization. However, how observation design in RL affects sample efficiency\nand generalization remains an under-explored area. We address this gap by\nproposing five strategies to design information-dense observations, focusing on\ngeneral features that are applicable to most traffic scenarios. We train our RL\nagents using these strategies on an intersection and evaluate their\ngeneralization through numerical experiments across completely unseen traffic\nscenarios, including a new intersection, an on-ramp, and a roundabout.\nIncorporating these information-dense observations reduces training times to\nunder one hour on a single CPU, and the evaluation results reveal that our RL\nagents can effectively zero-shot generalize. Code:\ngithub.com/cas-lab-munich/SigmaRL", "arxiv_id": "2408.07644v1", "pdf_url": "http://arxiv.org/pdf/2408.07644v1", "abstract_url": "http://arxiv.org/abs/2408.07644v1", "primary_category": "cs.RO", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "SigmaRL: A Sample-Efficient and Generalizable Multi-Agent Reinforcement Learning Framework for Motion Planning", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:38.077227"}
{"title": "Drug Discovery SMILES-to-Pharmacokinetics Diffusion Models with Deep Molecular Understanding", "authors": "Bing Hu, Anita Layton, Helen Chen", "abstract": "Artificial intelligence (AI) is increasingly used in every stage of drug\ndevelopment. One challenge facing drug discovery AI is that drug\npharmacokinetic (PK) datasets are often collected independently from each\nother, often with limited overlap, creating data overlap sparsity. Data\nsparsity makes data curation difficult for researchers looking to answer\nresearch questions in poly-pharmacy, drug combination research, and\nhigh-throughput screening. We propose Imagand, a novel\nSMILES-to-Pharmacokinetic (S2PK) diffusion model capable of generating an array\nof PK target properties conditioned on SMILES inputs. We show that\nImagand-generated synthetic PK data closely resembles real data univariate and\nbivariate distributions, and improves performance for downstream tasks. Imagand\nis a promising solution for data overlap sparsity and allows researchers to\nefficiently generate ligand PK data for drug discovery research. Code is\navailable at \\url{https://github.com/bing1100/Imagand}.", "arxiv_id": "2408.07636v1", "pdf_url": "http://arxiv.org/pdf/2408.07636v1", "abstract_url": "http://arxiv.org/abs/2408.07636v1", "primary_category": "q-bio.QM", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Drug Discovery SMILES-to-Pharmacokinetics Diffusion Models with Deep Molecular Understanding", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:38.728363"}
{"title": "Towards Fair and Rigorous Evaluations: Hyperparameter Optimization for Top-N Recommendation Task with Implicit Feedback", "authors": "Hui Fang, Xu Feng, Lu Qin, Zhu Sun", "abstract": "The widespread use of the internet has led to an overwhelming amount of data,\nwhich has resulted in the problem of information overload. Recommender systems\nhave emerged as a solution to this problem by providing personalized\nrecommendations to users based on their preferences and historical data.\nHowever, as recommendation models become increasingly complex, finding the best\nhyperparameter combination for different models has become a challenge. The\nhigh-dimensional hyperparameter search space poses numerous challenges for\nresearchers, and failure to disclose hyperparameter settings may impede the\nreproducibility of research results. In this paper, we investigate the Top-N\nimplicit recommendation problem and focus on optimizing the benchmark\nrecommendation algorithm commonly used in comparative experiments using\nhyperparameter optimization algorithms. We propose a research methodology that\nfollows the principles of a fair comparison, employing seven types of\nhyperparameter search algorithms to fine-tune six common recommendation\nalgorithms on three datasets. We have identified the most suitable\nhyperparameter search algorithms for various recommendation algorithms on\ndifferent types of datasets as a reference for later study. This study\ncontributes to algorithmic research in recommender systems based on\nhyperparameter optimization, providing a fair basis for comparison.", "arxiv_id": "2408.07630v1", "pdf_url": "http://arxiv.org/pdf/2408.07630v1", "abstract_url": "http://arxiv.org/abs/2408.07630v1", "primary_category": "cs.IR", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Towards Fair and Rigorous Evaluations: Hyperparameter Optimization for Top-N Recommendation Task with Implicit Feedback", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:39.907495"}
{"title": "Optimizing HIV Patient Engagement with Reinforcement Learning in Resource-Limited Settings", "authors": "\u00c1frica Peri\u00e1\u00f1ez, Kathrin Schmitz, Lazola Makhupula, Moiz Hassan, Moeti Moleko, Ana Fern\u00e1ndez del R\u00edo, Ivan Nazarov, Aditya Rastogi, Dexian Tang", "abstract": "By providing evidence-based clinical decision support, digital tools and\nelectronic health records can revolutionize patient management, especially in\nresource-poor settings where fewer health workers are available and often need\nmore training. When these tools are integrated with AI, they can offer\npersonalized support and adaptive interventions, effectively connecting\ncommunity health workers (CHWs) and healthcare facilities. The CHARM (Community\nHealth Access & Resource Management) app is an AI-native mobile app for CHWs.\nDeveloped through a joint partnership of Causal Foundry (CF) and\nmothers2mothers (m2m), CHARM empowers CHWs, mainly local women, by streamlining\ncase management, enhancing learning, and improving communication. This paper\ndetails CHARM's development, integration, and upcoming reinforcement\nlearning-based adaptive interventions, all aimed at enhancing health worker\nengagement, efficiency, and patient outcomes, thereby enhancing CHWs'\ncapabilities and community health.", "arxiv_id": "2408.07629v1", "pdf_url": "http://arxiv.org/pdf/2408.07629v1", "abstract_url": "http://arxiv.org/abs/2408.07629v1", "primary_category": "cs.LG", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Optimizing HIV Patient Engagement with Reinforcement Learning in Resource-Limited Settings", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:40.857125"}
{"title": "Battery GraphNets : Relational Learning for Lithium-ion Batteries(LiBs) Life Estimation", "authors": "Sakhinana Sagar Srinivas, Rajat Kumar Sarkar, Venkataramana Runkana", "abstract": "Battery life estimation is critical for optimizing battery performance and\nguaranteeing minimal degradation for better efficiency and reliability of\nbattery-powered systems. The existing methods to predict the Remaining Useful\nLife(RUL) of Lithium-ion Batteries (LiBs) neglect the relational dependencies\nof the battery parameters to model the nonlinear degradation trajectories. We\npresent the Battery GraphNets framework that jointly learns to incorporate a\ndiscrete dependency graph structure between battery parameters to capture the\ncomplex interactions and the graph-learning algorithm to model the intrinsic\nbattery degradation for RUL prognosis. The proposed method outperforms several\npopular methods by a significant margin on publicly available battery datasets\nand achieves SOTA performance. We report the ablation studies to support the\nefficacy of our approach.", "arxiv_id": "2408.07624v1", "pdf_url": "http://arxiv.org/pdf/2408.07624v1", "abstract_url": "http://arxiv.org/abs/2408.07624v1", "primary_category": "cs.LG", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Battery GraphNets : Relational Learning for Lithium-ion Batteries(LiBs) Life Estimation", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:41.904601"}
{"title": "Latent Anomaly Detection Through Density Matrices", "authors": "Joseph Gallego-Mejia, Oscar Bustos-Brinez, Fabio A. Gonz\u00e1lez", "abstract": "This paper introduces a novel anomaly detection framework that combines the\nrobust statistical principles of density-estimation-based anomaly detection\nmethods with the representation-learning capabilities of deep learning models.\nThe method originated from this framework is presented in two different\nversions: a shallow approach employing a density-estimation model based on\nadaptive Fourier features and density matrices, and a deep approach that\nintegrates an autoencoder to learn a low-dimensional representation of the\ndata. By estimating the density of new samples, both methods are able to find\nnormality scores. The methods can be seamlessly integrated into an end-to-end\narchitecture and optimized using gradient-based optimization techniques. To\nevaluate their performance, extensive experiments were conducted on various\nbenchmark datasets. The results demonstrate that both versions of the method\ncan achieve comparable or superior performance when compared to other\nstate-of-the-art methods. Notably, the shallow approach performs better on\ndatasets with fewer dimensions, while the autoencoder-based approach shows\nimproved performance on datasets with higher dimensions.", "arxiv_id": "2408.07623v1", "pdf_url": "http://arxiv.org/pdf/2408.07623v1", "abstract_url": "http://arxiv.org/abs/2408.07623v1", "primary_category": "cs.LG", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Latent Anomaly Detection Through Density Matrices", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:42.993428"}
{"title": "\"How Big is Big Enough?\" Adjusting Model Size in Continual Gaussian Processes", "authors": "Guiomar Pescador-Barrios, Sarah Filippi, Mark van der Wilk", "abstract": "For many machine learning methods, creating a model requires setting a\nparameter that controls the model's capacity before training, e.g.~number of\nneurons in DNNs, or inducing points in GPs. Increasing capacity improves\nperformance until all the information from the dataset is captured. After this\npoint, computational cost keeps increasing, without improved performance. This\nleads to the question ``How big is big enough?'' We investigate this problem\nfor Gaussian processes (single-layer neural networks) in continual learning.\nHere, data becomes available incrementally, and the final dataset size will\ntherefore not be known before training, preventing the use of heuristics for\nsetting the model size. We provide a method that automatically adjusts this,\nwhile maintaining near-optimal performance, and show that a single\nhyperparameter setting for our method performs well across datasets with a wide\nrange of properties.", "arxiv_id": "2408.07588v1", "pdf_url": "http://arxiv.org/pdf/2408.07588v1", "abstract_url": "http://arxiv.org/abs/2408.07588v1", "primary_category": "stat.ML", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "NOT_ENOUGH_RELATED"}
{"title": "\"How Big is Big Enough?\" Adjusting Model Size in Continual Gaussian Processes", "response": "NOT_ENOUGH_RELATED", "timestamp": "2024-08-19T13:34:43.814154"}
{"title": "FedQUIT: On-Device Federated Unlearning via a Quasi-Competent Virtual Teacher", "authors": "Alessio Mora, Lorenzo Valerio, Paolo Bellavista, Andrea Passarella", "abstract": "Federated Learning (FL) promises better privacy guarantees for individuals'\ndata when machine learning models are collaboratively trained. When an FL\nparticipant exercises its right to be forgotten, i.e., to detach from the FL\nframework it has participated and to remove its past contributions to the\nglobal model, the FL solution should perform all the necessary steps to make it\npossible without sacrificing the overall performance of the global model, which\nis not supported in state-of-the-art related solutions nowadays. In this paper,\nwe propose FedQUIT, a novel algorithm that uses knowledge distillation to scrub\nthe contribution of the forgetting data from an FL global model while\npreserving its generalization ability. FedQUIT directly works on clients'\ndevices and does not require sharing additional information if compared with a\nregular FL process, nor does it assume the availability of publicly available\nproxy data. Our solution is efficient, effective, and applicable in both\ncentralized and federated settings. Our experimental results show that, on\naverage, FedQUIT requires less than 2.5% additional communication rounds to\nrecover generalization performances after unlearning, obtaining a sanitized\nglobal model whose predictions are comparable to those of a global model that\nhas never seen the data to be forgotten.", "arxiv_id": "2408.07587v1", "pdf_url": "http://arxiv.org/pdf/2408.07587v1", "abstract_url": "http://arxiv.org/abs/2408.07587v1", "primary_category": "cs.LG", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "FedQUIT: On-Device Federated Unlearning via a Quasi-Competent Virtual Teacher", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:44.632335"}
{"title": "Theoretical and Practical Progress in Hyperspectral Pixel Unmixing with Large Spectral Libraries from a Sparse Perspective", "authors": "Jade Preston, William Basener", "abstract": "Hyperspectral unmixing is the process of determining the presence of\nindividual materials and their respective abundances from an observed pixel\nspectrum. Unmixing is a fundamental process in hyperspectral image analysis,\nand is growing in importance as increasingly large spectral libraries are\ncreated and used. Unmixing is typically done with ordinary least squares (OLS)\nregression. However, unmixing with large spectral libraries where the materials\npresent in a pixel are not a priori known, solving for the coefficients in OLS\nrequires inverting a non-invertible matrix from a large spectral library. A\nnumber of regression methods are available that can produce a numerical\nsolution using regularization, but with considerably varied effectiveness.\nAlso, simple methods that are unpopular in the statistics literature (i.e.\nstep-wise regression) are used with some level of effectiveness in\nhyperspectral analysis. In this paper, we provide a thorough performance\nevaluation of the methods considered, evaluating methods based on how often\nthey select the correct materials in the models. Investigated methods include\nordinary least squares regression, non-negative least squares regression, ridge\nregression, lasso regression, step-wise regression and Bayesian model\naveraging. We evaluated these unmixing approaches using multiple criteria:\nincorporation of non-negative abundances, model size, accurate mineral\ndetection and root mean squared error (RMSE). We provide a taxonomy of the\nregression methods, showing that most methods can be understood as Bayesian\nmethods with specific priors. We conclude that methods that can be derived with\npriors that correspond to the phenomenology of hyperspectral imagery outperform\nthose with priors that are optimal for prediction performance under the\nassumptions of ordinary least squares linear regression.", "arxiv_id": "2408.07580v1", "pdf_url": "http://arxiv.org/pdf/2408.07580v1", "abstract_url": "http://arxiv.org/abs/2408.07580v1", "primary_category": "eess.IV", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Theoretical and Practical Progress in Hyperspectral Pixel Unmixing with Large Spectral Libraries from a Sparse Perspective", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:45.489211"}
{"title": "TabularBench: Benchmarking Adversarial Robustness for Tabular Deep Learning in Real-world Use-cases", "authors": "Thibault Simonetto, Salah Ghamizi, Maxime Cordy", "abstract": "While adversarial robustness in computer vision is a mature research field,\nfewer researchers have tackled the evasion attacks against tabular deep\nlearning, and even fewer investigated robustification mechanisms and reliable\ndefenses. We hypothesize that this lag in the research on tabular adversarial\nattacks is in part due to the lack of standardized benchmarks. To fill this\ngap, we propose TabularBench, the first comprehensive benchmark of robustness\nof tabular deep learning classification models. We evaluated adversarial\nrobustness with CAA, an ensemble of gradient and search attacks which was\nrecently demonstrated as the most effective attack against a tabular model. In\naddition to our open benchmark (https://github.com/serval-uni-lu/tabularbench)\nwhere we welcome submissions of new models and defenses, we implement 7\nrobustification mechanisms inspired by state-of-the-art defenses in computer\nvision and propose the largest benchmark of robust tabular deep learning over\n200 models across five critical scenarios in finance, healthcare and security.\nWe curated real datasets for each use case, augmented with hundreds of\nthousands of realistic synthetic inputs, and trained and assessed our models\nwith and without data augmentations. We open-source our library that provides\nAPI access to all our pre-trained robust tabular models, and the largest\ndatasets of real and synthetic tabular inputs. Finally, we analyze the impact\nof various defenses on the robustness and provide actionable insights to design\nnew defenses and robustification mechanisms.", "arxiv_id": "2408.07579v1", "pdf_url": "http://arxiv.org/pdf/2408.07579v1", "abstract_url": "http://arxiv.org/abs/2408.07579v1", "primary_category": "cs.LG", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "TabularBench: Benchmarking Adversarial Robustness for Tabular Deep Learning in Real-world Use-cases", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:46.291971"}
{"title": "A Nested Graph Reinforcement Learning-based Decision-making Strategy for Eco-platooning", "authors": "Xin Gao, Xueyuan Li, Hao Liu, Ao Li, Zhaoyang Ma, Zirui Li", "abstract": "Platooning technology is renowned for its precise vehicle control, traffic\nflow optimization, and energy efficiency enhancement. However, in large-scale\nmixed platoons, vehicle heterogeneity and unpredictable traffic conditions lead\nto virtual bottlenecks. These bottlenecks result in reduced traffic throughput\nand increased energy consumption within the platoon. To address these\nchallenges, we introduce a decision-making strategy based on nested graph\nreinforcement learning. This strategy improves collaborative decision-making,\nensuring energy efficiency and alleviating congestion. We propose a theory of\nnested traffic graph representation that maps dynamic interactions between\nvehicles and platoons in non-Euclidean spaces. By incorporating spatio-temporal\nweighted graph into a multi-head attention mechanism, we further enhance the\nmodel's capacity to process both local and global data. Additionally, we have\ndeveloped a nested graph reinforcement learning framework to enhance the\nself-iterative learning capabilities of platooning. Using the I-24 dataset, we\ndesigned and conducted comparative algorithm experiments, generalizability\ntesting, and permeability ablation experiments, thereby validating the proposed\nstrategy's effectiveness. Compared to the baseline, our strategy increases\nthroughput by 10% and decreases energy use by 9%. Specifically, increasing the\npenetration rate of CAVs significantly enhances traffic throughput, though it\nalso increases energy consumption.", "arxiv_id": "2408.07578v1", "pdf_url": "http://arxiv.org/pdf/2408.07578v1", "abstract_url": "http://arxiv.org/abs/2408.07578v1", "primary_category": "cs.MA", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "A Nested Graph Reinforcement Learning-based Decision-making Strategy for Eco-platooning", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:47.521888"}
{"title": "Graph neural network surrogate for strategic transport planning", "authors": "Nikita Makarov, Santhanakrishnan Narayanan, Constantinos Antoniou", "abstract": "As the complexities of urban environments continue to grow, the modelling of\ntransportation systems become increasingly challenging. This paper explores the\napplication of advanced Graph Neural Network (GNN) architectures as surrogate\nmodels for strategic transport planning. Building upon a prior work that laid\nthe foundation with graph convolution networks (GCN), our study delves into the\ncomparative analysis of established GCN with the more expressive Graph\nAttention Network (GAT). Additionally, we propose a novel GAT variant (namely\nGATv3) to address over-smoothing issues in graph-based models. Our\ninvestigation also includes the exploration of a hybrid model combining both\nGCN and GAT architectures, aiming to investigate the performance of the\nmixture. The three models are applied to various experiments to understand\ntheir limits. We analyse hierarchical regression setups, combining\nclassification and regression tasks, and introduce fine-grained classification\nwith a proposal of a method to convert outputs to precise values. Results\nreveal the superior performance of the new GAT in classification tasks. To the\nbest of the authors' knowledge, this is the first GAT model in literature to\nachieve larger depths. Surprisingly, the fine-grained classification task\ndemonstrates the GCN's unexpected dominance with additional training data. This\nshows that synthetic data generators can increase the training data, without\noverfitting issues whilst improving model performance. In conclusion, this\nresearch advances GNN based surrogate modelling, providing insights for\nrefining GNN architectures. The findings open avenues for investigating the\npotential of the newly proposed GAT architecture and the modelling setups for\nother transportation problems.", "arxiv_id": "2408.07726v1", "pdf_url": "http://arxiv.org/pdf/2408.07726v1", "abstract_url": "http://arxiv.org/abs/2408.07726v1", "primary_category": "cs.LG", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Graph neural network surrogate for strategic transport planning", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:48.315067"}
{"title": "Multi-task Heterogeneous Graph Learning on Electronic Health Records", "authors": "Tsai Hor Chan, Guosheng Yin, Kyongtae Bae, Lequan Yu", "abstract": "Learning electronic health records (EHRs) has received emerging attention\nbecause of its capability to facilitate accurate medical diagnosis. Since the\nEHRs contain enriched information specifying complex interactions between\nentities, modeling EHRs with graphs is shown to be effective in practice. The\nEHRs, however, present a great degree of heterogeneity, sparsity, and\ncomplexity, which hamper the performance of most of the models applied to them.\nMoreover, existing approaches modeling EHRs often focus on learning the\nrepresentations for a single task, overlooking the multi-task nature of EHR\nanalysis problems and resulting in limited generalizability across different\ntasks. In view of these limitations, we propose a novel framework for EHR\nmodeling, namely MulT-EHR (Multi-Task EHR), which leverages a heterogeneous\ngraph to mine the complex relations and model the heterogeneity in the EHRs. To\nmitigate the large degree of noise, we introduce a denoising module based on\nthe causal inference framework to adjust for severe confounding effects and\nreduce noise in the EHR data. Additionally, since our model adopts a single\ngraph neural network for simultaneous multi-task prediction, we design a\nmulti-task learning module to leverage the inter-task knowledge to regularize\nthe training process. Extensive empirical studies on MIMIC-III and MIMIC-IV\ndatasets validate that the proposed method consistently outperforms the\nstate-of-the-art designs in four popular EHR analysis tasks -- drug\nrecommendation, and predictions of the length of stay, mortality, and\nreadmission. Thorough ablation studies demonstrate the robustness of our method\nupon variations to key components and hyperparameters.", "arxiv_id": "2408.07569v1", "pdf_url": "http://arxiv.org/pdf/2408.07569v1", "abstract_url": "http://arxiv.org/abs/2408.07569v1", "primary_category": "cs.LG", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Multi-task Heterogeneous Graph Learning on Electronic Health Records", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:49.093669"}
{"title": "Sonic: Fast and Transferable Data Poisoning on Clustering Algorithms", "authors": "Francesco Villani, Dario Lazzaro, Antonio Emanuele Cin\u00e0, Matteo Dell'Amico, Battista Biggio, Fabio Roli", "abstract": "Data poisoning attacks on clustering algorithms have received limited\nattention, with existing methods struggling to scale efficiently as dataset\nsizes and feature counts increase. These attacks typically require\nre-clustering the entire dataset multiple times to generate predictions and\nassess the attacker's objectives, significantly hindering their scalability.\nThis paper addresses these limitations by proposing Sonic, a novel genetic data\npoisoning attack that leverages incremental and scalable clustering algorithms,\ne.g., FISHDBC, as surrogates to accelerate poisoning attacks against\ngraph-based and density-based clustering methods, such as HDBSCAN. We\nempirically demonstrate the effectiveness and efficiency of Sonic in poisoning\nthe target clustering algorithms. We then conduct a comprehensive analysis of\nthe factors affecting the scalability and transferability of poisoning attacks\nagainst clustering algorithms, and we conclude by examining the robustness of\nhyperparameters in our attack strategy Sonic.", "arxiv_id": "2408.07558v1", "pdf_url": "http://arxiv.org/pdf/2408.07558v1", "abstract_url": "http://arxiv.org/abs/2408.07558v1", "primary_category": "cs.CR", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Sonic: Fast and Transferable Data Poisoning on Clustering Algorithms", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:49.853963"}
{"title": "PolyCL: Contrastive Learning for Polymer Representation Learning via Explicit and Implicit Augmentations", "authors": "Jiajun Zhou, Yijie Yang, Austin M. Mroz, Kim E. Jelfs", "abstract": "Polymers play a crucial role in a wide array of applications due to their\ndiverse and tunable properties. Establishing the relationship between polymer\nrepresentations and their properties is crucial to the computational design and\nscreening of potential polymers via machine learning. The quality of the\nrepresentation significantly influences the effectiveness of these\ncomputational methods. Here, we present a self-supervised contrastive learning\nparadigm, PolyCL, for learning high-quality polymer representation without the\nneed for labels. Our model combines explicit and implicit augmentation\nstrategies for improved learning performance. The results demonstrate that our\nmodel achieves either better, or highly competitive, performances on transfer\nlearning tasks as a feature extractor without an overcomplicated training\nstrategy or hyperparameter optimisation. Further enhancing the efficacy of our\nmodel, we conducted extensive analyses on various augmentation combinations\nused in contrastive learning. This led to identifying the most effective\ncombination to maximise PolyCL's performance.", "arxiv_id": "2408.07556v1", "pdf_url": "http://arxiv.org/pdf/2408.07556v1", "abstract_url": "http://arxiv.org/abs/2408.07556v1", "primary_category": "cs.LG", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "PolyCL: Contrastive Learning for Polymer Representation Learning via Explicit and Implicit Augmentations", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:50.492765"}
{"title": "\"Normalized Stress\" is Not Normalized: How to Interpret Stress Correctly", "authors": "Kiran Smelser, Jacob Miller, Stephen Kobourov", "abstract": "Stress is among the most commonly employed quality metrics and optimization\ncriteria for dimension reduction projections of high dimensional data. Complex,\nhigh dimensional data is ubiquitous across many scientific disciplines,\nincluding machine learning, biology, and the social sciences. One of the\nprimary methods of visualizing these datasets is with two dimensional scatter\nplots that visually capture some properties of the data. Because visually\ndetermining the accuracy of these plots is challenging, researchers often use\nquality metrics to measure projection accuracy or faithfulness to the full\ndata. One of the most commonly employed metrics, normalized stress, is\nsensitive to uniform scaling of the projection, despite this act not\nmeaningfully changing anything about the projection. We investigate the effect\nof scaling on stress and other distance based quality metrics analytically and\nempirically by showing just how much the values change and how this affects\ndimension reduction technique evaluations. We introduce a simple technique to\nmake normalized stress scale invariant and show that it accurately captures\nexpected behavior on a small benchmark.", "arxiv_id": "2408.07724v1", "pdf_url": "http://arxiv.org/pdf/2408.07724v1", "abstract_url": "http://arxiv.org/abs/2408.07724v1", "primary_category": "cs.LG", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "\"Normalized Stress\" is Not Normalized: How to Interpret Stress Correctly", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:51.287883"}
{"title": "PeriodWave: Multi-Period Flow Matching for High-Fidelity Waveform Generation", "authors": "Sang-Hoon Lee, Ha-Yeong Choi, Seong-Whan Lee", "abstract": "Recently, universal waveform generation tasks have been investigated\nconditioned on various out-of-distribution scenarios. Although GAN-based\nmethods have shown their strength in fast waveform generation, they are\nvulnerable to train-inference mismatch scenarios such as two-stage\ntext-to-speech. Meanwhile, diffusion-based models have shown their powerful\ngenerative performance in other domains; however, they stay out of the\nlimelight due to slow inference speed in waveform generation tasks. Above all,\nthere is no generator architecture that can explicitly disentangle the natural\nperiodic features of high-resolution waveform signals. In this paper, we\npropose PeriodWave, a novel universal waveform generation model. First, we\nintroduce a period-aware flow matching estimator that can capture the periodic\nfeatures of the waveform signal when estimating the vector fields.\nAdditionally, we utilize a multi-period estimator that avoids overlaps to\ncapture different periodic features of waveform signals. Although increasing\nthe number of periods can improve the performance significantly, this requires\nmore computational costs. To reduce this issue, we also propose a single\nperiod-conditional universal estimator that can feed-forward parallel by\nperiod-wise batch inference. Additionally, we utilize discrete wavelet\ntransform to losslessly disentangle the frequency information of waveform\nsignals for high-frequency modeling, and introduce FreeU to reduce the\nhigh-frequency noise for waveform generation. The experimental results\ndemonstrated that our model outperforms the previous models both in\nMel-spectrogram reconstruction and text-to-speech tasks. All source code will\nbe available at \\url{https://github.com/sh-lee-prml/PeriodWave}.", "arxiv_id": "2408.07547v1", "pdf_url": "http://arxiv.org/pdf/2408.07547v1", "abstract_url": "http://arxiv.org/abs/2408.07547v1", "primary_category": "cs.SD", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "PeriodWave: Multi-Period Flow Matching for High-Fidelity Waveform Generation", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:52.206786"}
{"title": "$\u03c7$SPN: Characteristic Interventional Sum-Product Networks for Causal Inference in Hybrid Domains", "authors": "Harsh Poonia, Moritz Willig, Zhongjie Yu, Matej Ze\u010devi\u0107, Kristian Kersting, Devendra Singh Dhami", "abstract": "Causal inference in hybrid domains, characterized by a mixture of discrete\nand continuous variables, presents a formidable challenge. We take a step\ntowards this direction and propose Characteristic Interventional Sum-Product\nNetwork ($\\chi$SPN) that is capable of estimating interventional distributions\nin presence of random variables drawn from mixed distributions. $\\chi$SPN uses\ncharacteristic functions in the leaves of an interventional SPN (iSPN) thereby\nproviding a unified view for discrete and continuous random variables through\nthe Fourier-Stieltjes transform of the probability measures. A neural network\nis used to estimate the parameters of the learned iSPN using the intervened\ndata. Our experiments on 3 synthetic heterogeneous datasets suggest that\n$\\chi$SPN can effectively capture the interventional distributions for both\ndiscrete and continuous variables while being expressive and causally adequate.\nWe also show that $\\chi$SPN generalize to multiple interventions while being\ntrained only on a single intervention data.", "arxiv_id": "2408.07545v1", "pdf_url": "http://arxiv.org/pdf/2408.07545v1", "abstract_url": "http://arxiv.org/abs/2408.07545v1", "primary_category": "cs.LG", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "$\u03c7$SPN: Characteristic Interventional Sum-Product Networks for Causal Inference in Hybrid Domains", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:52.938913"}
{"title": "New Curriculum, New Chance -- Retrieval Augmented Generation for Lesson Planning in Ugandan Secondary Schools. Prototype Quality Evaluation", "authors": "Simon Kloker, Herbertson Bukoli, Twaha Kateete", "abstract": "Introduction: Poor educational quality in Secondary Schools is still regarded\nas one of the major struggles in 21st century Uganda - especially in rural\nareas. Research identifies several problems, including low quality or absent\nteacher lesson planning. As the government pushes towards the implementation of\na new curriculum, exiting lesson plans become obsolete and the problem is\nworsened. Using a Retrieval Augmented Generation approach, we developed a\nprototype that generates customized lesson plans based on the\ngovernment-accredited textbooks. This helps teachers create lesson plans more\nefficiently and with better quality, ensuring they are fully aligned the new\ncurriculum and the competence-based learning approach.\n  Methods: The prototype was created using Cohere LLM and Sentence Embeddings,\nand LangChain Framework - and thereafter made available on a public website.\nVector stores were trained for three new curriculum textbooks (ICT,\nMathematics, History), all at Secondary 1 Level. Twenty-four lessons plans were\ngenerated following a pseudo-random generation protocol, based on the suggested\nperiods in the textbooks. The lesson plans were analyzed regarding their\ntechnical quality by three independent raters following the Lesson Plan\nAnalysis Protocol (LPAP) by Ndihokubwayo et al. (2022) that is specifically\ndesigned for East Africa and competence-based curriculums.\n  Results: Evaluation of 24 lesson plans using the LPAP resulted in an average\nquality of between 75 and 80%, corresponding to \"very good lesson plan\". None\nof the lesson plans scored below 65%, although one lesson plan could be argued\nto have been missing the topic. In conclusion, the quality of the generated\nlesson plans is at least comparable, if not better, than those created by\nhumans, as demonstrated in a study in Rwanda, whereby no lesson plan even\nreached the benchmark of 50%.", "arxiv_id": "2408.07542v1", "pdf_url": "http://arxiv.org/pdf/2408.07542v1", "abstract_url": "http://arxiv.org/abs/2408.07542v1", "primary_category": "cs.CY", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "New Curriculum, New Chance -- Retrieval Augmented Generation for Lesson Planning in Ugandan Secondary Schools. Prototype Quality Evaluation", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:53.850208"}
{"title": "Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments", "authors": "Seungjun Han, Wongyung Choi", "abstract": "Emergency department (ED) overcrowding and the complexity of rapid\ndecision-making in critical care settings pose significant challenges to\nhealthcare systems worldwide. While clinical decision support systems (CDSS)\nhave shown promise, the integration of large language models (LLMs) offers new\npossibilities for enhancing triage accuracy and clinical decision-making. This\nstudy presents an LLM-driven CDSS designed to assist ED physicians and nurses\nin patient triage, treatment planning, and overall emergency care management.\n  We developed a multi-agent CDSS utilizing Llama-3-70b as the base LLM,\norchestrated by CrewAI and Langchain. The system comprises four AI agents\nemulating key ED roles: Triage Nurse, Emergency Physician, Pharmacist, and ED\nCoordinator. It incorporates the Korean Triage and Acuity Scale (KTAS) for\ntriage assessment and integrates with the RxNorm API for medication management.\n  The model was evaluated using the Asclepius dataset, with performance\nassessed by a clinical emergency medicine specialist. The CDSS demonstrated\nhigh accuracy in triage decision-making compared to the baseline of a\nsingle-agent system. Furthermore, the system exhibited strong performance in\ncritical areas, including primary diagnosis, critical findings identification,\ndisposition decision-making, treatment planning, and resource allocation.\n  Our multi-agent CDSS demonstrates significant potential for supporting\ncomprehensive emergency care management. By leveraging state-of-the-art AI\ntechnologies, this system offers a scalable and adaptable tool that could\nenhance emergency medical care delivery, potentially alleviating ED\novercrowding and improving patient outcomes. This work contributes to the\ngrowing field of AI applications in emergency medicine and offers a promising\ndirection for future research and clinical implementation.", "arxiv_id": "2408.07531v1", "pdf_url": "http://arxiv.org/pdf/2408.07531v1", "abstract_url": "http://arxiv.org/abs/2408.07531v1", "primary_category": "cs.AI", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:56.714787"}
{"title": "Learning-based Models for Vulnerability Detection: An Extensive Study", "authors": "Chao Ni, Liyu Shen, Xiaodan Xu, Xin Yin, Shaohua Wang", "abstract": "Though many deep learning-based models have made great progress in\nvulnerability detection, we have no good understanding of these models, which\nlimits the further advancement of model capability, understanding of the\nmechanism of model detection, and efficiency and safety of practical\napplication of models. In this paper, we extensively and comprehensively\ninvestigate two types of state-of-the-art learning-based approaches\n(sequence-based and graph-based) by conducting experiments on a recently built\nlarge-scale dataset. We investigate seven research questions from five\ndimensions, namely model capabilities, model interpretation, model stability,\nease of use of model, and model economy. We experimentally demonstrate the\npriority of sequence-based models and the limited abilities of both LLM\n(ChatGPT) and graph-based models. We explore the types of vulnerability that\nlearning-based models skilled in and reveal the instability of the models\nthough the input is subtlely semantical-equivalently changed. We empirically\nexplain what the models have learned. We summarize the pre-processing as well\nas requirements for easily using the models. Finally, we initially induce the\nvital information for economically and safely practical usage of these models.", "arxiv_id": "2408.07526v1", "pdf_url": "http://arxiv.org/pdf/2408.07526v1", "abstract_url": "http://arxiv.org/abs/2408.07526v1", "primary_category": "cs.SE", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Learning-based Models for Vulnerability Detection: An Extensive Study", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:57.454878"}
{"title": "Optimising MFCC parameters for the automatic detection of respiratory diseases", "authors": "Yuyang Yan, Sami O. Simons, Loes van Bemmel, Lauren Reinders, Frits M. E. Franssen, Visara Urovi", "abstract": "Voice signals originating from the respiratory tract are utilized as valuable\nacoustic biomarkers for the diagnosis and assessment of respiratory diseases.\nAmong the employed acoustic features, Mel Frequency Cepstral Coefficients\n(MFCC) is widely used for automatic analysis, with MFCC extraction commonly\nrelying on default parameters. However, no comprehensive study has\nsystematically investigated the impact of MFCC extraction parameters on\nrespiratory disease diagnosis. In this study, we address this gap by examining\nthe effects of key parameters, namely the number of coefficients, frame length,\nand hop length between frames, on respiratory condition examination. Our\ninvestigation uses four datasets: the Cambridge COVID-19 Sound database, the\nCoswara dataset, the Saarbrucken Voice Disorders (SVD) database, and a TACTICAS\ndataset. The Support Vector Machine (SVM) is employed as the classifier, given\nits widespread adoption and efficacy. Our findings indicate that the accuracy\nof MFCC decreases as hop length increases, and the optimal number of\ncoefficients is observed to be approximately 30. The performance of MFCC varies\nwith frame length across the datasets: for the COVID-19 datasets (Cambridge\nCOVID-19 Sound database and Coswara dataset), performance declines with longer\nframe lengths, while for the SVD dataset, performance improves with increasing\nframe length (from 50 ms to 500 ms). Furthermore, we investigate the optimized\ncombination of these parameters and observe substantial enhancements in\naccuracy. Compared to the worst combination, the SVM model achieves an accuracy\nof 81.1%, 80.6%, and 71.7%, with improvements of 19.6%, 16.10%, and 14.90% for\nthe Cambridge COVID-19 Sound database, the Coswara dataset, and the SVD dataset\nrespectively.", "arxiv_id": "2408.07522v1", "pdf_url": "http://arxiv.org/pdf/2408.07522v1", "abstract_url": "http://arxiv.org/abs/2408.07522v1", "primary_category": "cs.SD", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Optimising MFCC parameters for the automatic detection of respiratory diseases", "response": "RELEVANT", "timestamp": "2024-08-19T13:34:58.251518"}
{"title": "Protected Test-Time Adaptation via Online Entropy Matching: A Betting Approach", "authors": "Yarin Bar, Shalev Shaer, Yaniv Romano", "abstract": "We present a novel approach for test-time adaptation via online\nself-training, consisting of two components. First, we introduce a statistical\nframework that detects distribution shifts in the classifier's entropy values\nobtained on a stream of unlabeled samples. Second, we devise an online\nadaptation mechanism that utilizes the evidence of distribution shifts captured\nby the detection tool to dynamically update the classifier's parameters. The\nresulting adaptation process drives the distribution of test entropy values\nobtained from the self-trained classifier to match those of the source domain,\nbuilding invariance to distribution shifts. This approach departs from the\nconventional self-training method, which focuses on minimizing the classifier's\nentropy. Our approach combines concepts in betting martingales and online\nlearning to form a detection tool capable of quickly reacting to distribution\nshifts. We then reveal a tight relation between our adaptation scheme and\noptimal transport, which forms the basis of our novel self-supervised loss.\nExperimental results demonstrate that our approach improves test-time accuracy\nunder distribution shifts while maintaining accuracy and calibration in their\nabsence, outperforming leading entropy minimization methods across various\nscenarios.", "arxiv_id": "2408.07511v1", "pdf_url": "http://arxiv.org/pdf/2408.07511v1", "abstract_url": "http://arxiv.org/abs/2408.07511v1", "primary_category": "cs.LG", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Protected Test-Time Adaptation via Online Entropy Matching: A Betting Approach", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:00.577265"}
{"title": "Decoder ensembling for learned latent geometries", "authors": "Stas Syrota, Pablo Moreno-Mu\u00f1oz, S\u00f8ren Hauberg", "abstract": "Latent space geometry provides a rigorous and empirically valuable framework\nfor interacting with the latent variables of deep generative models. This\napproach reinterprets Euclidean latent spaces as Riemannian through a pull-back\nmetric, allowing for a standard differential geometric analysis of the latent\nspace. Unfortunately, data manifolds are generally compact and easily\ndisconnected or filled with holes, suggesting a topological mismatch to the\nEuclidean latent space. The most established solution to this mismatch is to\nlet uncertainty be a proxy for topology, but in neural network models, this is\noften realized through crude heuristics that lack principle and generally do\nnot scale to high-dimensional representations. We propose using ensembles of\ndecoders to capture model uncertainty and show how to easily compute geodesics\non the associated expected manifold. Empirically, we find this simple and\nreliable, thereby coming one step closer to easy-to-use latent geometries.", "arxiv_id": "2408.07507v1", "pdf_url": "http://arxiv.org/pdf/2408.07507v1", "abstract_url": "http://arxiv.org/abs/2408.07507v1", "primary_category": "stat.ML", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Decoder ensembling for learned latent geometries", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:01.323160"}
{"title": "Faster Stochastic Optimization with Arbitrary Delays via Asynchronous Mini-Batching", "authors": "Amit Attia, Ofir Gaash, Tomer Koren", "abstract": "We consider the problem of asynchronous stochastic optimization, where an\noptimization algorithm makes updates based on stale stochastic gradients of the\nobjective that are subject to an arbitrary (possibly adversarial) sequence of\ndelays. We present a procedure which, for any given $q \\in (0,1]$, transforms\nany standard stochastic first-order method to an asynchronous method with\nconvergence guarantee depending on the $q$-quantile delay of the sequence. This\napproach leads to convergence rates of the form $O(\\tau_q/qT+\\sigma/\\sqrt{qT})$\nfor non-convex and $O(\\tau_q^2/(q T)^2+\\sigma/\\sqrt{qT})$ for convex smooth\nproblems, where $\\tau_q$ is the $q$-quantile delay, generalizing and improving\non existing results that depend on the average delay. We further show a method\nthat automatically adapts to all quantiles simultaneously, without any prior\nknowledge of the delays, achieving convergence rates of the form $O(\\inf_{q}\n\\tau_q/qT+\\sigma/\\sqrt{qT})$ for non-convex and $O(\\inf_{q} \\tau_q^2/(q\nT)^2+\\sigma/\\sqrt{qT})$ for convex smooth problems. Our technique is based on\nasynchronous mini-batching with a careful batch-size selection and filtering of\nstale gradients.", "arxiv_id": "2408.07503v1", "pdf_url": "http://arxiv.org/pdf/2408.07503v1", "abstract_url": "http://arxiv.org/abs/2408.07503v1", "primary_category": "math.OC", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Faster Stochastic Optimization with Arbitrary Delays via Asynchronous Mini-Batching", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:02.401490"}
{"title": "QirK: Question Answering via Intermediate Representation on Knowledge Graphs", "authors": "Jan Luca Scheerer, Anton Lykov, Moe Kayali, Ilias Fountalis, Dan Olteanu, Nikolaos Vasiloglou, Dan Suciu", "abstract": "We demonstrate QirK, a system for answering natural language questions on\nKnowledge Graphs (KG). QirK can answer structurally complex questions that are\nstill beyond the reach of emerging Large Language Models (LLMs). It does so\nusing a unique combination of database technology, LLMs, and semantic search\nover vector embeddings. The glue for these components is an intermediate\nrepresentation (IR). The input question is mapped to IR using LLMs, which is\nthen repaired into a valid relational database query with the aid of a semantic\nsearch on vector embeddings. This allows a practical synthesis of LLM\ncapabilities and KG reliability.\n  A short video demonstrating QirK is available at\nhttps://youtu.be/6c81BLmOZ0U.", "arxiv_id": "2408.07494v1", "pdf_url": "http://arxiv.org/pdf/2408.07494v1", "abstract_url": "http://arxiv.org/abs/2408.07494v1", "primary_category": "cs.DB", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "QirK: Question Answering via Intermediate Representation on Knowledge Graphs", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:03.433412"}
{"title": "Adaptive Basis Function Selection for Computationally Efficient Predictions", "authors": "Anton Kullberg, Frida Viset, Isaac Skog, Gustaf Hendeby", "abstract": "Basis Function (BF) expansions are a cornerstone of any engineer's toolbox\nfor computational function approximation which shares connections with both\nneural networks and Gaussian processes. Even though BF expansions are an\nintuitive and straightforward model to use, they suffer from quadratic\ncomputational complexity in the number of BFs if the predictive variance is to\nbe computed. We develop a method to automatically select the most important BFs\nfor prediction in a sub-domain of the model domain. This significantly reduces\nthe computational complexity of computing predictions while maintaining\npredictive accuracy. The proposed method is demonstrated using two numerical\nexamples, where reductions up to 50-75% are possible without significantly\nreducing the predictive accuracy.", "arxiv_id": "2408.07480v1", "pdf_url": "http://arxiv.org/pdf/2408.07480v1", "abstract_url": "http://arxiv.org/abs/2408.07480v1", "primary_category": "eess.SP", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Adaptive Basis Function Selection for Computationally Efficient Predictions", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:04.214869"}
{"title": "Unsupervised Blind Joint Dereverberation and Room Acoustics Estimation with Diffusion Models", "authors": "Jean-Marie Lemercier, Eloi Moliner, Simon Welker, Vesa V\u00e4lim\u00e4ki, Timo Gerkmann", "abstract": "This paper presents an unsupervised method for single-channel blind\ndereverberation and room impulse response (RIR) estimation, called BUDDy. The\nalgorithm is rooted in Bayesian posterior sampling: it combines a likelihood\nmodel enforcing fidelity to the reverberant measurement, and an anechoic speech\nprior implemented by an unconditional diffusion model. We design a parametric\nfilter representing the RIR, with exponential decay for each frequency subband.\nRoom acoustics estimation and speech dereverberation are jointly carried out,\nas the filter parameters are iteratively estimated and the speech utterance\nrefined along the reverse diffusion trajectory. In a blind scenario where the\nroom impulse response is unknown, BUDDy successfully performs speech\ndereverberation in various acoustic scenarios, significantly outperforming\nother blind unsupervised baselines. Unlike supervised methods, which often\nstruggle to generalize, BUDDy seamlessly adapts to different acoustic\nconditions. This paper extends our previous work by offering new experimental\nresults and insights into the algorithm's performance and versatility. We first\ninvestigate the robustness of informed dereverberation methods to RIR\nestimation errors, to motivate the joint acoustic estimation and\ndereverberation paradigm. Then, we demonstrate the adaptability of our method\nto high-resolution singing voice dereverberation, study its performance in RIR\nestimation, and conduct subjective evaluation experiments to validate the\nperceptual quality of the results, among other contributions. Audio samples and\ncode can be found online.", "arxiv_id": "2408.07472v1", "pdf_url": "http://arxiv.org/pdf/2408.07472v1", "abstract_url": "http://arxiv.org/abs/2408.07472v1", "primary_category": "eess.AS", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Unsupervised Blind Joint Dereverberation and Room Acoustics Estimation with Diffusion Models", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:04.958922"}
{"title": "Fact or Fiction? Improving Fact Verification with Knowledge Graphs through Simplified Subgraph Retrievals", "authors": "Tobias A. Opsahl", "abstract": "Despite recent success in natural language processing (NLP), fact\nverification still remains a difficult task. Due to misinformation spreading\nincreasingly fast, attention has been directed towards automatically verifying\nthe correctness of claims. In the domain of NLP, this is usually done by\ntraining supervised machine learning models to verify claims by utilizing\nevidence from trustworthy corpora. We present efficient methods for verifying\nclaims on a dataset where the evidence is in the form of structured knowledge\ngraphs. We use the FactKG dataset, which is constructed from the DBpedia\nknowledge graph extracted from Wikipedia. By simplifying the evidence retrieval\nprocess, from fine-tuned language models to simple logical retrievals, we are\nable to construct models that both require less computational resources and\nachieve better test-set accuracy.", "arxiv_id": "2408.07453v1", "pdf_url": "http://arxiv.org/pdf/2408.07453v1", "abstract_url": "http://arxiv.org/abs/2408.07453v1", "primary_category": "cs.CL", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Fact or Fiction? Improving Fact Verification with Knowledge Graphs through Simplified Subgraph Retrievals", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:08.748457"}
{"title": "Achieving Data Efficient Neural Networks with Hybrid Concept-based Models", "authors": "Tobias A. Opsahl, Vegard Antun", "abstract": "Most datasets used for supervised machine learning consist of a single label\nper data point. However, in cases where more information than just the class\nlabel is available, would it be possible to train models more efficiently? We\nintroduce two novel model architectures, which we call hybrid concept-based\nmodels, that train using both class labels and additional information in the\ndataset referred to as concepts. In order to thoroughly assess their\nperformance, we introduce ConceptShapes, an open and flexible class of datasets\nwith concept labels. We show that the hybrid concept-based models outperform\nstandard computer vision models and previously proposed concept-based models\nwith respect to accuracy, especially in sparse data settings. We also introduce\nan algorithm for performing adversarial concept attacks, where an image is\nperturbed in a way that does not change a concept-based model's concept\npredictions, but changes the class prediction. The existence of such\nadversarial examples raises questions about the interpretable qualities\npromised by concept-based models.", "arxiv_id": "2408.07438v1", "pdf_url": "http://arxiv.org/pdf/2408.07438v1", "abstract_url": "http://arxiv.org/abs/2408.07438v1", "primary_category": "cs.LG", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Achieving Data Efficient Neural Networks with Hybrid Concept-based Models", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:09.379068"}
{"title": "Real-world validation of safe reinforcement learning, model predictive control and decision tree-based home energy management systems", "authors": "Julian Ruddick, Glenn Ceusters, Gilles Van Kriekinge, Evgenii Genov, Thierry Coosemans, Maarten Messagie", "abstract": "Recent advancements in machine learning based energy management approaches,\nspecifically reinforcement learning with a safety layer (OptLayerPolicy) and a\nmetaheuristic algorithm generating a decision tree control policy (TreeC), have\nshown promise. However, their effectiveness has only been demonstrated in\ncomputer simulations. This paper presents the real-world validation of these\nmethods, comparing against model predictive control and simple rule-based\ncontrol benchmark. The experiments were conducted on the electrical\ninstallation of 4 reproductions of residential houses, which all have their own\nbattery, photovoltaic and dynamic load system emulating a non-controllable\nelectrical load and a controllable electric vehicle charger. The results show\nthat the simple rules, TreeC, and model predictive control-based methods\nachieved similar costs, with a difference of only 0.6%. The reinforcement\nlearning based method, still in its training phase, obtained a cost 25.5\\%\nhigher to the other methods. Additional simulations show that the costs can be\nfurther reduced by using a more representative training dataset for TreeC and\naddressing errors in the model predictive control implementation caused by its\nreliance on accurate data from various sources. The OptLayerPolicy safety layer\nallows safe online training of a reinforcement learning agent in the\nreal-world, given an accurate constraint function formulation. The proposed\nsafety layer method remains error-prone, nonetheless, it is found beneficial\nfor all investigated methods. The TreeC method, which does require building a\nrealistic simulation for training, exhibits the safest operational performance,\nexceeding the grid limit by only 27.1 Wh compared to 593.9 Wh for reinforcement\nlearning.", "arxiv_id": "2408.07435v1", "pdf_url": "http://arxiv.org/pdf/2408.07435v1", "abstract_url": "http://arxiv.org/abs/2408.07435v1", "primary_category": "eess.SY", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Real-world validation of safe reinforcement learning, model predictive control and decision tree-based home energy management systems", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:10.158030"}
{"title": "Operator Feature Neural Network for Symbolic Regression", "authors": "Yusong Deng, Min Wu, Lina Yu, Jingyi Liu, Shu Wei, Yanjie Li, Weijun Li", "abstract": "Symbolic regression is a task aimed at identifying patterns in data and\nrepresenting them through mathematical expressions, generally involving\nskeleton prediction and constant optimization. Many methods have achieved some\nsuccess, however they treat variables and symbols merely as characters of\nnatural language without considering their mathematical essence. This paper\nintroduces the operator feature neural network (OF-Net) which employs operator\nrepresentation for expressions and proposes an implicit feature encoding method\nfor the intrinsic mathematical operational logic of operators. By substituting\noperator features for numeric loss, we can predict the combination of operators\nof target expressions. We evaluate the model on public datasets, and the\nresults demonstrate that the model achieves superior recovery rates and high\n$R^2$ scores. With the discussion of the results, we analyze the merit and\ndemerit of OF-Net and propose optimizing schemes.", "arxiv_id": "2408.07719v1", "pdf_url": "http://arxiv.org/pdf/2408.07719v1", "abstract_url": "http://arxiv.org/abs/2408.07719v1", "primary_category": "cs.LG", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Operator Feature Neural Network for Symbolic Regression", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:10.845818"}
{"title": "Sum-Product-Set Networks", "authors": "Milan Pape\u017e, Martin Rektoris, Tom\u00e1\u0161 Pevn\u00fd, V\u00e1clav \u0160m\u00eddl", "abstract": "Daily internet communication relies heavily on tree-structured graphs,\nembodied by popular data formats such as XML and JSON. However, many recent\ngenerative (probabilistic) models utilize neural networks to learn a\nprobability distribution over undirected cyclic graphs. This assumption of a\ngeneric graph structure brings various computational challenges, and, more\nimportantly, the presence of non-linearities in neural networks does not permit\ntractable probabilistic inference. We address these problems by proposing\nsum-product-set networks, an extension of probabilistic circuits from\nunstructured tensor data to tree-structured graph data. To this end, we use\nrandom finite sets to reflect a variable number of nodes and edges in the graph\nand to allow for exact and efficient inference. We demonstrate that our\ntractable model performs comparably to various intractable models based on\nneural networks.", "arxiv_id": "2408.07394v1", "pdf_url": "http://arxiv.org/pdf/2408.07394v1", "abstract_url": "http://arxiv.org/abs/2408.07394v1", "primary_category": "cs.LG", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Sum-Product-Set Networks", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:11.769192"}
{"title": "DPSNN: Spiking Neural Network for Low-Latency Streaming Speech Enhancement", "authors": "Tao Sun, Sander Boht\u00e9", "abstract": "Speech enhancement (SE) improves communication in noisy environments,\naffecting areas such as automatic speech recognition, hearing aids, and\ntelecommunications. With these domains typically being power-constrained and\nevent-based while requiring low latency, neuromorphic algorithms in the form of\nspiking neural networks (SNNs) have great potential. Yet, current effective SNN\nsolutions require a contextual sampling window imposing substantial latency,\ntypically around 32ms, too long for many applications. Inspired by Dual-Path\nSpiking Neural Networks (DPSNNs) in classical neural networks, we develop a\ntwo-phase time-domain streaming SNN framework -- the Dual-Path Spiking Neural\nNetwork (DPSNN). In the DPSNN, the first phase uses Spiking Convolutional\nNeural Networks (SCNNs) to capture global contextual information, while the\nsecond phase uses Spiking Recurrent Neural Networks (SRNNs) to focus on\nfrequency-related features. In addition, the regularizer suppresses activation\nto further enhance energy efficiency of our DPSNNs. Evaluating on the VCTK and\nIntel DNS Datasets, we demonstrate that our approach achieves the very low\nlatency (approximately 5ms) required for applications like hearing aids, while\ndemonstrating excellent signal-to-noise ratio (SNR), perceptual quality, and\nenergy efficiency.", "arxiv_id": "2408.07388v1", "pdf_url": "http://arxiv.org/pdf/2408.07388v1", "abstract_url": "http://arxiv.org/abs/2408.07388v1", "primary_category": "cs.SD", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "DPSNN: Spiking Neural Network for Low-Latency Streaming Speech Enhancement", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:12.730296"}
{"title": "Fading memory and the convolution theorem", "authors": "Juan-Pablo Ortega, Florian Rossmannek", "abstract": "Several topological and analytical notions of continuity and fading memory\nfor causal and time-invariant filters are introduced, and the relations between\nthem are analysed. A significant generalization of the convolution theorem that\nestablishes the equivalence between the fading memory property and the\navailability of convolution representations of linear filters is proved. This\nresult extends a previous such characterization to a complete array of weighted\nnorms in the definition of the fading memory property. Additionally, the main\ntheorem shows that the availability of convolution representations can be\ncharacterized, at least when the codomain is finite-dimensional, not only by\nthe fading memory property but also by the reunion of two purely topological\nnotions that are called minimal continuity and minimal fading memory property.\nFinally, when the input space and the codomain of a linear functional are\nHilbert spaces, it is shown that minimal continuity and the minimal fading\nmemory property guarantee the existence of interesting embeddings of the\nassociated reproducing kernel Hilbert spaces and approximation results of\nsolutions of kernel regressions in the presence of finite data sets.", "arxiv_id": "2408.07386v1", "pdf_url": "http://arxiv.org/pdf/2408.07386v1", "abstract_url": "http://arxiv.org/abs/2408.07386v1", "primary_category": "math.OC", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Fading memory and the convolution theorem", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:13.709736"}
{"title": "Posterior Covariance Structures in Gaussian Processes", "authors": "Difeng Cai, Edmond Chow, Yuanzhe Xi", "abstract": "In this paper, we present a comprehensive analysis of the posterior\ncovariance field in Gaussian processes, with applications to the posterior\ncovariance matrix. The analysis is based on the Gaussian prior covariance but\nthe approach also applies to other covariance kernels. Our geometric analysis\nreveals how the Gaussian kernel's bandwidth parameter and the spatial\ndistribution of the observations influence the posterior covariance as well as\nthe corresponding covariance matrix, enabling straightforward identification of\nareas with high or low covariance in magnitude. Drawing inspiration from the a\nposteriori error estimation techniques in adaptive finite element methods, we\nalso propose several estimators to efficiently measure the absolute posterior\ncovariance field, which can be used for efficient covariance matrix\napproximation and preconditioning. We conduct a wide range of experiments to\nillustrate our theoretical findings and their practical applications.", "arxiv_id": "2408.07379v1", "pdf_url": "http://arxiv.org/pdf/2408.07379v1", "abstract_url": "http://arxiv.org/abs/2408.07379v1", "primary_category": "stat.ML", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Posterior Covariance Structures in Gaussian Processes", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:15.046954"}
{"title": "Impact of Inaccurate Contamination Ratio on Robust Unsupervised Anomaly Detection", "authors": "Jordan F. Masakuna, DJeff Kanda Nkashama, Arian Soltani, Marc Frappier, Pierre-Martin Tardif, Froduald Kabanza", "abstract": "Training data sets intended for unsupervised anomaly detection, typically\npresumed to be anomaly-free, often contain anomalies (or contamination), a\nchallenge that significantly undermines model performance. Most robust\nunsupervised anomaly detection models rely on contamination ratio information\nto tackle contamination. However, in reality, contamination ratio may be\ninaccurate. We investigate on the impact of inaccurate contamination ratio\ninformation in robust unsupervised anomaly detection. We verify whether they\nare resilient to misinformed contamination ratios. Our investigation on 6\nbenchmark data sets reveals that such models are not adversely affected by\nexposure to misinformation. In fact, they can exhibit improved performance when\nprovided with such inaccurate contamination ratios.", "arxiv_id": "2408.07718v1", "pdf_url": "http://arxiv.org/pdf/2408.07718v1", "abstract_url": "http://arxiv.org/abs/2408.07718v1", "primary_category": "cs.LG", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Impact of Inaccurate Contamination Ratio on Robust Unsupervised Anomaly Detection", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:15.730819"}
{"title": "An Adaptive Importance Sampling for Locally Stable Point Processes", "authors": "Hee-Geon Kang, Sunggon Kim", "abstract": "The problem of finding the expected value of a statistic of a locally stable\npoint process in a bounded region is addressed. We propose an adaptive\nimportance sampling for solving the problem. In our proposal, we restrict the\nimportance point process to the family of homogeneous Poisson point processes,\nwhich enables us to generate quickly independent samples of the importance\npoint process. The optimal intensity of the importance point process is found\nby applying the cross-entropy minimization method. In the proposed scheme, the\nexpected value of the function and the optimal intensity are iteratively\nestimated in an adaptive manner. We show that the proposed estimator converges\nto the target value almost surely, and prove the asymptotic normality of it. We\nexplain how to apply the proposed scheme to the estimation of the intensity of\na stationary pairwise interaction point process. The performance of the\nproposed scheme is compared numerically with the Markov chain Monte Carlo\nsimulation and the perfect sampling.", "arxiv_id": "2408.07372v1", "pdf_url": "http://arxiv.org/pdf/2408.07372v1", "abstract_url": "http://arxiv.org/abs/2408.07372v1", "primary_category": "stat.ML", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "An Adaptive Importance Sampling for Locally Stable Point Processes", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:16.404809"}
{"title": "Robust Active Learning (RoAL): Countering Dynamic Adversaries in Active Learning with Elastic Weight Consolidation", "authors": "Ricky Maulana Fajri, Yulong Pei, Lu Yin, Mykola Pechenizkiy", "abstract": "Despite significant advancements in active learning and adversarial attacks,\nthe intersection of these two fields remains underexplored, particularly in\ndeveloping robust active learning frameworks against dynamic adversarial\nthreats. The challenge of developing robust active learning frameworks under\ndynamic adversarial attacks is critical, as these attacks can lead to\ncatastrophic forgetting within the active learning cycle. This paper introduces\nRobust Active Learning (RoAL), a novel approach designed to address this issue\nby integrating Elastic Weight Consolidation (EWC) into the active learning\nprocess. Our contributions are threefold: First, we propose a new dynamic\nadversarial attack that poses significant threats to active learning\nframeworks. Second, we introduce a novel method that combines EWC with active\nlearning to mitigate catastrophic forgetting caused by dynamic adversarial\nattacks. Finally, we conduct extensive experimental evaluations to demonstrate\nthe efficacy of our approach. The results show that RoAL not only effectively\ncounters dynamic adversarial threats but also significantly reduces the impact\nof catastrophic forgetting, thereby enhancing the robustness and performance of\nactive learning systems in adversarial environments.", "arxiv_id": "2408.07364v2", "pdf_url": "http://arxiv.org/pdf/2408.07364v2", "abstract_url": "http://arxiv.org/abs/2408.07364v2", "primary_category": "cs.LG", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Robust Active Learning (RoAL): Countering Dynamic Adversaries in Active Learning with Elastic Weight Consolidation", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:17.211549"}
{"title": "BadMerging: Backdoor Attacks Against Model Merging", "authors": "Jinghuai Zhang, Jianfeng Chi, Zheng Li, Kunlin Cai, Yang Zhang, Yuan Tian", "abstract": "Fine-tuning pre-trained models for downstream tasks has led to a\nproliferation of open-sourced task-specific models. Recently, Model Merging\n(MM) has emerged as an effective approach to facilitate knowledge transfer\namong these independently fine-tuned models. MM directly combines multiple\nfine-tuned task-specific models into a merged model without additional\ntraining, and the resulting model shows enhanced capabilities in multiple\ntasks. Although MM provides great utility, it may come with security risks\nbecause an adversary can exploit MM to affect multiple downstream tasks.\nHowever, the security risks of MM have barely been studied. In this paper, we\nfirst find that MM, as a new learning paradigm, introduces unique challenges\nfor existing backdoor attacks due to the merging process. To address these\nchallenges, we introduce BadMerging, the first backdoor attack specifically\ndesigned for MM. Notably, BadMerging allows an adversary to compromise the\nentire merged model by contributing as few as one backdoored task-specific\nmodel. BadMerging comprises a two-stage attack mechanism and a novel\nfeature-interpolation-based loss to enhance the robustness of embedded\nbackdoors against the changes of different merging parameters. Considering that\na merged model may incorporate tasks from different domains, BadMerging can\njointly compromise the tasks provided by the adversary (on-task attack) and\nother contributors (off-task attack) and solve the corresponding unique\nchallenges with novel attack designs. Extensive experiments show that\nBadMerging achieves remarkable attacks against various MM algorithms. Our\nablation study demonstrates that the proposed attack designs can progressively\ncontribute to the attack performance. Finally, we show that prior defense\nmechanisms fail to defend against our attacks, highlighting the need for more\nadvanced defense.", "arxiv_id": "2408.07362v1", "pdf_url": "http://arxiv.org/pdf/2408.07362v1", "abstract_url": "http://arxiv.org/abs/2408.07362v1", "primary_category": "cs.CR", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "BadMerging: Backdoor Attacks Against Model Merging", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:18.014236"}
{"title": "Towards Few-shot Self-explaining Graph Neural Networks", "authors": "Jingyu Peng, Qi Liu, Linan Yue, Zaixi Zhang, Kai Zhang, Yunhao Sha", "abstract": "Recent advancements in Graph Neural Networks (GNNs) have spurred an upsurge\nof research dedicated to enhancing the explainability of GNNs, particularly in\ncritical domains such as medicine. A promising approach is the self-explaining\nmethod, which outputs explanations along with predictions. However, existing\nself-explaining models require a large amount of training data, rendering them\nunavailable in few-shot scenarios. To address this challenge, in this paper, we\npropose a Meta-learned Self-Explaining GNN (MSE-GNN), a novel framework that\ngenerates explanations to support predictions in few-shot settings. MSE-GNN\nadopts a two-stage self-explaining structure, consisting of an explainer and a\npredictor. Specifically, the explainer first imitates the attention mechanism\nof humans to select the explanation subgraph, whereby attention is naturally\npaid to regions containing important characteristics. Subsequently, the\npredictor mimics the decision-making process, which makes predictions based on\nthe generated explanation. Moreover, with a novel meta-training process and a\ndesigned mechanism that exploits task information, MSE-GNN can achieve\nremarkable performance on new few-shot tasks. Extensive experimental results on\nfour datasets demonstrate that MSE-GNN can achieve superior performance on\nprediction tasks while generating high-quality explanations compared with\nexisting methods. The code is publicly available at\nhttps://github.com/jypeng28/MSE-GNN.", "arxiv_id": "2408.07340v1", "pdf_url": "http://arxiv.org/pdf/2408.07340v1", "abstract_url": "http://arxiv.org/abs/2408.07340v1", "primary_category": "cs.LG", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Towards Few-shot Self-explaining Graph Neural Networks", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:18.974365"}
{"title": "RSEA-MVGNN: Multi-View Graph Neural Network with Reliable Structural Enhancement and Aggregation", "authors": "Junyu Chen, Long Shi, Badong Chen", "abstract": "Graph Neural Networks (GNNs) have exhibited remarkable efficacy in learning\nfrom multi-view graph data. In the framework of multi-view graph neural\nnetworks, a critical challenge lies in effectively combining diverse views,\nwhere each view has distinct graph structure features (GSFs). Existing\napproaches to this challenge primarily focus on two aspects: 1) prioritizing\nthe most important GSFs, 2) utilizing GNNs for feature aggregation. However,\nprioritizing the most important GSFs can lead to limited feature diversity, and\nexisting GNN-based aggregation strategies equally treat each view without\nconsidering view quality. To address these issues, we propose a novel\nMulti-View Graph Neural Network with Reliable Structural Enhancement and\nAggregation (RSEA-MVGNN). Firstly, we estimate view-specific uncertainty\nemploying subjective logic. Based on this uncertainty, we design reliable\nstructural enhancement by feature de-correlation algorithm. This approach\nenables each enhancement to focus on different GSFs, thereby achieving diverse\nfeature representation in the enhanced structure. Secondly, the model learns\nview-specific beliefs and uncertainty as opinions, which are utilized to\nevaluate view quality. Based on these opinions, the model enables high-quality\nviews to dominate GNN aggregation, thereby facilitating representation\nlearning. Experimental results conducted on five real-world datasets\ndemonstrate that RSEA-MVGNN outperforms several state-of-the-art GNN-based\nmethods.", "arxiv_id": "2408.07331v1", "pdf_url": "http://arxiv.org/pdf/2408.07331v1", "abstract_url": "http://arxiv.org/abs/2408.07331v1", "primary_category": "cs.LG", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "RSEA-MVGNN: Multi-View Graph Neural Network with Reliable Structural Enhancement and Aggregation", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:19.754776"}
{"title": "An Offline Meta Black-box Optimization Framework for Adaptive Design of Urban Traffic Light Management Systems", "authors": "Taeyoung Yun, Kanghoon Lee, Sujin Yun, Ilmyung Kim, Won-Woo Jung, Min-Cheol Kwon, Kyujin Choi, Yoohyeon Lee, Jinkyoo Park", "abstract": "Complex urban road networks with high vehicle occupancy frequently face\nsevere traffic congestion. Designing an effective strategy for managing\nmultiple traffic lights plays a crucial role in managing congestion. However,\nmost current traffic light management systems rely on human-crafted decisions,\nwhich may not adapt well to diverse traffic patterns. In this paper, we delve\ninto two pivotal design components of the traffic light management system that\ncan be dynamically adjusted to various traffic conditions: phase combination\nand phase time allocation. While numerous studies have sought an efficient\nstrategy for managing traffic lights, most of these approaches consider a fixed\ntraffic pattern and are limited to relatively small road networks. To overcome\nthese limitations, we introduce a novel and practical framework to formulate\nthe optimization of such design components using an offline meta black-box\noptimization. We then present a simple yet effective method to efficiently find\na solution for the aforementioned problem. In our framework, we first collect\nan offline meta dataset consisting of pairs of design choices and corresponding\ncongestion measures from various traffic patterns. After collecting the\ndataset, we employ the Attentive Neural Process (ANP) to predict the impact of\nthe proposed design on congestion across various traffic patterns with\nwell-calibrated uncertainty. Finally, Bayesian optimization, with ANP as a\nsurrogate model, is utilized to find an optimal design for unseen traffic\npatterns through limited online simulations. Our experiment results show that\nour method outperforms state-of-the-art baselines on complex road networks in\nterms of the number of waiting vehicles. Surprisingly, the deployment of our\nmethod into a real-world traffic system was able to improve traffic throughput\nby 4.80\\% compared to the original strategy.", "arxiv_id": "2408.07327v1", "pdf_url": "http://arxiv.org/pdf/2408.07327v1", "abstract_url": "http://arxiv.org/abs/2408.07327v1", "primary_category": "cs.LG", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "An Offline Meta Black-box Optimization Framework for Adaptive Design of Urban Traffic Light Management Systems", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:20.576957"}
{"title": "A systematic dataset generation technique applied to data-driven automotive aerodynamics", "authors": "Mark Benjamin, Gianluca Iaccarino", "abstract": "A novel strategy for generating datasets is developed within the context of\ndrag prediction for automotive geometries using neural networks. A primary\nchallenge in this space is constructing a training databse of sufficient size\nand diversity. Our method relies on a small number of starting data points, and\nprovides a recipe to interpolate systematically between them, generating an\narbitrary number of samples at the desired quality. We test this strategy using\na realistic automotive geometry, and demonstrate that convolutional neural\nnetworks perform exceedingly well at predicting drag coefficients and surface\npressures. Promising results are obtained in testing extrapolation performance.\nOur method can be applied to other problems of aerodynamic shape optimization.", "arxiv_id": "2408.07318v1", "pdf_url": "http://arxiv.org/pdf/2408.07318v1", "abstract_url": "http://arxiv.org/abs/2408.07318v1", "primary_category": "cs.LG", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "A systematic dataset generation technique applied to data-driven automotive aerodynamics", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:21.803632"}
{"title": "Kolmogorov-Arnold Networks (KAN) for Time Series Classification and Robust Analysis", "authors": "Chang Dong, Liangwei Zheng, Weitong Chen", "abstract": "Kolmogorov-Arnold Networks (KAN) has recently attracted significant attention\nas a promising alternative to traditional Multi-Layer Perceptrons (MLP).\nDespite their theoretical appeal, KAN require validation on large-scale\nbenchmark datasets. Time series data, which has become increasingly prevalent\nin recent years, especially univariate time series are naturally suited for\nvalidating KAN. Therefore, we conducted a fair comparison among KAN, MLP, and\nmixed structures. The results indicate that KAN can achieve performance\ncomparable to, or even slightly better than, MLP across 128 time series\ndatasets. We also performed an ablation study on KAN, revealing that the output\nis primarily determined by the base component instead of b-spline function.\nFurthermore, we assessed the robustness of these models and found that KAN and\nthe hybrid structure MLP\\_KAN exhibit significant robustness advantages,\nattributed to their lower Lipschitz constants. This suggests that KAN and KAN\nlayers hold strong potential to be robust models or to improve the adversarial\nrobustness of other models.", "arxiv_id": "2408.07314v1", "pdf_url": "http://arxiv.org/pdf/2408.07314v1", "abstract_url": "http://arxiv.org/abs/2408.07314v1", "primary_category": "cs.LG", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Kolmogorov-Arnold Networks (KAN) for Time Series Classification and Robust Analysis", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:22.692773"}
{"title": "Nonlocal Attention Operator: Materializing Hidden Knowledge Towards Interpretable Physics Discovery", "authors": "Yue Yu, Ning Liu, Fei Lu, Tian Gao, Siavash Jafarzadeh, Stewart Silling", "abstract": "Despite the recent popularity of attention-based neural architectures in core\nAI fields like natural language processing (NLP) and computer vision (CV),\ntheir potential in modeling complex physical systems remains under-explored.\nLearning problems in physical systems are often characterized as discovering\noperators that map between function spaces based on a few instances of function\npairs. This task frequently presents a severely ill-posed PDE inverse problem.\nIn this work, we propose a novel neural operator architecture based on the\nattention mechanism, which we coin Nonlocal Attention Operator (NAO), and\nexplore its capability towards developing a foundation physical model. In\nparticular, we show that the attention mechanism is equivalent to a double\nintegral operator that enables nonlocal interactions among spatial tokens, with\na data-dependent kernel characterizing the inverse mapping from data to the\nhidden parameter field of the underlying operator. As such, the attention\nmechanism extracts global prior information from training data generated by\nmultiple systems, and suggests the exploratory space in the form of a nonlinear\nkernel map. Consequently, NAO can address ill-posedness and rank deficiency in\ninverse PDE problems by encoding regularization and achieving generalizability.\nWe empirically demonstrate the advantages of NAO over baseline neural models in\nterms of generalizability to unseen data resolutions and system states. Our\nwork not only suggests a novel neural operator architecture for learning\ninterpretable foundation models of physical systems, but also offers a new\nperspective towards understanding the attention mechanism.", "arxiv_id": "2408.07307v1", "pdf_url": "http://arxiv.org/pdf/2408.07307v1", "abstract_url": "http://arxiv.org/abs/2408.07307v1", "primary_category": "cs.LG", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Nonlocal Attention Operator: Materializing Hidden Knowledge Towards Interpretable Physics Discovery", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:23.368293"}
{"title": "Learning Decisions Offline from Censored Observations with \u03b5-insensitive Operational Costs", "authors": "Minxia Chen, Ke Fu, Teng Huang, Miao Bai", "abstract": "Many important managerial decisions are made based on censored observations.\nMaking decisions without adequately handling the censoring leads to inferior\noutcomes. We investigate the data-driven decision-making problem with an\noffline dataset containing the feature data and the censored historical data of\nthe variable of interest without the censoring indicators. Without assuming the\nunderlying distribution, we design and leverage {\\epsilon}-insensitive\noperational costs to deal with the unobserved censoring in an offline\ndata-driven fashion. We demonstrate the customization of the\n{\\epsilon}-insensitive operational costs for a newsvendor problem and use such\ncosts to train two representative ML models, including linear regression (LR)\nmodels and neural networks (NNs). We derive tight generalization bounds for the\ncustom LR model without regularization (LR-{\\epsilon}NVC) and with\nregularization (LR-{\\epsilon}NVC-R), and a high-probability generalization\nbound for the custom NN (NN-{\\epsilon}NVC) trained by stochastic gradient\ndescent. The theoretical results reveal the stability and learnability of\nLR-{\\epsilon}NVC, LR-{\\epsilon}NVC-R and NN-{\\epsilon}NVC. We conduct extensive\nnumerical experiments to compare LR-{\\epsilon}NVC-R and NN-{\\epsilon}NVC with\ntwo existing approaches, estimate-as-solution (EAS) and integrated estimation\nand optimization (IEO). The results show that LR-{\\epsilon}NVC-R and\nNN-{\\epsilon}NVC outperform both EAS and IEO, with maximum cost savings up to\n14.40% and 12.21% compared to the lowest cost generated by the two existing\napproaches. In addition, LR-{\\epsilon}NVC-R's and NN-{\\epsilon}NVC's order\nquantities are statistically significantly closer to the optimal solutions\nshould the underlying distribution be known.", "arxiv_id": "2408.07305v1", "pdf_url": "http://arxiv.org/pdf/2408.07305v1", "abstract_url": "http://arxiv.org/abs/2408.07305v1", "primary_category": "cs.LG", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Learning Decisions Offline from Censored Observations with \u03b5-insensitive Operational Costs", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:24.273467"}
{"title": "Enhancing Visual Question Answering through Ranking-Based Hybrid Training and Multimodal Fusion", "authors": "Peiyuan Chen, Zecheng Zhang, Yiping Dong, Li Zhou, Han Wang", "abstract": "Visual Question Answering (VQA) is a challenging task that requires systems\nto provide accurate answers to questions based on image content. Current VQA\nmodels struggle with complex questions due to limitations in capturing and\nintegrating multimodal information effectively. To address these challenges, we\npropose the Rank VQA model, which leverages a ranking-inspired hybrid training\nstrategy to enhance VQA performance. The Rank VQA model integrates high-quality\nvisual features extracted using the Faster R-CNN model and rich semantic text\nfeatures obtained from a pre-trained BERT model. These features are fused\nthrough a sophisticated multimodal fusion technique employing multi-head\nself-attention mechanisms. Additionally, a ranking learning module is\nincorporated to optimize the relative ranking of answers, thus improving answer\naccuracy. The hybrid training strategy combines classification and ranking\nlosses, enhancing the model's generalization ability and robustness across\ndiverse datasets. Experimental results demonstrate the effectiveness of the\nRank VQA model. Our model significantly outperforms existing state-of-the-art\nmodels on standard VQA datasets, including VQA v2.0 and COCO-QA, in terms of\nboth accuracy and Mean Reciprocal Rank (MRR). The superior performance of Rank\nVQA is evident in its ability to handle complex questions that require\nunderstanding nuanced details and making sophisticated inferences from the\nimage and text. This work highlights the effectiveness of a ranking-based\nhybrid training strategy in improving VQA performance and lays the groundwork\nfor further research in multimodal learning methods.", "arxiv_id": "2408.07303v1", "pdf_url": "http://arxiv.org/pdf/2408.07303v1", "abstract_url": "http://arxiv.org/abs/2408.07303v1", "primary_category": "cs.CV", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Enhancing Visual Question Answering through Ranking-Based Hybrid Training and Multimodal Fusion", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:25.034292"}
{"title": "LiPCoT: Linear Predictive Coding based Tokenizer for Self-supervised Learning of Time Series Data via Language Models", "authors": "Md Fahim Anjum", "abstract": "Language models have achieved remarkable success in various natural language\nprocessing tasks. However, their application to time series data, a crucial\ncomponent in many domains, remains limited. This paper proposes LiPCoT (Linear\nPredictive Coding based Tokenizer for time series), a novel tokenizer that\nencodes time series data into a sequence of tokens, enabling self-supervised\nlearning of time series using existing Language model architectures such as\nBERT. Unlike traditional time series tokenizers that rely heavily on CNN\nencoder for time series feature generation, LiPCoT employs stochastic modeling\nthrough linear predictive coding to create a latent space for time series\nproviding a compact yet rich representation of the inherent stochastic nature\nof the data. Furthermore, LiPCoT is computationally efficient and can\neffectively handle time series data with varying sampling rates and lengths,\novercoming common limitations of existing time series tokenizers. In this\nproof-of-concept work, we present the effectiveness of LiPCoT in classifying\nParkinson's disease (PD) using an EEG dataset from 46 participants. In\nparticular, we utilize LiPCoT to encode EEG data into a small vocabulary of\ntokens and then use BERT for self-supervised learning and the downstream task\nof PD classification. We benchmark our approach against several\nstate-of-the-art CNN-based deep learning architectures for PD detection. Our\nresults reveal that BERT models utilizing self-supervised learning outperformed\nthe best-performing existing method by 7.1% in precision, 2.3% in recall, 5.5%\nin accuracy, 4% in AUC, and 5% in F1-score highlighting the potential for\nself-supervised learning even on small datasets. Our work will inform future\nfoundational models for time series, particularly for self-supervised learning.", "arxiv_id": "2408.07292v1", "pdf_url": "http://arxiv.org/pdf/2408.07292v1", "abstract_url": "http://arxiv.org/abs/2408.07292v1", "primary_category": "cs.LG", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "LiPCoT: Linear Predictive Coding based Tokenizer for Self-supervised Learning of Time Series Data via Language Models", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:25.795368"}
{"title": "Ensemble architecture in polyp segmentation", "authors": "Hao-Yun Hsu, Yi-Ching Cheng, Guan-Hua Huang", "abstract": "In this research, we revisit the architecture of semantic segmentation and\nevaluate the models excelling in polyp segmentation. We introduce an integrated\nframework that harnesses the advantages of different models to attain an\noptimal outcome. More specifically, we fuse the learned features from\nconvolutional and transformer models for prediction, and we view this approach\nas an ensemble technique to enhance model performance. Our experiments on polyp\nsegmentation reveal that the proposed architecture surpasses other top models,\nexhibiting improved learning capacity and resilience. The code is available at\nhttps://github.com/HuangDLab/EnFormer.", "arxiv_id": "2408.07262v1", "pdf_url": "http://arxiv.org/pdf/2408.07262v1", "abstract_url": "http://arxiv.org/abs/2408.07262v1", "primary_category": "cs.CV", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "NOT_ENOUGH_RELATED"}
{"title": "Ensemble architecture in polyp segmentation", "response": "NOT_ENOUGH_RELATED", "timestamp": "2024-08-19T13:35:26.618162"}
{"title": "Learning Multi-Index Models with Neural Networks via Mean-Field Langevin Dynamics", "authors": "Alireza Mousavi-Hosseini, Denny Wu, Murat A. Erdogdu", "abstract": "We study the problem of learning multi-index models in high-dimensions using\na two-layer neural network trained with the mean-field Langevin algorithm.\nUnder mild distributional assumptions on the data, we characterize the\neffective dimension $d_{\\mathrm{eff}}$ that controls both sample and\ncomputational complexity by utilizing the adaptivity of neural networks to\nlatent low-dimensional structures. When the data exhibit such a structure,\n$d_{\\mathrm{eff}}$ can be significantly smaller than the ambient dimension. We\nprove that the sample complexity grows almost linearly with $d_{\\mathrm{eff}}$,\nbypassing the limitations of the information and generative exponents that\nappeared in recent analyses of gradient-based feature learning. On the other\nhand, the computational complexity may inevitably grow exponentially with\n$d_{\\mathrm{eff}}$ in the worst-case scenario. Motivated by improving\ncomputational complexity, we take the first steps towards polynomial time\nconvergence of the mean-field Langevin algorithm by investigating a setting\nwhere the weights are constrained to be on a compact manifold with positive\nRicci curvature, such as the hypersphere. There, we study assumptions under\nwhich polynomial time convergence is achievable, whereas similar assumptions in\nthe Euclidean setting lead to exponential time complexity.", "arxiv_id": "2408.07254v1", "pdf_url": "http://arxiv.org/pdf/2408.07254v1", "abstract_url": "http://arxiv.org/abs/2408.07254v1", "primary_category": "stat.ML", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Learning Multi-Index Models with Neural Networks via Mean-Field Langevin Dynamics", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:27.537407"}
{"title": "All-around Neural Collapse for Imbalanced Classification", "authors": "Enhao Zhang, Chaohua Li, Chuanxing Geng, Songcan Chen", "abstract": "Neural Collapse (NC) presents an elegant geometric structure that enables\nindividual activations (features), class means and classifier (weights) vectors\nto reach \\textit{optimal} inter-class separability during the terminal phase of\ntraining on a \\textit{balanced} dataset. Once shifted to imbalanced\nclassification, such an optimal structure of NC can be readily destroyed by the\nnotorious \\textit{minority collapse}, where the classifier vectors\ncorresponding to the minority classes are squeezed. In response, existing works\nendeavor to recover NC typically by optimizing classifiers. However, we\ndiscover that this squeezing phenomenon is not only confined to classifier\nvectors but also occurs with class means.\n  Consequently, reconstructing NC solely at the classifier aspect may be\nfutile, as the feature means remain compressed, leading to the violation of\ninherent \\textit{self-duality} in NC (\\textit{i.e.}, class means and classifier\nvectors converge mutually) and incidentally, resulting in an unsatisfactory\ncollapse of individual activations towards the corresponding class means. To\nshake off these dilemmas, we present a unified \\textbf{All}-around\n\\textbf{N}eural \\textbf{C}ollapse framework (AllNC), aiming to comprehensively\nrestore NC across multiple aspects including individual activations, class\nmeans and classifier vectors. We thoroughly analyze its effectiveness and\nverify on multiple benchmark datasets that it achieves state-of-the-art in both\nbalanced and imbalanced settings.", "arxiv_id": "2408.07253v1", "pdf_url": "http://arxiv.org/pdf/2408.07253v1", "abstract_url": "http://arxiv.org/abs/2408.07253v1", "primary_category": "cs.LG", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "All-around Neural Collapse for Imbalanced Classification", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:28.350889"}
{"title": "BiLSTM and Attention-Based Modulation Classification of Realistic Wireless Signals", "authors": "Rohit Udaiwal, Nayan Baishya, Yash Gupta, B. R. Manoj", "abstract": "This work proposes a novel and efficient quadstream BiLSTM-Attention network,\nabbreviated as QSLA network, for robust automatic modulation classification\n(AMC) of wireless signals. The proposed model exploits multiple representations\nof the wireless signal as inputs to the network and the feature extraction\nprocess combines convolutional and BiLSTM layers for processing the spatial and\ntemporal features of the signal, respectively. An attention layer is used after\nthe BiLSTM layer to emphasize the important temporal features. The experimental\nresults on the recent and realistic RML22 dataset demonstrate the superior\nperformance of the proposed model with an accuracy up to around 99%. The model\nis compared with other benchmark models in the literature in terms of\nclassification accuracy, computational complexity, memory usage, and training\ntime to show the effectiveness of our proposed approach.", "arxiv_id": "2408.07247v1", "pdf_url": "http://arxiv.org/pdf/2408.07247v1", "abstract_url": "http://arxiv.org/abs/2408.07247v1", "primary_category": "cs.LG", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "BiLSTM and Attention-Based Modulation Classification of Realistic Wireless Signals", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:29.043322"}
{"title": "ChemVLM: Exploring the Power of Multimodal Large Language Models in Chemistry Area", "authors": "Junxian Li, Di Zhang, Xunzhi Wang, Zeying Hao, Jingdi Lei, Qian Tan, Cai Zhou, Wei Liu, Yaotian Yang, Xinrui Xiong, Weiyun Wang, Zhe Chen, Wenhai Wang, Wei Li, Shufei Zhang, Mao Su, Wanli Ouyang, Yuqiang Li, Dongzhan Zhou", "abstract": "Large Language Models (LLMs) have achieved remarkable success and have been\napplied across various scientific fields, including chemistry. However, many\nchemical tasks require the processing of visual information, which cannot be\nsuccessfully handled by existing chemical LLMs. This brings a growing need for\nmodels capable of integrating multimodal information in the chemical domain. In\nthis paper, we introduce \\textbf{ChemVLM}, an open-source chemical multimodal\nlarge language model specifically designed for chemical applications. ChemVLM\nis trained on a carefully curated bilingual multimodal dataset that enhances\nits ability to understand both textual and visual chemical information,\nincluding molecular structures, reactions, and chemistry examination questions.\nWe develop three datasets for comprehensive evaluation, tailored to Chemical\nOptical Character Recognition (OCR), Multimodal Chemical Reasoning (MMCR), and\nMultimodal Molecule Understanding tasks. We benchmark ChemVLM against a range\nof open-source and proprietary multimodal large language models on various\ntasks. Experimental results demonstrate that ChemVLM achieves competitive\nperformance across all evaluated tasks. Our model can be found at\nhttps://huggingface.co/AI4Chem/ChemVLM-26B.", "arxiv_id": "2408.07246v2", "pdf_url": "http://arxiv.org/pdf/2408.07246v2", "abstract_url": "http://arxiv.org/abs/2408.07246v2", "primary_category": "cs.LG", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "ChemVLM: Exploring the Power of Multimodal Large Language Models in Chemistry Area", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:30.116551"}
{"title": "q-exponential family for policy optimization", "authors": "Lingwei Zhu, Haseeb Shah, Han Wang, Martha White", "abstract": "Policy optimization methods benefit from a simple and tractable policy\nfunctional, usually the Gaussian for continuous action spaces. In this paper,\nwe consider a broader policy family that remains tractable: the $q$-exponential\nfamily. This family of policies is flexible, allowing the specification of both\nheavy-tailed policies ($q>1$) and light-tailed policies ($q<1$). This paper\nexamines the interplay between $q$-exponential policies for several\nactor-critic algorithms conducted on both online and offline problems. We find\nthat heavy-tailed policies are more effective in general and can consistently\nimprove on Gaussian. In particular, we find the Student's t-distribution to be\nmore stable than the Gaussian across settings and that a heavy-tailed\n$q$-Gaussian for Tsallis Advantage Weighted Actor-Critic consistently performs\nwell in offline benchmark problems. Our code is available at\n\\url{https://github.com/lingweizhu/qexp}.", "arxiv_id": "2408.07245v1", "pdf_url": "http://arxiv.org/pdf/2408.07245v1", "abstract_url": "http://arxiv.org/abs/2408.07245v1", "primary_category": "cs.LG", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "q-exponential family for policy optimization", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:30.916139"}
{"title": "Enhancing Autonomous Vehicle Perception in Adverse Weather through Image Augmentation during Semantic Segmentation Training", "authors": "Ethan Kou, Noah Curran", "abstract": "Robust perception is crucial in autonomous vehicle navigation and\nlocalization. Visual processing tasks, like semantic segmentation, should work\nin varying weather conditions and during different times of day. Semantic\nsegmentation is where each pixel is assigned a class, which is useful for\nlocating overall features (1). Training a segmentation model requires large\namounts of data, and the labeling process for segmentation data is especially\ntedious. Additionally, many large datasets include only images taken in clear\nweather. This is a problem because training a model exclusively on clear\nweather data hinders performance in adverse weather conditions like fog or\nrain. We hypothesize that given a dataset of only clear days images, applying\nimage augmentation (such as random rain, fog, and brightness) during training\nallows for domain adaptation to diverse weather conditions. We used CARLA, a 3D\nrealistic autonomous vehicle simulator, to collect 1200 images in clear weather\ncomposed of 29 classes from 10 different towns (2). We also collected 1200\nimages of random weather effects. We trained encoder-decoder UNet models to\nperform semantic segmentation. Applying augmentations significantly improved\nsegmentation under weathered night conditions (p < 0.001). However, models\ntrained on weather data have significantly lower losses than those trained on\naugmented data in all conditions except for clear days. This shows there is\nroom for improvement in the domain adaptation approach. Future work should test\nmore types of augmentations and also use real-life images instead of CARLA.\nIdeally, the augmented model meets or exceeds the performance of the weather\nmodel.", "arxiv_id": "2408.07239v1", "pdf_url": "http://arxiv.org/pdf/2408.07239v1", "abstract_url": "http://arxiv.org/abs/2408.07239v1", "primary_category": "cs.CV", "published_date": "2024-08-14", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Enhancing Autonomous Vehicle Perception in Adverse Weather through Image Augmentation during Semantic Segmentation Training", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:31.739091"}
{"title": "Using Advanced LLMs to Enhance Smaller LLMs: An Interpretable Knowledge Distillation Approach", "authors": "Tong Wang, K. Sudhir, Dat Hong", "abstract": "Advanced Large language models (LLMs) like GPT-4 or LlaMa 3 provide superior\nperformance in complex human-like interactions. But they are costly, or too\nlarge for edge devices such as smartphones and harder to self-host, leading to\nsecurity and privacy concerns. This paper introduces a novel interpretable\nknowledge distillation approach to enhance the performance of smaller, more\neconomical LLMs that firms can self-host. We study this problem in the context\nof building a customer service agent aimed at achieving high customer\nsatisfaction through goal-oriented dialogues. Unlike traditional knowledge\ndistillation, where the \"student\" model learns directly from the \"teacher\"\nmodel's responses via fine-tuning, our interpretable \"strategy\" teaching\napproach involves the teacher providing strategies to improve the student's\nperformance in various scenarios. This method alternates between a \"scenario\ngeneration\" step and a \"strategies for improvement\" step, creating a customized\nlibrary of scenarios and optimized strategies for automated prompting. The\nmethod requires only black-box access to both student and teacher models; hence\nit can be used without manipulating model parameters. In our customer service\napplication, the method improves performance, and the learned strategies are\ntransferable to other LLMs and scenarios beyond the training set. The method's\ninterpretabilty helps safeguard against potential harms through human audit.", "arxiv_id": "2408.07238v1", "pdf_url": "http://arxiv.org/pdf/2408.07238v1", "abstract_url": "http://arxiv.org/abs/2408.07238v1", "primary_category": "cs.CL", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Using Advanced LLMs to Enhance Smaller LLMs: An Interpretable Knowledge Distillation Approach", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:32.658818"}
{"title": "Pan-cancer gene set discovery via scRNA-seq for optimal deep learning based downstream tasks", "authors": "Jong Hyun Kim, Jongseong Jang", "abstract": "The application of machine learning to transcriptomics data has led to\nsignificant advances in cancer research. However, the high dimensionality and\ncomplexity of RNA sequencing (RNA-seq) data pose significant challenges in\npan-cancer studies. This study hypothesizes that gene sets derived from\nsingle-cell RNA sequencing (scRNA-seq) data will outperform those selected\nusing bulk RNA-seq in pan-cancer downstream tasks. We analyzed scRNA-seq data\nfrom 181 tumor biopsies across 13 cancer types. High-dimensional weighted gene\nco-expression network analysis (hdWGCNA) was performed to identify relevant\ngene sets, which were further refined using XGBoost for feature selection.\nThese gene sets were applied to downstream tasks using TCGA pan-cancer RNA-seq\ndata and compared to six reference gene sets and oncogenes from OncoKB\nevaluated with deep learning models, including multilayer perceptrons (MLPs)\nand graph neural networks (GNNs). The XGBoost-refined hdWGCNA gene set\ndemonstrated higher performance in most tasks, including tumor mutation burden\nassessment, microsatellite instability classification, mutation prediction,\ncancer subtyping, and grading. In particular, genes such as DPM1, BAD, and\nFKBP4 emerged as important pan-cancer biomarkers, with DPM1 consistently\nsignificant across tasks. This study presents a robust approach for feature\nselection in cancer genomics by integrating scRNA-seq data and advanced\nanalysis techniques, offering a promising avenue for improving predictive\naccuracy in cancer research.", "arxiv_id": "2408.07233v1", "pdf_url": "http://arxiv.org/pdf/2408.07233v1", "abstract_url": "http://arxiv.org/abs/2408.07233v1", "primary_category": "q-bio.GN", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Pan-cancer gene set discovery via scRNA-seq for optimal deep learning based downstream tasks", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:33.476700"}
{"title": "An Introduction to Reinforcement Learning: Fundamental Concepts and Practical Applications", "authors": "Majid Ghasemi, Amir Hossein Moosavi, Ibrahim Sorkhoh, Anjali Agrawal, Fadi Alzhouri, Dariush Ebrahimi", "abstract": "Reinforcement Learning (RL) is a branch of Artificial Intelligence (AI) which\nfocuses on training agents to make decisions by interacting with their\nenvironment to maximize cumulative rewards. An overview of RL is provided in\nthis paper, which discusses its core concepts, methodologies, recent trends,\nand resources for learning. We provide a detailed explanation of key components\nof RL such as states, actions, policies, and reward signals so that the reader\ncan build a foundational understanding. The paper also provides examples of\nvarious RL algorithms, including model-free and model-based methods. In\naddition, RL algorithms are introduced and resources for learning and\nimplementing them are provided, such as books, courses, and online communities.\nThis paper demystifies a comprehensive yet simple introduction for beginners by\noffering a structured and clear pathway for acquiring and implementing\nreal-time techniques.", "arxiv_id": "2408.07712v1", "pdf_url": "http://arxiv.org/pdf/2408.07712v1", "abstract_url": "http://arxiv.org/abs/2408.07712v1", "primary_category": "cs.AI", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "An Introduction to Reinforcement Learning: Fundamental Concepts and Practical Applications", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:34.341514"}
{"title": "A Review of Pseudo-Labeling for Computer Vision", "authors": "Patrick Kage, Jay C. Rothenberger, Pavlos Andreadis, Dimitrios I. Diochnos", "abstract": "Deep neural models have achieved state of the art performance on a wide range\nof problems in computer science, especially in computer vision. However, deep\nneural networks often require large datasets of labeled samples to generalize\neffectively, and an important area of active research is semi-supervised\nlearning, which attempts to instead utilize large quantities of (easily\nacquired) unlabeled samples. One family of methods in this space is\npseudo-labeling, a class of algorithms that use model outputs to assign labels\nto unlabeled samples which are then used as labeled samples during training.\nSuch assigned labels, called pseudo-labels, are most commonly associated with\nthe field of semi-supervised learning. In this work we explore a broader\ninterpretation of pseudo-labels within both self-supervised and unsupervised\nmethods. By drawing the connection between these areas we identify new\ndirections when advancements in one area would likely benefit others, such as\ncurriculum learning and self-supervised regularization.", "arxiv_id": "2408.07221v1", "pdf_url": "http://arxiv.org/pdf/2408.07221v1", "abstract_url": "http://arxiv.org/abs/2408.07221v1", "primary_category": "cs.CV", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "A Review of Pseudo-Labeling for Computer Vision", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:35.331969"}
{"title": "Causal Effect Estimation using identifiable Variational AutoEncoder with Latent Confounders and Post-Treatment Variables", "authors": "Yang Xie, Ziqi Xu, Debo Cheng, Jiuyong Li, Lin Liu, Yinghao Zhang, Zaiwen Feng", "abstract": "Estimating causal effects from observational data is challenging, especially\nin the presence of latent confounders. Much work has been done on addressing\nthis challenge, but most of the existing research ignores the bias introduced\nby the post-treatment variables. In this paper, we propose a novel method of\njoint Variational AutoEncoder (VAE) and identifiable Variational AutoEncoder\n(iVAE) for learning the representations of latent confounders and latent\npost-treatment variables from their proxy variables, termed CPTiVAE, to achieve\nunbiased causal effect estimation from observational data. We further prove the\nidentifiability in terms of the representation of latent post-treatment\nvariables. Extensive experiments on synthetic and semi-synthetic datasets\ndemonstrate that the CPTiVAE outperforms the state-of-the-art methods in the\npresence of latent confounders and post-treatment variables. We further apply\nCPTiVAE to a real-world dataset to show its potential application.", "arxiv_id": "2408.07219v1", "pdf_url": "http://arxiv.org/pdf/2408.07219v1", "abstract_url": "http://arxiv.org/abs/2408.07219v1", "primary_category": "cs.LG", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Causal Effect Estimation using identifiable Variational AutoEncoder with Latent Confounders and Post-Treatment Variables", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:35.995150"}
{"title": "Deep Index Policy for Multi-Resource Restless Matching Bandit and Its Application in Multi-Channel Scheduling", "authors": "Nida Zamir, I-Hong Hou", "abstract": "Scheduling in multi-channel wireless communication system presents formidable\nchallenges in effectively allocating resources. To address these challenges, we\ninvestigate the multi-resource restless matching bandit (MR-RMB) model for\nheterogeneous resource systems with an objective of maximizing long-term\ndiscounted total rewards while respecting resource constraints. We have also\ngeneralized to applications beyond multi-channel wireless. We discuss the\nMax-Weight Index Matching algorithm, which optimizes resource allocation based\non learned partial indexes. We have derived the policy gradient theorem for\nindex learning. Our main contribution is the introduction of a new Deep Index\nPolicy (DIP), an online learning algorithm tailored for MR-RMB. DIP learns the\npartial index by leveraging the policy gradient theorem for restless arms with\nconvoluted and unknown transition kernels of heterogeneous resources. We\ndemonstrate the utility of DIP by evaluating its performance for three\ndifferent MR-RMB problems. Our simulation results show that DIP indeed learns\nthe partial indexes efficiently.", "arxiv_id": "2408.07205v1", "pdf_url": "http://arxiv.org/pdf/2408.07205v1", "abstract_url": "http://arxiv.org/abs/2408.07205v1", "primary_category": "cs.LG", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Deep Index Policy for Multi-Resource Restless Matching Bandit and Its Application in Multi-Channel Scheduling", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:37.559194"}
{"title": "Quantification of total uncertainty in the physics-informed reconstruction of CVSim-6 physiology", "authors": "Mario De Florio, Zongren Zou, Daniele E. Schiavazzi, George Em Karniadakis", "abstract": "When predicting physical phenomena through simulation, quantification of the\ntotal uncertainty due to multiple sources is as crucial as making sure the\nunderlying numerical model is accurate. Possible sources include irreducible\naleatoric uncertainty due to noise in the data, epistemic uncertainty induced\nby insufficient data or inadequate parameterization, and model-form uncertainty\nrelated to the use of misspecified model equations. Physics-based\nregularization interacts in nontrivial ways with aleatoric, epistemic and\nmodel-form uncertainty and their combination, and a better understanding of\nthis interaction is needed to improve the predictive performance of\nphysics-informed digital twins that operate under real conditions. With a\nspecific focus on biological and physiological models, this study investigates\nthe decomposition of total uncertainty in the estimation of states and\nparameters of a differential system simulated with MC X-TFC, a new\nphysics-informed approach for uncertainty quantification based on random\nprojections and Monte-Carlo sampling. MC X-TFC is applied to a six-compartment\nstiff ODE system, the CVSim-6 model, developed in the context of human\nphysiology. The system is analyzed by progressively removing data while\nestimating an increasing number of parameters and by investigating total\nuncertainty under model-form misspecification of non-linear resistance in the\npulmonary compartment. In particular, we focus on the interaction between the\nformulation of the discrepancy term and quantification of model-form\nuncertainty, and show how additional physics can help in the estimation\nprocess. The method demonstrates robustness and efficiency in estimating\nunknown states and parameters, even with limited, sparse, and noisy data. It\nalso offers great flexibility in integrating data with physics for improved\nestimation, even in cases of model misspecification.", "arxiv_id": "2408.07201v1", "pdf_url": "http://arxiv.org/pdf/2408.07201v1", "abstract_url": "http://arxiv.org/abs/2408.07201v1", "primary_category": "cs.LG", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Quantification of total uncertainty in the physics-informed reconstruction of CVSim-6 physiology", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:38.331013"}
{"title": "Agent Q: Advanced Reasoning and Learning for Autonomous AI Agents", "authors": "Pranav Putta, Edmund Mills, Naman Garg, Sumeet Motwani, Chelsea Finn, Divyansh Garg, Rafael Rafailov", "abstract": "Large Language Models (LLMs) have shown remarkable capabilities in natural\nlanguage tasks requiring complex reasoning, yet their application in agentic,\nmulti-step reasoning within interactive environments remains a difficult\nchallenge. Traditional supervised pre-training on static datasets falls short\nin enabling autonomous agent capabilities needed to perform complex\ndecision-making in dynamic settings like web navigation. Previous attempts to\nbridge this ga-through supervised fine-tuning on curated expert\ndemonstrations-often suffer from compounding errors and limited exploration\ndata, resulting in sub-optimal policy outcomes. To overcome these challenges,\nwe propose a framework that combines guided Monte Carlo Tree Search (MCTS)\nsearch with a self-critique mechanism and iterative fine-tuning on agent\ninteractions using an off-policy variant of the Direct Preference Optimization\n(DPO) algorithm. Our method allows LLM agents to learn effectively from both\nsuccessful and unsuccessful trajectories, thereby improving their\ngeneralization in complex, multi-step reasoning tasks. We validate our approach\nin the WebShop environment-a simulated e-commerce platform where it\nconsistently outperforms behavior cloning and reinforced fine-tuning baseline,\nand beats average human performance when equipped with the capability to do\nonline search. In real-world booking scenarios, our methodology boosts Llama-3\n70B model's zero-shot performance from 18.6% to 81.7% success rate (a 340%\nrelative increase) after a single day of data collection and further to 95.4%\nwith online search. We believe this represents a substantial leap forward in\nthe capabilities of autonomous agents, paving the way for more sophisticated\nand reliable decision-making in real-world settings.", "arxiv_id": "2408.07199v1", "pdf_url": "http://arxiv.org/pdf/2408.07199v1", "abstract_url": "http://arxiv.org/abs/2408.07199v1", "primary_category": "cs.AI", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Agent Q: Advanced Reasoning and Learning for Autonomous AI Agents", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:39.211284"}
{"title": "Massive Dimensions Reduction and Hybridization with Meta-heuristics in Deep Learning", "authors": "Rasa Khosrowshahli, Shahryar Rahnamayan, Beatrice Ombuki-Berman", "abstract": "Deep learning is mainly based on utilizing gradient-based optimization for\ntraining Deep Neural Network (DNN) models. Although robust and widely used,\ngradient-based optimization algorithms are prone to getting stuck in local\nminima. In this modern deep learning era, the state-of-the-art DNN models have\nmillions and billions of parameters, including weights and biases, making them\nhuge-scale optimization problems in terms of search space. Tuning a huge number\nof parameters is a challenging task that causes vanishing/exploding gradients\nand overfitting; likewise, utilized loss functions do not exactly represent our\ntargeted performance metrics. A practical solution to exploring large and\ncomplex solution space is meta-heuristic algorithms. Since DNNs exceed\nthousands and millions of parameters, even robust meta-heuristic algorithms,\nsuch as Differential Evolution, struggle to efficiently explore and converge in\nsuch huge-dimensional search spaces, leading to very slow convergence and high\nmemory demand. To tackle the mentioned curse of dimensionality, the concept of\nblocking was recently proposed as a technique that reduces the search space\ndimensions by grouping them into blocks. In this study, we aim to introduce\nHistogram-based Blocking Differential Evolution (HBDE), a novel approach that\nhybridizes gradient-based and gradient-free algorithms to optimize parameters.\nExperimental results demonstrated that the HBDE could reduce the parameters in\nthe ResNet-18 model from 11M to 3K during the training/optimizing phase by\nmetaheuristics, namely, the proposed HBDE, which outperforms baseline\ngradient-based and parent gradient-free DE algorithms evaluated on CIFAR-10 and\nCIFAR-100 datasets showcasing its effectiveness with reduced computational\ndemands for the very first time.", "arxiv_id": "2408.07194v1", "pdf_url": "http://arxiv.org/pdf/2408.07194v1", "abstract_url": "http://arxiv.org/abs/2408.07194v1", "primary_category": "cs.NE", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Massive Dimensions Reduction and Hybridization with Meta-heuristics in Deep Learning", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:40.237454"}
{"title": "Solving Truly Massive Budgeted Monotonic POMDPs with Oracle-Guided Meta-Reinforcement Learning", "authors": "Manav Vora, Michael N Grussing, Melkior Ornik", "abstract": "Monotonic Partially Observable Markov Decision Processes (POMDPs), where the\nsystem state progressively decreases until a restorative action is performed,\ncan be used to model sequential repair problems effectively. This paper\nconsiders the problem of solving budget-constrained multi-component monotonic\nPOMDPs, where a finite budget limits the maximal number of restorative actions.\nFor a large number of components, solving such a POMDP using current methods is\ncomputationally intractable due to the exponential growth in the state space\nwith an increasing number of components. To address this challenge, we propose\na two-step approach. Since the individual components of a budget-constrained\nmulti-component monotonic POMDP are only connected via the shared budget, we\nfirst approximate the optimal budget allocation among these components using an\napproximation of each component POMDP's optimal value function which is\nobtained through a random forest model. Subsequently, we introduce an\noracle-guided meta-trained Proximal Policy Optimization (PPO) algorithm to\nsolve each of the independent budget-constrained single-component monotonic\nPOMDPs. The oracle policy is obtained by performing value iteration on the\ncorresponding monotonic Markov Decision Process (MDP). This two-step method\nprovides scalability in solving truly massive multi-component monotonic POMDPs.\nTo demonstrate the efficacy of our approach, we consider a real-world\nmaintenance scenario that involves inspection and repair of an administrative\nbuilding by a team of agents within a maintenance budget. Finally, we perform a\ncomputational complexity analysis for a varying number of components to show\nthe scalability of the proposed approach.", "arxiv_id": "2408.07192v1", "pdf_url": "http://arxiv.org/pdf/2408.07192v1", "abstract_url": "http://arxiv.org/abs/2408.07192v1", "primary_category": "cs.LG", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Solving Truly Massive Budgeted Monotonic POMDPs with Oracle-Guided Meta-Reinforcement Learning", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:41.052980"}
{"title": "Joint Graph Rewiring and Feature Denoising via Spectral Resonance", "authors": "Jonas Linkerh\u00e4gner, Cheng Shi, Ivan Dokmani\u0107", "abstract": "Graph neural networks (GNNs) take as input the graph structure and the\nfeature vectors associated with the nodes. Both contain noisy information about\nthe labels. Here we propose joint denoising and rewiring (JDR)--an algorithm to\njointly denoise the graph structure and features, which can improve the\nperformance of any downstream algorithm. We do this by defining and maximizing\nthe alignment between the leading eigenspaces of graph and feature matrices. To\napproximately solve this computationally hard problem, we propose a heuristic\nthat efficiently handles real-world graph datasets with many classes and\ndifferent levels of homophily or heterophily. We experimentally verify the\neffectiveness of our approach on synthetic data and real-world graph datasets.\nThe results show that JDR consistently outperforms existing rewiring methods on\nnode classification tasks using GNNs as downstream models.", "arxiv_id": "2408.07191v1", "pdf_url": "http://arxiv.org/pdf/2408.07191v1", "abstract_url": "http://arxiv.org/abs/2408.07191v1", "primary_category": "cs.LG", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Joint Graph Rewiring and Feature Denoising via Spectral Resonance", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:41.871100"}
{"title": "VulCatch: Enhancing Binary Vulnerability Detection through CodeT5 Decompilation and KAN Advanced Feature Extraction", "authors": "Abdulrahman Hamman Adama Chukkol, Senlin Luo, Kashif Sharif, Yunusa Haruna, Muhammad Muhammad Abdullahi", "abstract": "Binary program vulnerability detection is critical for software security, yet\nexisting deep learning approaches often rely on source code analysis, limiting\ntheir ability to detect unknown vulnerabilities. To address this, we propose\nVulCatch, a binary-level vulnerability detection framework. VulCatch introduces\na Synergy Decompilation Module (SDM) and Kolmogorov-Arnold Networks (KAN) to\ntransform raw binary code into pseudocode using CodeT5, preserving high-level\nsemantics for deep analysis with tools like Ghidra and IDA. KAN further\nenhances feature transformation, enabling the detection of complex\nvulnerabilities. VulCatch employs word2vec, Inception Blocks, BiLSTM Attention,\nand Residual connections to achieve high detection accuracy (98.88%) and\nprecision (97.92%), while minimizing false positives (1.56%) and false\nnegatives (2.71%) across seven CVE datasets.", "arxiv_id": "2408.07181v1", "pdf_url": "http://arxiv.org/pdf/2408.07181v1", "abstract_url": "http://arxiv.org/abs/2408.07181v1", "primary_category": "cs.CR", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "VulCatch: Enhancing Binary Vulnerability Detection through CodeT5 Decompilation and KAN Advanced Feature Extraction", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:42.522896"}
{"title": "A POD-TANN approach for the multiscale modeling of materials and macroelement derivation in geomechanics", "authors": "Giovanni Piunno, Ioannis Stefanou, Cristina Jommi", "abstract": "This paper introduces a novel approach that combines Proper Orthogonal\nDecomposition (POD) with Thermodynamics-based Artificial Neural Networks (TANN)\nto capture the macroscopic behavior of complex inelastic systems and derive\nmacroelements in geomechanics. The methodology leverages POD to extract\nmacroscopic Internal State Variables (ISVs) from microscopic state information,\nthereby enriching the macroscopic state description used to train an energy\npotential network within the TANN framework. The thermodynamic consistency\nprovided by TANN, combined with the hierarchical nature of POD, allows for\naccurate modeling of complex, non-linear material behavior and reliable\nmacroscopic geomechanical systems responses. The effectiveness of this approach\nis validated through applications of increasing complexity, demonstrating its\ncapability to handle various material behaviors and microstructural topologies.\nThese applications include the homogenization of continuous inelastic\nrepresentative unit cells (RUCs) and the derivation of a macroelement for a\ngeotechnical system involving a monopile in a clay layer subjected to\nhorizontal loading. The results indicate that the proposed POD-TANN methodology\nnot only achieves high accuracy in reproducing stress-strain responses, but\nalso significantly reduces computational costs, making it a practical tool for\nthe multiscale modeling of heterogeneous inelastic systems, and the efficient\nderivation of macroelements for complex geomechanical problems.", "arxiv_id": "2408.07165v1", "pdf_url": "http://arxiv.org/pdf/2408.07165v1", "abstract_url": "http://arxiv.org/abs/2408.07165v1", "primary_category": "cs.LG", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "A POD-TANN approach for the multiscale modeling of materials and macroelement derivation in geomechanics", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:43.206848"}
{"title": "Integration of Genetic Algorithms and Deep Learning for the Generation and Bioactivity Prediction of Novel Tyrosine Kinase Inhibitors", "authors": "Ricardo Romero", "abstract": "The intersection of artificial intelligence and bioinformatics has enabled\nsignificant advancements in drug discovery, particularly through the\napplication of machine learning models. In this study, we present a combined\napproach using genetic algorithms and deep learning models to address two\ncritical aspects of drug discovery: the generation of novel tyrosine kinase\ninhibitors and the prediction of their bioactivity. The generative model\nleverages genetic algorithms to create new small molecules with optimized ADMET\n(absorption, distribution, metabolism, excretion, and toxicity) and\ndrug-likeness properties. Concurrently, a deep learning model is employed to\npredict the bioactivity of these generated molecules against tyrosine kinases,\na key enzyme family involved in various cellular processes and cancer\nprogression. By integrating these advanced computational methods, we\ndemonstrate a powerful framework for accelerating the generation and\nidentification of potential tyrosine kinase inhibitors, contributing to more\nefficient and effective early-stage drug discovery processes.", "arxiv_id": "2408.07155v1", "pdf_url": "http://arxiv.org/pdf/2408.07155v1", "abstract_url": "http://arxiv.org/abs/2408.07155v1", "primary_category": "q-bio.BM", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Integration of Genetic Algorithms and Deep Learning for the Generation and Bioactivity Prediction of Novel Tyrosine Kinase Inhibitors", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:44.033256"}
{"title": "Alpha-Trimming: Locally Adaptive Tree Pruning for Random Forests", "authors": "Nikola Surjanovic, Andrew Henrey, Thomas M. Loughin", "abstract": "We demonstrate that adaptively controlling the size of individual regression\ntrees in a random forest can improve predictive performance, contrary to the\nconventional wisdom that trees should be fully grown. A fast pruning algorithm,\nalpha-trimming, is proposed as an effective approach to pruning trees within a\nrandom forest, where more aggressive pruning is performed in regions with a low\nsignal-to-noise ratio. The amount of overall pruning is controlled by adjusting\nthe weight on an information criterion penalty as a tuning parameter, with the\nstandard random forest being a special case of our alpha-trimmed random forest.\nA remarkable feature of alpha-trimming is that its tuning parameter can be\nadjusted without refitting the trees in the random forest once the trees have\nbeen fully grown once. In a benchmark suite of 46 example data sets, mean\nsquared prediction error is often substantially lowered by using our pruning\nalgorithm and is never substantially increased compared to a random forest with\nfully-grown trees at default parameter settings.", "arxiv_id": "2408.07151v1", "pdf_url": "http://arxiv.org/pdf/2408.07151v1", "abstract_url": "http://arxiv.org/abs/2408.07151v1", "primary_category": "stat.ML", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Alpha-Trimming: Locally Adaptive Tree Pruning for Random Forests", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:44.840484"}
{"title": "Approaches for enhancing extrapolability in process-based and data-driven models in hydrology", "authors": "Haiyang Shi", "abstract": "The application of process-based and data-driven hydrological models is\ncrucial in modern hydrological research, especially for predicting key water\ncycle variables such as runoff, evapotranspiration (ET), and soil moisture.\nThese models provide a scientific basis for water resource management, flood\nforecasting, and ecological protection. Process-based models simulate the\nphysical mechanisms of watershed hydrological processes, while data-driven\nmodels leverage large datasets and advanced machine learning algorithms. This\npaper reviewed and compared methods for assessing and enhancing the\nextrapolability of both model types, discussing their prospects and\nlimitations. Key strategies include the use of leave-one-out cross-validation\nand similarity-based methods to evaluate model performance in ungauged regions.\nDeep learning, transfer learning, and domain adaptation techniques are also\npromising in their potential to improve model predictions in data-sparse and\nextreme conditions. Interdisciplinary collaboration and continuous algorithmic\nadvancements are also important to strengthen the global applicability and\nreliability of hydrological models.", "arxiv_id": "2408.07071v1", "pdf_url": "http://arxiv.org/pdf/2408.07071v1", "abstract_url": "http://arxiv.org/abs/2408.07071v1", "primary_category": "physics.geo-ph", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Approaches for enhancing extrapolability in process-based and data-driven models in hydrology", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:45.481391"}
{"title": "Diversity Empowers Intelligence: Integrating Expertise of Software Engineering Agents", "authors": "Kexun Zhang, Weiran Yao, Zuxin Liu, Yihao Feng, Zhiwei Liu, Rithesh Murthy, Tian Lan, Lei Li, Renze Lou, Jiacheng Xu, Bo Pang, Yingbo Zhou, Shelby Heinecke, Silvio Savarese, Huan Wang, Caiming Xiong", "abstract": "Large language model (LLM) agents have shown great potential in solving\nreal-world software engineering (SWE) problems. The most advanced open-source\nSWE agent can resolve over 27% of real GitHub issues in SWE-Bench Lite.\nHowever, these sophisticated agent frameworks exhibit varying strengths,\nexcelling in certain tasks while underperforming in others. To fully harness\nthe diversity of these agents, we propose DEI (Diversity Empowered\nIntelligence), a framework that leverages their unique expertise. DEI functions\nas a meta-module atop existing SWE agent frameworks, managing agent collectives\nfor enhanced problem-solving. Experimental results show that a DEI-guided\ncommittee of agents is able to surpass the best individual agent's performance\nby a large margin. For instance, a group of open-source SWE agents, with a\nmaximum individual resolve rate of 27.3% on SWE-Bench Lite, can achieve a 34.3%\nresolve rate with DEI, making a 25% improvement and beating most closed-source\nsolutions. Our best-performing group excels with a 55% resolve rate, securing\nthe highest ranking on SWE-Bench Lite. Our findings contribute to the growing\nbody of research on collaborative AI systems and their potential to solve\ncomplex software engineering challenges.", "arxiv_id": "2408.07060v1", "pdf_url": "http://arxiv.org/pdf/2408.07060v1", "abstract_url": "http://arxiv.org/abs/2408.07060v1", "primary_category": "cs.SE", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Diversity Empowers Intelligence: Integrating Expertise of Software Engineering Agents", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:46.402283"}
{"title": "A Survey on Model MoErging: Recycling and Routing Among Specialized Experts for Collaborative Learning", "authors": "Prateek Yadav, Colin Raffel, Mohammed Muqeeth, Lucas Caccia, Haokun Liu, Tianlong Chen, Mohit Bansal, Leshem Choshen, Alessandro Sordoni", "abstract": "The availability of performant pre-trained models has led to a proliferation\nof fine-tuned expert models that are specialized to a particular domain or\ntask. Model MoErging methods aim to recycle expert models to create an\naggregate system with improved performance or generalization. A key component\nof MoErging methods is the creation of a router that decides which expert\nmodel(s) to use for a particular input or application. The promise,\neffectiveness, and large design space of MoErging has spurred the development\nof many new methods over the past few years. This rapid pace of development has\nmade it challenging to compare different MoErging methods, which are rarely\ncompared to one another and are often validated in different experimental\nsetups. To remedy such gaps, we present a comprehensive survey of MoErging\nmethods that includes a novel taxonomy for cataloging key design choices and\nclarifying suitable applications for each method. Apart from surveying MoErging\nresearch, we inventory software tools and applications that make use of\nMoErging. We additionally discuss related fields of study such as model\nmerging, multitask learning, and mixture-of-experts models. Taken as a whole,\nour survey provides a unified overview of existing MoErging methods and creates\na solid foundation for future work in this burgeoning field.", "arxiv_id": "2408.07057v1", "pdf_url": "http://arxiv.org/pdf/2408.07057v1", "abstract_url": "http://arxiv.org/abs/2408.07057v1", "primary_category": "cs.LG", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "A Survey on Model MoErging: Recycling and Routing Among Specialized Experts for Collaborative Learning", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:47.199006"}
{"title": "LongWriter: Unleashing 10,000+ Word Generation from Long Context LLMs", "authors": "Yushi Bai, Jiajie Zhang, Xin Lv, Linzhi Zheng, Siqi Zhu, Lei Hou, Yuxiao Dong, Jie Tang, Juanzi Li", "abstract": "Current long context large language models (LLMs) can process inputs up to\n100,000 tokens, yet struggle to generate outputs exceeding even a modest length\nof 2,000 words. Through controlled experiments, we find that the model's\neffective generation length is inherently bounded by the sample it has seen\nduring supervised fine-tuning (SFT). In other words, their output limitation is\ndue to the scarcity of long-output examples in existing SFT datasets. To\naddress this, we introduce AgentWrite, an agent-based pipeline that decomposes\nultra-long generation tasks into subtasks, enabling off-the-shelf LLMs to\ngenerate coherent outputs exceeding 20,000 words. Leveraging AgentWrite, we\nconstruct LongWriter-6k, a dataset containing 6,000 SFT data with output\nlengths ranging from 2k to 32k words. By incorporating this dataset into model\ntraining, we successfully scale the output length of existing models to over\n10,000 words while maintaining output quality. We also develop LongBench-Write,\na comprehensive benchmark for evaluating ultra-long generation capabilities.\nOur 9B parameter model, further improved through DPO, achieves state-of-the-art\nperformance on this benchmark, surpassing even much larger proprietary models.\nIn general, our work demonstrates that existing long context LLM already\npossesses the potential for a larger output window--all you need is data with\nextended output during model alignment to unlock this capability. Our code &\nmodels are at: https://github.com/THUDM/LongWriter.", "arxiv_id": "2408.07055v1", "pdf_url": "http://arxiv.org/pdf/2408.07055v1", "abstract_url": "http://arxiv.org/abs/2408.07055v1", "primary_category": "cs.CL", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "LongWriter: Unleashing 10,000+ Word Generation from Long Context LLMs", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:48.018568"}
{"title": "TableGuard -- Securing Structured & Unstructured Data", "authors": "Anantha Sharma, Ajinkya Deshmukh", "abstract": "With the increasing demand for data sharing across platforms and\norganizations, ensuring the privacy and security of sensitive information has\nbecome a critical challenge. This paper introduces \"TableGuard\". An innovative\napproach to data obfuscation tailored for relational databases. Building on the\nprinciples and techniques developed in prior work on context-sensitive\nobfuscation, TableGuard applies these methods to ensure that API calls return\nonly obfuscated data, thereby safeguarding privacy when sharing data with third\nparties. TableGuard leverages advanced context-sensitive obfuscation techniques\nto replace sensitive data elements with contextually appropriate alternatives.\nBy maintaining the relational integrity and coherence of the data, our approach\nmitigates the risks of cognitive dissonance and data leakage. We demonstrate\nthe implementation of TableGuard using a BERT based transformer model, which\nidentifies and obfuscates sensitive entities within relational tables. Our\nevaluation shows that TableGuard effectively balances privacy protection with\ndata utility, minimizing information loss while ensuring that the obfuscated\ndata remains functionally useful for downstream applications. The results\nhighlight the importance of domain-specific obfuscation strategies and the role\nof context length in preserving data integrity. The implications of this\nresearch are significant for organizations that need to share data securely\nwith external parties. TableGuard offers a robust framework for implementing\nprivacy-preserving data sharing mechanisms, thereby contributing to the broader\nfield of data privacy and security.", "arxiv_id": "2408.07045v1", "pdf_url": "http://arxiv.org/pdf/2408.07045v1", "abstract_url": "http://arxiv.org/abs/2408.07045v1", "primary_category": "cs.CR", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "TableGuard -- Securing Structured & Unstructured Data", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:50.782311"}
{"title": "Investigation of unsupervised and supervised hyperspectral anomaly detection", "authors": "Mazharul Hossain, Aaron Robinson, Lan Wang, Chrysanthe Preza", "abstract": "Hyperspectral sensing is a valuable tool for detecting anomalies and\ndistinguishing between materials in a scene. Hyperspectral anomaly detection\n(HS-AD) helps characterize the captured scenes and separates them into anomaly\nand background classes. It is vital in agriculture, environment, and military\napplications such as RSTA (reconnaissance, surveillance, and target\nacquisition) missions. We previously designed an equal voting ensemble of\nhyperspectral unmixing and three unsupervised HS-AD algorithms. We later\nutilized a supervised classifier to determine the weights of a voting ensemble,\ncreating a hybrid of heterogeneous unsupervised HS-AD algorithms with a\nsupervised classifier in a model stacking, which improved detection accuracy.\nHowever, supervised classification methods usually fail to detect novel or\nunknown patterns that substantially deviate from those seen previously. In this\nwork, we evaluate our technique and other supervised and unsupervised methods\nusing general hyperspectral data to provide new insights.", "arxiv_id": "2408.07114v1", "pdf_url": "http://arxiv.org/pdf/2408.07114v1", "abstract_url": "http://arxiv.org/abs/2408.07114v1", "primary_category": "eess.IV", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Investigation of unsupervised and supervised hyperspectral anomaly detection", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:51.908653"}
{"title": "Defining and Measuring Disentanglement for non-Independent Factors of Variation", "authors": "Antonio Almud\u00e9var, Alfonso Ortega, Luis Vicente, Antonio Miguel, Eduardo Lleida", "abstract": "Representation learning is an approach that allows to discover and extract\nthe factors of variation from the data. Intuitively, a representation is said\nto be disentangled if it separates the different factors of variation in a way\nthat is understandable to humans. Definitions of disentanglement and metrics to\nmeasure it usually assume that the factors of variation are independent of each\nother. However, this is generally false in the real world, which limits the use\nof these definitions and metrics to very specific and unrealistic scenarios. In\nthis paper we give a definition of disentanglement based on information theory\nthat is also valid when the factors of variation are not independent.\nFurthermore, we relate this definition to the Information Bottleneck Method.\nFinally, we propose a method to measure the degree of disentanglement from the\ngiven definition that works when the factors of variation are not independent.\nWe show through different experiments that the method proposed in this paper\ncorrectly measures disentanglement with non-independent factors of variation,\nwhile other methods fail in this scenario.", "arxiv_id": "2408.07016v1", "pdf_url": "http://arxiv.org/pdf/2408.07016v1", "abstract_url": "http://arxiv.org/abs/2408.07016v1", "primary_category": "cs.LG", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Defining and Measuring Disentanglement for non-Independent Factors of Variation", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:52.625620"}
{"title": "Faster Private Minimum Spanning Trees", "authors": "Rasmus Pagh, Lukas Retschmeier", "abstract": "Motivated by applications in clustering and synthetic data generation, we\nconsider the problem of releasing a minimum spanning tree (MST) under\nedge-weight differential privacy constraints where a graph topology $G=(V,E)$\nwith $n$ vertices and $m$ edges is public, the weight matrix $\\vec{W}\\in\n\\mathbb{R}^{n \\times n}$ is private, and we wish to release an approximate MST\nunder $\\rho$-zero-concentrated differential privacy. Weight matrices are\nconsidered neighboring if they differ by at most $\\Delta_\\infty$ in each entry,\ni.e., we consider an $\\ell_\\infty$ neighboring relationship. Existing private\nMST algorithms either add noise to each entry in $\\vec{W}$ and estimate the MST\nby post-processing or add noise to weights in-place during the execution of a\nspecific MST algorithm. Using the post-processing approach with an efficient\nMST algorithm takes $O(n^2)$ time on dense graphs but results in an additive\nerror on the weight of the MST of magnitude $O(n^2\\log n)$. In-place algorithms\ngive asymptotically better utility, but the running time of existing in-place\nalgorithms is $O(n^3)$ for dense graphs. Our main result is a new\ndifferentially private MST algorithm that matches the utility of existing\nin-place methods while running in time $O(m + n^{3/2}\\log n)$ for fixed privacy\nparameter $\\rho$. The technical core of our algorithm is an efficient sublinear\ntime simulation of Report-Noisy-Max that works by discretizing all edge weights\nto a multiple of $\\Delta_\\infty$ and forming groups of edges with identical\nweights. Specifically, we present a data structure that allows us to sample a\nnoisy minimum weight edge among at most $O(n^2)$ cut edges in $O(\\sqrt{n} \\log\nn)$ time. Experimental evaluations support our claims that our algorithm\nsignificantly improves previous algorithms either in utility or running time.", "arxiv_id": "2408.06997v1", "pdf_url": "http://arxiv.org/pdf/2408.06997v1", "abstract_url": "http://arxiv.org/abs/2408.06997v1", "primary_category": "cs.DS", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Faster Private Minimum Spanning Trees", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:53.448123"}
{"title": "Blessing of Dimensionality for Approximating Sobolev Classes on Manifolds", "authors": "Hong Ye Tan, Subhadip Mukherjee, Junqi Tang, Carola-Bibiane Sch\u00f6nlieb", "abstract": "The manifold hypothesis says that natural high-dimensional data is actually\nsupported on or around a low-dimensional manifold. Recent success of\nstatistical and learning-based methods empirically supports this hypothesis,\ndue to outperforming classical statistical intuition in very high dimensions. A\nnatural step for analysis is thus to assume the manifold hypothesis and derive\nbounds that are independent of any embedding space. Theoretical implications in\nthis direction have recently been explored in terms of generalization of ReLU\nnetworks and convergence of Langevin methods. We complement existing results by\nproviding theoretical statistical complexity results, which directly relates to\ngeneralization properties. In particular, we demonstrate that the statistical\ncomplexity required to approximate a class of bounded Sobolev functions on a\ncompact manifold is bounded from below, and moreover that this bound is\ndependent only on the intrinsic properties of the manifold. These provide\ncomplementary bounds for existing approximation results for ReLU networks on\nmanifolds, which give upper bounds on generalization capacity.", "arxiv_id": "2408.06996v1", "pdf_url": "http://arxiv.org/pdf/2408.06996v1", "abstract_url": "http://arxiv.org/abs/2408.06996v1", "primary_category": "cs.LG", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Blessing of Dimensionality for Approximating Sobolev Classes on Manifolds", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:54.380352"}
{"title": "IRS-Assisted Lossy Communications Under Correlated Rayleigh Fading: Outage Probability Analysis and Optimization", "authors": "Guanchang Li, Wensheng Lin, Lixin Li, Yixuan He, Fucheng Yang, Zhu Han", "abstract": "This paper focuses on an intelligent reflecting surface (IRS)-assisted lossy\ncommunication system with correlated Rayleigh fading. We analyze the correlated\nchannel model and derive the outage probability of the system. Then, we design\na deep reinforce learning (DRL) method to optimize the phase shift of IRS, in\norder to maximize the received signal power. Moreover, this paper presents\nresults of the simulations conducted to evaluate the performance of the\nDRL-based method. The simulation results indicate that the outage probability\nof the considered system increases significantly with more correlated channel\ncoefficients. Moreover, the performance gap between DRL and theoretical limit\nincreases with higher transmit power and/or larger distortion requirement.", "arxiv_id": "2408.06969v1", "pdf_url": "http://arxiv.org/pdf/2408.06969v1", "abstract_url": "http://arxiv.org/abs/2408.06969v1", "primary_category": "cs.NI", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "IRS-Assisted Lossy Communications Under Correlated Rayleigh Fading: Outage Probability Analysis and Optimization", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:55.331004"}
{"title": "Event-Stream Super Resolution using Sigma-Delta Neural Network", "authors": "Waseem Shariff, Joe Lemley, Peter Corcoran", "abstract": "This study introduces a novel approach to enhance the spatial-temporal\nresolution of time-event pixels based on luminance changes captured by event\ncameras. These cameras present unique challenges due to their low resolution\nand the sparse, asynchronous nature of the data they collect. Current event\nsuper-resolution algorithms are not fully optimized for the distinct data\nstructure produced by event cameras, resulting in inefficiencies in capturing\nthe full dynamism and detail of visual scenes with improved computational\ncomplexity. To bridge this gap, our research proposes a method that integrates\nbinary spikes with Sigma Delta Neural Networks (SDNNs), leveraging\nspatiotemporal constraint learning mechanism designed to simultaneously learn\nthe spatial and temporal distributions of the event stream. The proposed\nnetwork is evaluated using widely recognized benchmark datasets, including\nN-MNIST, CIFAR10-DVS, ASL-DVS, and Event-NFS. A comprehensive evaluation\nframework is employed, assessing both the accuracy, through root mean square\nerror (RMSE), and the computational efficiency of our model. The findings\ndemonstrate significant improvements over existing state-of-the-art methods,\nspecifically, the proposed method outperforms state-of-the-art performance in\ncomputational efficiency, achieving a 17.04-fold improvement in event sparsity\nand a 32.28-fold increase in synaptic operation efficiency over traditional\nartificial neural networks, alongside a two-fold better performance over\nspiking neural networks.", "arxiv_id": "2408.06968v1", "pdf_url": "http://arxiv.org/pdf/2408.06968v1", "abstract_url": "http://arxiv.org/abs/2408.06968v1", "primary_category": "eess.IV", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Event-Stream Super Resolution using Sigma-Delta Neural Network", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:56.077605"}
{"title": "Stabilizer bootstrapping: A recipe for efficient agnostic tomography and magic estimation", "authors": "Sitan Chen, Weiyuan Gong, Qi Ye, Zhihan Zhang", "abstract": "We study the task of agnostic tomography: given copies of an unknown\n$n$-qubit state $\\rho$ which has fidelity $\\tau$ with some state in a given\nclass $C$, find a state which has fidelity $\\ge \\tau - \\epsilon$ with $\\rho$.\nWe give a new framework, stabilizer bootstrapping, for designing\ncomputationally efficient protocols for this task, and use this to get new\nagnostic tomography protocols for the following classes:\n  Stabilizer states: We give a protocol that runs in time\n$\\mathrm{poly}(n,1/\\epsilon)\\cdot (1/\\tau)^{O(\\log(1/\\tau))}$, answering an\nopen question posed by Grewal, Iyer, Kretschmer, Liang [40] and Anshu and\nArunachalam [6]. Previous protocols ran in time $\\mathrm{exp}(\\Theta(n))$ or\nrequired $\\tau>\\cos^2(\\pi/8)$.\n  States with stabilizer dimension $n - t$: We give a protocol that runs in\ntime $n^3\\cdot(2^t/\\tau)^{O(\\log(1/\\epsilon))}$, extending recent work on\nlearning quantum states prepared by circuits with few non-Clifford gates, which\nonly applied in the realizable setting where $\\tau = 1$ [30, 37, 46, 61].\n  Discrete product states: If $C = K^{\\otimes n}$ for some $\\mu$-separated\ndiscrete set $K$ of single-qubit states, we give a protocol that runs in time\n$(n/\\mu)^{O((1 + \\log (1/\\tau))/\\mu)}/\\epsilon^2$. This strictly generalizes a\nprior guarantee which applied to stabilizer product states [39]. For stabilizer\nproduct states, we give a further improved protocol that runs in time\n$(n^2/\\epsilon^2)\\cdot (1/\\tau)^{O(\\log(1/\\tau))}$.\n  As a corollary, we give the first protocol for estimating stabilizer\nfidelity, a standard measure of magic for quantum states, to error $\\epsilon$\nin $n^3 \\mathrm{quasipoly}(1/\\epsilon)$ time.", "arxiv_id": "2408.06967v1", "pdf_url": "http://arxiv.org/pdf/2408.06967v1", "abstract_url": "http://arxiv.org/abs/2408.06967v1", "primary_category": "quant-ph", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Stabilizer bootstrapping: A recipe for efficient agnostic tomography and magic estimation", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:56.851191"}
{"title": "DyG-Mamba: Continuous State Space Modeling on Dynamic Graphs", "authors": "Dongyuan Li, Shiyin Tan, Ying Zhang, Ming Jin, Shirui Pan, Manabu Okumura, Renhe Jiang", "abstract": "Dynamic graph learning aims to uncover evolutionary laws in real-world\nsystems, enabling accurate social recommendation (link prediction) or early\ndetection of cancer cells (classification). Inspired by the success of state\nspace models, e.g., Mamba, for efficiently capturing long-term dependencies in\nlanguage modeling, we propose DyG-Mamba, a new continuous state space model\n(SSM) for dynamic graph learning. Specifically, we first found that using\ninputs as control signals for SSM is not suitable for continuous-time dynamic\nnetwork data with irregular sampling intervals, resulting in models being\ninsensitive to time information and lacking generalization properties. Drawing\ninspiration from the Ebbinghaus forgetting curve, which suggests that memory of\npast events is strongly correlated with time intervals rather than specific\ndetails of the events themselves, we directly utilize irregular time spans as\ncontrol signals for SSM to achieve significant robustness and generalization.\nThrough exhaustive experiments on 12 datasets for dynamic link prediction and\ndynamic node classification tasks, we found that DyG-Mamba achieves\nstate-of-the-art performance on most of the datasets, while also demonstrating\nsignificantly improved computation and memory efficiency.", "arxiv_id": "2408.06966v1", "pdf_url": "http://arxiv.org/pdf/2408.06966v1", "abstract_url": "http://arxiv.org/abs/2408.06966v1", "primary_category": "cs.LG", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "DyG-Mamba: Continuous State Space Modeling on Dynamic Graphs", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:57.514256"}
{"title": "Measuring User Understanding in Dialogue-based XAI Systems", "authors": "Dimitry Mindlin, Amelie Sophie Robrecht, Michael Morasch, Philipp Cimiano", "abstract": "The field of eXplainable Artificial Intelligence (XAI) is increasingly\nrecognizing the need to personalize and/or interactively adapt the explanation\nto better reflect users' explanation needs. While dialogue-based approaches to\nXAI have been proposed recently, the state-of-the-art in XAI is still\ncharacterized by what we call one-shot, non-personalized and one-way\nexplanations. In contrast, dialogue-based systems that can adapt explanations\nthrough interaction with a user promise to be superior to GUI-based or\ndashboard explanations as they offer a more intuitive way of requesting\ninformation. In general, while interactive XAI systems are often evaluated in\nterms of user satisfaction, there are limited studies that access user's\nobjective model understanding. This is in particular the case for\ndialogue-based XAI approaches. In this paper, we close this gap by carrying out\ncontrolled experiments within a dialogue framework in which we measure\nunderstanding of users in three phases by asking them to simulate the\npredictions of the model they are learning about. By this, we can quantify the\nlevel of (improved) understanding w.r.t. how the model works, comparing the\nstate prior, and after the interaction. We further analyze the data to reveal\npatterns of how the interaction between groups with high vs. low understanding\ngain differ. Overall, our work thus contributes to our understanding about the\neffectiveness of XAI approaches.", "arxiv_id": "2408.06960v2", "pdf_url": "http://arxiv.org/pdf/2408.06960v2", "abstract_url": "http://arxiv.org/abs/2408.06960v2", "primary_category": "cs.LG", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Measuring User Understanding in Dialogue-based XAI Systems", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:58.331135"}
{"title": "AuToMATo: A Parameter-Free Persistence-Based Clustering Algorithm", "authors": "Marius Huber, Sara Kalisnik, Patrick Schnider", "abstract": "We present AuToMATo, a novel parameter-free clustering algorithm based on\npersistent homology. AuToMATo combines the existing ToMATo clustering algorithm\nwith a bootstrapping procedure in order to separate significant peaks of an\nestimated density function from non-significant ones. We perform a thorough\ncomparison of AuToMATo against many other state-of-the-art clustering\nalgorithms. We find that not only that AuToMATo compares favorably against\nother parameter-free clustering algorithms, but in many instances also\nsignificantly outperforms even the best selection of parameters for other\nalgorithms. AuToMATo is motivated by applications in topological data analysis,\nin particular the Mapper algorithm, where it is desirable to work with a\nparameter-free clustering algorithm. Indeed, we provide evidence that AuToMATo\nperforms well when used with Mapper. Finally, we provide an open-source\nimplementation of AuToMATo in Python that is fully compatible with the\nstandardscikit-learn architecture.", "arxiv_id": "2408.06958v1", "pdf_url": "http://arxiv.org/pdf/2408.06958v1", "abstract_url": "http://arxiv.org/abs/2408.06958v1", "primary_category": "cs.LG", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "AuToMATo: A Parameter-Free Persistence-Based Clustering Algorithm", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:59.077136"}
{"title": "Heavy-Ball Momentum Accelerated Actor-Critic With Function Approximation", "authors": "Yanjie Dong, Haijun Zhang, Gang Wang, Shisheng Cui, Xiping Hu", "abstract": "By using an parametric value function to replace the Monte-Carlo rollouts for\nvalue estimation, the actor-critic (AC) algorithms can reduce the variance of\nstochastic policy gradient so that to improve the convergence rate. While\nexisting works mainly focus on analyzing convergence rate of AC algorithms\nunder Markovian noise, the impacts of momentum on AC algorithms remain largely\nunexplored. In this work, we first propose a heavy-ball momentum based\nadvantage actor-critic (\\mbox{HB-A2C}) algorithm by integrating the heavy-ball\nmomentum into the critic recursion that is parameterized by a linear function.\nWhen the sample trajectory follows a Markov decision process, we quantitatively\ncertify the acceleration capability of the proposed HB-A2C algorithm. Our\ntheoretical results demonstrate that the proposed HB-A2C finds an\n$\\epsilon$-approximate stationary point with $\\oo{\\epsilon^{-2}}$ iterations\nfor reinforcement learning tasks with Markovian noise. Moreover, we also reveal\nthe dependence of learning rates on the length of the sample trajectory. By\ncarefully selecting the momentum factor of the critic recursion, the proposed\nHB-A2C can balance the errors introduced by the initialization and the\nstoschastic approximation.", "arxiv_id": "2408.06945v2", "pdf_url": "http://arxiv.org/pdf/2408.06945v2", "abstract_url": "http://arxiv.org/abs/2408.06945v2", "primary_category": "cs.LG", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Heavy-Ball Momentum Accelerated Actor-Critic With Function Approximation", "response": "RELEVANT", "timestamp": "2024-08-19T13:35:59.740064"}
{"title": "Towards Holistic Disease Risk Prediction using Small Language Models", "authors": "Liv Bj\u00f6rkdahl, Oskar Pauli, Johan \u00d6stman, Chiara Ceccobello, Sara Lundell, Magnus Kjellberg", "abstract": "Data in the healthcare domain arise from a variety of sources and modalities,\nsuch as x-ray images, continuous measurements, and clinical notes. Medical\npractitioners integrate these diverse data types daily to make informed and\naccurate decisions. With recent advancements in language models capable of\nhandling multimodal data, it is a logical progression to apply these models to\nthe healthcare sector. In this work, we introduce a framework that connects\nsmall language models to multiple data sources, aiming to predict the risk of\nvarious diseases simultaneously. Our experiments encompass 12 different tasks\nwithin a multitask learning setup. Although our approach does not surpass\nstate-of-the-art methods specialized for single tasks, it demonstrates\ncompetitive performance and underscores the potential of small language models\nfor multimodal reasoning in healthcare.", "arxiv_id": "2408.06943v1", "pdf_url": "http://arxiv.org/pdf/2408.06943v1", "abstract_url": "http://arxiv.org/abs/2408.06943v1", "primary_category": "cs.LG", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Towards Holistic Disease Risk Prediction using Small Language Models", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:00.511678"}
{"title": "Breaking Class Barriers: Efficient Dataset Distillation via Inter-Class Feature Compensator", "authors": "Xin Zhang, Jiawei Du, Ping Liu, Joey Tianyi Zhou", "abstract": "Dataset distillation has emerged as a technique aiming to condense\ninformative features from large, natural datasets into a compact and synthetic\nform. While recent advancements have refined this technique, its performance is\nbottlenecked by the prevailing class-specific synthesis paradigm. Under this\nparadigm, synthetic data is optimized exclusively for a pre-assigned one-hot\nlabel, creating an implicit class barrier in feature condensation. This leads\nto inefficient utilization of the distillation budget and oversight of\ninter-class feature distributions, which ultimately limits the effectiveness\nand efficiency, as demonstrated in our analysis.\n  To overcome these constraints, this paper presents the Inter-class Feature\nCompensator (INFER), an innovative distillation approach that transcends the\nclass-specific data-label framework widely utilized in current dataset\ndistillation methods. Specifically, INFER leverages a Universal Feature\nCompensator (UFC) to enhance feature integration across classes, enabling the\ngeneration of multiple additional synthetic instances from a single UFC input.\nThis significantly improves the efficiency of the distillation budget.\n  Moreover, INFER enriches inter-class interactions during the distillation,\nthereby enhancing the effectiveness and generalizability of the distilled data.\nBy allowing for the linear interpolation of labels similar to those in the\noriginal dataset, INFER meticulously optimizes the synthetic data and\ndramatically reduces the size of soft labels in the synthetic dataset to almost\nzero, establishing a new benchmark for efficiency and effectiveness in dataset\ndistillation.", "arxiv_id": "2408.06927v1", "pdf_url": "http://arxiv.org/pdf/2408.06927v1", "abstract_url": "http://arxiv.org/abs/2408.06927v1", "primary_category": "cs.CV", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Breaking Class Barriers: Efficient Dataset Distillation via Inter-Class Feature Compensator", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:01.327990"}
{"title": "Heterogeneity: An Open Challenge for Federated On-board Machine Learning", "authors": "Maria Hartmann, Gr\u00e9goire Danoy, Pascal Bouvry", "abstract": "The design of satellite missions is currently undergoing a paradigm shift\nfrom the historical approach of individualised monolithic satellites towards\ndistributed mission configurations, consisting of multiple small satellites.\nWith a rapidly growing number of such satellites now deployed in orbit, each\ncollecting large amounts of data, interest in on-board orbital edge computing\nis rising. Federated Learning is a promising distributed computing approach in\nthis context, allowing multiple satellites to collaborate efficiently in\ntraining on-board machine learning models. Though recent works on the use of\nFederated Learning in orbital edge computing have focused largely on\nhomogeneous satellite constellations, Federated Learning could also be employed\nto allow heterogeneous satellites to form ad-hoc collaborations, e.g. in the\ncase of communications satellites operated by different providers. Such an\napplication presents additional challenges to the Federated Learning paradigm,\narising largely from the heterogeneity of such a system. In this position\npaper, we offer a systematic review of these challenges in the context of the\ncross-provider use case, giving a brief overview of the state-of-the-art for\neach, and providing an entry point for deeper exploration of each issue.", "arxiv_id": "2408.06903v1", "pdf_url": "http://arxiv.org/pdf/2408.06903v1", "abstract_url": "http://arxiv.org/abs/2408.06903v1", "primary_category": "cs.DC", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Heterogeneity: An Open Challenge for Federated On-board Machine Learning", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:02.002350"}
{"title": "Automatic Feature Recognition and Dimensional Attributes Extraction From CAD Models for Hybrid Additive-Subtractive Manufacturing", "authors": "Muhammad Tayyab Khan, Wenhe Feng, Lequn Chen, Ye Han Ng, Nicholas Yew Jin Tan, Seung Ki Moon", "abstract": "The integration of Computer-Aided Design (CAD), Computer-Aided Process\nPlanning (CAPP), and Computer-Aided Manufacturing (CAM) plays a crucial role in\nmodern manufacturing, facilitating seamless transitions from digital designs to\nphysical products. However, a significant challenge within this integration is\nthe Automatic Feature Recognition (AFR) of CAD models, especially in the\ncontext of hybrid manufacturing that combines subtractive and additive\nmanufacturing processes. Traditional AFR methods, focused mainly on the\nidentification of subtractive (machined) features including holes, fillets,\nchamfers, pockets, and slots, fail to recognize features pertinent to additive\nmanufacturing. Furthermore, the traditional methods fall short in accurately\nextracting geometric dimensions and orientations, which are also key factors\nfor effective manufacturing process planning. This paper presents a novel\napproach for creating a synthetic CAD dataset that encompasses features\nrelevant to both additive and subtractive machining through Python Open\nCascade. The Hierarchical Graph Convolutional Neural Network (HGCNN) model is\nimplemented to accurately identify the composite additive-subtractive features\nwithin the synthetic CAD dataset. The key novelty and contribution of the\nproposed methodology lie in its ability to recognize a wide range of\nmanufacturing features, and precisely extracting their dimensions,\norientations, and stock sizes. The proposed model demonstrates remarkable\nfeature recognition accuracy exceeding 97% and a dimension extraction accuracy\nof 100% for identified features. Therefore, the proposed methodology enhances\nthe integration of CAD, CAPP, and CAM within hybrid manufacturing by providing\nprecise feature recognition and dimension extraction. It facilitates improved\nmanufacturing process planning, by enabling more informed decision-making.", "arxiv_id": "2408.06891v2", "pdf_url": "http://arxiv.org/pdf/2408.06891v2", "abstract_url": "http://arxiv.org/abs/2408.06891v2", "primary_category": "cs.AI", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Automatic Feature Recognition and Dimensional Attributes Extraction From CAD Models for Hybrid Additive-Subtractive Manufacturing", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:02.764503"}
{"title": "BMFT: Achieving Fairness via Bias-based Weight Masking Fine-tuning", "authors": "Yuyang Xue, Junyu Yan, Raman Dutt, Fasih Haider, Jingshuai Liu, Steven McDonagh, Sotirios A. Tsaftaris", "abstract": "Developing models with robust group fairness properties is paramount,\nparticularly in ethically sensitive domains such as medical diagnosis. Recent\napproaches to achieving fairness in machine learning require a substantial\namount of training data and depend on model retraining, which may not be\npractical in real-world scenarios. To mitigate these challenges, we propose\nBias-based Weight Masking Fine-Tuning (BMFT), a novel post-processing method\nthat enhances the fairness of a trained model in significantly fewer epochs\nwithout requiring access to the original training data. BMFT produces a mask\nover model parameters, which efficiently identifies the weights contributing\nthe most towards biased predictions. Furthermore, we propose a two-step\ndebiasing strategy, wherein the feature extractor undergoes initial fine-tuning\non the identified bias-influenced weights, succeeded by a fine-tuning phase on\na reinitialised classification layer to uphold discriminative performance.\nExtensive experiments across four dermatological datasets and two sensitive\nattributes demonstrate that BMFT outperforms existing state-of-the-art (SOTA)\ntechniques in both diagnostic accuracy and fairness metrics. Our findings\nunderscore the efficacy and robustness of BMFT in advancing fairness across\nvarious out-of-distribution (OOD) settings. Our code is available at:\nhttps://github.com/vios-s/BMFT", "arxiv_id": "2408.06890v1", "pdf_url": "http://arxiv.org/pdf/2408.06890v1", "abstract_url": "http://arxiv.org/abs/2408.06890v1", "primary_category": "cs.LG", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "BMFT: Achieving Fairness via Bias-based Weight Masking Fine-tuning", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:03.690819"}
{"title": "Physics-informed graph neural networks for flow field estimation in carotid arteries", "authors": "Julian Suk, Dieuwertje Alblas, Barbara A. Hutten, Albert Wiegman, Christoph Brune, Pim van Ooij, Jelmer M. Wolterink", "abstract": "Hemodynamic quantities are valuable biomedical risk factors for\ncardiovascular pathology such as atherosclerosis. Non-invasive, in-vivo\nmeasurement of these quantities can only be performed using a select number of\nmodalities that are not widely available, such as 4D flow magnetic resonance\nimaging (MRI). In this work, we create a surrogate model for hemodynamic flow\nfield estimation, powered by machine learning. We train graph neural networks\nthat include priors about the underlying symmetries and physics, limiting the\namount of data required for training. This allows us to train the model using\nmoderately-sized, in-vivo 4D flow MRI datasets, instead of large in-silico\ndatasets obtained by computational fluid dynamics (CFD), as is the current\nstandard. We create an efficient, equivariant neural network by combining the\npopular PointNet++ architecture with group-steerable layers. To incorporate the\nphysics-informed priors, we derive an efficient discretisation scheme for the\ninvolved differential operators. We perform extensive experiments in carotid\narteries and show that our model can accurately estimate low-noise hemodynamic\nflow fields in the carotid artery. Moreover, we show how the learned relation\nbetween geometry and hemodynamic quantities transfers to 3D vascular models\nobtained using a different imaging modality than the training data. This shows\nthat physics-informed graph neural networks can be trained using 4D flow MRI\ndata to estimate blood flow in unseen carotid artery geometries.", "arxiv_id": "2408.07110v1", "pdf_url": "http://arxiv.org/pdf/2408.07110v1", "abstract_url": "http://arxiv.org/abs/2408.07110v1", "primary_category": "q-bio.QM", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Physics-informed graph neural networks for flow field estimation in carotid arteries", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:04.811434"}
{"title": "Optimal Bound for PCA with Outliers using Higher-Degree Voronoi Diagrams", "authors": "Sajjad Hashemian, Mohammad Saeed Arvenaghi, Ebrahim Ardeshir-Larijani", "abstract": "In this paper, we introduce new algorithms for Principal Component Analysis\n(PCA) with outliers. Utilizing techniques from computational geometry,\nspecifically higher-degree Voronoi diagrams, we navigate to the optimal\nsubspace for PCA even in the presence of outliers. This approach achieves an\noptimal solution with a time complexity of\n$n^{d+\\mathcal{O}(1)}\\text{poly}(n,d)$. Additionally, we present a randomized\nalgorithm with a complexity of $2^{\\mathcal{O}(r(d-r))} \\times \\text{poly}(n,\nd)$. This algorithm samples subspaces characterized in terms of a Grassmannian\nmanifold. By employing such sampling method, we ensure a high likelihood of\ncapturing the optimal subspace, with the success probability $(1 - \\delta)^T$.\nWhere $\\delta$ represents the probability that a sampled subspace does not\ncontain the optimal solution, and $T$ is the number of subspaces sampled,\nproportional to $2^{r(d-r)}$. Our use of higher-degree Voronoi diagrams and\nGrassmannian based sampling offers a clearer conceptual pathway and practical\nadvantages, particularly in handling large datasets or higher-dimensional\nsettings.", "arxiv_id": "2408.06867v1", "pdf_url": "http://arxiv.org/pdf/2408.06867v1", "abstract_url": "http://arxiv.org/abs/2408.06867v1", "primary_category": "cs.LG", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Optimal Bound for PCA with Outliers using Higher-Degree Voronoi Diagrams", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:06.041391"}
{"title": "Efficient Deep Model-Based Optoacoustic Image Reconstruction", "authors": "Christoph Dehner, Guillaume Zahnd", "abstract": "Clinical adoption of multispectral optoacoustic tomography necessitates\nimprovements of the image quality available in real-time, as well as a\nreduction in the scanner financial cost. Deep learning approaches have recently\nunlocked the reconstruction of high-quality optoacoustic images in real-time.\nHowever, currently used deep neural network architectures require powerful\ngraphics processing units to infer images at sufficiently high frame-rates,\nconsequently greatly increasing the price tag. Herein we propose\nEfficientDeepMB, a relatively lightweight (17M parameters) network architecture\nachieving high frame-rates on medium-sized graphics cards with no noticeable\ndowngrade in image quality. EfficientDeepMB is built upon DeepMB, a previously\nestablished deep learning framework to reconstruct high-quality images in\nreal-time, and upon EfficientNet, a network architectures designed to operate\nof mobile devices. We demonstrate the performance of EfficientDeepMB in terms\nof reconstruction speed and accuracy using a large and diverse dataset of in\nvivo optoacoustic scans. EfficientDeepMB is about three to five times faster\nthan DeepMB: deployed on a medium-sized NVIDIA RTX A2000 Ada, EfficientDeepMB\nreconstructs images at speeds enabling live image feedback (59Hz) while DeepMB\nfails to meets the real-time inference threshold (14Hz). The quantitative\ndifference between the reconstruction accuracy of EfficientDeepMB and DeepMB is\nmarginal (data residual norms of 0.1560 vs. 0.1487, mean absolute error of\n0.642 vs. 0.745). There are no perceptible qualitative differences between\nimages inferred with the two reconstruction methods.", "arxiv_id": "2408.07109v1", "pdf_url": "http://arxiv.org/pdf/2408.07109v1", "abstract_url": "http://arxiv.org/abs/2408.07109v1", "primary_category": "eess.IV", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Efficient Deep Model-Based Optoacoustic Image Reconstruction", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:06.774594"}
{"title": "PRESENT: Zero-Shot Text-to-Prosody Control", "authors": "Perry Lam, Huayun Zhang, Nancy F. Chen, Berrak Sisman, Dorien Herremans", "abstract": "Current strategies for achieving fine-grained prosody control in speech\nsynthesis entail extracting additional style embeddings or adopting more\ncomplex architectures. To enable zero-shot application of pretrained\ntext-to-speech (TTS) models, we present PRESENT (PRosody Editing without Style\nEmbeddings or New Training), which exploits explicit prosody prediction in\nFastSpeech2-based models by modifying the inference process directly. We apply\nour text-to-prosody framework to zero-shot language transfer using a JETS model\nexclusively trained on English LJSpeech data. We obtain character error rates\n(CER) of 12.8%, 18.7% and 5.9% for German, Hungarian and Spanish respectively,\nbeating the previous state-of-the-art CER by over 2x for all three languages.\nFurthermore, we allow subphoneme-level control, a first in this field. To\nevaluate its effectiveness, we show that PRESENT can improve the prosody of\nquestions, and use it to generate Mandarin, a tonal language where vowel pitch\nvaries at subphoneme level. We attain 25.3% hanzi CER and 13.0% pinyin CER with\nthe JETS model. All our code and audio samples are available online.", "arxiv_id": "2408.06827v1", "pdf_url": "http://arxiv.org/pdf/2408.06827v1", "abstract_url": "http://arxiv.org/abs/2408.06827v1", "primary_category": "eess.AS", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "PRESENT: Zero-Shot Text-to-Prosody Control", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:07.580531"}
{"title": "Efficient Search for Customized Activation Functions with Gradient Descent", "authors": "Lukas Strack, Mahmoud Safari, Frank Hutter", "abstract": "Different activation functions work best for different deep learning models.\nTo exploit this, we leverage recent advancements in gradient-based search\ntechniques for neural architectures to efficiently identify high-performing\nactivation functions for a given application. We propose a fine-grained search\ncell that combines basic mathematical operations to model activation functions,\nallowing for the exploration of novel activations. Our approach enables the\nidentification of specialized activations, leading to improved performance in\nevery model we tried, from image classification to language models. Moreover,\nthe identified activations exhibit strong transferability to larger models of\nthe same type, as well as new datasets. Importantly, our automated process for\ncreating customized activation functions is orders of magnitude more efficient\nthan previous approaches. It can easily be applied on top of arbitrary deep\nlearning pipelines and thus offers a promising practical avenue for enhancing\ndeep learning architectures.", "arxiv_id": "2408.06820v1", "pdf_url": "http://arxiv.org/pdf/2408.06820v1", "abstract_url": "http://arxiv.org/abs/2408.06820v1", "primary_category": "cs.LG", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Efficient Search for Customized Activation Functions with Gradient Descent", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:08.413433"}
{"title": "Enhancing Multiview Synergy: Robust Learning by Exploiting the Wave Loss Function with Consensus and Complementarity Principles", "authors": "A. Quadir, Mushir Akhtar, M. Tanveer", "abstract": "Multiview learning (MvL) is an advancing domain in machine learning,\nleveraging multiple data perspectives to enhance model performance through\nview-consistency and view-discrepancy. Despite numerous successful\nmultiview-based SVM models, existing frameworks predominantly focus on the\nconsensus principle, often overlooking the complementarity principle.\nFurthermore, they exhibit limited robustness against noisy, error-prone, and\nview-inconsistent samples, prevalent in multiview datasets. To tackle the\naforementioned limitations, this paper introduces Wave-MvSVM, a novel multiview\nsupport vector machine framework leveraging the wave loss (W-loss) function,\nspecifically designed to harness both consensus and complementarity principles.\nUnlike traditional approaches that often overlook the complementary information\namong different views, the proposed Wave-MvSVM ensures a more comprehensive and\nresilient learning process by integrating both principles effectively. The\nW-loss function, characterized by its smoothness, asymmetry, and bounded\nnature, is particularly effective in mitigating the adverse effects of noisy\nand outlier data, thereby enhancing model stability. Theoretically, the W-loss\nfunction also exhibits a crucial classification-calibrated property, further\nboosting its effectiveness. Wave-MvSVM employs a between-view co-regularization\nterm to enforce view consistency and utilizes an adaptive combination weight\nstrategy to maximize the discriminative power of each view. The optimization\nproblem is efficiently solved using a combination of GD and the ADMM, ensuring\nreliable convergence to optimal solutions. Theoretical analyses, grounded in\nRademacher complexity, validate the generalization capabilities of the\nWave-MvSVM model. Extensive empirical evaluations across diverse datasets\ndemonstrate the superior performance of Wave-MvSVM in comparison to existing\nbenchmark models.", "arxiv_id": "2408.06819v1", "pdf_url": "http://arxiv.org/pdf/2408.06819v1", "abstract_url": "http://arxiv.org/abs/2408.06819v1", "primary_category": "cs.LG", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Enhancing Multiview Synergy: Robust Learning by Exploiting the Wave Loss Function with Consensus and Complementarity Principles", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:09.265651"}
{"title": "On a Scale-Invariant Approach to Bundle Recommendations in Candy Crush Saga", "authors": "Styliani Katsarou, Francesca Carminati, Martin Dlask, Marta Braojos, Lavena Patra, Richard Perkins, Carlos Garcia Ling, Maria Paskevich", "abstract": "A good understanding of player preferences is crucial for increasing content\nrelevancy, especially in mobile games. This paper illustrates the use of\nattentive models for producing item recommendations in a mobile game scenario.\nThe methodology comprises a combination of supervised and unsupervised\napproaches to create user-level recommendations while introducing a novel\nscale-invariant approach to the prediction. The methodology is subsequently\napplied to a bundle recommendation in Candy Crush Saga. The strategy of\ndeployment, maintenance, and monitoring of ML models that are scaled up to\nserve millions of users is presented, along with the best practices and design\npatterns adopted to minimize technical debt typical of ML systems. The\nrecommendation approach is evaluated both offline and online, with a focus on\nunderstanding the increase in engagement, click- and take rates, novelty\neffects, recommendation diversity, and the impact of degenerate feedback loops.\nWe have demonstrated that the recommendation enhances user engagement by 30%\nconcerning click rate and by more than 40% concerning take rate. In addition,\nwe empirically quantify the diminishing effects of recommendation accuracy on\nuser engagement.", "arxiv_id": "2408.06799v2", "pdf_url": "http://arxiv.org/pdf/2408.06799v2", "abstract_url": "http://arxiv.org/abs/2408.06799v2", "primary_category": "cs.LG", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "NOT_ENOUGH_RELATED"}
{"title": "On a Scale-Invariant Approach to Bundle Recommendations in Candy Crush Saga", "response": "NOT_ENOUGH_RELATED", "timestamp": "2024-08-19T13:36:10.136600"}
{"title": "Maximizing V-information for Pre-training Superior Foundation Models", "authors": "Wenxuan Yang, Weimin Tan, Hanyu Zhang, Bo Yan", "abstract": "Pre-training foundation models on large-scale datasets demonstrates\nexceptional performance. However, recent research questions this traditional\nnotion, exploring whether an increase in pre-training data always leads to\nenhanced model performance. To address this issue, data-effective learning\napproaches have been introduced. However, current methods in this area lack a\nclear standard for sample selection. Our experiments reveal that by maximizing\nV-information, sample selection can be framed as an optimization problem,\nenabling effective improvement in model performance even with fewer samples.\nUnder this guidance, we develop an optimal data-effective learning method\n(OptiDEL) to maximize V-information. The OptiDEL method generates hard samples\nto achieve or even exceed the performance of models trained on the full dataset\nwhile using substantially less data. We compare the OptiDEL method with\nstate-of-the-art approaches finding that OptiDEL consistently outperforms\nexisting approaches across different datasets, with foundation models trained\non only 5% of the pre-training data surpassing the performance of those trained\non the full dataset.", "arxiv_id": "2408.07107v2", "pdf_url": "http://arxiv.org/pdf/2408.07107v2", "abstract_url": "http://arxiv.org/abs/2408.07107v2", "primary_category": "cs.LG", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Maximizing V-information for Pre-training Superior Foundation Models", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:10.956572"}
{"title": "Enhancing Diabetic Retinopathy Diagnosis: A Lightweight CNN Architecture for Efficient Exudate Detection in Retinal Fundus Images", "authors": "Mujadded Al Rabbani Alif", "abstract": "Retinal fundus imaging plays an essential role in diagnosing various stages\nof diabetic retinopathy, where exudates are critical markers of early disease\nonset. Prompt detection of these exudates is pivotal for enabling optometrists\nto arrest or significantly decelerate the disease progression. This paper\nintroduces a novel, lightweight convolutional neural network architecture\ntailored for automated exudate detection, designed to identify these markers\nefficiently and accurately. To address the challenge of limited training data,\nwe have incorporated domain-specific data augmentations to enhance the model's\ngeneralizability. Furthermore, we applied a suite of regularization techniques\nwithin our custom architecture to boost diagnostic accuracy while optimizing\ncomputational efficiency. Remarkably, this streamlined model contains only 4.73\nmillion parameters a reduction of nearly 60% compared to the standard ResNet-18\nmodel, which has 11.69 million parameters. Despite its reduced complexity, our\nmodel achieves an impressive F1 score of 90%, demonstrating its efficacy in the\nearly detection of diabetic retinopathy through fundus imaging.", "arxiv_id": "2408.06784v1", "pdf_url": "http://arxiv.org/pdf/2408.06784v1", "abstract_url": "http://arxiv.org/abs/2408.06784v1", "primary_category": "eess.IV", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Enhancing Diabetic Retinopathy Diagnosis: A Lightweight CNN Architecture for Efficient Exudate Detection in Retinal Fundus Images", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:11.974567"}
{"title": "Exploring Domain Shift on Radar-Based 3D Object Detection Amidst Diverse Environmental Conditions", "authors": "Miao Zhang, Sherif Abdulatif, Benedikt Loesch, Marco Altmann, Marius Schwarz, Bin Yang", "abstract": "The rapid evolution of deep learning and its integration with autonomous\ndriving systems have led to substantial advancements in 3D perception using\nmultimodal sensors. Notably, radar sensors show greater robustness compared to\ncameras and lidar under adverse weather and varying illumination conditions.\nThis study delves into the often-overlooked yet crucial issue of domain shift\nin 4D radar-based object detection, examining how varying environmental\nconditions, such as different weather patterns and road types, impact 3D object\ndetection performance. Our findings highlight distinct domain shifts across\nvarious weather scenarios, revealing unique dataset sensitivities that\nunderscore the critical role of radar point cloud generation. Additionally, we\ndemonstrate that transitioning between different road types, especially from\nhighways to urban settings, introduces notable domain shifts, emphasizing the\nnecessity for diverse data collection across varied road environments. To the\nbest of our knowledge, this is the first comprehensive analysis of domain shift\neffects on 4D radar-based object detection. We believe this empirical study\ncontributes to understanding the complex nature of domain shifts in radar data\nand suggests paths forward for data collection strategy in the face of\nenvironmental variability.", "arxiv_id": "2408.06772v1", "pdf_url": "http://arxiv.org/pdf/2408.06772v1", "abstract_url": "http://arxiv.org/abs/2408.06772v1", "primary_category": "cs.CV", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Exploring Domain Shift on Radar-Based 3D Object Detection Amidst Diverse Environmental Conditions", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:13.105987"}
{"title": "Robust Black-box Testing of Deep Neural Networks using Co-Domain Coverage", "authors": "Aishwarya Gupta, Indranil Saha, Piyush Rai", "abstract": "Rigorous testing of machine learning models is necessary for trustworthy\ndeployments. We present a novel black-box approach for generating test-suites\nfor robust testing of deep neural networks (DNNs). Most existing methods create\ntest inputs based on maximizing some \"coverage\" criterion/metric such as a\nfraction of neurons activated by the test inputs. Such approaches, however, can\nonly analyze each neuron's behavior or each layer's output in isolation and are\nunable to capture their collective effect on the DNN's output, resulting in\ntest suites that often do not capture the various failure modes of the DNN\nadequately. These approaches also require white-box access, i.e., access to the\nDNN's internals (node activations). We present a novel black-box coverage\ncriterion called Co-Domain Coverage (CDC), which is defined as a function of\nthe model's output and thus takes into account its end-to-end behavior.\nSubsequently, we develop a new fuzz testing procedure named CoDoFuzz, which\nuses CDC to guide the fuzzing process to generate a test suite for a DNN. We\nextensively compare the test suite generated by CoDoFuzz with those generated\nusing several state-of-the-art coverage-based fuzz testing methods for the DNNs\ntrained on six publicly available datasets. Experimental results establish the\nefficiency and efficacy of CoDoFuzz in generating the largest number of\nmisclassified inputs and the inputs for which the model lacks confidence in its\ndecision.", "arxiv_id": "2408.06766v1", "pdf_url": "http://arxiv.org/pdf/2408.06766v1", "abstract_url": "http://arxiv.org/abs/2408.06766v1", "primary_category": "cs.LG", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Robust Black-box Testing of Deep Neural Networks using Co-Domain Coverage", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:13.824226"}
{"title": "Class-aware and Augmentation-free Contrastive Learning from Label Proportion", "authors": "Jialiang Wang, Ning Zhang, Shimin Di, Ruidong Wang, Lei Chen", "abstract": "Learning from Label Proportion (LLP) is a weakly supervised learning scenario\nin which training data is organized into predefined bags of instances,\ndisclosing only the class label proportions per bag. This paradigm is essential\nfor user modeling and personalization, where user privacy is paramount,\noffering insights into user preferences without revealing individual data. LLP\nfaces a unique difficulty: the misalignment between bag-level supervision and\nthe objective of instance-level prediction, primarily due to the inherent\nambiguity in label proportion matching. Previous studies have demonstrated deep\nrepresentation learning can generate auxiliary signals to promote the\nsupervision level in the image domain. However, applying these techniques to\ntabular data presents significant challenges: 1) they rely heavily on\nlabel-invariant augmentation to establish multi-view, which is not feasible\nwith the heterogeneous nature of tabular datasets, and 2) tabular datasets\noften lack sufficient semantics for perfect class distinction, making them\nprone to suboptimality caused by the inherent ambiguity of label proportion\nmatching.\n  To address these challenges, we propose an augmentation-free contrastive\nframework TabLLP-BDC that introduces class-aware supervision (explicitly aware\nof class differences) at the instance level. Our solution features a two-stage\nBag Difference Contrastive (BDC) learning mechanism that establishes robust\nclass-aware instance-level supervision by disassembling the nuance between bag\nlabel proportions, without relying on augmentations. Concurrently, our model\npresents a pioneering multi-task pretraining pipeline tailored for\ntabular-based LLP, capturing intrinsic tabular feature correlations in\nalignment with label proportion distribution. Extensive experiments demonstrate\nthat TabLLP-BDC achieves state-of-the-art performance for LLP in the tabular\ndomain.", "arxiv_id": "2408.06743v1", "pdf_url": "http://arxiv.org/pdf/2408.06743v1", "abstract_url": "http://arxiv.org/abs/2408.06743v1", "primary_category": "cs.LG", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Class-aware and Augmentation-free Contrastive Learning from Label Proportion", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:14.655336"}
{"title": "Multimodal Analysis of White Blood Cell Differentiation in Acute Myeloid Leukemia Patients using a \u03b2-Variational Autoencoder", "authors": "Gizem Mert, Ario Sadafi, Raheleh Salehi, Nassir Navab, Carsten Marr", "abstract": "Biomedical imaging and RNA sequencing with single-cell resolution improves\nour understanding of white blood cell diseases like leukemia. By combining\nmorphological and transcriptomic data, we can gain insights into cellular\nfunctions and trajectoriess involved in blood cell differentiation. However,\nexisting methodologies struggle with integrating morphological and\ntranscriptomic data, leaving a significant research gap in comprehensively\nunderstanding the dynamics of cell differentiation. Here, we introduce an\nunsupervised method that explores and reconstructs these two modalities and\nuncovers the relationship between different subtypes of white blood cells from\nhuman peripheral blood smears in terms of morphology and their corresponding\ntranscriptome. Our method is based on a beta-variational autoencoder\n(\\beta-VAE) with a customized loss function, incorporating a R-CNN architecture\nto distinguish single-cell from background and to minimize any interference\nfrom artifacts. This implementation of \\beta-VAE shows good reconstruction\ncapability along with continuous latent embeddings, while maintaining clear\ndifferentiation between single-cell classes. Our novel approach is especially\nhelpful to uncover the correlation of two latent features in complex biological\nprocesses such as formation of granules in the cell (granulopoiesis) with gene\nexpression patterns. It thus provides a unique tool to improve the\nunderstanding of white blood cell maturation for biomedicine and diagnostics.", "arxiv_id": "2408.06720v1", "pdf_url": "http://arxiv.org/pdf/2408.06720v1", "abstract_url": "http://arxiv.org/abs/2408.06720v1", "primary_category": "cs.CV", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Multimodal Analysis of White Blood Cell Differentiation in Acute Myeloid Leukemia Patients using a \u03b2-Variational Autoencoder", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:15.316657"}
{"title": "Computation-friendly Graph Neural Network Design by Accumulating Knowledge on Large Language Models", "authors": "Jialiang Wang, Shimin Di, Hanmo Liu, Zhili Wang, Jiachuan Wang, Lei Chen, Xiaofang Zhou", "abstract": "Graph Neural Networks (GNNs), like other neural networks, have shown\nremarkable success but are hampered by the complexity of their architecture\ndesigns, which heavily depend on specific data and tasks. Traditionally,\ndesigning proper architectures involves trial and error, which requires\nintensive manual effort to optimize various components. To reduce human\nworkload, researchers try to develop automated algorithms to design GNNs.\nHowever, both experts and automated algorithms suffer from two major issues in\ndesigning GNNs: 1) the substantial computational resources expended in\nrepeatedly trying candidate GNN architectures until a feasible design is\nachieved, and 2) the intricate and prolonged processes required for humans or\nalgorithms to accumulate knowledge of the interrelationship between graphs,\nGNNs, and performance.\n  To further enhance the automation of GNN architecture design, we propose a\ncomputation-friendly way to empower Large Language Models (LLMs) with\nspecialized knowledge in designing GNNs, thereby drastically shortening the\ncomputational overhead and development cycle of designing GNN architectures.\nOur framework begins by establishing a knowledge retrieval pipeline that\ncomprehends the intercorrelations between graphs, GNNs, and performance. This\npipeline converts past model design experiences into structured knowledge for\nLLM reference, allowing it to quickly suggest initial model proposals.\nSubsequently, we introduce a knowledge-driven search strategy that emulates the\nexploration-exploitation process of human experts, enabling quick refinement of\ninitial proposals within a promising scope. Extensive experiments demonstrate\nthat our framework can efficiently deliver promising (e.g., Top-5.77%) initial\nmodel proposals for unseen datasets within seconds and without any prior\ntraining and achieve outstanding search performance in a few iterations.", "arxiv_id": "2408.06717v1", "pdf_url": "http://arxiv.org/pdf/2408.06717v1", "abstract_url": "http://arxiv.org/abs/2408.06717v1", "primary_category": "cs.LG", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Computation-friendly Graph Neural Network Design by Accumulating Knowledge on Large Language Models", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:16.281200"}
{"title": "Variational Learning of Gaussian Process Latent Variable Models through Stochastic Gradient Annealed Importance Sampling", "authors": "Jian Xu, Shian Du, Junmei Yang, Qianli Ma, Delu Zeng", "abstract": "Gaussian Process Latent Variable Models (GPLVMs) have become increasingly\npopular for unsupervised tasks such as dimensionality reduction and missing\ndata recovery due to their flexibility and non-linear nature. An\nimportance-weighted version of the Bayesian GPLVMs has been proposed to obtain\na tighter variational bound. However, this version of the approach is primarily\nlimited to analyzing simple data structures, as the generation of an effective\nproposal distribution can become quite challenging in high-dimensional spaces\nor with complex data sets. In this work, we propose an Annealed Importance\nSampling (AIS) approach to address these issues. By transforming the posterior\ninto a sequence of intermediate distributions using annealing, we combine the\nstrengths of Sequential Monte Carlo samplers and VI to explore a wider range of\nposterior distributions and gradually approach the target distribution. We\nfurther propose an efficient algorithm by reparameterizing all variables in the\nevidence lower bound (ELBO). Experimental results on both toy and image\ndatasets demonstrate that our method outperforms state-of-the-art methods in\nterms of tighter variational bounds, higher log-likelihoods, and more robust\nconvergence.", "arxiv_id": "2408.06710v1", "pdf_url": "http://arxiv.org/pdf/2408.06710v1", "abstract_url": "http://arxiv.org/abs/2408.06710v1", "primary_category": "cs.LG", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Variational Learning of Gaussian Process Latent Variable Models through Stochastic Gradient Annealed Importance Sampling", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:17.095453"}
{"title": "\"You still have to study\" -- On the Security of LLM generated code", "authors": "Stefan Goetz, Andreas Schaad", "abstract": "We witness an increasing usage of AI-assistants even for routine (classroom)\nprogramming tasks. However, the code generated on basis of a so called \"prompt\"\nby the programmer does not always meet accepted security standards. On the one\nhand, this may be due to lack of best-practice examples in the training data.\nOn the other hand, the actual quality of the programmers prompt appears to\ninfluence whether generated code contains weaknesses or not. In this paper we\nanalyse 4 major LLMs with respect to the security of generated code. We do this\non basis of a case study for the Python and Javascript language, using the\nMITRE CWE catalogue as the guiding security definition. Our results show that\nusing different prompting techniques, some LLMs initially generate 65% code\nwhich is deemed insecure by a trained security engineer. On the other hand\nalmost all analysed LLMs will eventually generate code being close to 100%\nsecure with increasing manual guidance of a skilled engineer.", "arxiv_id": "2408.07106v1", "pdf_url": "http://arxiv.org/pdf/2408.07106v1", "abstract_url": "http://arxiv.org/abs/2408.07106v1", "primary_category": "cs.SE", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "\"You still have to study\" -- On the Security of LLM generated code", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:17.820104"}
{"title": "DiffSG: A Generative Solver for Network Optimization with Diffusion Model", "authors": "Ruihuai Liang, Bo Yang, Zhiwen Yu, Bin Guo, Xuelin Cao, M\u00e9rouane Debbah, H. Vincent Poor, Chau Yuen", "abstract": "Diffusion generative models, famous for their performance in image\ngeneration, are popular in various cross-domain applications. However, their\nuse in the communication community has been mostly limited to auxiliary tasks\nlike data modeling and feature extraction. These models hold greater promise\nfor fundamental problems in network optimization compared to traditional\nmachine learning methods. Discriminative deep learning often falls short due to\nits single-step input-output mapping and lack of global awareness of the\nsolution space, especially given the complexity of network optimization's\nobjective functions. In contrast, diffusion generative models can consider a\nbroader range of solutions and exhibit stronger generalization by learning\nparameters that describe the distribution of the underlying solution space,\nwith higher probabilities assigned to better solutions. We propose a new\nframework Diffusion Model-based Solution Generation (DiffSG), which leverages\nthe intrinsic distribution learning capabilities of diffusion generative models\nto learn high-quality solution distributions based on given inputs. The optimal\nsolution within this distribution is highly probable, allowing it to be\neffectively reached through repeated sampling. We validate the performance of\nDiffSG on several typical network optimization problems, including\nmixed-integer non-linear programming, convex optimization, and hierarchical\nnon-convex optimization. Our results show that DiffSG outperforms existing\nbaselines. In summary, we demonstrate the potential of diffusion generative\nmodels in tackling complex network optimization problems and outline a\npromising path for their broader application in the communication community.", "arxiv_id": "2408.06701v1", "pdf_url": "http://arxiv.org/pdf/2408.06701v1", "abstract_url": "http://arxiv.org/abs/2408.06701v1", "primary_category": "cs.NI", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "DiffSG: A Generative Solver for Network Optimization with Diffusion Model", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:19.508682"}
{"title": "Information Geometry and Beta Link for Optimizing Sparse Variational Student-t Processes", "authors": "Jian Xu, Delu Zeng, John Paisley", "abstract": "Recently, a sparse version of Student-t Processes, termed sparse variational\nStudent-t Processes, has been proposed to enhance computational efficiency and\nflexibility for real-world datasets using stochastic gradient descent. However,\ntraditional gradient descent methods like Adam may not fully exploit the\nparameter space geometry, potentially leading to slower convergence and\nsuboptimal performance. To mitigate these issues, we adopt natural gradient\nmethods from information geometry for variational parameter optimization of\nStudent-t Processes. This approach leverages the curvature and structure of the\nparameter space, utilizing tools such as the Fisher information matrix which is\nlinked to the Beta function in our model. This method provides robust\nmathematical support for the natural gradient algorithm when using Student's\nt-distribution as the variational distribution. Additionally, we present a\nmini-batch algorithm for efficiently computing natural gradients. Experimental\nresults across four benchmark datasets demonstrate that our method consistently\naccelerates convergence speed.", "arxiv_id": "2408.06699v1", "pdf_url": "http://arxiv.org/pdf/2408.06699v1", "abstract_url": "http://arxiv.org/abs/2408.06699v1", "primary_category": "cs.LG", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Information Geometry and Beta Link for Optimizing Sparse Variational Student-t Processes", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:20.351006"}
{"title": "SlotLifter: Slot-guided Feature Lifting for Learning Object-centric Radiance Fields", "authors": "Yu Liu, Baoxiong Jia, Yixin Chen, Siyuan Huang", "abstract": "The ability to distill object-centric abstractions from intricate visual\nscenes underpins human-level generalization. Despite the significant progress\nin object-centric learning methods, learning object-centric representations in\nthe 3D physical world remains a crucial challenge. In this work, we propose\nSlotLifter, a novel object-centric radiance model addressing scene\nreconstruction and decomposition jointly via slot-guided feature lifting. Such\na design unites object-centric learning representations and image-based\nrendering methods, offering state-of-the-art performance in scene decomposition\nand novel-view synthesis on four challenging synthetic and four complex\nreal-world datasets, outperforming existing 3D object-centric learning methods\nby a large margin. Through extensive ablative studies, we showcase the efficacy\nof designs in SlotLifter, revealing key insights for potential future\ndirections.", "arxiv_id": "2408.06697v1", "pdf_url": "http://arxiv.org/pdf/2408.06697v1", "abstract_url": "http://arxiv.org/abs/2408.06697v1", "primary_category": "cs.CV", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "SlotLifter: Slot-guided Feature Lifting for Learning Object-centric Radiance Fields", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:20.993601"}
{"title": "Model Based and Physics Informed Deep Learning Neural Network Structures", "authors": "Ali Mohammad-Djafari, Ning Chu, Li Wang, Caifang Cai, Liang Yu", "abstract": "Neural Networks (NN) has been used in many areas with great success. When a\nNN's structure (Model) is given, during the training steps, the parameters of\nthe model are determined using an appropriate criterion and an optimization\nalgorithm (Training). Then, the trained model can be used for the prediction or\ninference step (Testing). As there are also many hyperparameters, related to\nthe optimization criteria and optimization algorithms, a validation step is\nnecessary before its final use. One of the great difficulties is the choice of\nthe NN's structure. Even if there are many \"on the shelf\" networks, selecting\nor proposing a new appropriate network for a given data, signal or image\nprocessing, is still an open problem. In this work, we consider this problem\nusing model based signal and image processing and inverse problems methods. We\nclassify the methods in five classes, based on: i) Explicit analytical\nsolutions, ii) Transform domain decomposition, iii) Operator Decomposition, iv)\nOptimization algorithms unfolding, and v) Physics Informed NN methods (PINN).\nFew examples in each category are explained.", "arxiv_id": "2408.07104v1", "pdf_url": "http://arxiv.org/pdf/2408.07104v1", "abstract_url": "http://arxiv.org/abs/2408.07104v1", "primary_category": "cs.LG", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Model Based and Physics Informed Deep Learning Neural Network Structures", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:21.810420"}
{"title": "Masked Image Modeling: A Survey", "authors": "Vlad Hondru, Florinel Alin Croitoru, Shervin Minaee, Radu Tudor Ionescu, Nicu Sebe", "abstract": "In this work, we survey recent studies on masked image modeling (MIM), an\napproach that emerged as a powerful self-supervised learning technique in\ncomputer vision. The MIM task involves masking some information, e.g. pixels,\npatches, or even latent representations, and training a model, usually an\nautoencoder, to predicting the missing information by using the context\navailable in the visible part of the input. We identify and formalize two\ncategories of approaches on how to implement MIM as a pretext task, one based\non reconstruction and one based on contrastive learning. Then, we construct a\ntaxonomy and review the most prominent papers in recent years. We complement\nthe manually constructed taxonomy with a dendrogram obtained by applying a\nhierarchical clustering algorithm. We further identify relevant clusters via\nmanually inspecting the resulting dendrogram. Our review also includes datasets\nthat are commonly used in MIM research. We aggregate the performance results of\nvarious masked image modeling methods on the most popular datasets, to\nfacilitate the comparison of competing methods. Finally, we identify research\ngaps and propose several interesting directions of future work.", "arxiv_id": "2408.06687v1", "pdf_url": "http://arxiv.org/pdf/2408.06687v1", "abstract_url": "http://arxiv.org/abs/2408.06687v1", "primary_category": "cs.CV", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Masked Image Modeling: A Survey", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:22.737634"}
{"title": "Coherence Awareness in Diffractive Neural Networks", "authors": "Matan Kleiner, Lior Michaeli, Tomer Michaeli", "abstract": "Diffractive neural networks hold great promise for applications requiring\nintensive computational processing. Considerable attention has focused on\ndiffractive networks for either spatially coherent or spatially incoherent\nillumination. Here we illustrate that, as opposed to imaging systems, in\ndiffractive networks the degree of spatial coherence has a dramatic effect. In\nparticular, we show that when the spatial coherence length on the object is\ncomparable to the minimal feature size preserved by the optical system, neither\nthe incoherent nor the coherent extremes serve as acceptable approximations.\nImportantly, this situation is inherent to many settings involving active\nillumination, including reflected light microscopy, autonomous vehicles and\nsmartphones. Following this observation, we propose a general framework for\ntraining diffractive networks for any specified degree of spatial and temporal\ncoherence, supporting all types of linear and nonlinear layers. Using our\nmethod, we numerically optimize networks for image classification, and\nthoroughly investigate their performance dependence on the illumination\ncoherence properties. We further introduce the concept of coherence-blind\nnetworks, which have enhanced resilience to changes in illumination conditions.\nOur findings serve as a steppingstone toward adopting all-optical neural\nnetworks in real-world applications, leveraging nothing but natural light.", "arxiv_id": "2408.06681v1", "pdf_url": "http://arxiv.org/pdf/2408.06681v1", "abstract_url": "http://arxiv.org/abs/2408.06681v1", "primary_category": "physics.optics", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Coherence Awareness in Diffractive Neural Networks", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:24.398784"}
{"title": "Case-based Explainability for Random Forest: Prototypes, Critics, Counter-factuals and Semi-factuals", "authors": "Gregory Yampolsky, Dhruv Desai, Mingshu Li, Stefano Pasquali, Dhagash Mehta", "abstract": "The explainability of black-box machine learning algorithms, commonly known\nas Explainable Artificial Intelligence (XAI), has become crucial for financial\nand other regulated industrial applications due to regulatory requirements and\nthe need for transparency in business practices. Among the various paradigms of\nXAI, Explainable Case-Based Reasoning (XCBR) stands out as a pragmatic approach\nthat elucidates the output of a model by referencing actual examples from the\ndata used to train or test the model. Despite its potential, XCBR has been\nrelatively underexplored for many algorithms such as tree-based models until\nrecently. We start by observing that most XCBR methods are defined based on the\ndistance metric learned by the algorithm. By utilizing a recently proposed\ntechnique to extract the distance metric learned by Random Forests (RFs), which\nis both geometry- and accuracy-preserving, we investigate various XCBR methods.\nThese methods amount to identify special points from the training datasets,\nsuch as prototypes, critics, counter-factuals, and semi-factuals, to explain\nthe predictions for a given query of the RF. We evaluate these special points\nusing various evaluation metrics to assess their explanatory power and\neffectiveness.", "arxiv_id": "2408.06679v1", "pdf_url": "http://arxiv.org/pdf/2408.06679v1", "abstract_url": "http://arxiv.org/abs/2408.06679v1", "primary_category": "cs.LG", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Case-based Explainability for Random Forest: Prototypes, Critics, Counter-factuals and Semi-factuals", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:25.191526"}
{"title": "Leveraging Priors via Diffusion Bridge for Time Series Generation", "authors": "Jinseong Park, Seungyun Lee, Woojin Jeong, Yujin Choi, Jaewook Lee", "abstract": "Time series generation is widely used in real-world applications such as\nsimulation, data augmentation, and hypothesis test techniques. Recently,\ndiffusion models have emerged as the de facto approach for time series\ngeneration, emphasizing diverse synthesis scenarios based on historical or\ncorrelated time series data streams. Since time series have unique\ncharacteristics, such as fixed time order and data scaling, standard Gaussian\nprior might be ill-suited for general time series generation. In this paper, we\nexploit the usage of diverse prior distributions for synthesis. Then, we\npropose TimeBridge, a framework that enables flexible synthesis by leveraging\ndiffusion bridges to learn the transport between chosen prior and data\ndistributions. Our model covers a wide range of scenarios in time series\ndiffusion models, which leverages (i) data- and time-dependent priors for\nunconditional synthesis, and (ii) data-scale preserving synthesis with a\nconstraint as a prior for conditional generation. Experimentally, our model\nachieves state-of-the-art performance in both unconditional and conditional\ntime series generation tasks.", "arxiv_id": "2408.06672v1", "pdf_url": "http://arxiv.org/pdf/2408.06672v1", "abstract_url": "http://arxiv.org/abs/2408.06672v1", "primary_category": "cs.LG", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Leveraging Priors via Diffusion Bridge for Time Series Generation", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:26.111693"}
{"title": "RW-NSGCN: A Robust Approach to Structural Attacks via Negative Sampling", "authors": "Shuqi He, Jun Zhuang, Ding Wang, Jun Song", "abstract": "Node classification using Graph Neural Networks (GNNs) has been widely\napplied in various practical scenarios, such as predicting user interests and\ndetecting communities in social networks. However, recent studies have shown\nthat graph-structured networks often contain potential noise and attacks, in\nthe form of topological perturbations and weight disturbances, which can lead\nto decreased classification performance in GNNs. To improve the robustness of\nthe model, we propose a novel method: Random Walk Negative Sampling Graph\nConvolutional Network (RW-NSGCN). Specifically, RW-NSGCN integrates the Random\nWalk with Restart (RWR) and PageRank (PGR) algorithms for negative sampling and\nemploys a Determinantal Point Process (DPP)-based GCN for convolution\noperations. RWR leverages both global and local information to manage noise and\nlocal variations, while PGR assesses node importance to stabilize the\ntopological structure. The DPP-based GCN ensures diversity among negative\nsamples and aggregates their features to produce robust node embeddings,\nthereby improving classification performance. Experimental results demonstrate\nthat the RW-NSGCN model effectively addresses network topology attacks and\nweight instability, increasing the accuracy of anomaly detection and overall\nstability. In terms of classification accuracy, RW-NSGCN significantly\noutperforms existing methods, showing greater resilience across various\nscenarios and effectively mitigating the impact of such vulnerabilities.", "arxiv_id": "2408.06665v1", "pdf_url": "http://arxiv.org/pdf/2408.06665v1", "abstract_url": "http://arxiv.org/abs/2408.06665v1", "primary_category": "cs.LG", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "RW-NSGCN: A Robust Approach to Structural Attacks via Negative Sampling", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:26.930460"}
{"title": "COD: Learning Conditional Invariant Representation for Domain Adaptation Regression", "authors": "Hao-Ran Yang, Chuan-Xian Ren, You-Wei Luo", "abstract": "Aiming to generalize the label knowledge from a source domain with continuous\noutputs to an unlabeled target domain, Domain Adaptation Regression (DAR) is\ndeveloped for complex practical learning problems. However, due to the\ncontinuity problem in regression, existing conditional distribution alignment\ntheory and methods with discrete prior, which are proven to be effective in\nclassification settings, are no longer applicable. In this work, focusing on\nthe feasibility problems in DAR, we establish the sufficiency theory for the\nregression model, which shows the generalization error can be sufficiently\ndominated by the cross-domain conditional discrepancy. Further, to characterize\nconditional discrepancy with continuous conditioning variable, a novel\nConditional Operator Discrepancy (COD) is proposed, which admits the metric\nproperty on conditional distributions via the kernel embedding theory. Finally,\nto minimize the discrepancy, a COD-based conditional invariant representation\nlearning model is proposed, and the reformulation is derived to show that\nreasonable modifications on moment statistics can further improve the\ndiscriminability of the adaptation model. Extensive experiments on standard DAR\ndatasets verify the validity of theoretical results and the superiority over\nSOTA DAR methods.", "arxiv_id": "2408.06638v1", "pdf_url": "http://arxiv.org/pdf/2408.06638v1", "abstract_url": "http://arxiv.org/abs/2408.06638v1", "primary_category": "cs.LG", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "COD: Learning Conditional Invariant Representation for Domain Adaptation Regression", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:27.766793"}
{"title": "Harnessing Earnings Reports for Stock Predictions: A QLoRA-Enhanced LLM Approach", "authors": "Haowei Ni, Shuchen Meng, Xupeng Chen, Ziqing Zhao, Andi Chen, Panfeng Li, Shiyao Zhang, Qifu Yin, Yuanqing Wang, Yuxi Chan", "abstract": "Accurate stock market predictions following earnings reports are crucial for\ninvestors. Traditional methods, particularly classical machine learning models,\nstruggle with these predictions because they cannot effectively process and\ninterpret extensive textual data contained in earnings reports and often\noverlook nuances that influence market movements. This paper introduces an\nadvanced approach by employing Large Language Models (LLMs) instruction\nfine-tuned with a novel combination of instruction-based techniques and\nquantized low-rank adaptation (QLoRA) compression. Our methodology integrates\n'base factors', such as financial metric growth and earnings transcripts, with\n'external factors', including recent market indices performances and analyst\ngrades, to create a rich, supervised dataset. This comprehensive dataset\nenables our models to achieve superior predictive performance in terms of\naccuracy, weighted F1, and Matthews correlation coefficient (MCC), especially\nevident in the comparison with benchmarks such as GPT-4. We specifically\nhighlight the efficacy of the llama-3-8b-Instruct-4bit model, which showcases\nsignificant improvements over baseline models. The paper also discusses the\npotential of expanding the output capabilities to include a 'Hold' option and\nextending the prediction horizon, aiming to accommodate various investment\nstyles and time frames. This study not only demonstrates the power of\nintegrating cutting-edge AI with fine-tuned financial data but also paves the\nway for future research in enhancing AI-driven financial analysis tools.", "arxiv_id": "2408.06634v1", "pdf_url": "http://arxiv.org/pdf/2408.06634v1", "abstract_url": "http://arxiv.org/abs/2408.06634v1", "primary_category": "q-fin.CP", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Harnessing Earnings Reports for Stock Predictions: A QLoRA-Enhanced LLM Approach", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:28.503213"}
{"title": "Towards Robust and Cost-Efficient Knowledge Unlearning for Large Language Models", "authors": "Sungmin Cha, Sungjun Cho, Dasol Hwang, Moontae Lee", "abstract": "Large Language Models (LLMs) have demonstrated strong reasoning and\nmemorization capabilities via pretraining on massive textual corpora. However,\ntraining LLMs on human-written text entails significant risk of privacy and\ncopyright violations, which demands an efficient machine unlearning framework\nto remove knowledge of sensitive data without retraining the model from\nscratch. While Gradient Ascent (GA) is widely used for unlearning by reducing\nthe likelihood of generating unwanted information, the unboundedness of\nincreasing the cross-entropy loss causes not only unstable optimization, but\nalso catastrophic forgetting of knowledge that needs to be retained. We also\ndiscover its joint application under low-rank adaptation results in\nsignificantly suboptimal computational cost vs. generative performance\ntrade-offs. In light of this limitation, we propose two novel techniques for\nrobust and cost-efficient unlearning on LLMs. We first design an Inverted Hinge\nloss that suppresses unwanted tokens by increasing the probability of the next\nmost likely token, thereby retaining fluency and structure in language\ngeneration. We also propose to initialize low-rank adapter weights based on\nFisher-weighted low-rank approximation, which induces faster unlearning and\nbetter knowledge retention by allowing model updates to be focused on\nparameters that are important in generating textual data we wish to remove.", "arxiv_id": "2408.06621v1", "pdf_url": "http://arxiv.org/pdf/2408.06621v1", "abstract_url": "http://arxiv.org/abs/2408.06621v1", "primary_category": "cs.LG", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Towards Robust and Cost-Efficient Knowledge Unlearning for Large Language Models", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:29.176551"}
{"title": "Unveiling the Flaws: A Critical Analysis of Initialization Effect on Time Series Anomaly Detection", "authors": "Alex Koran, Hadi Hojjati, Narges Armanfard", "abstract": "Deep learning for time-series anomaly detection (TSAD) has gained significant\nattention over the past decade. Despite the reported improvements in several\npapers, the practical application of these models remains limited. Recent\nstudies have cast doubt on these models, attributing their results to flawed\nevaluation techniques. However, the impact of initialization has largely been\noverlooked. This paper provides a critical analysis of the initialization\neffects on TSAD model performance. Our extensive experiments reveal that TSAD\nmodels are highly sensitive to hyperparameters such as window size, seed\nnumber, and normalization. This sensitivity often leads to significant\nvariability in performance, which can be exploited to artificially inflate the\nreported efficacy of these models. We demonstrate that even minor changes in\ninitialization parameters can result in performance variations that overshadow\nthe claimed improvements from novel model architectures. Our findings highlight\nthe need for rigorous evaluation protocols and transparent reporting of\npreprocessing steps to ensure the reliability and fairness of anomaly detection\nmethods. This paper calls for a more cautious interpretation of TSAD\nadvancements and encourages the development of more robust and transparent\nevaluation practices to advance the field and its practical applications.", "arxiv_id": "2408.06620v1", "pdf_url": "http://arxiv.org/pdf/2408.06620v1", "abstract_url": "http://arxiv.org/abs/2408.06620v1", "primary_category": "cs.LG", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Unveiling the Flaws: A Critical Analysis of Initialization Effect on Time Series Anomaly Detection", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:29.952646"}
{"title": "Generalized knowledge-enhanced framework for biomedical entity and relation extraction", "authors": "Minh Nguyen, Phuong Le", "abstract": "In recent years, there has been an increasing number of frameworks developed\nfor biomedical entity and relation extraction. This research effort aims to\naddress the accelerating growth in biomedical publications and the intricate\nnature of biomedical texts, which are written for mainly domain experts. To\nhandle these challenges, we develop a novel framework that utilizes external\nknowledge to construct a task-independent and reusable background knowledge\ngraph for biomedical entity and relation extraction. The design of our model is\ninspired by how humans learn domain-specific topics. In particular, humans\noften first acquire the most basic and common knowledge regarding a field to\nbuild the foundational knowledge and then use that as a basis for extending to\nvarious specialized topics. Our framework employs such common-knowledge-sharing\nmechanism to build a general neural-network knowledge graph that is learning\ntransferable to different domain-specific biomedical texts effectively.\nExperimental evaluations demonstrate that our model, equipped with this\ngeneralized and cross-transferable knowledge base, achieves competitive\nperformance benchmarks, including BioRelEx for binding interaction detection\nand ADE for Adverse Drug Effect identification.", "arxiv_id": "2408.06618v1", "pdf_url": "http://arxiv.org/pdf/2408.06618v1", "abstract_url": "http://arxiv.org/abs/2408.06618v1", "primary_category": "cs.CL", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Generalized knowledge-enhanced framework for biomedical entity and relation extraction", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:30.718954"}
{"title": "CROME: Cross-Modal Adapters for Efficient Multimodal LLM", "authors": "Sayna Ebrahimi, Sercan O. Arik, Tejas Nama, Tomas Pfister", "abstract": "Multimodal Large Language Models (MLLMs) demonstrate remarkable\nimage-language capabilities, but their widespread use faces challenges in\ncost-effective training and adaptation. Existing approaches often necessitate\nexpensive language model retraining and limited adaptability. Additionally, the\ncurrent focus on zero-shot performance improvements offers insufficient\nguidance for task-specific tuning. We propose CROME, an efficient\nvision-language instruction tuning framework. It features a novel gated\ncross-modal adapter that effectively combines visual and textual\nrepresentations prior to input into a frozen LLM. This lightweight adapter,\ntrained with minimal parameters, enables efficient cross-modal understanding.\nNotably, CROME demonstrates superior zero-shot performance on standard visual\nquestion answering and instruction-following benchmarks. Moreover, it yields\nfine-tuning with exceptional parameter efficiency, competing with task-specific\nspecialist state-of-the-art methods. CROME demonstrates the potential of pre-LM\nalignment for building scalable, adaptable, and parameter-efficient multimodal\nmodels.", "arxiv_id": "2408.06610v1", "pdf_url": "http://arxiv.org/pdf/2408.06610v1", "abstract_url": "http://arxiv.org/abs/2408.06610v1", "primary_category": "cs.CV", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "CROME: Cross-Modal Adapters for Efficient Multimodal LLM", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:31.743232"}
{"title": "Prioritizing Modalities: Flexible Importance Scheduling in Federated Multimodal Learning", "authors": "Jieming Bian, Lei Wang, Jie Xu", "abstract": "Federated Learning (FL) is a distributed machine learning approach that\nenables devices to collaboratively train models without sharing their local\ndata, ensuring user privacy and scalability. However, applying FL to real-world\ndata presents challenges, particularly as most existing FL research focuses on\nunimodal data. Multimodal Federated Learning (MFL) has emerged to address these\nchallenges, leveraging modality-specific encoder models to process diverse\ndatasets. Current MFL methods often uniformly allocate computational\nfrequencies across all modalities, which is inefficient for IoT devices with\nlimited resources. In this paper, we propose FlexMod, a novel approach to\nenhance computational efficiency in MFL by adaptively allocating training\nresources for each modality encoder based on their importance and training\nrequirements. We employ prototype learning to assess the quality of modality\nencoders, use Shapley values to quantify the importance of each modality, and\nadopt the Deep Deterministic Policy Gradient (DDPG) method from deep\nreinforcement learning to optimize the allocation of training resources. Our\nmethod prioritizes critical modalities, optimizing model performance and\nresource utilization. Experimental results on three real-world datasets\ndemonstrate that our proposed method significantly improves the performance of\nMFL models.", "arxiv_id": "2408.06549v1", "pdf_url": "http://arxiv.org/pdf/2408.06549v1", "abstract_url": "http://arxiv.org/abs/2408.06549v1", "primary_category": "cs.LG", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Prioritizing Modalities: Flexible Importance Scheduling in Federated Multimodal Learning", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:32.665849"}
{"title": "Variance-Reduced Cascade Q-learning: Algorithms and Sample Complexity", "authors": "Mohammad Boveiri, Peyman Mohajerin Esfahani", "abstract": "We study the problem of estimating the optimal Q-function of\n$\\gamma$-discounted Markov decision processes (MDPs) under the synchronous\nsetting, where independent samples for all state-action pairs are drawn from a\ngenerative model at each iteration. We introduce and analyze a novel model-free\nalgorithm called Variance-Reduced Cascade Q-learning (VRCQ). VRCQ comprises two\nkey building blocks: (i) the established direct variance reduction technique\nand (ii) our proposed variance reduction scheme, Cascade Q-learning. By\nleveraging these techniques, VRCQ provides superior guarantees in the\n$\\ell_\\infty$-norm compared with the existing model-free stochastic\napproximation-type algorithms. Specifically, we demonstrate that VRCQ is\nminimax optimal. Additionally, when the action set is a singleton (so that the\nQ-learning problem reduces to policy evaluation), it achieves non-asymptotic\ninstance optimality while requiring the minimum number of samples theoretically\npossible. Our theoretical results and their practical implications are\nsupported by numerical experiments.", "arxiv_id": "2408.06544v1", "pdf_url": "http://arxiv.org/pdf/2408.06544v1", "abstract_url": "http://arxiv.org/abs/2408.06544v1", "primary_category": "stat.ML", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Variance-Reduced Cascade Q-learning: Algorithms and Sample Complexity", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:33.587170"}
{"title": "Value of Information and Reward Specification in Active Inference and POMDPs", "authors": "Ran Wei", "abstract": "Expected free energy (EFE) is a central quantity in active inference which\nhas recently gained popularity due to its intuitive decomposition of the\nexpected value of control into a pragmatic and an epistemic component. While\nnumerous conjectures have been made to justify EFE as a decision making\nobjective function, the most widely accepted is still its intuitiveness and\nresemblance to variational free energy in approximate Bayesian inference. In\nthis work, we take a bottom up approach and ask: taking EFE as given, what's\nthe resulting agent's optimality gap compared with a reward-driven\nreinforcement learning (RL) agent, which is well understood? By casting EFE\nunder a particular class of belief MDP and using analysis tools from RL theory,\nwe show that EFE approximates the Bayes optimal RL policy via information\nvalue. We discuss the implications for objective specification of active\ninference agents.", "arxiv_id": "2408.06542v1", "pdf_url": "http://arxiv.org/pdf/2408.06542v1", "abstract_url": "http://arxiv.org/abs/2408.06542v1", "primary_category": "cs.AI", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Value of Information and Reward Specification in Active Inference and POMDPs", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:35.769333"}
{"title": "Dynamic Exclusion of Low-Fidelity Data in Bayesian Optimization for Autonomous Beamline Alignment", "authors": "Megha R. Narayanan, Thomas W. Morris", "abstract": "Aligning beamlines at synchrotron light sources is a high-dimensional,\nexpensive-to-sample optimization problem, as beams are focused using a series\nof dynamic optical components. Bayesian Optimization is an efficient machine\nlearning approach to finding global optima of beam quality, but the model can\neasily be impaired by faulty data points caused by the beam going off the edge\nof the sensor or by background noise. This study, conducted at the National\nSynchrotron Light Source II (NSLS-II) facility at Brookhaven National\nLaboratory (BNL), is an investigation of methods to identify untrustworthy\nreadings of beam quality and discourage the optimization model from seeking out\npoints likely to yield low-fidelity beams. The approaches explored include\ndynamic pruning using loss analysis of size and position models and a\nlengthscale-based genetic algorithm to determine which points to include in the\nmodel for optimal fit. Each method successfully classified high and low\nfidelity points. This research advances BNL's mission to tackle our nation's\nenergy challenges by providing scientists at all beamlines with access to\nhigher quality beams, and faster convergence to these optima for their\nexperiments.", "arxiv_id": "2408.06540v1", "pdf_url": "http://arxiv.org/pdf/2408.06540v1", "abstract_url": "http://arxiv.org/abs/2408.06540v1", "primary_category": "physics.acc-ph", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Dynamic Exclusion of Low-Fidelity Data in Bayesian Optimization for Autonomous Beamline Alignment", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:37.001878"}
{"title": "A Comparison of Imitation Learning Algorithms for Bimanual Manipulation", "authors": "Michael Drolet, Simon Stepputtis, Siva Kailas, Ajinkya Jain, Jan Peters, Stefan Schaal, Heni Ben Amor", "abstract": "Amidst the wide popularity of imitation learning algorithms in robotics,\ntheir properties regarding hyperparameter sensitivity, ease of training, data\nefficiency, and performance have not been well-studied in high-precision\nindustry-inspired environments. In this work, we demonstrate the limitations\nand benefits of prominent imitation learning approaches and analyze their\ncapabilities regarding these properties. We evaluate each algorithm on a\ncomplex bimanual manipulation task involving an over-constrained dynamics\nsystem in a setting involving multiple contacts between the manipulated object\nand the environment. While we find that imitation learning is well suited to\nsolve such complex tasks, not all algorithms are equal in terms of handling\nenvironmental and hyperparameter perturbations, training requirements,\nperformance, and ease of use. We investigate the empirical influence of these\nkey characteristics by employing a carefully designed experimental procedure\nand learning environment. Paper website: https://bimanual-imitation.github.io/", "arxiv_id": "2408.06536v1", "pdf_url": "http://arxiv.org/pdf/2408.06536v1", "abstract_url": "http://arxiv.org/abs/2408.06536v1", "primary_category": "cs.RO", "published_date": "2024-08-13", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "A Comparison of Imitation Learning Algorithms for Bimanual Manipulation", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:37.887609"}
{"title": "Operator Learning Using Random Features: A Tool for Scientific Computing", "authors": "Nicholas H. Nelsen, Andrew M. Stuart", "abstract": "Supervised operator learning centers on the use of training data, in the form\nof input-output pairs, to estimate maps between infinite-dimensional spaces. It\nis emerging as a powerful tool to complement traditional scientific computing,\nwhich may often be framed in terms of operators mapping between spaces of\nfunctions. Building on the classical random features methodology for scalar\nregression, this paper introduces the function-valued random features method.\nThis leads to a supervised operator learning architecture that is practical for\nnonlinear problems yet is structured enough to facilitate efficient training\nthrough the optimization of a convex, quadratic cost. Due to the quadratic\nstructure, the trained model is equipped with convergence guarantees and error\nand complexity bounds, properties that are not readily available for most other\noperator learning architectures. At its core, the proposed approach builds a\nlinear combination of random operators. This turns out to be a low-rank\napproximation of an operator-valued kernel ridge regression algorithm, and\nhence the method also has strong connections to Gaussian process regression.\nThe paper designs function-valued random features that are tailored to the\nstructure of two nonlinear operator learning benchmark problems arising from\nparametric partial differential equations. Numerical results demonstrate the\nscalability, discretization invariance, and transferability of the\nfunction-valued random features method.", "arxiv_id": "2408.06526v1", "pdf_url": "http://arxiv.org/pdf/2408.06526v1", "abstract_url": "http://arxiv.org/abs/2408.06526v1", "primary_category": "cs.LG", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Operator Learning Using Random Features: A Tool for Scientific Computing", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:38.555276"}
{"title": "The NP-hardness of the Gromov-Wasserstein distance", "authors": "Natalia Kravtsova", "abstract": "This note addresses the property frequently mentioned in the literature that\nthe Gromov-Wasserstein (GW) distance is NP-hard. We provide the details on the\nnon-convex nature of the GW optimization problem that imply NP-hardness of the\nGW distance between finite spaces for any instance of an input data. We further\nillustrate the non-convexity of the problem with several explicit examples.", "arxiv_id": "2408.06525v1", "pdf_url": "http://arxiv.org/pdf/2408.06525v1", "abstract_url": "http://arxiv.org/abs/2408.06525v1", "primary_category": "stat.ML", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "NOT_ENOUGH_RELATED"}
{"title": "The NP-hardness of the Gromov-Wasserstein distance", "response": "NOT_ENOUGH_RELATED", "timestamp": "2024-08-19T13:36:39.534961"}
{"title": "From Graphs to Qubits: A Critical Review of Quantum Graph Neural Networks", "authors": "Andrea Ceschini, Francesco Mauro, Francesca De Falco, Alessandro Sebastianelli, Alessio Verdone, Antonello Rosato, Bertrand Le Saux, Massimo Panella, Paolo Gamba, Silvia L. Ullo", "abstract": "Quantum Graph Neural Networks (QGNNs) represent a novel fusion of quantum\ncomputing and Graph Neural Networks (GNNs), aimed at overcoming the\ncomputational and scalability challenges inherent in classical GNNs that are\npowerful tools for analyzing data with complex relational structures but suffer\nfrom limitations such as high computational complexity and over-smoothing in\nlarge-scale applications. Quantum computing, leveraging principles like\nsuperposition and entanglement, offers a pathway to enhanced computational\ncapabilities. This paper critically reviews the state-of-the-art in QGNNs,\nexploring various architectures. We discuss their applications across diverse\nfields such as high-energy physics, molecular chemistry, finance and earth\nsciences, highlighting the potential for quantum advantage. Additionally, we\naddress the significant challenges faced by QGNNs, including noise,\ndecoherence, and scalability issues, proposing potential strategies to mitigate\nthese problems. This comprehensive review aims to provide a foundational\nunderstanding of QGNNs, fostering further research and development in this\npromising interdisciplinary field.", "arxiv_id": "2408.06524v1", "pdf_url": "http://arxiv.org/pdf/2408.06524v1", "abstract_url": "http://arxiv.org/abs/2408.06524v1", "primary_category": "quant-ph", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "From Graphs to Qubits: A Critical Review of Quantum Graph Neural Networks", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:40.755734"}
{"title": "Learned Ranking Function: From Short-term Behavior Predictions to Long-term User Satisfaction", "authors": "Yi Wu, Daryl Chang, Jennifer She, Zhe Zhao, Li Wei, Lukasz Heldt", "abstract": "We present the Learned Ranking Function (LRF), a system that takes short-term\nuser-item behavior predictions as input and outputs a slate of recommendations\nthat directly optimizes for long-term user satisfaction. Most previous work is\nbased on optimizing the hyperparameters of a heuristic function. We propose to\nmodel the problem directly as a slate optimization problem with the objective\nof maximizing long-term user satisfaction. We also develop a novel constraint\noptimization algorithm that stabilizes objective trade-offs for multi-objective\noptimization. We evaluate our approach with live experiments and describe its\ndeployment on YouTube.", "arxiv_id": "2408.06512v1", "pdf_url": "http://arxiv.org/pdf/2408.06512v1", "abstract_url": "http://arxiv.org/abs/2408.06512v1", "primary_category": "cs.LG", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Learned Ranking Function: From Short-term Behavior Predictions to Long-term User Satisfaction", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:41.484685"}
{"title": "Fooling SHAP with Output Shuffling Attacks", "authors": "Jun Yuan, Aritra Dasgupta", "abstract": "Explainable AI~(XAI) methods such as SHAP can help discover feature\nattributions in black-box models. If the method reveals a significant\nattribution from a ``protected feature'' (e.g., gender, race) on the model\noutput, the model is considered unfair. However, adversarial attacks can\nsubvert the detection of XAI methods. Previous approaches to constructing such\nan adversarial model require access to underlying data distribution, which may\nnot be possible in many practical scenarios. We relax this constraint and\npropose a novel family of attacks, called shuffling attacks, that are\ndata-agnostic. The proposed attack strategies can adapt any trained machine\nlearning model to fool Shapley value-based explanations. We prove that Shapley\nvalues cannot detect shuffling attacks. However, algorithms that estimate\nShapley values, such as linear SHAP and SHAP, can detect these attacks with\nvarying degrees of effectiveness. We demonstrate the efficacy of the attack\nstrategies by comparing the performance of linear SHAP and SHAP using\nreal-world datasets.", "arxiv_id": "2408.06509v1", "pdf_url": "http://arxiv.org/pdf/2408.06509v1", "abstract_url": "http://arxiv.org/abs/2408.06509v1", "primary_category": "cs.LG", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Fooling SHAP with Output Shuffling Attacks", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:42.186623"}
{"title": "Prompt Recovery for Image Generation Models: A Comparative Study of Discrete Optimizers", "authors": "Joshua Nathaniel Williams, Avi Schwarzschild, J. Zico Kolter", "abstract": "Recovering natural language prompts for image generation models, solely based\non the generated images is a difficult discrete optimization problem. In this\nwork, we present the first head-to-head comparison of recent discrete\noptimization techniques for the problem of prompt inversion. We evaluate Greedy\nCoordinate Gradients (GCG), PEZ , Random Search, AutoDAN and BLIP2's image\ncaptioner across various evaluation metrics related to the quality of inverted\nprompts and the quality of the images generated by the inverted prompts. We\nfind that focusing on the CLIP similarity between the inverted prompts and the\nground truth image acts as a poor proxy for the similarity between ground truth\nimage and the image generated by the inverted prompts. While the discrete\noptimizers effectively minimize their objectives, simply using responses from a\nwell-trained captioner often leads to generated images that more closely\nresemble those produced by the original prompts.", "arxiv_id": "2408.06502v1", "pdf_url": "http://arxiv.org/pdf/2408.06502v1", "abstract_url": "http://arxiv.org/abs/2408.06502v1", "primary_category": "cs.CV", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Prompt Recovery for Image Generation Models: A Comparative Study of Discrete Optimizers", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:42.885152"}
{"title": "Music2Latent: Consistency Autoencoders for Latent Audio Compression", "authors": "Marco Pasini, Stefan Lattner, George Fazekas", "abstract": "Efficient audio representations in a compressed continuous latent space are\ncritical for generative audio modeling and Music Information Retrieval (MIR)\ntasks. However, some existing audio autoencoders have limitations, such as\nmulti-stage training procedures, slow iterative sampling, or low reconstruction\nquality. We introduce Music2Latent, an audio autoencoder that overcomes these\nlimitations by leveraging consistency models. Music2Latent encodes samples into\na compressed continuous latent space in a single end-to-end training process\nwhile enabling high-fidelity single-step reconstruction. Key innovations\ninclude conditioning the consistency model on upsampled encoder outputs at all\nlevels through cross connections, using frequency-wise self-attention to\ncapture long-range frequency dependencies, and employing frequency-wise learned\nscaling to handle varying value distributions across frequencies at different\nnoise levels. We demonstrate that Music2Latent outperforms existing continuous\naudio autoencoders in sound quality and reconstruction accuracy while achieving\ncompetitive performance on downstream MIR tasks using its latent\nrepresentations. To our knowledge, this represents the first successful attempt\nat training an end-to-end consistency autoencoder model.", "arxiv_id": "2408.06500v1", "pdf_url": "http://arxiv.org/pdf/2408.06500v1", "abstract_url": "http://arxiv.org/abs/2408.06500v1", "primary_category": "cs.SD", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Music2Latent: Consistency Autoencoders for Latent Audio Compression", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:43.676799"}
{"title": "Implicit Neural Representation For Accurate CFD Flow Field Prediction", "authors": "Laurent de Vito, Nils Pinnau, Simone Dey", "abstract": "Despite the plethora of deep learning frameworks for flow field prediction,\nmost of them deal with flow fields on regular domains, and although the best\nones can cope with irregular domains, they mostly rely on graph networks, so\nthat real industrial applications remain currently elusive. We present a deep\nlearning framework for 3D flow field prediction applied to blades of aircraft\nengine turbines and compressors. Crucially, we view any 3D field as a function\nfrom coordinates that is modeled by a neural network we call the backbone-net.\nIt inherits the property of coordinate-based MLPs, namely the\ndiscretization-agnostic representation of flow fields in domains of arbitrary\ntopology at infinite resolution. First, we demonstrate the performance of the\nbackbone-net solo in regressing 3D steady simulations of single blade rows in\nvarious flow regimes: it can accurately render important flow characteristics\nsuch as boundary layers, wakes and shock waves. Second, we introduce a\nhyper-net that maps the surface mesh of a blade to the parameters of the\nbackbone-net. By doing so, the flow solution can be directly predicted from the\nblade geometry, irrespective of its parameterization. Together, backbone-net\nand hyper-net form a highly-accurate memory-efficient data-driven proxy to CFD\nsolvers with good generalization on unseen geometries.", "arxiv_id": "2408.06486v1", "pdf_url": "http://arxiv.org/pdf/2408.06486v1", "abstract_url": "http://arxiv.org/abs/2408.06486v1", "primary_category": "cs.LG", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Implicit Neural Representation For Accurate CFD Flow Field Prediction", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:44.470184"}
{"title": "Kernel Sum of Squares for Data Adapted Kernel Learning of Dynamical Systems from Data: A global optimization approach", "authors": "Daniel Lengyel, Panos Parpas, Boumediene Hamzi, Houman Owhadi", "abstract": "This paper examines the application of the Kernel Sum of Squares (KSOS)\nmethod for enhancing kernel learning from data, particularly in the context of\ndynamical systems. Traditional kernel-based methods, despite their theoretical\nsoundness and numerical efficiency, frequently struggle with selecting optimal\nbase kernels and parameter tuning, especially with gradient-based methods prone\nto local optima. KSOS mitigates these issues by leveraging a global\noptimization framework with kernel-based surrogate functions, thereby achieving\nmore reliable and precise learning of dynamical systems. Through comprehensive\nnumerical experiments on the Logistic Map, Henon Map, and Lorentz System, KSOS\nis shown to consistently outperform gradient descent in minimizing the\nrelative-$\\rho$ metric and improving kernel accuracy. These results highlight\nKSOS's effectiveness in predicting the behavior of chaotic dynamical systems,\ndemonstrating its capability to adapt kernels to underlying dynamics and\nenhance the robustness and predictive power of kernel-based approaches, making\nit a valuable asset for time series analysis in various scientific fields.", "arxiv_id": "2408.06465v1", "pdf_url": "http://arxiv.org/pdf/2408.06465v1", "abstract_url": "http://arxiv.org/abs/2408.06465v1", "primary_category": "cs.LG", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Kernel Sum of Squares for Data Adapted Kernel Learning of Dynamical Systems from Data: A global optimization approach", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:45.197338"}
{"title": "Wireless Channel Aware Data Augmentation Methods for Deep Leaning-Based Indoor Localization", "authors": "Omer Gokalp Serbetci, Daoud Burghal, Andreas F. Molisch", "abstract": "Indoor localization is a challenging problem that - unlike outdoor\nlocalization - lacks a universal and robust solution. Machine Learning (ML),\nparticularly Deep Learning (DL), methods have been investigated as a promising\napproach. Although such methods bring remarkable localization accuracy, they\nheavily depend on the training data collected from the environment. The data\ncollection is usually a laborious and time-consuming task, but Data\nAugmentation (DA) can be used to alleviate this issue. In this paper, different\nfrom previously used DA, we propose methods that utilize the domain knowledge\nabout wireless propagation channels and devices. The methods exploit the\ntypical hardware component drift in the transceivers and/or the statistical\nbehavior of the channel, in combination with the measured Power Delay Profile\n(PDP). We comprehensively evaluate the proposed methods to demonstrate their\neffectiveness. This investigation mainly focuses on the impact of factors such\nas the number of measurements, augmentation proportion, and the environment of\ninterest impact the effectiveness of the different DA methods. We show that in\nthe low-data regime (few actual measurements available), localization accuracy\nincreases up to 50%, matching non-augmented results in the high-data regime. In\naddition, the proposed methods may outperform the measurement-only high-data\nperformance by up to 33% using only 1/4 of the amount of measured data. We also\nexhibit the effect of different training data distribution and quality on the\neffectiveness of DA. Finally, we demonstrate the power of the proposed methods\nwhen employed along with Transfer Learning (TL) to address the data scarcity in\ntarget and/or source environments.", "arxiv_id": "2408.06452v1", "pdf_url": "http://arxiv.org/pdf/2408.06452v1", "abstract_url": "http://arxiv.org/abs/2408.06452v1", "primary_category": "eess.SY", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Wireless Channel Aware Data Augmentation Methods for Deep Leaning-Based Indoor Localization", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:46.017257"}
{"title": "Evaluating Language Models for Efficient Code Generation", "authors": "Jiawei Liu, Songrun Xie, Junhao Wang, Yuxiang Wei, Yifeng Ding, Lingming Zhang", "abstract": "We introduce Differential Performance Evaluation (DPE), a framework designed\nto reliably evaluate Large Language Models (LLMs) for efficient code\ngeneration. Traditional coding benchmarks often fail to provide reliable\ninsights into code efficiency, due to their reliance on simplistic test inputs\nand the absence of effective compound metrics. DPE addresses these issues by\nfocusing on efficiency-demanding programming tasks and establishing an\ninsightful compound metric for performance evaluation. DPE operates in two\nphases: To curate efficiency datasets, it selects efficiency-demanding tasks\nfrom existing coding benchmarks and generates computationally expensive inputs\nto stress the efficiency of LLM solutions. To assess the code efficiency, DPE\nprofiles the new solution and compares it globally against a set of reference\nsolutions that exhibit distinct efficiency levels, where the matched level\ndefines its efficiency score. As a proof of concept, we use DPE to create\nEvalPerf, a benchmark with 121 performance-challenging coding tasks. Our\ncomprehensive evaluation draws interesting findings on the efficiency impact of\nmodel sizes, instruction tuning, and prompting. For example, while the scaling\nlaw fails to account for code efficiency, general instruction tuning benefits\nboth code correctness and efficiency. We also evaluate the evaluation by\nexamining the effectiveness of DPE, showing that EvalPerf is reliable and\nconvenient to use even across platforms.", "arxiv_id": "2408.06450v1", "pdf_url": "http://arxiv.org/pdf/2408.06450v1", "abstract_url": "http://arxiv.org/abs/2408.06450v1", "primary_category": "cs.SE", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Evaluating Language Models for Efficient Code Generation", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:46.796212"}
{"title": "Multi-View Neural Differential Equations for Continuous-Time Stream Data in Long-Term Traffic Forecasting", "authors": "Zibo Liu, Zhe Jiang, Shigang Chen", "abstract": "Long-term traffic flow forecasting plays a crucial role in intelligent\ntransportation as it allows traffic managers to adjust their decisions in\nadvance. However, the problem is challenging due to spatio-temporal\ncorrelations and complex dynamic patterns in continuous-time stream data.\nNeural Differential Equations (NDEs) are among the state-of-the-art methods for\nlearning continuous-time traffic dynamics. However, the traditional NDE models\nface issues in long-term traffic forecasting due to failures in capturing\ndelayed traffic patterns, dynamic edge (location-to-location correlation)\npatterns, and abrupt trend patterns. To fill this gap, we propose a new NDE\narchitecture called Multi-View Neural Differential Equations. Our model\ncaptures current states, delayed states, and trends in different state\nvariables (views) by learning latent multiple representations within Neural\nDifferential Equations. Extensive experiments conducted on several real-world\ntraffic datasets demonstrate that our proposed method outperforms the\nstate-of-the-art and achieves superior prediction accuracy for long-term\nforecasting and robustness with noisy or missing inputs.", "arxiv_id": "2408.06445v1", "pdf_url": "http://arxiv.org/pdf/2408.06445v1", "abstract_url": "http://arxiv.org/abs/2408.06445v1", "primary_category": "cs.LG", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Multi-View Neural Differential Equations for Continuous-Time Stream Data in Long-Term Traffic Forecasting", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:47.500555"}
{"title": "Bayesian Learning in a Nonlinear Multiscale State-Space Model", "authors": "Nayely V\u00e9lez-Cruz, Manfred D. Laubichler", "abstract": "The ubiquity of multiscale interactions in complex systems is\nwell-recognized, with development and heredity serving as a prime example of\nhow processes at different temporal scales influence one another. This work\nintroduces a novel multiscale state-space model to explore the dynamic\ninterplay between systems interacting across different time scales, with\nfeedback between each scale. We propose a Bayesian learning framework to\nestimate unknown states by learning the unknown process noise covariances\nwithin this multiscale model. We develop a Particle Gibbs with Ancestor\nSampling (PGAS) algorithm for inference and demonstrate through simulations the\nefficacy of our approach.", "arxiv_id": "2408.06425v2", "pdf_url": "http://arxiv.org/pdf/2408.06425v2", "abstract_url": "http://arxiv.org/abs/2408.06425v2", "primary_category": "eess.SP", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "NOT_ENOUGH_RELATED"}
{"title": "Bayesian Learning in a Nonlinear Multiscale State-Space Model", "response": "NOT_ENOUGH_RELATED", "timestamp": "2024-08-19T13:36:48.307759"}
{"title": "Neural Networks as Spin Models: From Glass to Hidden Order Through Training", "authors": "Richard Barney, Michael Winer, Victor Galitski", "abstract": "We explore a one-to-one correspondence between a neural network (NN) and a\nstatistical mechanical spin model where neurons are mapped to Ising spins and\nweights to spin-spin couplings. The process of training an NN produces a family\nof spin Hamiltonians parameterized by training time. We study the magnetic\nphases and the melting transition temperature as training progresses. First, we\nprove analytically that the common initial state before training--an NN with\nindependent random weights--maps to a layered version of the classical\nSherrington-Kirkpatrick spin glass exhibiting a replica symmetry breaking. The\nspin-glass-to-paramagnet transition temperature is calculated. Further, we use\nthe Thouless-Anderson-Palmer (TAP) equations--a theoretical technique to\nanalyze the landscape of energy minima of random systems--to determine the\nevolution of the magnetic phases on two types of NNs (one with continuous and\none with binarized activations) trained on the MNIST dataset. The two NN types\ngive rise to similar results, showing a quick destruction of the spin glass and\nthe appearance of a phase with a hidden order, whose melting transition\ntemperature $T_c$ grows as a power law in training time. We also discuss the\nproperties of the spectrum of the spin system's bond matrix in the context of\nrich vs. lazy learning. We suggest that this statistical mechanical view of NNs\nprovides a useful unifying perspective on the training process, which can be\nviewed as selecting and strengthening a symmetry-broken state associated with\nthe training task.", "arxiv_id": "2408.06421v1", "pdf_url": "http://arxiv.org/pdf/2408.06421v1", "abstract_url": "http://arxiv.org/abs/2408.06421v1", "primary_category": "cond-mat.dis-nn", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Neural Networks as Spin Models: From Glass to Hidden Order Through Training", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:49.134391"}
{"title": "LOLgorithm: Integrating Semantic,Syntactic and Contextual Elements for Humor Classification", "authors": "Tanisha Khurana, Kaushik Pillalamarri, Vikram Pande, Munindar Singh", "abstract": "This paper explores humor detection through a linguistic lens, prioritizing\nsyntactic, semantic, and contextual features over computational methods in\nNatural Language Processing. We categorize features into syntactic, semantic,\nand contextual dimensions, including lexicons, structural statistics, Word2Vec,\nWordNet, and phonetic style. Our proposed model, Colbert, utilizes BERT\nembeddings and parallel hidden layers to capture sentence congruity. By\ncombining syntactic, semantic, and contextual features, we train Colbert for\nhumor detection. Feature engineering examines essential syntactic and semantic\nfeatures alongside BERT embeddings. SHAP interpretations and decision trees\nidentify influential features, revealing that a holistic approach improves\nhumor detection accuracy on unseen data. Integrating linguistic cues from\ndifferent dimensions enhances the model's ability to understand humor\ncomplexity beyond traditional computational methods.", "arxiv_id": "2408.06335v1", "pdf_url": "http://arxiv.org/pdf/2408.06335v1", "abstract_url": "http://arxiv.org/abs/2408.06335v1", "primary_category": "cs.CL", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "LOLgorithm: Integrating Semantic,Syntactic and Contextual Elements for Humor Classification", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:49.971475"}
{"title": "Can We Rely on LLM Agents to Draft Long-Horizon Plans? Let's Take TravelPlanner as an Example", "authors": "Yanan Chen, Ali Pesaranghader, Tanmana Sadhu, Dong Hoon Yi", "abstract": "Large language models (LLMs) have brought autonomous agents closer to\nartificial general intelligence (AGI) due to their promising generalization and\nemergent capabilities. There is, however, a lack of studies on how LLM-based\nagents behave, why they could potentially fail, and how to improve them,\nparticularly in demanding real-world planning tasks. In this paper, as an\neffort to fill the gap, we present our study using a realistic benchmark,\nTravelPlanner, where an agent must meet multiple constraints to generate\naccurate plans. We leverage this benchmark to address four key research\nquestions: (1) are LLM agents robust enough to lengthy and noisy contexts when\nit comes to reasoning and planning? (2) can few-shot prompting adversely impact\nthe performance of LLM agents in scenarios with long context? (3) can we rely\non refinement to improve plans, and (4) can fine-tuning LLMs with both positive\nand negative feedback lead to further improvement? Our comprehensive\nexperiments indicate that, firstly, LLMs often fail to attend to crucial parts\nof a long context, despite their ability to handle extensive reference\ninformation and few-shot examples; secondly, they still struggle with analyzing\nthe long plans and cannot provide accurate feedback for refinement; thirdly, we\npropose Feedback-Aware Fine-Tuning (FAFT), which leverages both positive and\nnegative feedback, resulting in substantial gains over Supervised Fine-Tuning\n(SFT). Our findings offer in-depth insights to the community on various aspects\nrelated to real-world planning applications.", "arxiv_id": "2408.06318v1", "pdf_url": "http://arxiv.org/pdf/2408.06318v1", "abstract_url": "http://arxiv.org/abs/2408.06318v1", "primary_category": "cs.AI", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Can We Rely on LLM Agents to Draft Long-Horizon Plans? Let's Take TravelPlanner as an Example", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:50.791362"}
{"title": "Body Transformer: Leveraging Robot Embodiment for Policy Learning", "authors": "Carmelo Sferrazza, Dun-Ming Huang, Fangchen Liu, Jongmin Lee, Pieter Abbeel", "abstract": "In recent years, the transformer architecture has become the de facto\nstandard for machine learning algorithms applied to natural language processing\nand computer vision. Despite notable evidence of successful deployment of this\narchitecture in the context of robot learning, we claim that vanilla\ntransformers do not fully exploit the structure of the robot learning problem.\nTherefore, we propose Body Transformer (BoT), an architecture that leverages\nthe robot embodiment by providing an inductive bias that guides the learning\nprocess. We represent the robot body as a graph of sensors and actuators, and\nrely on masked attention to pool information throughout the architecture. The\nresulting architecture outperforms the vanilla transformer, as well as the\nclassical multilayer perceptron, in terms of task completion, scaling\nproperties, and computational efficiency when representing either imitation or\nreinforcement learning policies. Additional material including the open-source\ncode is available at https://sferrazza.cc/bot_site.", "arxiv_id": "2408.06316v1", "pdf_url": "http://arxiv.org/pdf/2408.06316v1", "abstract_url": "http://arxiv.org/abs/2408.06316v1", "primary_category": "cs.RO", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Body Transformer: Leveraging Robot Embodiment for Policy Learning", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:51.531007"}
{"title": "Source Separation of Multi-source Raw Music using a Residual Quantized Variational Autoencoder", "authors": "Leonardo Berti", "abstract": "I developed a neural audio codec model based on the residual quantized\nvariational autoencoder architecture. I train the model on the Slakh2100\ndataset, a standard dataset for musical source separation, composed of\nmulti-track audio. The model can separate audio sources, achieving almost SoTA\nresults with much less computing power. The code is publicly available at\ngithub.com/LeonardoBerti00/Source-Separation-of-Multi-source-Music-using-Residual-Quantizad-Variational-Autoencoder", "arxiv_id": "2408.07020v1", "pdf_url": "http://arxiv.org/pdf/2408.07020v1", "abstract_url": "http://arxiv.org/abs/2408.07020v1", "primary_category": "cs.SD", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Source Separation of Multi-source Raw Music using a Residual Quantized Variational Autoencoder", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:52.267710"}
{"title": "Finding Patterns in Ambiguity: Interpretable Stress Testing in the Decision~Boundary", "authors": "In\u00eas Gomes, Lu\u00eds F. Teixeira, Jan N. van Rijn, Carlos Soares, Andr\u00e9 Restivo, Lu\u00eds Cunha, Mois\u00e9s Santos", "abstract": "The increasing use of deep learning across various domains highlights the\nimportance of understanding the decision-making processes of these black-box\nmodels. Recent research focusing on the decision boundaries of deep\nclassifiers, relies on generated synthetic instances in areas of low\nconfidence, uncovering samples that challenge both models and humans. We\npropose a novel approach to enhance the interpretability of deep binary\nclassifiers by selecting representative samples from the decision boundary -\nprototypes - and applying post-model explanation algorithms. We evaluate the\neffectiveness of our approach through 2D visualizations and GradientSHAP\nanalysis. Our experiments demonstrate the potential of the proposed method,\nrevealing distinct and compact clusters and diverse prototypes that capture\nessential features that lead to low-confidence decisions. By offering a more\naggregated view of deep classifiers' decision boundaries, our work contributes\nto the responsible development and deployment of reliable machine learning\nsystems.", "arxiv_id": "2408.06302v1", "pdf_url": "http://arxiv.org/pdf/2408.06302v1", "abstract_url": "http://arxiv.org/abs/2408.06302v1", "primary_category": "cs.LG", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Finding Patterns in Ambiguity: Interpretable Stress Testing in the Decision~Boundary", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:53.016525"}
{"title": "Inverse designing metamaterials with programmable nonlinear functional responses in graph space", "authors": "Marco Maurizi, Derek Xu, Yu-Tong Wang, Desheng Yao, David Hahn, Mourad Oudich, Anish Satpati, Mathieu Bauchy, Wei Wang, Yizhou Sun, Yun Jing, Xiaoyu Rayne Zheng", "abstract": "Material responses to static and dynamic stimuli, represented as nonlinear\ncurves, are design targets for engineering functionalities like structural\nsupport, impact protection, and acoustic and photonic bandgaps.\nThree-dimensional metamaterials offer significant tunability due to their\ninternal structure, yet existing methods struggle to capture their complex\nbehavior-to-structure relationships. We present GraphMetaMat, a graph-based\nframework capable of designing three-dimensional metamaterials with\nprogrammable responses and arbitrary manufacturing constraints. Integrating\ngraph networks, physics biases, reinforcement learning, and tree search,\nGraphMetaMat can target stress-strain curves spanning four orders of magnitude\nand complex behaviors, as well as viscoelastic transmission responses with\nvarying attenuation gaps. GraphMetaMat can create cushioning materials for\nprotective equipment and vibration-damping panels for electric vehicles,\noutperforming commercial materials, and enabling the automatic design of\nmaterials with on-demand functionalities.", "arxiv_id": "2408.06300v1", "pdf_url": "http://arxiv.org/pdf/2408.06300v1", "abstract_url": "http://arxiv.org/abs/2408.06300v1", "primary_category": "cond-mat.mtrl-sci", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Inverse designing metamaterials with programmable nonlinear functional responses in graph space", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:53.765397"}
{"title": "LEARN: An Invex Loss for Outlier Oblivious Robust Online Optimization", "authors": "Adarsh Barik, Anand Krishna, Vincent Y. F. Tan", "abstract": "We study a robust online convex optimization framework, where an adversary\ncan introduce outliers by corrupting loss functions in an arbitrary number of\nrounds k, unknown to the learner. Our focus is on a novel setting allowing\nunbounded domains and large gradients for the losses without relying on a\nLipschitz assumption. We introduce the Log Exponential Adjusted Robust and\niNvex (LEARN) loss, a non-convex (invex) robust loss function to mitigate the\neffects of outliers and develop a robust variant of the online gradient descent\nalgorithm by leveraging the LEARN loss. We establish tight regret guarantees\n(up to constants), in a dynamic setting, with respect to the uncorrupted rounds\nand conduct experiments to validate our theory. Furthermore, we present a\nunified analysis framework for developing online optimization algorithms for\nnon-convex (invex) losses, utilizing it to provide regret bounds with respect\nto the LEARN loss, which may be of independent interest.", "arxiv_id": "2408.06297v1", "pdf_url": "http://arxiv.org/pdf/2408.06297v1", "abstract_url": "http://arxiv.org/abs/2408.06297v1", "primary_category": "cs.LG", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "LEARN: An Invex Loss for Outlier Oblivious Robust Online Optimization", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:54.477296"}
{"title": "The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery", "authors": "Chris Lu, Cong Lu, Robert Tjarko Lange, Jakob Foerster, Jeff Clune, David Ha", "abstract": "One of the grand challenges of artificial general intelligence is developing\nagents capable of conducting scientific research and discovering new knowledge.\nWhile frontier models have already been used as aides to human scientists, e.g.\nfor brainstorming ideas, writing code, or prediction tasks, they still conduct\nonly a small part of the scientific process. This paper presents the first\ncomprehensive framework for fully automatic scientific discovery, enabling\nfrontier large language models to perform research independently and\ncommunicate their findings. We introduce The AI Scientist, which generates\nnovel research ideas, writes code, executes experiments, visualizes results,\ndescribes its findings by writing a full scientific paper, and then runs a\nsimulated review process for evaluation. In principle, this process can be\nrepeated to iteratively develop ideas in an open-ended fashion, acting like the\nhuman scientific community. We demonstrate its versatility by applying it to\nthree distinct subfields of machine learning: diffusion modeling,\ntransformer-based language modeling, and learning dynamics. Each idea is\nimplemented and developed into a full paper at a cost of less than $15 per\npaper. To evaluate the generated papers, we design and validate an automated\nreviewer, which we show achieves near-human performance in evaluating paper\nscores. The AI Scientist can produce papers that exceed the acceptance\nthreshold at a top machine learning conference as judged by our automated\nreviewer. This approach signifies the beginning of a new era in scientific\ndiscovery in machine learning: bringing the transformative benefits of AI\nagents to the entire research process of AI itself, and taking us closer to a\nworld where endless affordable creativity and innovation can be unleashed on\nthe world's most challenging problems. Our code is open-sourced at\nhttps://github.com/SakanaAI/AI-Scientist", "arxiv_id": "2408.06292v2", "pdf_url": "http://arxiv.org/pdf/2408.06292v2", "abstract_url": "http://arxiv.org/abs/2408.06292v2", "primary_category": "cs.AI", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:55.402177"}
{"title": "Mambular: A Sequential Model for Tabular Deep Learning", "authors": "Anton Frederik Thielmann, Manish Kumar, Christoph Weisser, Arik Reuter, Benjamin S\u00e4fken, Soheila Samiee", "abstract": "The analysis of tabular data has traditionally been dominated by\ngradient-boosted decision trees (GBDTs), known for their proficiency with mixed\ncategorical and numerical features. However, recent deep learning innovations\nare challenging this dominance. We introduce Mambular, an adaptation of the\nMamba architecture optimized for tabular data. We extensively benchmark\nMambular against state-of-the-art models, including neural networks and\ntree-based methods, and demonstrate its competitive performance across diverse\ndatasets. Additionally, we explore various adaptations of Mambular to\nunderstand its effectiveness for tabular data. We investigate different pooling\nstrategies, feature interaction mechanisms, and bi-directional processing. Our\nanalysis shows that interpreting features as a sequence and passing them\nthrough Mamba layers results in surprisingly performant models. The results\nhighlight Mambulars potential as a versatile and powerful architecture for\ntabular data analysis, expanding the scope of deep learning applications in\nthis domain.\n  The source code is available at https://github.com/basf/mamba-tabular.", "arxiv_id": "2408.06291v1", "pdf_url": "http://arxiv.org/pdf/2408.06291v1", "abstract_url": "http://arxiv.org/abs/2408.06291v1", "primary_category": "cs.LG", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Mambular: A Sequential Model for Tabular Deep Learning", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:57.140028"}
{"title": "Synthetic Patient-Physician Dialogue Generation from Clinical Notes Using LLM", "authors": "Trisha Das, Dina Albassam, Jimeng Sun", "abstract": "Medical dialogue systems (MDS) enhance patient-physician communication,\nimprove healthcare accessibility, and reduce costs. However, acquiring suitable\ndata to train these systems poses significant challenges. Privacy concerns\nprevent the use of real conversations, necessitating synthetic alternatives.\nSynthetic dialogue generation from publicly available clinical notes offers a\npromising solution to this issue, providing realistic data while safeguarding\nprivacy. Our approach, SynDial, uses a single LLM iteratively with zero-shot\nprompting and a feedback loop to generate and refine high-quality synthetic\ndialogues. The feedback consists of weighted evaluation scores for similarity\nand extractiveness. The iterative process ensures dialogues meet predefined\nthresholds, achieving superior extractiveness as a result of the feedback loop.\nAdditionally, evaluation shows that the generated dialogues excel in factuality\nmetric compared to the baselines and has comparable diversity scores with GPT4.", "arxiv_id": "2408.06285v1", "pdf_url": "http://arxiv.org/pdf/2408.06285v1", "abstract_url": "http://arxiv.org/abs/2408.06285v1", "primary_category": "cs.CL", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Synthetic Patient-Physician Dialogue Generation from Clinical Notes Using LLM", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:57.959033"}
{"title": "Multi-marginal Schr\u00f6dinger Bridges with Iterative Reference Refinement", "authors": "Yunyi Shen, Renato Berlinghieri, Tamara Broderick", "abstract": "Practitioners frequently aim to infer an unobserved population trajectory\nusing sample snapshots at multiple time points. For instance, in single-cell\nsequencing, scientists would like to learn how gene expression evolves over\ntime. But sequencing any cell destroys that cell. So we cannot access any\ncell's full trajectory, but we can access snapshot samples from many cells.\nStochastic differential equations are commonly used to analyze systems with\nfull individual-trajectory access; since here we have only sample snapshots,\nthese methods are inapplicable. The deep learning community has recently\nexplored using Schr\\\"odinger bridges (SBs) and their extensions to estimate\nthese dynamics. However, these methods either (1) interpolate between just two\ntime points or (2) require a single fixed reference dynamic within the SB,\nwhich is often just set to be Brownian motion. But learning piecewise from\nadjacent time points can fail to capture long-term dependencies. And\npractitioners are typically able to specify a model class for the reference\ndynamic but not the exact values of the parameters within it. So we propose a\nnew method that (1) learns the unobserved trajectories from sample snapshots\nacross multiple time points and (2) requires specification only of a class of\nreference dynamics, not a single fixed one. In particular, we suggest an\niterative projection method inspired by Schr\\\"odinger bridges; we alternate\nbetween learning a piecewise SB on the unobserved trajectories and using the\nlearned SB to refine our best guess for the dynamics within the reference\nclass. We demonstrate the advantages of our method via a well-known simulated\nparametric model from ecology, simulated and real data from systems biology,\nand real motion-capture data.", "arxiv_id": "2408.06277v2", "pdf_url": "http://arxiv.org/pdf/2408.06277v2", "abstract_url": "http://arxiv.org/abs/2408.06277v2", "primary_category": "stat.ML", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Multi-marginal Schr\u00f6dinger Bridges with Iterative Reference Refinement", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:58.981545"}
{"title": "Anchored Preference Optimization and Contrastive Revisions: Addressing Underspecification in Alignment", "authors": "Karel D'Oosterlinck, Winnie Xu, Chris Develder, Thomas Demeester, Amanpreet Singh, Christopher Potts, Douwe Kiela, Shikib Mehri", "abstract": "Large Language Models (LLMs) are often aligned using contrastive alignment\nobjectives and preference pair datasets. The interaction between model, paired\ndata, and objective makes alignment a complicated procedure, sometimes\nproducing subpar results. We study this and find that (i) preference data gives\na better learning signal when the underlying responses are contrastive, and\n(ii) alignment objectives lead to better performance when they specify more\ncontrol over the model during training. Based on these insights, we introduce\nContrastive Learning from AI Revisions (CLAIR), a data-creation method which\nleads to more contrastive preference pairs, and Anchored Preference\nOptimization (APO), a controllable and more stable alignment objective. We\nalign Llama-3-8B-Instruct using various comparable datasets and alignment\nobjectives and measure MixEval-Hard scores, which correlate highly with human\njudgments. The CLAIR preferences lead to the strongest performance out of all\ndatasets, and APO consistently outperforms less controllable objectives. Our\nbest model, trained on 32K CLAIR preferences with APO, improves\nLlama-3-8B-Instruct by 7.65%, closing the gap with GPT4-turbo by 45%. Our code\nis available at https://github.com/ContextualAI/CLAIR_and_APO.", "arxiv_id": "2408.06266v1", "pdf_url": "http://arxiv.org/pdf/2408.06266v1", "abstract_url": "http://arxiv.org/abs/2408.06266v1", "primary_category": "cs.LG", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Anchored Preference Optimization and Contrastive Revisions: Addressing Underspecification in Alignment", "response": "RELEVANT", "timestamp": "2024-08-19T13:36:59.724281"}
{"title": "DUNE: A Machine Learning Deep UNet++ based Ensemble Approach to Monthly, Seasonal and Annual Climate Forecasting", "authors": "Pratik Shukla, Milton Halem", "abstract": "Capitalizing on the recent availability of ERA5 monthly averaged long-term\ndata records of mean atmospheric and climate fields based on high-resolution\nreanalysis, deep-learning architectures offer an alternative to physics-based\ndaily numerical weather predictions for subseasonal to seasonal (S2S) and\nannual means. A novel Deep UNet++-based Ensemble (DUNE) neural architecture is\nintroduced, employing multi-encoder-decoder structures with residual blocks.\nWhen initialized from a prior month or year, this architecture produced the\nfirst AI-based global monthly, seasonal, or annual mean forecast of 2-meter\ntemperatures (T2m) and sea surface temperatures (SST). ERA5 monthly mean data\nis used as input for T2m over land, SST over oceans, and solar radiation at the\ntop of the atmosphere for each month of 40 years to train the model. Validation\nforecasts are performed for an additional two years, followed by five years of\nforecast evaluations to account for natural annual variability. AI-trained\ninference forecast weights generate forecasts in seconds, enabling ensemble\nseasonal forecasts. Root Mean Squared Error (RMSE), Anomaly Correlation\nCoefficient (ACC), and Heidke Skill Score (HSS) statistics are presented\nglobally and over specific regions. These forecasts outperform persistence,\nclimatology, and multiple linear regression for all domains. DUNE forecasts\ndemonstrate comparable statistical accuracy to NOAA's operational monthly and\nseasonal probabilistic outlook forecasts over the US but at significantly\nhigher resolutions. RMSE and ACC error statistics for other recent AI-based\ndaily forecasts also show superior performance for DUNE-based forecasts. The\nDUNE model's application to an ensemble data assimilation cycle shows\ncomparable forecast accuracy with a single high-resolution model, potentially\neliminating the need for retraining on extrapolated datasets.", "arxiv_id": "2408.06262v1", "pdf_url": "http://arxiv.org/pdf/2408.06262v1", "abstract_url": "http://arxiv.org/abs/2408.06262v1", "primary_category": "cs.LG", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "DUNE: A Machine Learning Deep UNet++ based Ensemble Approach to Monthly, Seasonal and Annual Climate Forecasting", "response": "RELEVANT", "timestamp": "2024-08-19T13:37:00.773496"}
{"title": "Open-Source Molecular Processing Pipeline for Generating Molecules", "authors": "V Shreyas, Jose Siguenza, Karan Bania, Bharath Ramsundar", "abstract": "Generative models for molecules have shown considerable promise for use in\ncomputational chemistry, but remain difficult to use for non-experts. For this\nreason, we introduce open-source infrastructure for easily building generative\nmolecular models into the widely used DeepChem [Ramsundar et al., 2019] library\nwith the aim of creating a robust and reusable molecular generation pipeline.\nIn particular, we add high quality PyTorch [Paszke et al., 2019]\nimplementations of the Molecular Generative Adversarial Networks (MolGAN) [Cao\nand Kipf, 2022] and Normalizing Flows [Papamakarios et al., 2021]. Our\nimplementations show strong performance comparable with past work [Kuznetsov\nand Polykovskiy, 2021, Cao and Kipf, 2022].", "arxiv_id": "2408.06261v2", "pdf_url": "http://arxiv.org/pdf/2408.06261v2", "abstract_url": "http://arxiv.org/abs/2408.06261v2", "primary_category": "cs.LG", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Open-Source Molecular Processing Pipeline for Generating Molecules", "response": "RELEVANT", "timestamp": "2024-08-19T13:37:01.634885"}
{"title": "Deep Learning System Boundary Testing through Latent Space Style Mixing", "authors": "Amr Abdellatif, Xingcheng Chen, Vincenzo Riccio, Andrea Stocco", "abstract": "Evaluating the behavioral frontier of deep learning (DL) systems is crucial\nfor understanding their generalizability and robustness. However, boundary\ntesting is challenging due to their high-dimensional input space. Generative\nartificial intelligence offers a promising solution by modeling data\ndistribution within compact latent space representations, thereby facilitating\nfiner-grained explorations. In this work, we introduce MIMICRY, a novel\nblack-box system-agnostic test generator that leverages these latent\nrepresentations to generate frontier inputs for the DL systems under test.\nSpecifically, MIMICRY uses style-based generative adversarial networks trained\nto learn the representation of inputs with disentangled features. This\nrepresentation enables embedding style-mixing operations between a source and a\ntarget input, combining their features to explore the boundary between them. We\nevaluated the effectiveness of different MIMICRY configurations in generating\nboundary inputs for four popular DL image classification systems. Our results\nshow that manipulating the latent space allows for effective and efficient\nexploration of behavioral frontiers. As opposed to a model-based baseline,\nMIMICRY generates a higher quality frontier of behaviors which includes more\nand closer inputs. Additionally, we assessed the validity of these inputs,\nrevealing a high validity rate according to human assessors.", "arxiv_id": "2408.06258v1", "pdf_url": "http://arxiv.org/pdf/2408.06258v1", "abstract_url": "http://arxiv.org/abs/2408.06258v1", "primary_category": "cs.SE", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Deep Learning System Boundary Testing through Latent Space Style Mixing", "response": "RELEVANT", "timestamp": "2024-08-19T13:37:02.364436"}
{"title": "Reciprocal Learning", "authors": "Julian Rodemann, Christoph Jansen, Georg Schollmeyer", "abstract": "We demonstrate that a wide array of machine learning algorithms are specific\ninstances of one single paradigm: reciprocal learning. These instances range\nfrom active learning over multi-armed bandits to self-training. We show that\nall these algorithms do not only learn parameters from data but also vice\nversa: They iteratively alter training data in a way that depends on the\ncurrent model fit. We introduce reciprocal learning as a generalization of\nthese algorithms using the language of decision theory. This allows us to study\nunder what conditions they converge. The key is to guarantee that reciprocal\nlearning contracts such that the Banach fixed-point theorem applies. In this\nway, we find that reciprocal learning algorithms converge at linear rates to an\napproximately optimal model under relatively mild assumptions on the loss\nfunction, if their predictions are probabilistic and the sample adaption is\nboth non-greedy and either randomized or regularized. We interpret these\nfindings and provide corollaries that relate them to specific active learning,\nself-training, and bandit algorithms.", "arxiv_id": "2408.06257v1", "pdf_url": "http://arxiv.org/pdf/2408.06257v1", "abstract_url": "http://arxiv.org/abs/2408.06257v1", "primary_category": "stat.ML", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Reciprocal Learning", "response": "RELEVANT", "timestamp": "2024-08-19T13:37:03.088894"}
{"title": "A Comprehensive Case Study on the Performance of Machine Learning Methods on the Classification of Solar Panel Electroluminescence Images", "authors": "Xinyi Song, Kennedy Odongo, Francis G. Pascual, Yili Hong", "abstract": "Photovoltaics (PV) are widely used to harvest solar energy, an important form\nof renewable energy. Photovoltaic arrays consist of multiple solar panels\nconstructed from solar cells. Solar cells in the field are vulnerable to\nvarious defects, and electroluminescence (EL) imaging provides effective and\nnon-destructive diagnostics to detect those defects. We use multiple\ntraditional machine learning and modern deep learning models to classify EL\nsolar cell images into different functional/defective categories. Because of\nthe asymmetry in the number of functional vs. defective cells, an imbalanced\nlabel problem arises in the EL image data. The current literature lacks\ninsights on which methods and metrics to use for model training and prediction.\nIn this paper, we comprehensively compare different machine learning and deep\nlearning methods under different performance metrics on the classification of\nsolar cell EL images from monocrystalline and polycrystalline modules. We\nprovide a comprehensive discussion on different metrics. Our results provide\ninsights and guidelines for practitioners in selecting prediction methods and\nperformance metrics.", "arxiv_id": "2408.06229v1", "pdf_url": "http://arxiv.org/pdf/2408.06229v1", "abstract_url": "http://arxiv.org/abs/2408.06229v1", "primary_category": "stat.AP", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "A Comprehensive Case Study on the Performance of Machine Learning Methods on the Classification of Solar Panel Electroluminescence Images", "response": "RELEVANT", "timestamp": "2024-08-19T13:37:03.818171"}
{"title": "A Large-Scale Study of Model Integration in ML-Enabled Software Systems", "authors": "Yorick Sens, Henriette Knopp, Sven Peldszus, Thorsten Berger", "abstract": "The rise of machine learning (ML) and its embedding in systems has\ndrastically changed the engineering of software-intensive systems.\nTraditionally, software engineering focuses on manually created artifacts such\nas source code and the process of creating them, as well as best practices for\nintegrating them, i.e., software architectures. In contrast, the development of\nML artifacts, i.e. ML models, comes from data science and focuses on the ML\nmodels and their training data. However, to deliver value to end users, these\nML models must be embedded in traditional software, often forming complex\ntopologies. In fact, ML-enabled software can easily incorporate many different\nML models. While the challenges and practices of building ML-enabled systems\nhave been studied to some extent, beyond isolated examples, little is known\nabout the characteristics of real-world ML-enabled systems. Properly embedding\nML models in systems so that they can be easily maintained or reused is far\nfrom trivial. We need to improve our empirical understanding of such systems,\nwhich we address by presenting the first large-scale study of real ML-enabled\nsoftware systems, covering over 2,928 open source systems on GitHub. We\nclassified and analyzed them to determine their characteristics, as well as\ntheir practices for reusing ML models and related code, and the architecture of\nthese systems. Our findings provide practitioners and researchers with insight\ninto practices for embedding and integrating ML models, bringing data science\nand software engineering closer together.", "arxiv_id": "2408.06226v1", "pdf_url": "http://arxiv.org/pdf/2408.06226v1", "abstract_url": "http://arxiv.org/abs/2408.06226v1", "primary_category": "cs.SE", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "A Large-Scale Study of Model Integration in ML-Enabled Software Systems", "response": "RELEVANT", "timestamp": "2024-08-19T13:37:04.514962"}
{"title": "A Digital Twin Framework Utilizing Machine Learning for Robust Predictive Maintenance: Enhancing Tire Health Monitoring", "authors": "Vispi Karkaria, Jie Chen, Christopher Luey, Chase Siuta, Damien Lim, Robert Radulescu, Wei Chen", "abstract": "We introduce a novel digital twin framework for predictive maintenance of\nlong-term physical systems. Using monitoring tire health as an application, we\nshow how the digital twin framework can be used to enhance automotive safety\nand efficiency, and how the technical challenges can be overcome using a\nthree-step approach. Firstly, for managing the data complexity over a long\noperation span, we employ data reduction techniques to concisely represent\nphysical tires using historical performance and usage data. Relying on these\ndata, for fast real-time prediction, we train a transformer-based model offline\non our concise dataset to predict future tire health over time, represented as\nRemaining Casing Potential (RCP). Based on our architecture, our model\nquantifies both epistemic and aleatoric uncertainty, providing reliable\nconfidence intervals around predicted RCP. Secondly, to incorporate real-time\ndata, we update the predictive model in the digital twin framework, ensuring\nits accuracy throughout its life span with the aid of hybrid modeling and the\nuse of discrepancy function. Thirdly, to assist decision making in predictive\nmaintenance, we implement a Tire State Decision Algorithm, which strategically\ndetermines the optimal timing for tire replacement based on RCP forecasted by\nour transformer model. This approach ensures our digital twin accurately\npredicts system health, continually refines its digital representation, and\nsupports predictive maintenance decisions. Our framework effectively embodies a\nphysical system, leveraging big data and machine learning for predictive\nmaintenance, model updates, and decision-making.", "arxiv_id": "2408.06220v1", "pdf_url": "http://arxiv.org/pdf/2408.06220v1", "abstract_url": "http://arxiv.org/abs/2408.06220v1", "primary_category": "cs.LG", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "A Digital Twin Framework Utilizing Machine Learning for Robust Predictive Maintenance: Enhancing Tire Health Monitoring", "response": "RELEVANT", "timestamp": "2024-08-19T13:37:05.842359"}
{"title": "Pattern-Matching Dynamic Memory Network for Dual-Mode Traffic Prediction", "authors": "Wenchao Weng, Mei Wu, Hanyu Jiang, Wanzeng Kong, Xiangjie Kong, Feng Xia", "abstract": "In recent years, deep learning has increasingly gained attention in the field\nof traffic prediction. Existing traffic prediction models often rely on GCNs or\nattention mechanisms with O(N^2) complexity to dynamically extract traffic node\nfeatures, which lack efficiency and are not lightweight. Additionally, these\nmodels typically only utilize historical data for prediction, without\nconsidering the impact of the target information on the prediction. To address\nthese issues, we propose a Pattern-Matching Dynamic Memory Network (PM-DMNet).\nPM-DMNet employs a novel dynamic memory network to capture traffic pattern\nfeatures with only O(N) complexity, significantly reducing computational\noverhead while achieving excellent performance. The PM-DMNet also introduces\ntwo prediction methods: Recursive Multi-step Prediction (RMP) and Parallel\nMulti-step Prediction (PMP), which leverage the time features of the prediction\ntargets to assist in the forecasting process. Furthermore, a transfer attention\nmechanism is integrated into PMP, transforming historical data features to\nbetter align with the predicted target states, thereby capturing trend changes\nmore accurately and reducing errors. Extensive experiments demonstrate the\nsuperiority of the proposed model over existing benchmarks. The source codes\nare available at: https://github.com/wengwenchao123/PM-DMNet.", "arxiv_id": "2408.07100v1", "pdf_url": "http://arxiv.org/pdf/2408.07100v1", "abstract_url": "http://arxiv.org/abs/2408.07100v1", "primary_category": "cs.LG", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Pattern-Matching Dynamic Memory Network for Dual-Mode Traffic Prediction", "response": "RELEVANT", "timestamp": "2024-08-19T13:37:06.779186"}
{"title": "Computability of Classification and Deep Learning: From Theoretical Limits to Practical Feasibility through Quantization", "authors": "Holger Boche, Vit Fojtik, Adalbert Fono, Gitta Kutyniok", "abstract": "The unwavering success of deep learning in the past decade led to the\nincreasing prevalence of deep learning methods in various application fields.\nHowever, the downsides of deep learning, most prominently its lack of\ntrustworthiness, may not be compatible with safety-critical or\nhigh-responsibility applications requiring stricter performance guarantees.\nRecently, several instances of deep learning applications have been shown to be\nsubject to theoretical limitations of computability, undermining the\nfeasibility of performance guarantees when employed on real-world computers. We\nextend the findings by studying computability in the deep learning framework\nfrom two perspectives: From an application viewpoint in the context of\nclassification problems and a general limitation viewpoint in the context of\ntraining neural networks. In particular, we show restrictions on the\nalgorithmic solvability of classification problems that also render the\nalgorithmic detection of failure in computations in a general setting\ninfeasible. Subsequently, we prove algorithmic limitations in training deep\nneural networks even in cases where the underlying problem is well-behaved.\nFinally, we end with a positive observation, showing that in quantized versions\nof classification and deep network training, computability restrictions do not\narise or can be overcome to a certain degree.", "arxiv_id": "2408.06212v1", "pdf_url": "http://arxiv.org/pdf/2408.06212v1", "abstract_url": "http://arxiv.org/abs/2408.06212v1", "primary_category": "cs.LG", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Computability of Classification and Deep Learning: From Theoretical Limits to Practical Feasibility through Quantization", "response": "RELEVANT", "timestamp": "2024-08-19T13:37:07.601235"}
{"title": "Improving Structural Diversity of Blackbox LLMs via Chain-of-Specification Prompting", "authors": "Halley Young, Yimeng Zeng, Jacob Gardner, Osbert Bastani", "abstract": "The capability to generate diverse text is a key challenge facing large\nlanguage models (LLMs). Thus far, diversity has been studied via metrics such\nas $n$-gram diversity or diversity of BERT embeddings. However, for these kinds\nof diversity, the user has little control over the dimensions along which\ndiversity is considered. For example, in the poetry domain, one might desire\ndiversity in terms of rhyme and meter, whereas in the code domain, one might\ndesire diversity in terms of the kinds of expressions used to solve a problem.\nWe propose a diversity metric called structural diversity, where the user\nprovides a mapping from generated text to features capturing the kinds of\ndiversity that they care about. In addition, we propose a novel strategy called\nchain-of-specification (CoS) prompting for improving diversity by first having\nthe LLM generate a specification encoding one instance of structural features,\nand then prompting the LLM to generate text that satisfies these features;\nnotably, our strategy works with blackbox LLMs. In our experiments, we show\nthat for structural diversity in the poetry and code domains, CoS significantly\nimproves diversity compared to several baselines.", "arxiv_id": "2408.06186v1", "pdf_url": "http://arxiv.org/pdf/2408.06186v1", "abstract_url": "http://arxiv.org/abs/2408.06186v1", "primary_category": "cs.CL", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Improving Structural Diversity of Blackbox LLMs via Chain-of-Specification Prompting", "response": "RELEVANT", "timestamp": "2024-08-19T13:37:08.298855"}
{"title": "Centralized and Federated Heart Disease Classification Models Using UCI Dataset and their Shapley-value Based Interpretability", "authors": "Mario Padilla Rodriguez, Mohamed Nafea", "abstract": "Cardiovascular diseases are a leading cause of mortality worldwide,\nhighlighting the need for accurate diagnostic methods. This study benchmarks\ncentralized and federated machine learning algorithms for heart disease\nclassification using the UCI dataset which includes 920 patient records from\nfour hospitals in the USA, Hungary and Switzerland. Our benchmark is supported\nby Shapley-value interpretability analysis to quantify features' importance for\nclassification. In the centralized setup, various binary classification\nalgorithms are trained on pooled data, with a support vector machine (SVM)\nachieving the highest testing accuracy of 83.3\\%, surpassing the established\nbenchmark of 78.7\\% with logistic regression. Additionally, federated learning\nalgorithms with four clients (hospitals) are explored, leveraging the dataset's\nnatural partition to enhance privacy without sacrificing accuracy. Federated\nSVM, an uncommon approach in the literature, achieves a top testing accuracy of\n73.8\\%. Our interpretability analysis aligns with existing medical knowledge of\nheart disease indicators. Overall, this study establishes a benchmark for\nefficient and interpretable pre-screening tools for heart disease while\nmaintaining patients' privacy. This work is available at\nhttps://github.com/padillma1/Heart-Disease-Classification-on-UCI-dataset-and-Shapley-Interpretability-Analysis.", "arxiv_id": "2408.06183v2", "pdf_url": "http://arxiv.org/pdf/2408.06183v2", "abstract_url": "http://arxiv.org/abs/2408.06183v2", "primary_category": "cs.LG", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Centralized and Federated Heart Disease Classification Models Using UCI Dataset and their Shapley-value Based Interpretability", "response": "RELEVANT", "timestamp": "2024-08-19T13:37:09.505875"}
{"title": "Unleash The Power of Pre-Trained Language Models for Irregularly Sampled Time Series", "authors": "Weijia Zhang, Chenlong Yin, Hao Liu, Hui Xiong", "abstract": "Pre-trained Language Models (PLMs), such as ChatGPT, have significantly\nadvanced the field of natural language processing. This progress has inspired a\nseries of innovative studies that explore the adaptation of PLMs to time series\nanalysis, intending to create a unified foundation model that addresses various\ntime series analytical tasks. However, these efforts predominantly focus on\nRegularly Sampled Time Series (RSTS), neglecting the unique challenges posed by\nIrregularly Sampled Time Series (ISTS), which are characterized by non-uniform\nsampling intervals and prevalent missing data. To bridge this gap, this work\nexplores the potential of PLMs for ISTS analysis. We begin by investigating the\neffect of various methods for representing ISTS, aiming to maximize the\nefficacy of PLMs in this under-explored area. Furthermore, we present a unified\nPLM-based framework, ISTS-PLM, which integrates time-aware and variable-aware\nPLMs tailored for comprehensive intra and inter-time series modeling and\nincludes a learnable input embedding layer and a task-specific output layer to\ntackle diverse ISTS analytical tasks. Extensive experiments on a comprehensive\nbenchmark demonstrate that the ISTS-PLM, utilizing a simple yet effective\nseries-based representation for ISTS, consistently achieves state-of-the-art\nperformance across various analytical tasks, such as classification,\ninterpolation, and extrapolation, as well as few-shot and zero-shot learning\nscenarios, spanning scientific domains like healthcare and biomechanics.", "arxiv_id": "2408.08328v1", "pdf_url": "http://arxiv.org/pdf/2408.08328v1", "abstract_url": "http://arxiv.org/abs/2408.08328v1", "primary_category": "cs.AI", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Unleash The Power of Pre-Trained Language Models for Irregularly Sampled Time Series", "response": "RELEVANT", "timestamp": "2024-08-19T13:37:10.608123"}
{"title": "A Methodological Report on Anomaly Detection on Dynamic Knowledge Graphs", "authors": "Xiaohua Lu, Leshanshui Yang", "abstract": "In this paper, we explore different approaches to anomaly detection on\ndynamic knowledge graphs, specifically in a microservices environment for\nKubernetes applications. Our approach explores three dynamic knowledge graph\nrepresentations: sequential data, one-hop graph structure, and two-hop graph\nstructure, with each representation incorporating increasingly complex\nstructural information. Each phase includes different machine learning and deep\nlearning models. We empirically analyse their performance and propose an\napproach based on ensemble learning of these models. Our approach significantly\noutperforms the baseline on the ISWC 2024 Dynamic Knowledge Graph Anomaly\nDetection dataset, providing a robust solution for anomaly detection in dynamic\ncomplex data.", "arxiv_id": "2408.06121v1", "pdf_url": "http://arxiv.org/pdf/2408.06121v1", "abstract_url": "http://arxiv.org/abs/2408.06121v1", "primary_category": "cs.LG", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "A Methodological Report on Anomaly Detection on Dynamic Knowledge Graphs", "response": "RELEVANT", "timestamp": "2024-08-19T13:37:11.370223"}
{"title": "PhaGO: Protein function annotation for bacteriophages by integrating the genomic context", "authors": "Jiaojiao Guan, Yongxin Ji, Cheng Peng, Wei Zou, Xubo Tang, Jiayu Shang, Yanni Sun", "abstract": "Bacteriophages are viruses that target bacteria, playing a crucial role in\nmicrobial ecology. Phage proteins are important in understanding phage biology,\nsuch as virus infection, replication, and evolution. Although a large number of\nnew phages have been identified via metagenomic sequencing, many of them have\nlimited protein function annotation. Accurate function annotation of phage\nproteins presents several challenges, including their inherent diversity and\nthe scarcity of annotated ones. Existing tools have yet to fully leverage the\nunique properties of phages in annotating protein functions. In this work, we\npropose a new protein function annotation tool for phages by leveraging the\nmodular genomic structure of phage genomes. By employing embeddings from the\nlatest protein foundation models and Transformer to capture contextual\ninformation between proteins in phage genomes, PhaGO surpasses state-of-the-art\nmethods in annotating diverged proteins and proteins with uncommon functions by\n6.78% and 13.05% improvement, respectively. PhaGO can annotate proteins lacking\nhomology search results, which is critical for characterizing the rapidly\naccumulating phage genomes. We demonstrate the utility of PhaGO by identifying\n688 potential holins in phages, which exhibit high structural conservation with\nknown holins. The results show the potential of PhaGO to extend our\nunderstanding of newly discovered phages.", "arxiv_id": "2408.06402v1", "pdf_url": "http://arxiv.org/pdf/2408.06402v1", "abstract_url": "http://arxiv.org/abs/2408.06402v1", "primary_category": "q-bio.QM", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "PhaGO: Protein function annotation for bacteriophages by integrating the genomic context", "response": "RELEVANT", "timestamp": "2024-08-19T13:37:12.660842"}
{"title": "Contexts Matter: An Empirical Study on Contextual Influence in Fairness Testing for Deep Learning Systems", "authors": "Chengwen Du, Tao Chen", "abstract": "Background: Fairness testing for deep learning systems has been becoming\nincreasingly important. However, much work assumes perfect context and\nconditions from the other parts: well-tuned hyperparameters for accuracy;\nrectified bias in data, and mitigated bias in the labeling. Yet, these are\noften difficult to achieve in practice due to their resource-/labour-intensive\nnature. Aims: In this paper, we aim to understand how varying contexts affect\nfairness testing outcomes. Method:We conduct an extensive empirical study,\nwhich covers $10,800$ cases, to investigate how contexts can change the\nfairness testing result at the model level against the existing assumptions. We\nalso study why the outcomes were observed from the lens of correlation/fitness\nlandscape analysis. Results: Our results show that different context types and\nsettings generally lead to a significant impact on the testing, which is mainly\ncaused by the shifts of the fitness landscape under varying contexts.\nConclusions: Our findings provide key insights for practitioners to evaluate\nthe test generators and hint at future research directions.", "arxiv_id": "2408.06102v1", "pdf_url": "http://arxiv.org/pdf/2408.06102v1", "abstract_url": "http://arxiv.org/abs/2408.06102v1", "primary_category": "cs.SE", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Contexts Matter: An Empirical Study on Contextual Influence in Fairness Testing for Deep Learning Systems", "response": "RELEVANT", "timestamp": "2024-08-19T13:37:13.443821"}
{"title": "Generalization capabilities of MeshGraphNets to unseen geometries for fluid dynamics", "authors": "Robin Schm\u00f6cker, Alexander Henkes, Julian Roth, Thomas Wick", "abstract": "This works investigates the generalization capabilities of MeshGraphNets\n(MGN) [Pfaff et al. Learning Mesh-Based Simulation with Graph Networks. ICML\n2021] to unseen geometries for fluid dynamics, e.g. predicting the flow around\na new obstacle that was not part of the training data. For this purpose, we\ncreate a new benchmark dataset for data-driven computational fluid dynamics\n(CFD) which extends DeepMind's flow around a cylinder dataset by including\ndifferent shapes and multiple objects. We then use this new dataset to extend\nthe generalization experiments conducted by DeepMind on MGNs by testing how\nwell an MGN can generalize to different shapes. In our numerical tests, we show\nthat MGNs can sometimes generalize well to various shapes by training on a\ndataset of one obstacle shape and testing on a dataset of another obstacle\nshape.", "arxiv_id": "2408.06101v1", "pdf_url": "http://arxiv.org/pdf/2408.06101v1", "abstract_url": "http://arxiv.org/abs/2408.06101v1", "primary_category": "cs.LG", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Generalization capabilities of MeshGraphNets to unseen geometries for fluid dynamics", "response": "RELEVANT", "timestamp": "2024-08-19T13:37:14.446608"}
{"title": "Bearing Fault Diagnosis using Graph Sampling and Aggregation Network", "authors": "Jiaying Chen, Xusheng Du, Yurong Qian, Gwanggil Jeon", "abstract": "Bearing fault diagnosis technology has a wide range of practical applications\nin industrial production, energy and other fields. Timely and accurate\ndetection of bearing faults plays an important role in preventing catastrophic\naccidents and ensuring product quality. Traditional signal analysis techniques\nand deep learning-based fault detection algorithms do not take into account the\nintricate correlation between signals, making it difficult to further improve\ndetection accuracy. To address this problem, we introduced Graph Sampling and\nAggregation (GraphSAGE) network and proposed GraphSAGE-based Bearing fault\nDiagnosis (GSABFD) algorithm. The original vibration signal is firstly sliced\nthrough a fixed size non-overlapping sliding window, and the sliced data is\nfeature transformed using signal analysis methods; then correlations are\nconstructed for the transformed vibration signal and further transformed into\nvertices in the graph; then the GraphSAGE network is used for training; finally\nthe fault level of the object is calculated in the output layer of the network.\nThe proposed algorithm is compared with five advanced algorithms in a\nreal-world public dataset for experiments, and the results show that the GSABFD\nalgorithm improves the AUC value by 5% compared with the next best algorithm.", "arxiv_id": "2408.07099v1", "pdf_url": "http://arxiv.org/pdf/2408.07099v1", "abstract_url": "http://arxiv.org/abs/2408.07099v1", "primary_category": "cs.LG", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Bearing Fault Diagnosis using Graph Sampling and Aggregation Network", "response": "RELEVANT", "timestamp": "2024-08-19T13:37:15.353755"}
{"title": "Approximating Discrimination Within Models When Faced With Several Non-Binary Sensitive Attributes", "authors": "Yijun Bian, Yujie Luo, Ping Xu", "abstract": "Discrimination mitigation with machine learning (ML) models could be\ncomplicated because multiple factors may interweave with each other including\nhierarchically and historically. Yet few existing fairness measures are able to\ncapture the discrimination level within ML models in the face of multiple\nsensitive attributes. To bridge this gap, we propose a fairness measure based\non distances between sets from a manifold perspective, named as 'harmonic\nfairness measure via manifolds (HFM)' with two optional versions, which can\ndeal with a fine-grained discrimination evaluation for several sensitive\nattributes of multiple values. To accelerate the computation of distances of\nsets, we further propose two approximation algorithms named 'Approximation of\ndistance between sets for one sensitive attribute with multiple values\n(ApproxDist)' and 'Approximation of extended distance between sets for several\nsensitive attributes with multiple values (ExtendDist)' to respectively resolve\nbias evaluation of one single sensitive attribute with multiple values and that\nof several sensitive attributes with multiple values. Moreover, we provide an\nalgorithmic effectiveness analysis for ApproxDist under certain assumptions to\nexplain how well it could work. The empirical results demonstrate that our\nproposed fairness measure HFM is valid and approximation algorithms (i.e.,\nApproxDist and ExtendDist) are effective and efficient.", "arxiv_id": "2408.06099v1", "pdf_url": "http://arxiv.org/pdf/2408.06099v1", "abstract_url": "http://arxiv.org/abs/2408.06099v1", "primary_category": "cs.LG", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Approximating Discrimination Within Models When Faced With Several Non-Binary Sensitive Attributes", "response": "RELEVANT", "timestamp": "2024-08-19T13:37:17.246262"}
{"title": "High-dimensional optimization for multi-spiked tensor PCA", "authors": "G\u00e9rard Ben Arous, C\u00e9dric Gerbelot, Vanessa Piccolo", "abstract": "We study the dynamics of two local optimization algorithms, online stochastic\ngradient descent (SGD) and gradient flow, within the framework of the\nmulti-spiked tensor model in the high-dimensional regime. This multi-index\nmodel arises from the tensor principal component analysis (PCA) problem, which\naims to infer $r$ unknown, orthogonal signal vectors within the $N$-dimensional\nunit sphere through maximum likelihood estimation from noisy observations of an\norder-$p$ tensor. We determine the number of samples and the conditions on the\nsignal-to-noise ratios (SNRs) required to efficiently recover the unknown\nspikes from natural initializations. Specifically, we distinguish between three\ntypes of recovery: exact recovery of each spike, recovery of a permutation of\nall spikes, and recovery of the correct subspace spanned by the signal vectors.\nWe show that with online SGD, it is possible to recover all spikes provided a\nnumber of sample scaling as $N^{p-2}$, aligning with the computational\nthreshold identified in the rank-one tensor PCA problem [Ben Arous, Gheissari,\nJagannath 2020, 2021]. For gradient flow, we show that the algorithmic\nthreshold to efficiently recover the first spike is also of order $N^{p-2}$.\nHowever, recovering the subsequent directions requires the number of samples to\nscale as $N^{p-1}$. Our results are obtained through a detailed analysis of a\nlow-dimensional system that describes the evolution of the correlations between\nthe estimators and the spikes. In particular, the hidden vectors are recovered\none by one according to a sequential elimination phenomenon: as one correlation\nexceeds a critical threshold, all correlations sharing a row or column index\ndecrease and become negligible, allowing the subsequent correlation to grow and\nbecome macroscopic. The sequence in which correlations become macroscopic\ndepends on their initial values and on the associated SNRs.", "arxiv_id": "2408.06401v1", "pdf_url": "http://arxiv.org/pdf/2408.06401v1", "abstract_url": "http://arxiv.org/abs/2408.06401v1", "primary_category": "stat.ML", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "High-dimensional optimization for multi-spiked tensor PCA", "response": "RELEVANT", "timestamp": "2024-08-19T13:37:17.993319"}
{"title": "Building Decision Making Models Through Language Model Regime", "authors": "Yu Zhang, Haoxiang Liu, Feijun Jiang, Weihua Luo, Kaifu Zhang", "abstract": "We propose a novel approach for decision making problems leveraging the\ngeneralization capabilities of large language models (LLMs). Traditional\nmethods such as expert systems, planning algorithms, and reinforcement learning\noften exhibit limited generalization, typically requiring the training of new\nmodels for each unique task. In contrast, LLMs demonstrate remarkable success\nin generalizing across varied language tasks, inspiring a new strategy for\ntraining decision making models. Our approach, referred to as \"Learning then\nUsing\" (LTU), entails a two-stage process. Initially, the \\textit{learning}\nphase develops a robust foundational decision making model by integrating\ndiverse knowledge from various domains and decision making contexts. The\nsubsequent \\textit{using} phase refines this foundation model for specific\ndecision making scenarios. Distinct from other studies that employ LLMs for\ndecision making through supervised learning, our LTU method embraces a\nversatile training methodology that combines broad pre-training with targeted\nfine-tuning. Experiments in e-commerce domains such as advertising and search\noptimization have shown that LTU approach outperforms traditional supervised\nlearning regimes in decision making capabilities and generalization. The LTU\napproach is the first practical training architecture for both single-step and\nmulti-step decision making tasks combined with LLMs, which can be applied\nbeyond game and robot domains. It provides a robust and adaptable framework for\ndecision making, enhances the effectiveness and flexibility of various systems\nin tackling various challenges.", "arxiv_id": "2408.06087v1", "pdf_url": "http://arxiv.org/pdf/2408.06087v1", "abstract_url": "http://arxiv.org/abs/2408.06087v1", "primary_category": "cs.CL", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Building Decision Making Models Through Language Model Regime", "response": "RELEVANT", "timestamp": "2024-08-19T13:37:18.753293"}
{"title": "A-BDD: Leveraging Data Augmentations for Safe Autonomous Driving in Adverse Weather and Lighting", "authors": "Felix Assion, Florens Gressner, Nitin Augustine, Jona Klemenc, Ahmed Hammam, Alexandre Krattinger, Holger Trittenbach, Sascha Riemer", "abstract": "High-autonomy vehicle functions rely on machine learning (ML) algorithms to\nunderstand the environment. Despite displaying remarkable performance in fair\nweather scenarios, perception algorithms are heavily affected by adverse\nweather and lighting conditions. To overcome these difficulties, ML engineers\nmainly rely on comprehensive real-world datasets. However, the difficulties in\nreal-world data collection for critical areas of the operational design domain\n(ODD) often means synthetic data is required for perception training and safety\nvalidation. Thus, we present A-BDD, a large set of over 60,000 synthetically\naugmented images based on BDD100K that are equipped with semantic segmentation\nand bounding box annotations (inherited from the BDD100K dataset). The dataset\ncontains augmented data for rain, fog, overcast and sunglare/shadow with\nvarying intensity levels. We further introduce novel strategies utilizing\nfeature-based image quality metrics like FID and CMMD, which help identify\nuseful augmented and real-world data for ML training and testing. By conducting\nexperiments on A-BDD, we provide evidence that data augmentations can play a\npivotal role in closing performance gaps in adverse weather and lighting\nconditions.", "arxiv_id": "2408.06071v1", "pdf_url": "http://arxiv.org/pdf/2408.06071v1", "abstract_url": "http://arxiv.org/abs/2408.06071v1", "primary_category": "cs.CV", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "A-BDD: Leveraging Data Augmentations for Safe Autonomous Driving in Adverse Weather and Lighting", "response": "RELEVANT", "timestamp": "2024-08-19T13:37:20.714498"}
{"title": "Fully Bayesian Differential Gaussian Processes through Stochastic Differential Equations", "authors": "Jian Xu, Zhiqi Lin, Min Chen, Junmei Yang, Delu Zeng, John Paisley", "abstract": "Traditional deep Gaussian processes model the data evolution using a discrete\nhierarchy, whereas differential Gaussian processes (DIFFGPs) represent the\nevolution as an infinitely deep Gaussian process. However, prior DIFFGP methods\noften overlook the uncertainty of kernel hyperparameters and assume them to be\nfixed and time-invariant, failing to leverage the unique synergy between\ncontinuous-time models and approximate inference. In this work, we propose a\nfully Bayesian approach that treats the kernel hyperparameters as random\nvariables and constructs coupled stochastic differential equations (SDEs) to\nlearn their posterior distribution and that of inducing points. By\nincorporating estimation uncertainty on hyperparameters, our method enhances\nthe model's flexibility and adaptability to complex dynamics. Additionally, our\napproach provides a time-varying, comprehensive, and realistic posterior\napproximation through coupling variables using SDE methods. Experimental\nresults demonstrate the advantages of our method over traditional approaches,\nshowcasing its superior performance in terms of flexibility, accuracy, and\nother metrics. Our work opens up exciting research avenues for advancing\nBayesian inference and offers a powerful modeling tool for continuous-time\nGaussian processes.", "arxiv_id": "2408.06069v1", "pdf_url": "http://arxiv.org/pdf/2408.06069v1", "abstract_url": "http://arxiv.org/abs/2408.06069v1", "primary_category": "cs.LG", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Fully Bayesian Differential Gaussian Processes through Stochastic Differential Equations", "response": "RELEVANT", "timestamp": "2024-08-19T13:37:21.580643"}
{"title": "Don't You (Project Around Discs)? Neural Network Surrogate and Projected Gradient Descent for Calibrating an Intervertebral Disc Finite Element Model", "authors": "Matan Atad, Gabriel Gruber, Marx Ribeiro, Luis Fernando Nicolini, Robert Graf, Hendrik M\u00f6ller, Kati Nispel, Ivan Ezhov, Daniel Rueckert, Jan S. Kirschke", "abstract": "Accurate calibration of finite element (FE) models of human intervertebral\ndiscs (IVDs) is essential for their reliability and application in diagnosing\nand planning treatments for spinal conditions. Traditional calibration methods\nare computationally intensive, requiring iterative, derivative-free\noptimization algorithms that often take hours or days to converge.\n  This study addresses these challenges by introducing a novel, efficient, and\neffective calibration method for an L4-L5 IVD FE model using a neural network\n(NN) surrogate. The NN surrogate predicts simulation outcomes with high\naccuracy, outperforming other machine learning models, and significantly\nreduces the computational cost associated with traditional FE simulations.\nNext, a Projected Gradient Descent (PGD) approach guided by gradients of the NN\nsurrogate is proposed to efficiently calibrate FE models. Our method explicitly\nenforces feasibility with a projection step, thus maintaining material bounds\nthroughout the optimization process.\n  The proposed method is evaluated against state-of-the-art Genetic Algorithm\n(GA) and inverse model baselines on synthetic and in vitro experimental\ndatasets. Our approach demonstrates superior performance on synthetic data,\nachieving a Mean Absolute Error (MAE) of 0.06 compared to the baselines' MAE of\n0.18 and 0.54, respectively. On experimental specimens, our method outperforms\nthe baseline in 5 out of 6 cases. Most importantly, our approach reduces\ncalibration time to under three seconds, compared to up to 8 days per sample\nrequired by traditional calibration. Such efficiency paves the way for applying\nmore complex FE models, enabling accurate patient-specific simulations and\nadvancing spinal treatment planning.", "arxiv_id": "2408.06067v1", "pdf_url": "http://arxiv.org/pdf/2408.06067v1", "abstract_url": "http://arxiv.org/abs/2408.06067v1", "primary_category": "cs.LG", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Don't You (Project Around Discs)? Neural Network Surrogate and Projected Gradient Descent for Calibrating an Intervertebral Disc Finite Element Model", "response": "RELEVANT", "timestamp": "2024-08-19T13:37:22.451926"}
{"title": "TruVRF: Towards Triple-Granularity Verification on Machine Unlearning", "authors": "Chunyi Zhou, Anmin Fu, Zhiyang Dai", "abstract": "The concept of the right to be forgotten has led to growing interest in\nmachine unlearning, but reliable validation methods are lacking, creating\nopportunities for dishonest model providers to mislead data contributors.\nTraditional invasive methods like backdoor injection are not feasible for\nlegacy data. To address this, we introduce TruVRF, a non-invasive unlearning\nverification framework operating at class-, volume-, and sample-level\ngranularities. TruVRF includes three Unlearning-Metrics designed to detect\ndifferent types of dishonest servers: Neglecting, Lazy, and Deceiving.\nUnlearning-Metric-I checks class alignment, Unlearning-Metric-II verifies\nsample count, and Unlearning-Metric-III confirms specific sample deletion.\nEvaluations on three datasets show TruVRF's robust performance, with over 90%\naccuracy for Metrics I and III, and a 4.8% to 8.2% inference deviation for\nMetric II. TruVRF also demonstrates generalizability and practicality across\nvarious conditions and with state-of-the-art unlearning frameworks like SISA\nand Amnesiac Unlearning.", "arxiv_id": "2408.06063v1", "pdf_url": "http://arxiv.org/pdf/2408.06063v1", "abstract_url": "http://arxiv.org/abs/2408.06063v1", "primary_category": "cs.LG", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "TruVRF: Towards Triple-Granularity Verification on Machine Unlearning", "response": "RELEVANT", "timestamp": "2024-08-19T13:37:25.811959"}
{"title": "MetMamba: Regional Weather Forecasting with Spatial-Temporal Mamba Model", "authors": "Haoyu Qin, Yungang Chen, Qianchuan Jiang, Pengchao Sun, Xiancai Ye, Chao Lin", "abstract": "Deep Learning based Weather Prediction (DLWP) models have been improving\nrapidly over the last few years, surpassing state of the art numerical weather\nforecasts by significant margins. While much of the optimization effort is\nfocused on training curriculum to extend forecast range in the global context,\ntwo aspects remains less explored: limited area modeling and better backbones\nfor weather forecasting. We show in this paper that MetMamba, a DLWP model\nbuilt on a state-of-the-art state-space model, Mamba, offers notable\nperformance gains and unique advantages over other popular backbones using\ntraditional attention mechanisms and neural operators. We also demonstrate the\nfeasibility of deep learning based limited area modeling via coupled training\nwith a global host model.", "arxiv_id": "2408.06400v2", "pdf_url": "http://arxiv.org/pdf/2408.06400v2", "abstract_url": "http://arxiv.org/abs/2408.06400v2", "primary_category": "physics.ao-ph", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "MetMamba: Regional Weather Forecasting with Spatial-Temporal Mamba Model", "response": "RELEVANT", "timestamp": "2024-08-19T13:37:26.836269"}
{"title": "Perceptual Similarity for Measuring Decision-Making Style and Policy Diversity in Games", "authors": "Chiu-Chou Lin, Wei-Chen Chiu, I-Chen Wu", "abstract": "Defining and measuring decision-making styles, also known as playstyles, is\ncrucial in gaming, where these styles reflect a broad spectrum of individuality\nand diversity. However, finding a universally applicable measure for these\nstyles poses a challenge. Building on Playstyle Distance, the first\nunsupervised metric to measure playstyle similarity based on game screens and\nraw actions, we introduce three enhancements to increase accuracy: multiscale\nanalysis with varied state granularity, a perceptual kernel rooted in\npsychology, and the utilization of the intersection-over-union method for\nefficient evaluation. These innovations not only advance measurement precision\nbut also offer insights into human cognition of similarity. Across two racing\ngames and seven Atari games, our techniques significantly improve the precision\nof zero-shot playstyle classification, achieving an accuracy exceeding 90\npercent with fewer than 512 observation-action pairs, which is less than half\nan episode of these games. Furthermore, our experiments with 2048 and Go\ndemonstrate the potential of discrete playstyle measures in puzzle and board\ngames. We also develop an algorithm for assessing decision-making diversity\nusing these measures. Our findings improve the measurement of end-to-end game\nanalysis and the evolution of artificial intelligence for diverse playstyles.", "arxiv_id": "2408.06051v1", "pdf_url": "http://arxiv.org/pdf/2408.06051v1", "abstract_url": "http://arxiv.org/abs/2408.06051v1", "primary_category": "cs.AI", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Perceptual Similarity for Measuring Decision-Making Style and Policy Diversity in Games", "response": "RELEVANT", "timestamp": "2024-08-19T13:37:27.961918"}
{"title": "What Ails Generative Structure-based Drug Design: Too Little or Too Much Expressivity?", "authors": "Rafa\u0142 Karczewski, Samuel Kaski, Markus Heinonen, Vikas Garg", "abstract": "Several generative models with elaborate training and sampling procedures\nhave been proposed recently to accelerate structure-based drug design (SBDD);\nhowever, perplexingly, their empirical performance turns out to be suboptimal.\nWe seek to better understand this phenomenon from both theoretical and\nempirical perspectives. Since most of these models apply graph neural networks\n(GNNs), one may suspect that they inherit the representational limitations of\nGNNs. We analyze this aspect, establishing the first such results for\nprotein-ligand complexes. A plausible counterview may attribute the\nunderperformance of these models to their excessive parameterizations, inducing\nexpressivity at the expense of generalization. We also investigate this\npossibility with a simple metric-aware approach that learns an economical\nsurrogate for affinity to infer an unlabelled molecular graph and optimizes for\nlabels conditioned on this graph and molecular properties. The resulting model\nachieves state-of-the-art results using 100x fewer trainable parameters and\naffords up to 1000x speedup. Collectively, our findings underscore the need to\nreassess and redirect the existing paradigm and efforts for SBDD.", "arxiv_id": "2408.06050v1", "pdf_url": "http://arxiv.org/pdf/2408.06050v1", "abstract_url": "http://arxiv.org/abs/2408.06050v1", "primary_category": "cs.LG", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "What Ails Generative Structure-based Drug Design: Too Little or Too Much Expressivity?", "response": "RELEVANT", "timestamp": "2024-08-19T13:37:28.986301"}
{"title": "Spacetime $E(n)$-Transformer: Equivariant Attention for Spatio-temporal Graphs", "authors": "Sergio G. Charles", "abstract": "We introduce an $E(n)$-equivariant Transformer architecture for\nspatio-temporal graph data. By imposing rotation, translation, and permutation\nequivariance inductive biases in both space and time, we show that the\nSpacetime $E(n)$-Transformer (SET) outperforms purely spatial and temporal\nmodels without symmetry-preserving properties. We benchmark SET against said\nmodels on the charged $N$-body problem, a simple physical system with complex\ndynamics. While existing spatio-temporal graph neural networks focus on\nsequential modeling, we empirically demonstrate that leveraging underlying\ndomain symmetries yields considerable improvements for modeling dynamical\nsystems on graphs.", "arxiv_id": "2408.06039v1", "pdf_url": "http://arxiv.org/pdf/2408.06039v1", "abstract_url": "http://arxiv.org/abs/2408.06039v1", "primary_category": "cs.LG", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Spacetime $E(n)$-Transformer: Equivariant Attention for Spatio-temporal Graphs", "response": "RELEVANT", "timestamp": "2024-08-19T13:37:29.818690"}
{"title": "Graph Clustering with Cross-View Feature Propagation", "authors": "Zhixuan Duan, Zuo Wang, Fanghui Bi", "abstract": "Graph clustering is a fundamental and challenging learning task, which is\nconventionally approached by grouping similar vertices based on edge structure\nand feature similarity.In contrast to previous methods, in this paper, we\ninvestigate how multi-view feature propagation can influence cluster discovery\nin graph data.To this end, we present Graph Clustering With Cross-View Feature\nPropagation (GCCFP), a novel method that leverages multi-view feature\npropagation to enhance cluster identification in graph data.GCCFP employs a\nunified objective function that utilizes graph topology and multi-view vertex\nfeatures to determine vertex cluster membership, regularized by a module that\nsupports key latent feature propagation. We derive an iterative algorithm to\noptimize this function, prove model convergence within a finite number of\niterations, and analyze its computational complexity. Our experiments on\nvarious real-world graphs demonstrate the superior clustering performance of\nGCCFP compared to well-established methods, manifesting its effectiveness\nacross different scenarios.", "arxiv_id": "2408.06029v1", "pdf_url": "http://arxiv.org/pdf/2408.06029v1", "abstract_url": "http://arxiv.org/abs/2408.06029v1", "primary_category": "cs.LG", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Graph Clustering with Cross-View Feature Propagation", "response": "RELEVANT", "timestamp": "2024-08-19T13:37:30.705585"}
{"title": "A Comprehensive Survey on EEG-Based Emotion Recognition: A Graph-Based Perspective", "authors": "Chenyu Liu, Xinliang Zhou, Yihao Wu, Yi Ding, Liming Zhai, Kun Wang, Ziyu Jia, Yang Liu", "abstract": "Compared to other modalities, electroencephalogram (EEG) based emotion\nrecognition can intuitively respond to emotional patterns in the human brain\nand, therefore, has become one of the most focused tasks in affective\ncomputing. The nature of emotions is a physiological and psychological state\nchange in response to brain region connectivity, making emotion recognition\nfocus more on the dependency between brain regions instead of specific brain\nregions. A significant trend is the application of graphs to encapsulate such\ndependency as dynamic functional connections between nodes across temporal and\nspatial dimensions. Concurrently, the neuroscientific underpinnings behind this\ndependency endow the application of graphs in this field with a distinctive\nsignificance. However, there is neither a comprehensive review nor a tutorial\nfor constructing emotion-relevant graphs in EEG-based emotion recognition. In\nthis paper, we present a comprehensive survey of these studies, delivering a\nsystematic review of graph-related methods in this field from a methodological\nperspective. We propose a unified framework for graph applications in this\nfield and categorize these methods on this basis. Finally, based on previous\nstudies, we also present several open challenges and future directions in this\nfield.", "arxiv_id": "2408.06027v2", "pdf_url": "http://arxiv.org/pdf/2408.06027v2", "abstract_url": "http://arxiv.org/abs/2408.06027v2", "primary_category": "eess.SP", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "A Comprehensive Survey on EEG-Based Emotion Recognition: A Graph-Based Perspective", "response": "RELEVANT", "timestamp": "2024-08-19T13:37:31.648620"}
{"title": "Layer-Specific Optimization: Sensitivity Based Convolution Layers Basis Search", "authors": "Vasiliy Alekseev, Ilya Lukashevich, Ilia Zharikov, Ilya Vasiliev", "abstract": "Deep neural network models have a complex architecture and are\noverparameterized. The number of parameters is more than the whole dataset,\nwhich is highly resource-consuming. This complicates their application and\nlimits its usage on different devices. Reduction in the number of network\nparameters helps to reduce the size of the model, but at the same time,\nthoughtlessly applied, can lead to a deterioration in the quality of the\nnetwork. One way to reduce the number of model parameters is matrix\ndecomposition, where a matrix is represented as a product of smaller matrices.\nIn this paper, we propose a new way of applying the matrix decomposition with\nrespect to the weights of convolutional layers. The essence of the method is to\ntrain not all convolutions, but only the subset of convolutions (basis\nconvolutions), and represent the rest as linear combinations of the basis ones.\nExperiments on models from the ResNet family and the CIFAR-10 dataset\ndemonstrate that basis convolutions can not only reduce the size of the model\nbut also accelerate the forward and backward passes of the network. Another\ncontribution of this work is that we propose a fast method for selecting a\nsubset of network layers in which the use of matrix decomposition does not\ndegrade the quality of the final model.", "arxiv_id": "2408.06024v2", "pdf_url": "http://arxiv.org/pdf/2408.06024v2", "abstract_url": "http://arxiv.org/abs/2408.06024v2", "primary_category": "cs.CV", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Layer-Specific Optimization: Sensitivity Based Convolution Layers Basis Search", "response": "RELEVANT", "timestamp": "2024-08-19T13:37:32.442632"}
{"title": "Uncertainty-Informed Volume Visualization using Implicit Neural Representation", "authors": "Shanu Saklani, Chitwan Goel, Shrey Bansal, Zhe Wang, Soumya Dutta, Tushar M. Athawale, David Pugmire, Christopher R. Johnson", "abstract": "The increasing adoption of Deep Neural Networks (DNNs) has led to their\napplication in many challenging scientific visualization tasks. While advanced\nDNNs offer impressive generalization capabilities, understanding factors such\nas model prediction quality, robustness, and uncertainty is crucial. These\ninsights can enable domain scientists to make informed decisions about their\ndata. However, DNNs inherently lack ability to estimate prediction uncertainty,\nnecessitating new research to construct robust uncertainty-aware visualization\ntechniques tailored for various visualization tasks. In this work, we propose\nuncertainty-aware implicit neural representations to model scalar field data\nsets effectively and comprehensively study the efficacy and benefits of\nestimated uncertainty information for volume visualization tasks. We evaluate\nthe effectiveness of two principled deep uncertainty estimation techniques: (1)\nDeep Ensemble and (2) Monte Carlo Dropout (MCDropout). These techniques enable\nuncertainty-informed volume visualization in scalar field data sets. Our\nextensive exploration across multiple data sets demonstrates that\nuncertainty-aware models produce informative volume visualization results.\nMoreover, integrating prediction uncertainty enhances the trustworthiness of\nour DNN model, making it suitable for robustly analyzing and visualizing\nreal-world scientific volumetric data sets.", "arxiv_id": "2408.06018v1", "pdf_url": "http://arxiv.org/pdf/2408.06018v1", "abstract_url": "http://arxiv.org/abs/2408.06018v1", "primary_category": "cs.GR", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Uncertainty-Informed Volume Visualization using Implicit Neural Representation", "response": "RELEVANT", "timestamp": "2024-08-19T13:37:33.184474"}
{"title": "LUT Tensor Core: Lookup Table Enables Efficient Low-Bit LLM Inference Acceleration", "authors": "Zhiwen Mo, Lei Wang, Jianyu Wei, Zhichen Zeng, Shijie Cao, Lingxiao Ma, Naifeng Jing, Ting Cao, Jilong Xue, Fan Yang, Mao Yang", "abstract": "As large language model (LLM) inference demands ever-greater resources, there\nis a rapid growing trend of using low-bit weights to shrink memory usage and\nboost inference efficiency. However, these low-bit LLMs introduce the need for\nmixed-precision matrix multiplication (mpGEMM), which is a crucial yet\nunder-explored operation that involves multiplying lower-precision weights with\nhigher-precision activations. Unfortunately, current hardware does not natively\nsupport mpGEMM, resulting in indirect and inefficient dequantization-based\nimplementations.\n  To address the mpGEMM requirements in low-bit LLMs, we explored the lookup\ntable (LUT)-based approach for mpGEMM. However, a conventional LUT\nimplementation falls short of its potential. To fully harness the power of\nLUT-based mpGEMM, we introduce LUT Tensor Core, a software-hardware co-design\noptimized for low-bit LLM inference. Specifically, we introduce software-based\noperator fusion and table symmetrization techniques to optimize table\nprecompute and table storage, respectively. Then, LUT Tensor Core proposes the\nhardware design featuring an elongated tiling shape design to enhance table\nreuse and a bit-serial design to support various precision combinations in\nmpGEMM. Moreover, we design an end-to-end compilation stack with new\ninstructions for LUT-based mpGEMM, enabling efficient LLM compilation and\noptimizations. The evaluation on low-bit LLMs (e.g., BitNet, LLAMA) shows that\nLUT Tensor Core achieves more than a magnitude of improvements on both compute\ndensity and energy efficiency.", "arxiv_id": "2408.06003v1", "pdf_url": "http://arxiv.org/pdf/2408.06003v1", "abstract_url": "http://arxiv.org/abs/2408.06003v1", "primary_category": "cs.AR", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "LUT Tensor Core: Lookup Table Enables Efficient Low-Bit LLM Inference Acceleration", "response": "RELEVANT", "timestamp": "2024-08-19T13:37:34.004050"}
{"title": "Transfer learning of state-based potential games for process optimization in decentralized manufacturing systems", "authors": "Steve Yuwono, Dorothea Schwung, Andreas Schwung", "abstract": "This paper presents a novel transfer learning approach in state-based\npotential games (TL-SbPGs) for enhancing distributed self-optimization in\nmanufacturing systems. The approach focuses on the practical relevant\nindustrial setting where sharing and transferring gained knowledge among\nsimilar-behaved players improves the self-learning mechanism in large-scale\nsystems. With TL-SbPGs, the gained knowledge can be reused by other players to\noptimize their policies, thereby improving the learning outcomes of the players\nand accelerating the learning process. To accomplish this goal, we develop\ntransfer learning concepts and similarity criteria for players, which offer two\ndistinct settings: (a) predefined similarities between players and (b)\ndynamically inferred similarities between players during training. We formally\nprove the applicability of the SbPG framework in transfer learning.\nAdditionally, we introduce an efficient method to determine the optimal timing\nand weighting of the transfer learning procedure during the training phase.\nThrough experiments on a laboratory-scale testbed, we demonstrate that TL-SbPGs\nsignificantly boost production efficiency while reducing power consumption of\nthe production schedules while also outperforming native SbPGs.", "arxiv_id": "2408.05992v1", "pdf_url": "http://arxiv.org/pdf/2408.05992v1", "abstract_url": "http://arxiv.org/abs/2408.05992v1", "primary_category": "cs.LG", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Transfer learning of state-based potential games for process optimization in decentralized manufacturing systems", "response": "RELEVANT", "timestamp": "2024-08-19T13:37:34.822189"}
{"title": "Parameters Inference for Nonlinear Wave Equations with Markovian Switching", "authors": "Yi Zhang, Zhikun Zhang, Xiangjun Wang", "abstract": "Traditional partial differential equations with constant coefficients often\nstruggle to capture abrupt changes in real-world phenomena, leading to the\ndevelopment of variable coefficient PDEs and Markovian switching models.\nRecently, research has introduced the concept of PDEs with Markov switching\nmodels, established their well-posedness and presented numerical methods.\nHowever, there has been limited discussion on parameter estimation for the jump\ncoefficients in these models. This paper addresses this gap by focusing on\nparameter inference for the wave equation with Markovian switching. We propose\na Bayesian statistical framework using discrete sparse Bayesian learning to\nestablish its convergence and a uniform error bound. Our method requires fewer\nassumptions and enables independent parameter inference for each segment by\nallowing different underlying structures for the parameter estimation problem\nwithin each segmented time interval. The effectiveness of our approach is\ndemonstrated through three numerical cases, which involve noisy spatiotemporal\ndata from different wave equations with Markovian switching. The results show\nstrong performance in parameter estimation for variable coefficient PDEs.", "arxiv_id": "2408.05990v1", "pdf_url": "http://arxiv.org/pdf/2408.05990v1", "abstract_url": "http://arxiv.org/abs/2408.05990v1", "primary_category": "stat.ML", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Parameters Inference for Nonlinear Wave Equations with Markovian Switching", "response": "RELEVANT", "timestamp": "2024-08-19T13:37:35.526973"}
{"title": "Distributed Stackelberg Strategies in State-based Potential Games for Autonomous Decentralized Learning Manufacturing Systems", "authors": "Steve Yuwono, Dorothea Schwung, Andreas Schwung", "abstract": "This article describes a novel game structure for autonomously optimizing\ndecentralized manufacturing systems with multi-objective optimization\nchallenges, namely Distributed Stackelberg Strategies in State-Based Potential\nGames (DS2-SbPG). DS2-SbPG integrates potential games and Stackelberg games,\nwhich improves the cooperative trade-off capabilities of potential games and\nthe multi-objective optimization handling by Stackelberg games. Notably, all\ntraining procedures remain conducted in a fully distributed manner. DS2-SbPG\noffers a promising solution to finding optimal trade-offs between objectives by\neliminating the complexities of setting up combined objective optimization\nfunctions for individual players in self-learning domains, particularly in\nreal-world industrial settings with diverse and numerous objectives between the\nsub-systems. We further prove that DS2-SbPG constitutes a dynamic potential\ngame that results in corresponding converge guarantees. Experimental validation\nconducted on a laboratory-scale testbed highlights the efficacy of DS2-SbPG and\nits two variants, such as DS2-SbPG for single-leader-follower and Stack\nDS2-SbPG for multi-leader-follower. The results show significant reductions in\npower consumption and improvements in overall performance, which signals the\npotential of DS2-SbPG in real-world applications.", "arxiv_id": "2408.06397v1", "pdf_url": "http://arxiv.org/pdf/2408.06397v1", "abstract_url": "http://arxiv.org/abs/2408.06397v1", "primary_category": "cs.GT", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Distributed Stackelberg Strategies in State-based Potential Games for Autonomous Decentralized Learning Manufacturing Systems", "response": "RELEVANT", "timestamp": "2024-08-19T13:37:36.331010"}
{"title": "Attention Please: What Transformer Models Really Learn for Process Prediction", "authors": "Martin K\u00e4ppel, Lars Ackermann, Stefan Jablonski, Simon H\u00e4rtl", "abstract": "Predictive process monitoring aims to support the execution of a process\nduring runtime with various predictions about the further evolution of a\nprocess instance. In the last years a plethora of deep learning architectures\nhave been established as state-of-the-art for different prediction targets,\namong others the transformer architecture. The transformer architecture is\nequipped with a powerful attention mechanism, assigning attention scores to\neach input part that allows to prioritize most relevant information leading to\nmore accurate and contextual output. However, deep learning models largely\nrepresent a black box, i.e., their reasoning or decision-making process cannot\nbe understood in detail. This paper examines whether the attention scores of a\ntransformer based next-activity prediction model can serve as an explanation\nfor its decision-making. We find that attention scores in next-activity\nprediction models can serve as explainers and exploit this fact in two proposed\ngraph-based explanation approaches. The gained insights could inspire future\nwork on the improvement of predictive business process models as well as\nenabling a neural network based mining of process models from event logs.", "arxiv_id": "2408.07097v1", "pdf_url": "http://arxiv.org/pdf/2408.07097v1", "abstract_url": "http://arxiv.org/abs/2408.07097v1", "primary_category": "cs.LG", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Attention Please: What Transformer Models Really Learn for Process Prediction", "response": "RELEVANT", "timestamp": "2024-08-19T13:37:37.181249"}
{"title": "Design Proteins Using Large Language Models: Enhancements and Comparative Analyses", "authors": "Kamyar Zeinalipour, Neda Jamshidi, Monica Bianchini, Marco Maggini, Marco Gori", "abstract": "Pre-trained LLMs have demonstrated substantial capabilities across a range of\nconventional natural language processing (NLP) tasks, such as summarization and\nentity recognition. In this paper, we explore the application of LLMs in the\ngeneration of high-quality protein sequences. Specifically, we adopt a suite of\npre-trained LLMs, including Mistral-7B1, Llama-2-7B2, Llama-3-8B3, and\ngemma-7B4, to produce valid protein sequences. All of these models are publicly\navailable.5 Unlike previous work in this field, our approach utilizes a\nrelatively small dataset comprising 42,000 distinct human protein sequences. We\nretrain these models to process protein-related data, ensuring the generation\nof biologically feasible protein structures. Our findings demonstrate that even\nwith limited data, the adapted models exhibit efficiency comparable to\nestablished protein-focused models such as ProGen varieties, ProtGPT2, and\nProLLaMA, which were trained on millions of protein sequences. To validate and\nquantify the performance of our models, we conduct comparative analyses\nemploying standard metrics such as pLDDT, RMSD, TM-score, and REU. Furthermore,\nwe commit to making the trained versions of all four models publicly available,\nfostering greater transparency and collaboration in the field of computational\nbiology.", "arxiv_id": "2408.06396v1", "pdf_url": "http://arxiv.org/pdf/2408.06396v1", "abstract_url": "http://arxiv.org/abs/2408.06396v1", "primary_category": "q-bio.QM", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Design Proteins Using Large Language Models: Enhancements and Comparative Analyses", "response": "RELEVANT", "timestamp": "2024-08-19T13:37:38.064043"}
{"title": "Global-to-Local Support Spectrums for Language Model Explainability", "authors": "Lucas Agussurja, Xinyang Lu, Bryan Kian Hsiang Low", "abstract": "Existing sample-based methods, like influence functions and representer\npoints, measure the importance of a training point by approximating the effect\nof its removal from training. As such, they are skewed towards outliers and\npoints that are very close to the decision boundaries. The explanations\nprovided by these methods are often static and not specific enough for\ndifferent test points. In this paper, we propose a method to generate an\nexplanation in the form of support spectrums which are based on two main ideas:\nthe support sets and a global-to-local importance measure. The support set is\nthe set of training points, in the predicted class, that ``lie in between'' the\ntest point and training points in the other classes. They indicate how well the\ntest point can be distinguished from the points not in the predicted class. The\nglobal-to-local importance measure is obtained by decoupling existing methods\ninto the global and local components which are then used to select the points\nin the support set. Using this method, we are able to generate explanations\nthat are tailored to specific test points. In the experiments, we show the\neffectiveness of the method in image classification and text generation tasks.", "arxiv_id": "2408.05976v1", "pdf_url": "http://arxiv.org/pdf/2408.05976v1", "abstract_url": "http://arxiv.org/abs/2408.05976v1", "primary_category": "cs.LG", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Global-to-Local Support Spectrums for Language Model Explainability", "response": "RELEVANT", "timestamp": "2024-08-19T13:37:39.126553"}
{"title": "Target Detection of Safety Protective Gear Using the Improved YOLOv5", "authors": "Hao Liu, Xue Qin", "abstract": "In high-risk railway construction, personal protective equipment monitoring\nis critical but challenging due to small and frequently obstructed targets. We\npropose YOLO-EA, an innovative model that enhances safety measure detection by\nintegrating ECA into its backbone's convolutional layers, improving discernment\nof minuscule objects like hardhats. YOLO-EA further refines target recognition\nunder occlusion by replacing GIoU with EIoU loss. YOLO-EA's effectiveness was\nempirically substantiated using a dataset derived from real-world railway\nconstruction site surveillance footage. It outperforms YOLOv5, achieving 98.9%\nprecision and 94.7% recall, up 2.5% and 0.5% respectively, while maintaining\nreal-time performance at 70.774 fps. This highly efficient and precise YOLO-EA\nholds great promise for practical application in intricate construction\nscenarios, enforcing stringent safety compliance during complex railway\nconstruction projects.", "arxiv_id": "2408.05964v1", "pdf_url": "http://arxiv.org/pdf/2408.05964v1", "abstract_url": "http://arxiv.org/abs/2408.05964v1", "primary_category": "cs.CV", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Target Detection of Safety Protective Gear Using the Improved YOLOv5", "response": "RELEVANT", "timestamp": "2024-08-19T13:37:39.943558"}
{"title": "ConvKGYarn: Spinning Configurable and Scalable Conversational Knowledge Graph QA datasets with Large Language Models", "authors": "Ronak Pradeep, Daniel Lee, Ali Mousavi, Jeff Pound, Yisi Sang, Jimmy Lin, Ihab Ilyas, Saloni Potdar, Mostafa Arefiyan, Yunyao Li", "abstract": "The rapid advancement of Large Language Models (LLMs) and conversational\nassistants necessitates dynamic, scalable, and configurable conversational\ndatasets for training and evaluation. These datasets must accommodate diverse\nuser interaction modes, including text and voice, each presenting unique\nmodeling challenges. Knowledge Graphs (KGs), with their structured and evolving\nnature, offer an ideal foundation for current and precise knowledge. Although\nhuman-curated KG-based conversational datasets exist, they struggle to keep\npace with the rapidly changing user information needs. We present ConvKGYarn, a\nscalable method for generating up-to-date and configurable conversational KGQA\ndatasets. Qualitative psychometric analyses confirm our method can generate\nhigh-quality datasets rivaling a popular conversational KGQA dataset while\noffering it at scale and covering a wide range of human-interaction\nconfigurations. We showcase its utility by testing LLMs on diverse\nconversations - exploring model behavior on conversational KGQA sets with\ndifferent configurations grounded in the same KG fact set. Our results\nhighlight the ability of ConvKGYarn to improve KGQA foundations and evaluate\nparametric knowledge of LLMs, thus offering a robust solution to the constantly\nevolving landscape of conversational assistants.", "arxiv_id": "2408.05948v1", "pdf_url": "http://arxiv.org/pdf/2408.05948v1", "abstract_url": "http://arxiv.org/abs/2408.05948v1", "primary_category": "cs.CL", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "ConvKGYarn: Spinning Configurable and Scalable Conversational Knowledge Graph QA datasets with Large Language Models", "response": "RELEVANT", "timestamp": "2024-08-19T13:37:40.761120"}
{"title": "BI-MDRG: Bridging Image History in Multimodal Dialogue Response Generation", "authors": "Hee Suk Yoon, Eunseop Yoon, Joshua Tian Jin Tee, Kang Zhang, Yu-Jung Heo, Du-Seong Chang, Chang D. Yoo", "abstract": "Multimodal Dialogue Response Generation (MDRG) is a recently proposed task\nwhere the model needs to generate responses in texts, images, or a blend of\nboth based on the dialogue context. Due to the lack of a large-scale dataset\nspecifically for this task and the benefits of leveraging powerful pre-trained\nmodels, previous work relies on the text modality as an intermediary step for\nboth the image input and output of the model rather than adopting an end-to-end\napproach. However, this approach can overlook crucial information about the\nimage, hindering 1) image-grounded text response and 2) consistency of objects\nin the image response. In this paper, we propose BI-MDRG that bridges the\nresponse generation path such that the image history information is utilized\nfor enhanced relevance of text responses to the image content and the\nconsistency of objects in sequential image responses. Through extensive\nexperiments on the multimodal dialogue benchmark dataset, we show that BI-MDRG\ncan effectively increase the quality of multimodal dialogue. Additionally,\nrecognizing the gap in benchmark datasets for evaluating the image consistency\nin multimodal dialogue, we have created a curated set of 300 dialogues\nannotated to track object consistency across conversations.", "arxiv_id": "2408.05926v1", "pdf_url": "http://arxiv.org/pdf/2408.05926v1", "abstract_url": "http://arxiv.org/abs/2408.05926v1", "primary_category": "cs.AI", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "BI-MDRG: Bridging Image History in Multimodal Dialogue Response Generation", "response": "RELEVANT", "timestamp": "2024-08-19T13:37:42.788299"}
{"title": "Urban Region Pre-training and Prompting: A Graph-based Approach", "authors": "Jiahui Jin, Yifan Song, Dong Kan, Haojia Zhu, Xiangguo Sun, Zhicheng Li, Xigang Sun, Jinghui Zhang", "abstract": "Urban region representation is crucial for various urban downstream tasks.\nHowever, despite the proliferation of methods and their success, acquiring\ngeneral urban region knowledge and adapting to different tasks remains\nchallenging. Previous work often neglects the spatial structures and functional\nlayouts between entities, limiting their ability to capture transferable\nknowledge across regions. Further, these methods struggle to adapt effectively\nto specific downstream tasks, as they do not adequately address the unique\nfeatures and relationships required for different downstream tasks. In this\npaper, we propose a $\\textbf{G}$raph-based $\\textbf{U}$rban $\\textbf{R}$egion\n$\\textbf{P}$re-training and $\\textbf{P}$rompting framework ($\\textbf{GURPP}$)\nfor region representation learning. Specifically, we first construct an urban\nregion graph that integrates detailed spatial entity data for more effective\nurban region representation. Then, we develop a subgraph-centric urban region\npre-training model to capture the heterogeneous and transferable patterns of\ninteractions among entities. To further enhance the adaptability of these\nembeddings to different tasks, we design two graph-based prompting methods to\nincorporate explicit/hidden task knowledge. Extensive experiments on various\nurban region prediction tasks and different cities demonstrate the superior\nperformance of our GURPP framework. The implementation is available at this\nrepository: https://anonymous.4open.science/r/GURPP.", "arxiv_id": "2408.05920v1", "pdf_url": "http://arxiv.org/pdf/2408.05920v1", "abstract_url": "http://arxiv.org/abs/2408.05920v1", "primary_category": "cs.AI", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Urban Region Pre-training and Prompting: A Graph-based Approach", "response": "RELEVANT", "timestamp": "2024-08-19T13:37:43.785309"}
{"title": "Inverse design of Non-parameterized Ventilated Acoustic Resonator via Variational Autoencoder with Acoustic Response-encoded Latent Space", "authors": "Min Woo Cho, Seok Hyeon Hwang, Jun-Young Jang, Jin Yeong Song, Sun-kwang Hwang, Kyoung Je Cha, Dong Yong Park, Kyungjun Song, Sang Min Park", "abstract": "Ventilated acoustic resonator(VAR), a type of acoustic metamaterial, emerge\nas an alternative for sound attenuation in environments that require\nventilation, owing to its excellent low-frequency attenuation performance and\nflexible shape adaptability. However, due to the non-linear acoustic responses\nof VARs, the VAR designs are generally obtained within a limited parametrized\ndesign space, and the design relies on the iteration of the numerical\nsimulation which consumes a considerable amount of computational time and\nresources. This paper proposes an acoustic response-encoded variational\nautoencoder (AR-VAE), a novel variational autoencoder-based generative design\nmodel for the efficient and accurate inverse design of VAR even with\nnon-parametrized designs. The AR-VAE matches the high-dimensional acoustic\nresponse with the VAR cross-section image in the dimension-reduced latent\nspace, which enables the AR-VAE to generate various non-parametrized VAR\ncross-section images with the target acoustic response. AR-VAE generates\nnon-parameterized VARs from target acoustic responses, which show a 25-fold\nreduction in mean squared error compared to conventional deep learning-based\nparameter searching methods while exhibiting lower average mean squared error\nand peak frequency variance. By combining the inverse-designed VARs by AR-VAE,\nmulti-cavity VAR was devised for broadband and multitarget peak frequency\nattenuation. The proposed design method presents a new approach for structural\ninverse-design with a high-dimensional non-linear physical response.", "arxiv_id": "2408.05917v1", "pdf_url": "http://arxiv.org/pdf/2408.05917v1", "abstract_url": "http://arxiv.org/abs/2408.05917v1", "primary_category": "cs.CE", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Inverse design of Non-parameterized Ventilated Acoustic Resonator via Variational Autoencoder with Acoustic Response-encoded Latent Space", "response": "RELEVANT", "timestamp": "2024-08-19T13:37:44.551139"}
{"title": "Cluster-Segregate-Perturb (CSP): A Model-agnostic Explainability Pipeline for Spatiotemporal Land Surface Forecasting Models", "authors": "Tushar Verma, Sudipan Saha", "abstract": "Satellite images have become increasingly valuable for modelling regional\nclimate change effects. Earth surface forecasting represents one such task that\nintegrates satellite images with meteorological data to capture the joint\nevolution of regional climate change effects. However, understanding the\ncomplex relationship between specific meteorological variables and land surface\nevolution poses a significant challenge. In light of this challenge, our paper\nintroduces a pipeline that integrates principles from both perturbation-based\nexplainability techniques like LIME and global marginal explainability\ntechniques like PDP, besides addressing the constraints of using such\ntechniques when applying them to high-dimensional spatiotemporal deep models.\nThe proposed pipeline simplifies the undertaking of diverse investigative\nanalyses, such as marginal sensitivity analysis, marginal correlation analysis,\nlag analysis, etc., on complex land surface forecasting models In this study we\nutilised Convolutional Long Short-Term Memory (ConvLSTM) as the surface\nforecasting model and did analyses on the Normalized Difference Vegetation\nIndex (NDVI) of the surface forecasts, since meteorological variables like\ntemperature, pressure, and precipitation significantly influence it. The study\narea encompasses various regions in Europe. Our analyses show that\nprecipitation exhibits the highest sensitivity in the study area, followed by\ntemperature and pressure. Pressure has little to no direct effect on NDVI.\nAdditionally, interesting nonlinear correlations between meteorological\nvariables and NDVI have been uncovered.", "arxiv_id": "2408.05916v1", "pdf_url": "http://arxiv.org/pdf/2408.05916v1", "abstract_url": "http://arxiv.org/abs/2408.05916v1", "primary_category": "cs.LG", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Cluster-Segregate-Perturb (CSP): A Model-agnostic Explainability Pipeline for Spatiotemporal Land Surface Forecasting Models", "response": "RELEVANT", "timestamp": "2024-08-19T13:37:56.427010"}
{"title": "Fast John Ellipsoid Computation with Differential Privacy Optimization", "authors": "Jiuxiang Gu, Xiaoyu Li, Yingyu Liang, Zhenmei Shi, Zhao Song, Junwei Yu", "abstract": "Determining the John ellipsoid - the largest volume ellipsoid contained\nwithin a convex polytope - is a fundamental problem with applications in\nmachine learning, optimization, and data analytics. Recent work has developed\nfast algorithms for approximating the John ellipsoid using sketching and\nleverage score sampling techniques. However, these algorithms do not provide\nprivacy guarantees for sensitive input data. In this paper, we present the\nfirst differentially private algorithm for fast John ellipsoid computation. Our\nmethod integrates noise perturbation with sketching and leverage score sampling\nto achieve both efficiency and privacy. We prove that (1) our algorithm\nprovides $(\\epsilon,\\delta)$-differential privacy, and the privacy guarantee\nholds for neighboring datasets that are $\\epsilon_0$-close, allowing\nflexibility in the privacy definition; (2) our algorithm still converges to a\n$(1+\\xi)$-approximation of the optimal John ellipsoid in\n$O(\\xi^{-2}(\\log(n/\\delta_0) + (L\\epsilon_0)^{-2}))$ iterations where $n$ is\nthe number of data point, $L$ is the Lipschitz constant, $\\delta_0$ is the\nfailure probability, and $\\epsilon_0$ is the closeness of neighboring input\ndatasets. Our theoretical analysis demonstrates the algorithm's convergence and\nprivacy properties, providing a robust approach for balancing utility and\nprivacy in John ellipsoid computation. This is the first differentially private\nalgorithm for fast John ellipsoid computation, opening avenues for future\nresearch in privacy-preserving optimization techniques.", "arxiv_id": "2408.06395v1", "pdf_url": "http://arxiv.org/pdf/2408.06395v1", "abstract_url": "http://arxiv.org/abs/2408.06395v1", "primary_category": "cs.DS", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Fast John Ellipsoid Computation with Differential Privacy Optimization", "response": "RELEVANT", "timestamp": "2024-08-19T13:37:57.338595"}
{"title": "Quantum Gradient Class Activation Map for Model Interpretability", "authors": "Hsin-Yi Lin, Huan-Hsin Tseng, Samuel Yen-Chi Chen, Shinjae Yoo", "abstract": "Quantum machine learning (QML) has recently made significant advancements in\nvarious topics. Despite the successes, the safety and interpretability of QML\napplications have not been thoroughly investigated. This work proposes using\nVariational Quantum Circuits (VQCs) for activation mapping to enhance model\ntransparency, introducing the Quantum Gradient Class Activation Map\n(QGrad-CAM). This hybrid quantum-classical computing framework leverages both\nquantum and classical strengths and gives access to the derivation of an\nexplicit formula of feature map importance. Experimental results demonstrate\nsignificant, fine-grained, class-discriminative visual explanations generated\nacross both image and speech datasets.", "arxiv_id": "2408.05899v1", "pdf_url": "http://arxiv.org/pdf/2408.05899v1", "abstract_url": "http://arxiv.org/abs/2408.05899v1", "primary_category": "quant-ph", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Quantum Gradient Class Activation Map for Model Interpretability", "response": "RELEVANT", "timestamp": "2024-08-19T13:37:58.069323"}
{"title": "Polyp SAM 2: Advancing Zero shot Polyp Segmentation in Colorectal Cancer Detection", "authors": "Mobina Mansoori, Sajjad Shahabodini, Jamshid Abouei, Konstantinos N. Plataniotis, Arash Mohammadi", "abstract": "Polyp segmentation plays a crucial role in the early detection and diagnosis\nof colorectal cancer. However, obtaining accurate segmentations often requires\nlabor-intensive annotations and specialized models. Recently, Meta AI Research\nreleased a general Segment Anything Model 2 (SAM 2), which has demonstrated\npromising performance in several segmentation tasks. In this work, we evaluate\nthe performance of SAM 2 in segmenting polyps under various prompted settings.\nWe hope this report will provide insights to advance the field of polyp\nsegmentation and promote more interesting work in the future. This project is\npublicly available at https://github.com/ sajjad-sh33/Polyp-SAM-2.", "arxiv_id": "2408.05892v1", "pdf_url": "http://arxiv.org/pdf/2408.05892v1", "abstract_url": "http://arxiv.org/abs/2408.05892v1", "primary_category": "eess.IV", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Polyp SAM 2: Advancing Zero shot Polyp Segmentation in Colorectal Cancer Detection", "response": "RELEVANT", "timestamp": "2024-08-19T13:37:58.886620"}
{"title": "Online-Score-Aided Federated Learning: Taming the Resource Constraints in Wireless Networks", "authors": "Md Ferdous Pervej, Minseok Choi, Andreas F. Molisch", "abstract": "While FL is a widely popular distributed ML strategy that protects data\nprivacy, time-varying wireless network parameters and heterogeneous system\nconfigurations of the wireless device pose significant challenges. Although the\nlimited radio and computational resources of the network and the clients,\nrespectively, are widely acknowledged, two critical yet often ignored aspects\nare (a) wireless devices can only dedicate a small chunk of their limited\nstorage for the FL task and (b) new training samples may arrive in an online\nmanner in many practical wireless applications. Therefore, we propose a new FL\nalgorithm called OSAFL, specifically designed to learn tasks relevant to\nwireless applications under these practical considerations. Since it has long\nbeen proven that under extreme resource constraints, clients may perform an\narbitrary number of local training steps, which may lead to client drift under\nstatistically heterogeneous data distributions, we leverage normalized gradient\nsimilarities and exploit weighting clients' updates based on optimized scores\nthat facilitate the convergence rate of the proposed OSAFL algorithm. Our\nextensive simulation results on two different tasks -- each with three\ndifferent datasets -- with four popular ML models validate the effectiveness of\nOSAFL compared to six existing state-of-the-art FL baselines.", "arxiv_id": "2408.05886v1", "pdf_url": "http://arxiv.org/pdf/2408.05886v1", "abstract_url": "http://arxiv.org/abs/2408.05886v1", "primary_category": "cs.LG", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Online-Score-Aided Federated Learning: Taming the Resource Constraints in Wireless Networks", "response": "RELEVANT", "timestamp": "2024-08-19T13:37:59.803270"}
{"title": "A Unified Manifold Similarity Measure Enhancing Few-Shot, Transfer, and Reinforcement Learning in Manifold-Distributed Datasets", "authors": "Sayed W Qayyumi, Laureance F Park, Oliver Obst", "abstract": "Training a classifier with high mean accuracy from a manifold-distributed\ndataset can be challenging. This problem is compounded further when there are\nonly few labels available for training. For transfer learning to work, both the\nsource and target datasets must have a similar manifold structure. As part of\nthis study, we present a novel method for determining the similarity between\ntwo manifold structures. This method can be used to determine whether the\ntarget and source datasets have a similar manifold structure suitable for\ntransfer learning.\n  We then present a few-shot learning method to classify manifold-distributed\ndatasets with limited labels using transfer learning. Based on the base and\ntarget datasets, a similarity comparison is made to determine if the two\ndatasets are suitable for transfer learning. A manifold structure and label\ndistribution are learned from the base and target datasets. When the structures\nare similar, the manifold structure and its relevant label information from the\nrichly labeled source dataset is transferred to target dataset. We use the\ntransferred information, together with the labels and unlabeled data from the\ntarget dataset, to develop a few-shot classifier that produces high mean\nclassification accuracy on manifold-distributed datasets.\n  In the final part of this article, we discuss the application of our manifold\nstructure similarity measure to reinforcement learning and image recognition.", "arxiv_id": "2408.07095v1", "pdf_url": "http://arxiv.org/pdf/2408.07095v1", "abstract_url": "http://arxiv.org/abs/2408.07095v1", "primary_category": "cs.LG", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "A Unified Manifold Similarity Measure Enhancing Few-Shot, Transfer, and Reinforcement Learning in Manifold-Distributed Datasets", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:00.547936"}
{"title": "GFlowNet Training by Policy Gradients", "authors": "Puhua Niu, Shili Wu, Mingzhou Fan, Xiaoning Qian", "abstract": "Generative Flow Networks (GFlowNets) have been shown effective to generate\ncombinatorial objects with desired properties. We here propose a new GFlowNet\ntraining framework, with policy-dependent rewards, that bridges keeping flow\nbalance of GFlowNets to optimizing the expected accumulated reward in\ntraditional Reinforcement-Learning (RL). This enables the derivation of new\npolicy-based GFlowNet training methods, in contrast to existing ones resembling\nvalue-based RL. It is known that the design of backward policies in GFlowNet\ntraining affects efficiency. We further develop a coupled training strategy\nthat jointly solves GFlowNet forward policy training and backward policy\ndesign. Performance analysis is provided with a theoretical guarantee of our\npolicy-based GFlowNet training. Experiments on both simulated and real-world\ndatasets verify that our policy-based strategies provide advanced RL\nperspectives for robust gradient estimation to improve GFlowNet performance.", "arxiv_id": "2408.05885v1", "pdf_url": "http://arxiv.org/pdf/2408.05885v1", "abstract_url": "http://arxiv.org/abs/2408.05885v1", "primary_category": "cs.LG", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "GFlowNet Training by Policy Gradients", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:01.330508"}
{"title": "Low-Rank Approximation, Adaptation, and Other Tales", "authors": "Jun Lu", "abstract": "Low-rank approximation is a fundamental technique in modern data analysis,\nwidely utilized across various fields such as signal processing, machine\nlearning, and natural language processing. Despite its ubiquity, the mechanics\nof low-rank approximation and its application in adaptation can sometimes be\nobscure, leaving practitioners and researchers with questions about its true\ncapabilities and limitations. This paper seeks to clarify low-rank\napproximation and adaptation by offering a comprehensive guide that reveals\ntheir inner workings and explains their utility in a clear and accessible way.\nOur focus here is to develop a solid intuition for how low-rank approximation\nand adaptation operate, and why they are so effective. We begin with basic\nconcepts and gradually build up to the mathematical underpinnings, ensuring\nthat readers of all backgrounds can gain a deeper understanding of low-rank\napproximation and adaptation. We strive to strike a balance between informal\nexplanations and rigorous mathematics, ensuring that both newcomers and\nexperienced experts can benefit from this survey. Additionally, we introduce\nnew low-rank decomposition and adaptation algorithms that have not yet been\nexplored in the field, hoping that future researchers will investigate their\npotential applicability.", "arxiv_id": "2408.05883v1", "pdf_url": "http://arxiv.org/pdf/2408.05883v1", "abstract_url": "http://arxiv.org/abs/2408.05883v1", "primary_category": "cs.LG", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Low-Rank Approximation, Adaptation, and Other Tales", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:02.165263"}
{"title": "Overcoming Imbalanced Safety Data Using Extended Accident Triangle", "authors": "Kailai Sun, Tianxiang Lan, Yang Miang Goh, Yueng-Hsiang Huang", "abstract": "There is growing interest in using safety analytics and machine learning to\nsupport the prevention of workplace incidents, especially in high-risk\nindustries like construction and trucking. Although existing safety analytics\nstudies have made remarkable progress, they suffer from imbalanced datasets, a\ncommon problem in safety analytics, resulting in prediction inaccuracies. This\ncan lead to management problems, e.g., incorrect resource allocation and\nimproper interventions. To overcome the imbalanced data problem, we extend the\ntheory of accident triangle to claim that the importance of data samples should\nbe based on characteristics such as injury severity, accident frequency, and\naccident type. Thus, three oversampling methods are proposed based on assigning\ndifferent weights to samples in the minority class. We find robust improvements\namong different machine learning algorithms. For the lack of open-source safety\ndatasets, we are sharing three imbalanced datasets, e.g., a 9-year nationwide\nconstruction accident record dataset, and their corresponding codes.", "arxiv_id": "2408.07094v1", "pdf_url": "http://arxiv.org/pdf/2408.07094v1", "abstract_url": "http://arxiv.org/abs/2408.07094v1", "primary_category": "cs.LG", "published_date": "2024-08-12", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Overcoming Imbalanced Safety Data Using Extended Accident Triangle", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:03.247230"}
{"title": "LLM-Based Robust Product Classification in Commerce and Compliance", "authors": "Sina Gholamian, Gianfranco Romani, Bartosz Rudnikowicz, Laura Skylaki", "abstract": "Product classification is a crucial task in international trade, as\ncompliance regulations are verified and taxes and duties are applied based on\nproduct categories. Manual classification of products is time-consuming and\nerror-prone, and the sheer volume of products imported and exported renders the\nmanual process infeasible. Consequently, e-commerce platforms and enterprises\ninvolved in international trade have turned to automatic product classification\nusing machine learning. However, current approaches do not consider the\nreal-world challenges associated with product classification, such as very\nabbreviated and incomplete product descriptions. In addition, recent\nadvancements in generative Large Language Models (LLMs) and their reasoning\ncapabilities are mainly untapped in product classification and e-commerce. In\nthis research, we explore the real-life challenges of industrial classification\nand we propose data perturbations that allow for realistic data simulation.\nFurthermore, we employ LLM-based product classification to improve the\nrobustness of the prediction in presence of incomplete data. Our research shows\nthat LLMs with in-context learning outperform the supervised approaches in the\nclean-data scenario. Additionally, we illustrate that LLMs are significantly\nmore robust than the supervised approaches when data attacks are present.", "arxiv_id": "2408.05874v1", "pdf_url": "http://arxiv.org/pdf/2408.05874v1", "abstract_url": "http://arxiv.org/abs/2408.05874v1", "primary_category": "cs.CL", "published_date": "2024-08-11", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "LLM-Based Robust Product Classification in Commerce and Compliance", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:04.064077"}
{"title": "Leveraging Knowledge Graph-Based Human-Like Memory Systems to Solve Partially Observable Markov Decision Processes", "authors": "Taewoon Kim, Vincent Fran\u00e7ois-Lavet, Michael Cochez", "abstract": "Humans observe only part of their environment at any moment but can still\nmake complex, long-term decisions thanks to our long-term memory system. To\ntest how an AI can learn and utilize its long-term memory system, we have\ndeveloped a partially observable Markov decision processes (POMDP) environment,\nwhere the agent has to answer questions while navigating a maze. The\nenvironment is completely knowledge graph (KG) based, where the hidden states\nare dynamic KGs. A KG is both human- and machine-readable, making it easy to\nsee what the agents remember and forget. We train and compare agents with\ndifferent memory systems, to shed light on how human brains work when it comes\nto managing its own memory systems. By repurposing the given learning objective\nas learning a memory management policy, we were able to capture the most likely\nbelief state, which is not only interpretable but also reusable.", "arxiv_id": "2408.05861v1", "pdf_url": "http://arxiv.org/pdf/2408.05861v1", "abstract_url": "http://arxiv.org/abs/2408.05861v1", "primary_category": "cs.AI", "published_date": "2024-08-11", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Leveraging Knowledge Graph-Based Human-Like Memory Systems to Solve Partially Observable Markov Decision Processes", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:04.800206"}
{"title": "Root Cause Attribution of Delivery Risks via Causal Discovery with Reinforcement Learning", "authors": "Shi Bo, Minheng Xiao", "abstract": "This paper presents a novel approach to root cause attribution of delivery\nrisks within supply chains by integrating causal discovery with reinforcement\nlearning. As supply chains become increasingly complex, traditional methods of\nroot cause analysis struggle to capture the intricate interrelationships\nbetween various factors, often leading to spurious correlations and suboptimal\ndecision-making. Our approach addresses these challenges by leveraging causal\ndiscovery to identify the true causal relationships between operational\nvariables, and reinforcement learning to iteratively refine the causal graph.\nThis method enables the accurate identification of key drivers of late\ndeliveries, such as shipping mode and delivery status, and provides actionable\ninsights for optimizing supply chain performance. We apply our approach to a\nreal-world supply chain dataset, demonstrating its effectiveness in uncovering\nthe underlying causes of delivery delays and offering strategies for mitigating\nthese risks. The findings have significant implications for improving\noperational efficiency, customer satisfaction, and overall profitability within\nsupply chains.", "arxiv_id": "2408.05860v1", "pdf_url": "http://arxiv.org/pdf/2408.05860v1", "abstract_url": "http://arxiv.org/abs/2408.05860v1", "primary_category": "cs.AI", "published_date": "2024-08-11", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Root Cause Attribution of Delivery Risks via Causal Discovery with Reinforcement Learning", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:05.623740"}
{"title": "Comparative Evaluation of Memory Technologies for Synaptic Crossbar Arrays- Part 2: Design Knobs and DNN Accuracy Trends", "authors": "Jeffry Victor, Chunguang Wang, Sumeet K. Gupta", "abstract": "Crossbar memory arrays have been touted as the workhorse of in-memory\ncomputing (IMC)-based acceleration of Deep Neural Networks (DNNs), but the\nassociated hardware non-idealities limit their efficacy. To address this,\ncross-layer design solutions that reduce the impact of hardware non-idealities\non DNN accuracy are needed. In Part 1 of this paper, we established the\nco-optimization strategies for various memory technologies and their crossbar\narrays, and conducted a comparative technology evaluation in the context of IMC\nrobustness. In this part, we analyze various design knobs such as array size\nand bit-slice (number of bits per device) and their impact on the performance\nof 8T SRAM, ferroelectric transistor (FeFET), Resistive RAM (ReRAM) and\nspin-orbit-torque magnetic RAM (SOT-MRAM) in the context of inference accuracy\nat 7nm technology node. Further, we study the effect of circuit design\nsolutions such as Partial Wordline Activation (PWA) and custom ADC reference\nlevels that reduce the hardware non-idealities and comparatively analyze the\nresponse of each technology to such accuracy enhancing techniques. Our results\non ResNet-20 (with CIFAR-10) show that PWA increases accuracy by up to 32.56%\nwhile custom ADC reference levels yield up to 31.62% accuracy enhancement. We\nobserve that compared to the other technologies, FeFET, by virtue of its small\nlayout height and high distinguishability of its memory states, is best suited\nfor large arrays. For higher bit-slices and a more complex dataset (ResNet-50\nwith Cifar-100) we found that ReRAM matches the performance of FeFET.", "arxiv_id": "2408.05857v1", "pdf_url": "http://arxiv.org/pdf/2408.05857v1", "abstract_url": "http://arxiv.org/abs/2408.05857v1", "primary_category": "cs.ET", "published_date": "2024-08-11", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Comparative Evaluation of Memory Technologies for Synaptic Crossbar Arrays- Part 2: Design Knobs and DNN Accuracy Trends", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:06.375351"}
{"title": "Using Retriever Augmented Large Language Models for Attack Graph Generation", "authors": "Renascence Tarafder Prapty, Ashish Kundu, Arun Iyengar", "abstract": "As the complexity of modern systems increases, so does the importance of\nassessing their security posture through effective vulnerability management and\nthreat modeling techniques. One powerful tool in the arsenal of cybersecurity\nprofessionals is the attack graph, a representation of all potential attack\npaths within a system that an adversary might exploit to achieve a certain\nobjective. Traditional methods of generating attack graphs involve expert\nknowledge, manual curation, and computational algorithms that might not cover\nthe entire threat landscape due to the ever-evolving nature of vulnerabilities\nand exploits. This paper explores the approach of leveraging large language\nmodels (LLMs), such as ChatGPT, to automate the generation of attack graphs by\nintelligently chaining Common Vulnerabilities and Exposures (CVEs) based on\ntheir preconditions and effects. It also shows how to utilize LLMs to create\nattack graphs from threat reports.", "arxiv_id": "2408.05855v1", "pdf_url": "http://arxiv.org/pdf/2408.05855v1", "abstract_url": "http://arxiv.org/abs/2408.05855v1", "primary_category": "cs.CR", "published_date": "2024-08-11", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Using Retriever Augmented Large Language Models for Attack Graph Generation", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:07.283685"}
{"title": "On the Robustness of Kernel Goodness-of-Fit Tests", "authors": "Xing Liu, Fran\u00e7ois-Xavier Briol", "abstract": "Goodness-of-fit testing is often criticized for its lack of practical\nrelevance; since ``all models are wrong'', the null hypothesis that the data\nconform to our model is ultimately always rejected when the sample size is\nlarge enough. Despite this, probabilistic models are still used extensively,\nraising the more pertinent question of whether the model is good enough for a\nspecific task. This question can be formalized as a robust goodness-of-fit\ntesting problem by asking whether the data were generated by a distribution\ncorresponding to our model up to some mild perturbation. In this paper, we show\nthat existing kernel goodness-of-fit tests are not robust according to common\nnotions of robustness including qualitative and quantitative robustness. We\nalso show that robust techniques based on tilted kernels from the parameter\nestimation literature are not sufficient for ensuring both types of robustness\nin the context of goodness-of-fit testing. We therefore propose the first\nrobust kernel goodness-of-fit test which resolves this open problem using\nkernel Stein discrepancy balls, which encompass perturbation models such as\nHuber contamination models and density uncertainty bands.", "arxiv_id": "2408.05854v1", "pdf_url": "http://arxiv.org/pdf/2408.05854v1", "abstract_url": "http://arxiv.org/abs/2408.05854v1", "primary_category": "stat.ML", "published_date": "2024-08-11", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "On the Robustness of Kernel Goodness-of-Fit Tests", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:08.387680"}
{"title": "An End-to-End Model for Time Series Classification In the Presence of Missing Values", "authors": "Pengshuai Yao, Mengna Liu, Xu Cheng, Fan Shi, Huan Li, Xiufeng Liu, Shengyong Chen", "abstract": "Time series classification with missing data is a prevalent issue in time\nseries analysis, as temporal data often contain missing values in practical\napplications. The traditional two-stage approach, which handles imputation and\nclassification separately, can result in sub-optimal performance as label\ninformation is not utilized in the imputation process. On the other hand, a\none-stage approach can learn features under missing information, but feature\nrepresentation is limited as imputed errors are propagated in the\nclassification process. To overcome these challenges, this study proposes an\nend-to-end neural network that unifies data imputation and representation\nlearning within a single framework, allowing the imputation process to take\nadvantage of label information. Differing from previous methods, our approach\nplaces less emphasis on the accuracy of imputation data and instead prioritizes\nclassification performance. A specifically designed multi-scale feature\nlearning module is implemented to extract useful information from the\nnoise-imputation data. The proposed model is evaluated on 68 univariate time\nseries datasets from the UCR archive, as well as a multivariate time series\ndataset with various missing data ratios and 4 real-world datasets with missing\ninformation. The results indicate that the proposed model outperforms\nstate-of-the-art approaches for incomplete time series classification,\nparticularly in scenarios with high levels of missing data.", "arxiv_id": "2408.05849v1", "pdf_url": "http://arxiv.org/pdf/2408.05849v1", "abstract_url": "http://arxiv.org/abs/2408.05849v1", "primary_category": "cs.LG", "published_date": "2024-08-11", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "An End-to-End Model for Time Series Classification In the Presence of Missing Values", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:09.128355"}
{"title": "Online Matrix Completion: A Collaborative Approach with Hott Items", "authors": "Dheeraj Baby, Soumyabrata Pal", "abstract": "We investigate the low rank matrix completion problem in an online setting\nwith ${M}$ users, ${N}$ items, ${T}$ rounds, and an unknown rank-$r$ reward\nmatrix ${R}\\in \\mathbb{R}^{{M}\\times {N}}$. This problem has been well-studied\nin the literature and has several applications in practice. In each round, we\nrecommend ${S}$ carefully chosen distinct items to every user and observe noisy\nrewards. In the regime where ${M},{N} >> {T}$, we propose two distinct\ncomputationally efficient algorithms for recommending items to users and\nanalyze them under the benign \\emph{hott items} assumption.1) First, for\n${S}=1$, under additional incoherence/smoothness assumptions on ${R}$, we\npropose the phased algorithm \\textsc{PhasedClusterElim}. Our algorithm obtains\na near-optimal per-user regret of\n$\\tilde{O}({N}{M}^{-1}(\\Delta^{-1}+\\Delta_{{hott}}^{-2}))$ where\n$\\Delta_{{hott}},\\Delta$ are problem-dependent gap parameters with\n$\\Delta_{{hott}} >> \\Delta$ almost always. 2) Second, we consider a simplified\nsetting with ${S}=r$ where we make significantly milder assumptions on ${R}$.\nHere, we introduce another phased algorithm, \\textsc{DeterminantElim}, to\nderive a regret guarantee of $\\widetilde{O}({N}{M}^{-1/r}\\Delta_{det}^{-1}))$\nwhere $\\Delta_{{det}}$ is another problem-dependent gap. Both algorithms\ncrucially use collaboration among users to jointly eliminate sub-optimal items\nfor groups of users successively in phases, but with distinctive and novel\napproaches.", "arxiv_id": "2408.05843v1", "pdf_url": "http://arxiv.org/pdf/2408.05843v1", "abstract_url": "http://arxiv.org/abs/2408.05843v1", "primary_category": "cs.LG", "published_date": "2024-08-11", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Online Matrix Completion: A Collaborative Approach with Hott Items", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:10.341255"}
{"title": "Post-Training Sparse Attention with Double Sparsity", "authors": "Shuo Yang, Ying Sheng, Joseph E. Gonzalez, Ion Stoica, Lianmin Zheng", "abstract": "The inference process for large language models is slow and memory-intensive,\nwith one of the most critical bottlenecks being excessive Key-Value (KV) cache\naccesses. This paper introduces \"Double Sparsity,\" a novel post-training sparse\nattention technique designed to alleviate this bottleneck by reducing KV cache\naccess. Double Sparsity combines token sparsity, which focuses on utilizing\nonly the important tokens for computing self-attention, with channel sparsity,\nan approach that uses important feature channels for identifying important\ntokens. Our key insight is that the pattern of channel sparsity is relatively\nstatic, allowing us to use offline calibration to make it efficient at runtime,\nthereby enabling accurate and efficient identification of important tokens.\nMoreover, this method can be combined with offloading to achieve significant\nmemory usage reduction. Experimental results demonstrate that Double Sparsity\ncan achieve \\(\\frac{1}{16}\\) token and channel sparsity with minimal impact on\naccuracy across various tasks, including wiki-2 perplexity, key-value\nretrieval, and long context benchmarks with models including Llama-2-7B,\nLlama-2-70B, and Mixtral-8x7B. It brings up to a 14.1$\\times$ acceleration in\nattention operations and a 1.9$\\times$ improvement in end-to-end inference on\nGPUs. With offloading, it achieves a decoding speed acceleration of\n16.3$\\times$ compared to state-of-the-art solutions at a sequence length of\n256K. Our code is publicly available at\n\\url{https://github.com/andy-yang-1/DoubleSparse}.", "arxiv_id": "2408.07092v1", "pdf_url": "http://arxiv.org/pdf/2408.07092v1", "abstract_url": "http://arxiv.org/abs/2408.07092v1", "primary_category": "cs.LG", "published_date": "2024-08-11", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Post-Training Sparse Attention with Double Sparsity", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:11.187370"}
{"title": "Divide-and-Conquer Predictive Coding: a structured Bayesian inference algorithm", "authors": "Eli Sennesh, Hao Wu, Tommaso Salvatori", "abstract": "Unexpected stimuli induce \"error\" or \"surprise\" signals in the brain. The\ntheory of predictive coding promises to explain these observations in terms of\nBayesian inference by suggesting that the cortex implements variational\ninference in a probabilistic graphical model. However, when applied to machine\nlearning tasks, this family of algorithms has yet to perform on par with other\nvariational approaches in high-dimensional, structured inference problems. To\naddress this, we introduce a novel predictive coding algorithm for structured\ngenerative models, that we call divide-and-conquer predictive coding (DCPC).\nDCPC differs from other formulations of predictive coding, as it respects the\ncorrelation structure of the generative model and provably performs\nmaximum-likelihood updates of model parameters, all without sacrificing\nbiological plausibility. Empirically, DCPC achieves better numerical\nperformance than competing algorithms and provides accurate inference in a\nnumber of problems not previously addressed with predictive coding. We provide\nan open implementation of DCPC in Pyro on Github.", "arxiv_id": "2408.05834v1", "pdf_url": "http://arxiv.org/pdf/2408.05834v1", "abstract_url": "http://arxiv.org/abs/2408.05834v1", "primary_category": "stat.ML", "published_date": "2024-08-11", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Divide-and-Conquer Predictive Coding: a structured Bayesian inference algorithm", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:11.990002"}
{"title": "Sampling Foundational Transformer: A Theoretical Perspective", "authors": "Viet Anh Nguyen, Minh Lenhat, Khoa Nguyen, Duong Duc Hieu, Dao Huu Hung, Truong Son Hy", "abstract": "The versatility of self-attention mechanism earned transformers great success\nin almost all data modalities, with limitations on the quadratic complexity and\ndifficulty of training. To apply transformers across different data modalities,\npractitioners have to make specific clever data-modality-dependent\nconstructions. In this paper, we propose Sampling Foundational Transformer\n(SFT) that can work on multiple data modalities (e.g., point cloud, graph, and\nsequence) and constraints (e.g., rotational-invariant). The existence of such\nmodel is important as contemporary foundational modeling requires operability\non multiple data sources. For efficiency on large number of tokens, our model\nrelies on our context aware sampling-without-replacement mechanism for both\nlinear asymptotic computational complexity and real inference time gain. For\nefficiency, we rely on our newly discovered pseudoconvex formulation of\ntransformer layer to increase model's convergence rate. As a model working on\nmultiple data modalities, SFT has achieved competitive results on many\nbenchmarks, while being faster in inference, compared to other very specialized\nmodels.", "arxiv_id": "2408.05822v1", "pdf_url": "http://arxiv.org/pdf/2408.05822v1", "abstract_url": "http://arxiv.org/abs/2408.05822v1", "primary_category": "cs.LG", "published_date": "2024-08-11", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Sampling Foundational Transformer: A Theoretical Perspective", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:12.966127"}
{"title": "On the Convergence of a Federated Expectation-Maximization Algorithm", "authors": "Zhixu Tao, Rajita Chandak, Sanjeev Kulkarni", "abstract": "Data heterogeneity has been a long-standing bottleneck in studying the\nconvergence rates of Federated Learning algorithms. In order to better\nunderstand the issue of data heterogeneity, we study the convergence rate of\nthe Expectation-Maximization (EM) algorithm for the Federated Mixture of $K$\nLinear Regressions model. We fully characterize the convergence rate of the EM\nalgorithm under all regimes of $m/n$ where $m$ is the number of clients and $n$\nis the number of data points per client. We show that with a\nsignal-to-noise-ratio (SNR) of order $\\Omega(\\sqrt{K})$, the well-initialized\nEM algorithm converges within the minimax distance of the ground truth under\neach of the regimes. Interestingly, we identify that when $m$ grows\nexponentially in $n$, the EM algorithm only requires a constant number of\niterations to converge. We perform experiments on synthetic datasets to\nillustrate our results. Surprisingly, the results show that rather than being a\nbottleneck, data heterogeneity can accelerate the convergence of federated\nlearning algorithms.", "arxiv_id": "2408.05819v1", "pdf_url": "http://arxiv.org/pdf/2408.05819v1", "abstract_url": "http://arxiv.org/abs/2408.05819v1", "primary_category": "stat.ML", "published_date": "2024-08-11", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "On the Convergence of a Federated Expectation-Maximization Algorithm", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:13.697845"}
{"title": "Kernel Density Estimators in Large Dimensions", "authors": "Giulio Biroli, Marc M\u00e9zard", "abstract": "This paper studies Kernel density estimation for a high-dimensional\ndistribution $\\rho(x)$. Traditional approaches have focused on the limit of\nlarge number of data points $n$ and fixed dimension $d$. We analyze instead the\nregime where both the number $n$ of data points $y_i$ and their dimensionality\n$d$ grow with a fixed ratio $\\alpha=(\\log n)/d$. Our study reveals three\ndistinct statistical regimes for the kernel-based estimate of the density $\\hat\n\\rho_h^{\\mathcal {D}}(x)=\\frac{1}{n h^d}\\sum_{i=1}^n\nK\\left(\\frac{x-y_i}{h}\\right)$, depending on the bandwidth $h$: a classical\nregime for large bandwidth where the Central Limit Theorem (CLT) holds, which\nis akin to the one found in traditional approaches. Below a certain value of\nthe bandwidth, $h_{CLT}(\\alpha)$, we find that the CLT breaks down. The\nstatistics of $\\hat \\rho_h^{\\mathcal {D}}(x)$ for a fixed $x$ drawn from\n$\\rho(x)$ is given by a heavy-tailed distribution (an alpha-stable\ndistribution). In particular below a value $h_G(\\alpha)$, we find that $\\hat\n\\rho_h^{\\mathcal {D}}(x)$ is governed by extreme value statistics: only a few\npoints in the database matter and give the dominant contribution to the density\nestimator. We provide a detailed analysis for high-dimensional multivariate\nGaussian data. We show that the optimal bandwidth threshold based on\nKullback-Leibler divergence lies in the new statistical regime identified in\nthis paper. Our findings reveal limitations of classical approaches, show the\nrelevance of these new statistical regimes, and offer new insights for Kernel\ndensity estimation in high-dimensional settings.", "arxiv_id": "2408.05807v2", "pdf_url": "http://arxiv.org/pdf/2408.05807v2", "abstract_url": "http://arxiv.org/abs/2408.05807v2", "primary_category": "cs.LG", "published_date": "2024-08-11", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Kernel Density Estimators in Large Dimensions", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:14.741171"}
{"title": "A Single Goal is All You Need: Skills and Exploration Emerge from Contrastive RL without Rewards, Demonstrations, or Subgoals", "authors": "Grace Liu, Michael Tang, Benjamin Eysenbach", "abstract": "In this paper, we present empirical evidence of skills and directed\nexploration emerging from a simple RL algorithm long before any successful\ntrials are observed. For example, in a manipulation task, the agent is given a\nsingle observation of the goal state and learns skills, first for moving its\nend-effector, then for pushing the block, and finally for picking up and\nplacing the block. These skills emerge before the agent has ever successfully\nplaced the block at the goal location and without the aid of any reward\nfunctions, demonstrations, or manually-specified distance metrics. Once the\nagent has learned to reach the goal state reliably, exploration is reduced.\nImplementing our method involves a simple modification of prior work and does\nnot require density estimates, ensembles, or any additional hyperparameters.\nIntuitively, the proposed method seems like it should be terrible at\nexploration, and we lack a clear theoretical understanding of why it works so\neffectively, though our experiments provide some hints.", "arxiv_id": "2408.05804v1", "pdf_url": "http://arxiv.org/pdf/2408.05804v1", "abstract_url": "http://arxiv.org/abs/2408.05804v1", "primary_category": "cs.LG", "published_date": "2024-08-11", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "A Single Goal is All You Need: Skills and Exploration Emerge from Contrastive RL without Rewards, Demonstrations, or Subgoals", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:15.690814"}
{"title": "Time Makes Space: Emergence of Place Fields in Networks Encoding Temporally Continuous Sensory Experiences", "authors": "Zhaoze Wang, Ronald W. Di Tullio, Spencer Rooke, Vijay Balasubramanian", "abstract": "The vertebrate hippocampus is believed to use recurrent connectivity in area\nCA3 to support episodic memory recall from partial cues. This brain area also\ncontains place cells, whose location-selective firing fields implement maps\nsupporting spatial memory. Here we show that place cells emerge in networks\ntrained to remember temporally continuous sensory episodes. We model CA3 as a\nrecurrent autoencoder that recalls and reconstructs sensory experiences from\nnoisy and partially occluded observations by agents traversing simulated rooms.\nThe agents move in realistic trajectories modeled from rodents and environments\nare modeled as high-dimensional sensory experience maps. Training our\nautoencoder to pattern-complete and reconstruct experiences with a constraint\non total activity causes spatially localized firing fields, i.e., place cells,\nto emerge in the encoding layer. The emergent place fields reproduce key\naspects of hippocampal phenomenology: a) remapping (maintenance of and\nreversion to distinct learned maps in different environments), implemented via\nrepositioning of experience manifolds in the network's hidden layer, b)\northogonality of spatial representations in different arenas, c) robust place\nfield emergence in differently shaped rooms, with single units showing multiple\nplace fields in large or complex spaces, and d) slow representational drift of\nplace fields. We argue that these results arise because continuous traversal of\nspace makes sensory experience temporally continuous. We make testable\npredictions: a) rapidly changing sensory context will disrupt place fields, b)\nplace fields will form even if recurrent connections are blocked, but reversion\nto previously learned representations upon remapping will be abolished, c) the\ndimension of temporally smooth experience sets the dimensionality of place\nfields, including during virtual navigation of abstract spaces.", "arxiv_id": "2408.05798v1", "pdf_url": "http://arxiv.org/pdf/2408.05798v1", "abstract_url": "http://arxiv.org/abs/2408.05798v1", "primary_category": "q-bio.NC", "published_date": "2024-08-11", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Time Makes Space: Emergence of Place Fields in Networks Encoding Temporally Continuous Sensory Experiences", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:16.632214"}
{"title": "A Comparative Study of Convolutional and Recurrent Neural Networks for Storm Surge Prediction in Tampa Bay", "authors": "Mandana Farhang Ghahfarokhi, Seyed Hossein Sonbolestan, Mahta Zamanizadeh", "abstract": "In this paper, we compare the performance of three common deep learning\narchitectures, CNN-LSTM, LSTM, and 3D-CNN, in the context of surrogate storm\nsurge modeling. The study site for this paper is the Tampa Bay area in Florida.\nUsing high-resolution atmospheric data from the reanalysis models and\nhistorical water level data from NOAA tide stations, we trained and tested\nthese models to evaluate their performance. Our findings indicate that the\nCNN-LSTM model outperforms the other architectures, achieving a test loss of\n0.010 and an R-squared (R2) score of 0.84. The LSTM model, although it achieved\nthe lowest training loss of 0.007 and the highest training R2 of 0.88,\nexhibited poorer generalization with a test loss of 0.014 and an R2 of 0.77.\nThe 3D-CNN model showed reasonable performance with a test loss of 0.011 and an\nR2 of 0.82 but displayed instability under extreme conditions. A case study on\nHurricane Ian, which caused a significant negative surge of -1.5 meters in\nTampa Bay indicates the CNN-LSTM model's robustness and accuracy in extreme\nscenarios.", "arxiv_id": "2408.05797v1", "pdf_url": "http://arxiv.org/pdf/2408.05797v1", "abstract_url": "http://arxiv.org/abs/2408.05797v1", "primary_category": "cs.LG", "published_date": "2024-08-11", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "A Comparative Study of Convolutional and Recurrent Neural Networks for Storm Surge Prediction in Tampa Bay", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:17.294136"}
{"title": "Continual Learning of Nonlinear Independent Representations", "authors": "Boyang Sun, Ignavier Ng, Guangyi Chen, Yifan Shen, Qirong Ho, Kun Zhang", "abstract": "Identifying the causal relations between interested variables plays a pivotal\nrole in representation learning as it provides deep insights into the dataset.\nIdentifiability, as the central theme of this approach, normally hinges on\nleveraging data from multiple distributions (intervention, distribution shift,\ntime series, etc.). Despite the exciting development in this field, a practical\nbut often overlooked problem is: what if those distribution shifts happen\nsequentially? In contrast, any intelligence possesses the capacity to abstract\nand refine learned knowledge sequentially -- lifelong learning. In this paper,\nwith a particular focus on the nonlinear independent component analysis (ICA)\nframework, we move one step forward toward the question of enabling models to\nlearn meaningful (identifiable) representations in a sequential manner, termed\ncontinual causal representation learning. We theoretically demonstrate that\nmodel identifiability progresses from a subspace level to a component-wise\nlevel as the number of distributions increases. Empirically, we show that our\nmethod achieves performance comparable to nonlinear ICA methods trained jointly\non multiple offline distributions and, surprisingly, the incoming new\ndistribution does not necessarily benefit the identification of all latent\nvariables.", "arxiv_id": "2408.05788v1", "pdf_url": "http://arxiv.org/pdf/2408.05788v1", "abstract_url": "http://arxiv.org/abs/2408.05788v1", "primary_category": "cs.LG", "published_date": "2024-08-11", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Continual Learning of Nonlinear Independent Representations", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:18.074764"}
{"title": "On zero-shot learning in neural state estimation of power distribution systems", "authors": "Aleksandr Berezin, Stephan Balduin, Thomas Oberlie\u00dfen, Sebastian Peter, Eric MSP Veith", "abstract": "This paper addresses the challenge of neural state estimation in power\ndistribution systems. We identified a research gap in the current state of the\nart, which lies in the inability of models to adapt to changes in the power\ngrid, such as loss of sensors and branch switching. Our experiments demonstrate\nthat graph neural networks are the most promising models for this use case and\nthat their performance can degrade with scale. We propose augmentations to\nremedy this issue and perform a comprehensive grid search of different model\nconfigurations for common zero-shot learning scenarios in neural state\nestimation.", "arxiv_id": "2408.05787v1", "pdf_url": "http://arxiv.org/pdf/2408.05787v1", "abstract_url": "http://arxiv.org/abs/2408.05787v1", "primary_category": "cs.LG", "published_date": "2024-08-11", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "On zero-shot learning in neural state estimation of power distribution systems", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:18.832730"}
{"title": "CURLing the Dream: Contrastive Representations for World Modeling in Reinforcement Learning", "authors": "Victor Augusto Kich, Jair Augusto Bottega, Raul Steinmetz, Ricardo Bedin Grando, Ayano Yorozu, Akihisa Ohya", "abstract": "In this work, we present Curled-Dreamer, a novel reinforcement learning\nalgorithm that integrates contrastive learning into the DreamerV3 framework to\nenhance performance in visual reinforcement learning tasks. By incorporating\nthe contrastive loss from the CURL algorithm and a reconstruction loss from\nautoencoder, Curled-Dreamer achieves significant improvements in various\nDeepMind Control Suite tasks. Our extensive experiments demonstrate that\nCurled-Dreamer consistently outperforms state-of-the-art algorithms, achieving\nhigher mean and median scores across a diverse set of tasks. The results\nindicate that the proposed approach not only accelerates learning but also\nenhances the robustness of the learned policies. This work highlights the\npotential of combining different learning paradigms to achieve superior\nperformance in reinforcement learning applications.", "arxiv_id": "2408.05781v1", "pdf_url": "http://arxiv.org/pdf/2408.05781v1", "abstract_url": "http://arxiv.org/abs/2408.05781v1", "primary_category": "cs.LG", "published_date": "2024-08-11", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "CURLing the Dream: Contrastive Representations for World Modeling in Reinforcement Learning", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:19.497220"}
{"title": "Pareto Front Shape-Agnostic Pareto Set Learning in Multi-Objective Optimization", "authors": "Rongguang Ye, Longcan Chen, Wei-Bin Kou, Jinyuan Zhang, Hisao Ishibuchi", "abstract": "Pareto set learning (PSL) is an emerging approach for acquiring the complete\nPareto set of a multi-objective optimization problem. Existing methods\nprimarily rely on the mapping of preference vectors in the objective space to\nPareto optimal solutions in the decision space. However, the sampling of\npreference vectors theoretically requires prior knowledge of the Pareto front\nshape to ensure high performance of the PSL methods. Designing a sampling\nstrategy of preference vectors is difficult since the Pareto front shape cannot\nbe known in advance. To make Pareto set learning work effectively in any Pareto\nfront shape, we propose a Pareto front shape-agnostic Pareto Set Learning\n(GPSL) that does not require the prior information about the Pareto front. The\nfundamental concept behind GPSL is to treat the learning of the Pareto set as a\ndistribution transformation problem. Specifically, GPSL can transform an\narbitrary distribution into the Pareto set distribution. We demonstrate that\ntraining a neural network by maximizing hypervolume enables the process of\ndistribution transformation. Our proposed method can handle any shape of the\nPareto front and learn the Pareto set without requiring prior knowledge.\nExperimental results show the high performance of our proposed method on\ndiverse test problems compared with recent Pareto set learning algorithms.", "arxiv_id": "2408.05778v1", "pdf_url": "http://arxiv.org/pdf/2408.05778v1", "abstract_url": "http://arxiv.org/abs/2408.05778v1", "primary_category": "cs.LG", "published_date": "2024-08-11", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Pareto Front Shape-Agnostic Pareto Set Learning in Multi-Objective Optimization", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:20.337041"}
{"title": "Scalable and Adaptive Spectral Embedding for Attributed Graph Clustering", "authors": "Yunhui Liu, Tieke He, Qing Wu, Tao Zheng, Jianhua Zhao", "abstract": "Attributed graph clustering, which aims to group the nodes of an attributed\ngraph into disjoint clusters, has made promising advancements in recent years.\nHowever, most existing methods face challenges when applied to large graphs due\nto the expensive computational cost and high memory usage. In this paper, we\nintroduce Scalable and Adaptive Spectral Embedding (SASE), a simple attributed\ngraph clustering method devoid of parameter learning. SASE comprises three main\ncomponents: node features smoothing via $k$-order simple graph convolution,\nscalable spectral clustering using random Fourier features, and adaptive order\nselection. With these designs, SASE not only effectively captures global\ncluster structures but also exhibits linear time and space complexity relative\nto the graph size. Empirical results demonstrate the superiority of SASE. For\nexample, on the ArXiv dataset with 169K nodes and 1.17M edges, SASE achieves a\n6.9\\% improvement in ACC and a $5.87\\times$ speedup compared to the runner-up,\nS3GC.", "arxiv_id": "2408.05765v1", "pdf_url": "http://arxiv.org/pdf/2408.05765v1", "abstract_url": "http://arxiv.org/abs/2408.05765v1", "primary_category": "cs.LG", "published_date": "2024-08-11", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Scalable and Adaptive Spectral Embedding for Attributed Graph Clustering", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:22.404721"}
{"title": "Personalized Federated Learning for improving radar based precipitation nowcasting on heterogeneous areas", "authors": "Judith S\u00e1inz-Pardo D\u00edaz, Mar\u00eda Castrillo, Juraj Bartok, Ignacio Heredia Cach\u00e1, Irina Malkin Ond\u00edk, Ivan Martynovskyi, Khadijeh Alibabaei, Lisana Berberi, Valentin Kozlov, \u00c1lvaro L\u00f3pez Garc\u00eda", "abstract": "The increasing generation of data in different areas of life, such as the\nenvironment, highlights the need to explore new techniques for processing and\nexploiting data for useful purposes. In this context, artificial intelligence\ntechniques, especially through deep learning models, are key tools to be used\non the large amount of data that can be obtained, for example, from weather\nradars. In many cases, the information collected by these radars is not open,\nor belongs to different institutions, thus needing to deal with the distributed\nnature of this data. In this work, the applicability of a personalized\nfederated learning architecture, which has been called adapFL, on distributed\nweather radar images is addressed. To this end, given a single available radar\ncovering 400 km in diameter, the captured images are divided in such a way that\nthey are disjointly distributed into four different federated clients. The\nresults obtained with adapFL are analyzed in each zone, as well as in a central\narea covering part of the surface of each of the previously distributed areas.\nThe ultimate goal of this work is to study the generalization capability of\nthis type of learning technique for its extrapolation to use cases in which a\nrepresentative number of radars is available, whose data can not be centralized\ndue to technical, legal or administrative concerns. The results of this\npreliminary study indicate that the performance obtained in each zone with the\nadapFL approach allows improving the results of the federated learning\napproach, the individual deep learning models and the classical Continuity\nTracking Radar Echoes by Correlation approach.", "arxiv_id": "2408.05761v1", "pdf_url": "http://arxiv.org/pdf/2408.05761v1", "abstract_url": "http://arxiv.org/abs/2408.05761v1", "primary_category": "cs.LG", "published_date": "2024-08-11", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Personalized Federated Learning for improving radar based precipitation nowcasting on heterogeneous areas", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:23.263140"}
{"title": "Efficient and Versatile Robust Fine-Tuning of Zero-shot Models", "authors": "Sungyeon Kim, Boseung Jeong, Donghyun Kim, Suha Kwak", "abstract": "Large-scale image-text pre-trained models enable zero-shot classification and\nprovide consistent accuracy across various data distributions. Nonetheless,\noptimizing these models in downstream tasks typically requires fine-tuning,\nwhich reduces generalization to out-of-distribution (OOD) data and demands\nextensive computational resources. We introduce Robust Adapter (R-Adapter), a\nnovel method for fine-tuning zero-shot models to downstream tasks while\nsimultaneously addressing both these issues. Our method integrates lightweight\nmodules into the pre-trained model and employs novel self-ensemble techniques\nto boost OOD robustness and reduce storage expenses substantially. Furthermore,\nwe propose MPM-NCE loss designed for fine-tuning on vision-language downstream\ntasks. It ensures precise alignment of multiple image-text pairs and\ndiscriminative feature learning. By extending the benchmark for robust\nfine-tuning beyond classification to include diverse tasks such as cross-modal\nretrieval and open vocabulary segmentation, we demonstrate the broad\napplicability of R-Adapter. Our extensive experiments demonstrate that\nR-Adapter achieves state-of-the-art performance across a diverse set of tasks,\ntuning only 13% of the parameters of the CLIP encoders.", "arxiv_id": "2408.05749v1", "pdf_url": "http://arxiv.org/pdf/2408.05749v1", "abstract_url": "http://arxiv.org/abs/2408.05749v1", "primary_category": "cs.CV", "published_date": "2024-08-11", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Efficient and Versatile Robust Fine-Tuning of Zero-shot Models", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:24.181738"}
{"title": "Low-Dimensional Federated Knowledge Graph Embedding via Knowledge Distillation", "authors": "Xiaoxiong Zhang, Zhiwei Zeng, Xin Zhou, Zhiqi Shen", "abstract": "Federated Knowledge Graph Embedding (FKGE) aims to facilitate collaborative\nlearning of entity and relation embeddings from distributed Knowledge Graphs\n(KGs) across multiple clients, while preserving data privacy. Training FKGE\nmodels with higher dimensions is typically favored due to their potential for\nachieving superior performance. However, high-dimensional embeddings present\nsignificant challenges in terms of storage resource and inference speed. Unlike\ntraditional KG embedding methods, FKGE involves multiple client-server\ncommunication rounds, where communication efficiency is critical. Existing\nembedding compression methods for traditional KGs may not be directly\napplicable to FKGE as they often require multiple model trainings which\npotentially incur substantial communication costs. In this paper, we propose a\nlight-weight component based on Knowledge Distillation (KD) which is titled\nFedKD and tailored specifically for FKGE methods. During client-side local\ntraining, FedKD facilitates the low-dimensional student model to mimic the\nscore distribution of triples from the high-dimensional teacher model using KL\ndivergence loss. Unlike traditional KD way, FedKD adaptively learns a\ntemperature to scale the score of positive triples and separately adjusts the\nscores of corresponding negative triples using a predefined temperature,\nthereby mitigating teacher over-confidence issue. Furthermore, we dynamically\nadjust the weight of KD loss to optimize the training process. Extensive\nexperiments on three datasets support the effectiveness of FedKD.", "arxiv_id": "2408.05748v1", "pdf_url": "http://arxiv.org/pdf/2408.05748v1", "abstract_url": "http://arxiv.org/abs/2408.05748v1", "primary_category": "cs.AI", "published_date": "2024-08-11", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Low-Dimensional Federated Knowledge Graph Embedding via Knowledge Distillation", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:25.085257"}
{"title": "MTSCI: A Conditional Diffusion Model for Multivariate Time Series Consistent Imputation", "authors": "Jianping Zhou, Junhao Li, Guanjie Zheng, Xinbing Wang, Chenghu Zhou", "abstract": "Missing values are prevalent in multivariate time series, compromising the\nintegrity of analyses and degrading the performance of downstream tasks.\nConsequently, research has focused on multivariate time series imputation,\naiming to accurately impute the missing values based on available observations.\nA key research question is how to ensure imputation consistency, i.e.,\nintra-consistency between observed and imputed values, and inter-consistency\nbetween adjacent windows after imputation. However, previous methods rely\nsolely on the inductive bias of the imputation targets to guide the learning\nprocess, ignoring imputation consistency and ultimately resulting in poor\nperformance. Diffusion models, known for their powerful generative abilities,\nprefer to generate consistent results based on available observations.\nTherefore, we propose a conditional diffusion model for Multivariate Time\nSeries Consistent Imputation (MTSCI). Specifically, MTSCI employs a contrastive\ncomplementary mask to generate dual views during the forward noising process.\nThen, the intra contrastive loss is calculated to ensure intra-consistency\nbetween the imputed and observed values. Meanwhile, MTSCI utilizes a mixup\nmechanism to incorporate conditional information from adjacent windows during\nthe denoising process, facilitating the inter-consistency between imputed\nsamples. Extensive experiments on multiple real-world datasets demonstrate that\nour method achieves the state-of-the-art performance on multivariate time\nseries imputation task under different missing scenarios. Code is available at\nhttps://github.com/JeremyChou28/MTSCI.", "arxiv_id": "2408.05740v1", "pdf_url": "http://arxiv.org/pdf/2408.05740v1", "abstract_url": "http://arxiv.org/abs/2408.05740v1", "primary_category": "cs.LG", "published_date": "2024-08-11", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "MTSCI: A Conditional Diffusion Model for Multivariate Time Series Consistent Imputation", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:25.901903"}
{"title": "Autoregressive Enzyme Function Prediction with Multi-scale Multi-modality Fusion", "authors": "Dingyi Rong, Wenzhuo Zheng, Bozitao Zhong, Zhouhan Lin, Liang Hong, Ning Liu", "abstract": "Accurate prediction of enzyme function is crucial for elucidating biological\nmechanisms and driving innovation across various sectors. Existing deep\nlearning methods tend to rely solely on either sequence data or structural data\nand predict the EC number as a whole, neglecting the intrinsic hierarchical\nstructure of EC numbers. To address these limitations, we introduce MAPred, a\nnovel multi-modality and multi-scale model designed to autoregressively predict\nthe EC number of proteins. MAPred integrates both the primary amino acid\nsequence and the 3D tokens of proteins, employing a dual-pathway approach to\ncapture comprehensive protein characteristics and essential local functional\nsites. Additionally, MAPred utilizes an autoregressive prediction network to\nsequentially predict the digits of the EC number, leveraging the hierarchical\norganization of EC classifications. Evaluations on benchmark datasets,\nincluding New-392, Price, and New-815, demonstrate that our method outperforms\nexisting models, marking a significant advance in the reliability and\ngranularity of protein function prediction within bioinformatics.", "arxiv_id": "2408.06391v1", "pdf_url": "http://arxiv.org/pdf/2408.06391v1", "abstract_url": "http://arxiv.org/abs/2408.06391v1", "primary_category": "q-bio.QM", "published_date": "2024-08-11", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Autoregressive Enzyme Function Prediction with Multi-scale Multi-modality Fusion", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:26.634062"}
{"title": "Deep Learning with Data Privacy via Residual Perturbation", "authors": "Wenqi Tao, Huaming Ling, Zuoqiang Shi, Bao Wang", "abstract": "Protecting data privacy in deep learning (DL) is of crucial importance.\nSeveral celebrated privacy notions have been established and used for\nprivacy-preserving DL. However, many existing mechanisms achieve privacy at the\ncost of significant utility degradation and computational overhead. In this\npaper, we propose a stochastic differential equation-based residual\nperturbation for privacy-preserving DL, which injects Gaussian noise into each\nresidual mapping of ResNets. Theoretically, we prove that residual perturbation\nguarantees differential privacy (DP) and reduces the generalization gap of DL.\nEmpirically, we show that residual perturbation is computationally efficient\nand outperforms the state-of-the-art differentially private stochastic gradient\ndescent (DPSGD) in utility maintenance without sacrificing membership privacy.", "arxiv_id": "2408.05723v1", "pdf_url": "http://arxiv.org/pdf/2408.05723v1", "abstract_url": "http://arxiv.org/abs/2408.05723v1", "primary_category": "cs.LG", "published_date": "2024-08-11", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Deep Learning with Data Privacy via Residual Perturbation", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:27.355209"}
{"title": "Fast and Scalable Semi-Supervised Learning for Multi-View Subspace Clustering", "authors": "Huaming Ling, Chenglong Bao, Jiebo Song, Zuoqiang Shi", "abstract": "In this paper, we introduce a Fast and Scalable Semi-supervised Multi-view\nSubspace Clustering (FSSMSC) method, a novel solution to the high computational\ncomplexity commonly found in existing approaches. FSSMSC features linear\ncomputational and space complexity relative to the size of the data. The method\ngenerates a consensus anchor graph across all views, representing each data\npoint as a sparse linear combination of chosen landmarks. Unlike traditional\nmethods that manage the anchor graph construction and the label propagation\nprocess separately, this paper proposes a unified optimization model that\nfacilitates simultaneous learning of both. An effective alternating update\nalgorithm with convergence guarantees is proposed to solve the unified\noptimization model. Additionally, the method employs the obtained anchor graph\nand landmarks' low-dimensional representations to deduce low-dimensional\nrepresentations for raw data. Following this, a straightforward clustering\napproach is conducted on these low-dimensional representations to achieve the\nfinal clustering results. The effectiveness and efficiency of FSSMSC are\nvalidated through extensive experiments on multiple benchmark datasets of\nvarying scales.", "arxiv_id": "2408.05707v1", "pdf_url": "http://arxiv.org/pdf/2408.05707v1", "abstract_url": "http://arxiv.org/abs/2408.05707v1", "primary_category": "cs.LG", "published_date": "2024-08-11", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Fast and Scalable Semi-Supervised Learning for Multi-View Subspace Clustering", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:28.030130"}
{"title": "Approximate ADCs for In-Memory Computing", "authors": "Arkapravo Ghosh, Hemkar Reddy Sadana, Mukut Debnath, Panthadip Maji, Shubham Negi, Sumeet Gupta, Mrigank Sharad, Kaushik Roy", "abstract": "In memory computing (IMC) architectures for deep learning (DL) accelerators\nleverage energy-efficient and highly parallel matrix vector multiplication\n(MVM) operations, implemented directly in memory arrays. Such IMC designs have\nbeen explored based on CMOS as well as emerging non-volatile memory (NVM)\ntechnologies like RRAM. IMC architectures generally involve a large number of\ncores consisting of memory arrays, storing the trained weights of the DL model.\nPeripheral units like DACs and ADCs are also used for applying inputs and\nreading out the output values. Recently reported designs reveal that the ADCs\nrequired for reading out the MVM results, consume more than 85% of the total\ncompute power and also dominate the area, thereby eschewing the benefits of the\nIMC scheme. Mitigation of imperfections in the ADCs, namely, non-linearity and\nvariations, incur significant design overheads, due to dedicated calibration\nunits. In this work we present peripheral aware design of IMC cores, to\nmitigate such overheads. It involves incorporating the non-idealities of ADCs\nin the training of the DL models, along with that of the memory units. The\nproposed approach applies equally well to both current mode as well as charge\nmode MVM operations demonstrated in recent years., and can significantly\nsimplify the design of mixed-signal IMC units.", "arxiv_id": "2408.06390v1", "pdf_url": "http://arxiv.org/pdf/2408.06390v1", "abstract_url": "http://arxiv.org/abs/2408.06390v1", "primary_category": "cs.ET", "published_date": "2024-08-11", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Approximate ADCs for In-Memory Computing", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:31.145280"}
{"title": "Predicting Chaotic System Behavior using Machine Learning Techniques", "authors": "Huaiyuan Rao, Yichen Zhao, Qiang Lai", "abstract": "Recently, machine learning techniques, particularly deep learning, have\ndemonstrated superior performance over traditional time series forecasting\nmethods across various applications, including both single-variable and\nmulti-variable predictions. This study aims to investigate the capability of i)\nNext Generation Reservoir Computing (NG-RC) ii) Reservoir Computing (RC) iii)\nLong short-term Memory (LSTM) for predicting chaotic system behavior, and to\ncompare their performance in terms of accuracy, efficiency, and robustness.\nThese methods are applied to predict time series obtained from four\nrepresentative chaotic systems including Lorenz, R\\\"ossler, Chen, Qi systems.\nIn conclusion, we found that NG-RC is more computationally efficient and offers\ngreater potential for predicting chaotic system behavior.", "arxiv_id": "2408.05702v1", "pdf_url": "http://arxiv.org/pdf/2408.05702v1", "abstract_url": "http://arxiv.org/abs/2408.05702v1", "primary_category": "cs.LG", "published_date": "2024-08-11", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Predicting Chaotic System Behavior using Machine Learning Techniques", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:32.166893"}
{"title": "SMILES-Mamba: Chemical Mamba Foundation Models for Drug ADMET Prediction", "authors": "Bohao Xu, Yingzhou Lu, Chenhao Li, Ling Yue, Xiao Wang, Nan Hao, Tianfan Fu, Jim Chen", "abstract": "In drug discovery, predicting the absorption, distribution, metabolism,\nexcretion, and toxicity (ADMET) properties of small-molecule drugs is critical\nfor ensuring safety and efficacy. However, the process of accurately predicting\nthese properties is often resource-intensive and requires extensive\nexperimental data. To address this challenge, we propose SMILES-Mamba, a\ntwo-stage model that leverages both unlabeled and labeled data through a\ncombination of self-supervised pretraining and fine-tuning strategies. The\nmodel first pre-trains on a large corpus of unlabeled SMILES strings to capture\nthe underlying chemical structure and relationships, before being fine-tuned on\nsmaller, labeled datasets specific to ADMET tasks. Our results demonstrate that\nSMILES-Mamba exhibits competitive performance across 22 ADMET datasets,\nachieving the highest score in 14 tasks, highlighting the potential of\nself-supervised learning in improving molecular property prediction. This\napproach not only enhances prediction accuracy but also reduces the dependence\non large, labeled datasets, offering a promising direction for future research\nin drug discovery.", "arxiv_id": "2408.05696v1", "pdf_url": "http://arxiv.org/pdf/2408.05696v1", "abstract_url": "http://arxiv.org/abs/2408.05696v1", "primary_category": "cs.LG", "published_date": "2024-08-11", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "SMILES-Mamba: Chemical Mamba Foundation Models for Drug ADMET Prediction", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:32.950849"}
{"title": "A Novel Momentum-Based Deep Learning Techniques for Medical Image Classification and Segmentation", "authors": "Koushik Biswas, Ridal Pal, Shaswat Patel, Debesh Jha, Meghana Karri, Amit Reza, Gorkem Durak, Alpay Medetalibeyoglu, Matthew Antalek, Yury Velichko, Daniela Ladner, Amir Borhani, Ulas Bagci", "abstract": "Accurately segmenting different organs from medical images is a critical\nprerequisite for computer-assisted diagnosis and intervention planning. This\nstudy proposes a deep learning-based approach for segmenting various organs\nfrom CT and MRI scans and classifying diseases. Our study introduces a novel\ntechnique integrating momentum within residual blocks for enhanced training\ndynamics in medical image analysis. We applied our method in two distinct\ntasks: segmenting liver, lung, & colon data and classifying abdominal pelvic CT\nand MRI scans. The proposed approach has shown promising results, outperforming\nstate-of-the-art methods on publicly available benchmarking datasets. For\ninstance, in the lung segmentation dataset, our approach yielded significant\nenhancements over the TransNetR model, including a 5.72% increase in dice\nscore, a 5.04% improvement in mean Intersection over Union (mIoU), an 8.02%\nimprovement in recall, and a 4.42% improvement in precision. Hence,\nincorporating momentum led to state-of-the-art performance in both segmentation\nand classification tasks, representing a significant advancement in the field\nof medical imaging.", "arxiv_id": "2408.05692v1", "pdf_url": "http://arxiv.org/pdf/2408.05692v1", "abstract_url": "http://arxiv.org/abs/2408.05692v1", "primary_category": "cs.CV", "published_date": "2024-08-11", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "A Novel Momentum-Based Deep Learning Techniques for Medical Image Classification and Segmentation", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:33.707039"}
{"title": "The Bandit Whisperer: Communication Learning for Restless Bandits", "authors": "Yunfan Zhao, Tonghan Wang, Dheeraj Nagaraj, Aparna Taneja, Milind Tambe", "abstract": "Applying Reinforcement Learning (RL) to Restless Multi-Arm Bandits (RMABs)\noffers a promising avenue for addressing allocation problems with resource\nconstraints and temporal dynamics. However, classic RMAB models largely\noverlook the challenges of (systematic) data errors - a common occurrence in\nreal-world scenarios due to factors like varying data collection protocols and\nintentional noise for differential privacy. We demonstrate that conventional RL\nalgorithms used to train RMABs can struggle to perform well in such settings.\nTo solve this problem, we propose the first communication learning approach in\nRMABs, where we study which arms, when involved in communication, are most\neffective in mitigating the influence of such systematic data errors. In our\nsetup, the arms receive Q-function parameters from similar arms as messages to\nguide behavioral policies, steering Q-function updates. We learn communication\nstrategies by considering the joint utility of messages across all pairs of\narms and using a Q-network architecture that decomposes the joint utility. Both\ntheoretical and empirical evidence validate the effectiveness of our method in\nsignificantly improving RMAB performance across diverse problems.", "arxiv_id": "2408.05686v1", "pdf_url": "http://arxiv.org/pdf/2408.05686v1", "abstract_url": "http://arxiv.org/abs/2408.05686v1", "primary_category": "cs.LG", "published_date": "2024-08-11", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "The Bandit Whisperer: Communication Learning for Restless Bandits", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:34.521486"}
{"title": "SRTFD: Scalable Real-Time Fault Diagnosis through Online Continual Learning", "authors": "Dandan Zhao, Karthick Sharma, Hongpeng Yin, Yuxin Qi, Shuhao Zhang", "abstract": "Fault diagnosis (FD) is essential for maintaining operational safety and\nminimizing economic losses by detecting system abnormalities. Recently, deep\nlearning (DL)-driven FD methods have gained prominence, offering significant\nimprovements in precision and adaptability through the utilization of extensive\ndatasets and advanced DL models. Modern industrial environments, however,\ndemand FD methods that can handle new fault types, dynamic conditions,\nlarge-scale data, and provide real-time responses with minimal prior\ninformation. Although online continual learning (OCL) demonstrates potential in\naddressing these requirements by enabling DL models to continuously learn from\nstreaming data, it faces challenges such as data redundancy, imbalance, and\nlimited labeled data. To overcome these limitations, we propose SRTFD, a\nscalable real-time fault diagnosis framework that enhances OCL with three\ncritical methods: Retrospect Coreset Selection (RCS), which selects the most\nrelevant data to reduce redundant training and improve efficiency; Global\nBalance Technique (GBT), which ensures balanced coreset selection and robust\nmodel performance; and Confidence and Uncertainty-driven Pseudo-label Learning\n(CUPL), which updates the model using unlabeled data for continuous adaptation.\nExtensive experiments on a real-world dataset and two public simulated datasets\ndemonstrate SRTFD's effectiveness and potential for providing advanced,\nscalable, and precise fault diagnosis in modern industrial systems.", "arxiv_id": "2408.05681v1", "pdf_url": "http://arxiv.org/pdf/2408.05681v1", "abstract_url": "http://arxiv.org/abs/2408.05681v1", "primary_category": "cs.LG", "published_date": "2024-08-11", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "SRTFD: Scalable Real-Time Fault Diagnosis through Online Continual Learning", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:35.400630"}
{"title": "Efficient Federated Learning Using Dynamic Update and Adaptive Pruning with Momentum on Shared Server Data", "authors": "Ji Liu, Juncheng Jia, Hong Zhang, Yuhui Yun, Leye Wang, Yang Zhou, Huaiyu Dai, Dejing Dou", "abstract": "Despite achieving remarkable performance, Federated Learning (FL) encounters\ntwo important problems, i.e., low training efficiency and limited computational\nresources. In this paper, we propose a new FL framework, i.e., FedDUMAP, with\nthree original contributions, to leverage the shared insensitive data on the\nserver in addition to the distributed data in edge devices so as to efficiently\ntrain a global model. First, we propose a simple dynamic server update\nalgorithm, which takes advantage of the shared insensitive data on the server\nwhile dynamically adjusting the update steps on the server in order to speed up\nthe convergence and improve the accuracy. Second, we propose an adaptive\noptimization method with the dynamic server update algorithm to exploit the\nglobal momentum on the server and each local device for superior accuracy.\nThird, we develop a layer-adaptive model pruning method to carry out specific\npruning operations, which is adapted to the diverse features of each layer so\nas to attain an excellent trade-off between effectiveness and efficiency. Our\nproposed FL model, FedDUMAP, combines the three original techniques and has a\nsignificantly better performance compared with baseline approaches in terms of\nefficiency (up to 16.9 times faster), accuracy (up to 20.4% higher), and\ncomputational cost (up to 62.6% smaller).", "arxiv_id": "2408.05678v1", "pdf_url": "http://arxiv.org/pdf/2408.05678v1", "abstract_url": "http://arxiv.org/abs/2408.05678v1", "primary_category": "cs.DC", "published_date": "2024-08-11", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Efficient Federated Learning Using Dynamic Update and Adaptive Pruning with Momentum on Shared Server Data", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:36.335050"}
{"title": "Tensor Decomposition Meets RKHS: Efficient Algorithms for Smooth and Misaligned Data", "authors": "Brett W. Larsen, Tamara G. Kolda, Anru R. Zhang, Alex H. Williams", "abstract": "The canonical polyadic (CP) tensor decomposition decomposes a\nmultidimensional data array into a sum of outer products of finite-dimensional\nvectors. Instead, we can replace some or all of the vectors with continuous\nfunctions (infinite-dimensional vectors) from a reproducing kernel Hilbert\nspace (RKHS). We refer to tensors with some infinite-dimensional modes as\nquasitensors, and the approach of decomposing a tensor with some continuous\nRKHS modes is referred to as CP-HiFi (hybrid infinite and finite dimensional)\ntensor decomposition. An advantage of CP-HiFi is that it can enforce smoothness\nin the infinite dimensional modes. Further, CP-HiFi does not require the\nobserved data to lie on a regular and finite rectangular grid and naturally\nincorporates misaligned data. We detail the methodology and illustrate it on a\nsynthetic example.", "arxiv_id": "2408.05677v1", "pdf_url": "http://arxiv.org/pdf/2408.05677v1", "abstract_url": "http://arxiv.org/abs/2408.05677v1", "primary_category": "math.NA", "published_date": "2024-08-11", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Tensor Decomposition Meets RKHS: Efficient Algorithms for Smooth and Misaligned Data", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:36.980436"}
{"title": "Utilizing Large Language Models to Optimize the Detection and Explainability of Phishing Websites", "authors": "Sayak Saha Roy, Shirin Nilizadeh", "abstract": "In this paper, we introduce PhishLang, an open-source, lightweight Large\nLanguage Model (LLM) specifically designed for phishing website detection\nthrough contextual analysis of the website. Unlike traditional heuristic or\nmachine learning models that rely on static features and struggle to adapt to\nnew threats and deep learning models that are computationally intensive, our\nmodel utilizes the advanced language processing capabilities of LLMs to learn\ngranular features that are characteristic of phishing attacks. Furthermore,\nPhishLang operates with minimal data preprocessing and offers performance\ncomparable to leading deep learning tools, while being significantly faster and\nless resource-intensive. Over a 3.5-month testing period, PhishLang\nsuccessfully identified approximately 26K phishing URLs, many of which were\nundetected by popular antiphishing blocklists, thus demonstrating its potential\nto aid current detection measures. We also evaluate PhishLang against several\nrealistic adversarial attacks and develop six patches that make it very robust\nagainst such threats. Furthermore, we integrate PhishLang with GPT-3.5 Turbo to\ncreate \\textit{explainable blocklisting} - warnings that provide users with\ncontextual information about different features that led to a website being\nmarked as phishing. Finally, we have open-sourced the PhishLang framework and\ndeveloped a Chromium-based browser extension and URL scanner website, which\nimplement explainable warnings for end-users.", "arxiv_id": "2408.05667v1", "pdf_url": "http://arxiv.org/pdf/2408.05667v1", "abstract_url": "http://arxiv.org/abs/2408.05667v1", "primary_category": "cs.CR", "published_date": "2024-08-11", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Utilizing Large Language Models to Optimize the Detection and Explainability of Phishing Websites", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:38.106721"}
{"title": "Controlling for discrete unmeasured confounding in nonlinear causal models", "authors": "Patrick Burauel, Frederick Eberhardt, Michel Besserve", "abstract": "Unmeasured confounding is a major challenge for identifying causal\nrelationships from non-experimental data. Here, we propose a method that can\naccommodate unmeasured discrete confounding. Extending recent identifiability\nresults in deep latent variable models, we show theoretically that confounding\ncan be detected and corrected under the assumption that the observed data is a\npiecewise affine transformation of a latent Gaussian mixture model and that the\nidentity of the mixture components is confounded. We provide a flow-based\nalgorithm to estimate this model and perform deconfounding. Experimental\nresults on synthetic and real-world data provide support for the effectiveness\nof our approach.", "arxiv_id": "2408.05647v1", "pdf_url": "http://arxiv.org/pdf/2408.05647v1", "abstract_url": "http://arxiv.org/abs/2408.05647v1", "primary_category": "cs.LG", "published_date": "2024-08-10", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Controlling for discrete unmeasured confounding in nonlinear causal models", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:38.926231"}
{"title": "Eigen Attention: Attention in Low-Rank Space for KV Cache Compression", "authors": "Utkarsh Saxena, Gobinda Saha, Sakshi Choudhary, Kaushik Roy", "abstract": "Large language models (LLMs) represent a groundbreaking advancement in the\ndomain of natural language processing due to their impressive reasoning\nabilities. Recently, there has been considerable interest in increasing the\ncontext lengths for these models to enhance their applicability to complex\ntasks. However, at long context lengths and large batch sizes, the key-value\n(KV) cache, which stores the attention keys and values, emerges as the new\nbottleneck in memory usage during inference. To address this, we propose Eigen\nAttention, which performs the attention operation in a low-rank space, thereby\nreducing the KV cache memory overhead. Our proposed approach is orthogonal to\nexisting KV cache compression techniques and can be used synergistically with\nthem. Through extensive experiments over OPT, MPT, and Llama model families, we\ndemonstrate that Eigen Attention results in up to 40% reduction in KV cache\nsizes and up to 60% reduction in attention operation latency with minimal drop\nin performance.", "arxiv_id": "2408.05646v1", "pdf_url": "http://arxiv.org/pdf/2408.05646v1", "abstract_url": "http://arxiv.org/abs/2408.05646v1", "primary_category": "cs.LG", "published_date": "2024-08-10", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Eigen Attention: Attention in Low-Rank Space for KV Cache Compression", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:40.155147"}
{"title": "BeyondCT: A deep learning model for predicting pulmonary function from chest CT scans", "authors": "Kaiwen Geng, Zhiyi Shi, Xiaoyan Zhao, Alaa Ali, Jing Wang, Joseph Leader, Jiantao Pu", "abstract": "Abstract\n  Background: Pulmonary function tests (PFTs) and computed tomography (CT)\nimaging are vital in diagnosing, managing, and monitoring lung diseases. A\ncommon issue in practice is the lack of access to recorded pulmonary functions\ndespite available chest CT scans.\n  Purpose: To develop and validate a deep learning algorithm for predicting\npulmonary function directly from chest CT scans.\n  Methods: The development cohort came from the Pittsburgh Lung Screening Study\n(PLuSS) (n=3619). The validation cohort came from the Specialized Centers of\nClinically Oriented Research (SCCOR) in COPD (n=662). A deep learning model\ncalled BeyondCT, combining a three-dimensional (3D) convolutional neural\nnetwork (CNN) and Vision Transformer (ViT) architecture, was used to predict\nforced vital capacity (FVC) and forced expiratory volume in one second (FEV1)\nfrom non-contrasted inspiratory chest CT scans. A 3D CNN model without ViT was\nused for comparison. Subject demographics (age, gender, smoking status) were\nalso incorporated into the model. Performance was compared to actual PFTs using\nmean absolute error (MAE, L), percentage error, and R square.\n  Results: The 3D-CNN model achieved MAEs of 0.395 L and 0.383 L, percentage\nerrors of 13.84% and 18.85%, and R square of 0.665 and 0.679 for FVC and FEV1,\nrespectively. The BeyondCT model without demographics had MAEs of 0.362 L and\n0.371 L, percentage errors of 10.89% and 14.96%, and R square of 0.719 and\n0.727, respectively. Including demographics improved performance (p<0.05), with\nMAEs of 0.356 L and 0.353 L, percentage errors of 10.79% and 14.82%, and R\nsquare of 0.77 and 0.739 for FVC and FEV1 in the test set.\n  Conclusion: The BeyondCT model showed robust performance in predicting lung\nfunction from non-contrast inspiratory chest CT scans.", "arxiv_id": "2408.05645v1", "pdf_url": "http://arxiv.org/pdf/2408.05645v1", "abstract_url": "http://arxiv.org/abs/2408.05645v1", "primary_category": "eess.IV", "published_date": "2024-08-10", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "BeyondCT: A deep learning model for predicting pulmonary function from chest CT scans", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:41.315656"}
{"title": "Federated Smoothing Proximal Gradient for Quantile Regression with Non-Convex Penalties", "authors": "Reza Mirzaeifard, Diyako Ghaderyan, Stefan Werner", "abstract": "Distributed sensors in the internet-of-things (IoT) generate vast amounts of\nsparse data. Analyzing this high-dimensional data and identifying relevant\npredictors pose substantial challenges, especially when data is preferred to\nremain on the device where it was collected for reasons such as data integrity,\ncommunication bandwidth, and privacy. This paper introduces a federated\nquantile regression algorithm to address these challenges. Quantile regression\nprovides a more comprehensive view of the relationship between variables than\nmean regression models. However, traditional approaches face difficulties when\ndealing with nonconvex sparse penalties and the inherent non-smoothness of the\nloss function. For this purpose, we propose a federated smoothing proximal\ngradient (FSPG) algorithm that integrates a smoothing mechanism with the\nproximal gradient framework, thereby enhancing both precision and computational\nspeed. This integration adeptly handles optimization over a network of devices,\neach holding local data samples, making it particularly effective in federated\nlearning scenarios. The FSPG algorithm ensures steady progress and reliable\nconvergence in each iteration by maintaining or reducing the value of the\nobjective function. By leveraging nonconvex penalties, such as the minimax\nconcave penalty (MCP) and smoothly clipped absolute deviation (SCAD), the\nproposed method can identify and preserve key predictors within sparse models.\nComprehensive simulations validate the robust theoretical foundations of the\nproposed algorithm and demonstrate improved estimation precision and reliable\nconvergence.", "arxiv_id": "2408.05640v2", "pdf_url": "http://arxiv.org/pdf/2408.05640v2", "abstract_url": "http://arxiv.org/abs/2408.05640v2", "primary_category": "cs.LG", "published_date": "2024-08-10", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Federated Smoothing Proximal Gradient for Quantile Regression with Non-Convex Penalties", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:42.356092"}
{"title": "Speculative Diffusion Decoding: Accelerating Language Generation through Diffusion", "authors": "Jacob K Christopher, Brian R Bartoldson, Bhavya Kailkhura, Ferdinando Fioretto", "abstract": "Speculative decoding has emerged as a widely adopted method to accelerate\nlarge language model inference without sacrificing the quality of the model\noutputs. While this technique has facilitated notable speed improvements by\nenabling parallel sequence verification, its efficiency remains inherently\nlimited by the reliance on incremental token generation in existing draft\nmodels. To overcome this limitation, this paper proposes an adaptation of\nspeculative decoding which uses discrete diffusion models to generate draft\nsequences. This allows parallelization of both the drafting and verification\nsteps, providing significant speed-ups to the inference process. Our proposed\napproach, \\textit{Speculative Diffusion Decoding (SpecDiff)}, is validated on\nstandard language generation benchmarks and empirically demonstrated to provide\na \\textbf{up to 8.7x speed-up over standard generation processes and up to 2.5x\nspeed-up over existing speculative decoding approaches.}", "arxiv_id": "2408.05636v1", "pdf_url": "http://arxiv.org/pdf/2408.05636v1", "abstract_url": "http://arxiv.org/abs/2408.05636v1", "primary_category": "cs.CL", "published_date": "2024-08-10", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Speculative Diffusion Decoding: Accelerating Language Generation through Diffusion", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:43.330440"}
{"title": "Quantum-secure multiparty deep learning", "authors": "Kfir Sulimany, Sri Krishna Vadlamani, Ryan Hamerly, Prahlad Iyengar, Dirk Englund", "abstract": "Secure multiparty computation enables the joint evaluation of multivariate\nfunctions across distributed users while ensuring the privacy of their local\ninputs. This field has become increasingly urgent due to the exploding demand\nfor computationally intensive deep learning inference. These computations are\ntypically offloaded to cloud computing servers, leading to vulnerabilities that\ncan compromise the security of the clients' data. To solve this problem, we\nintroduce a linear algebra engine that leverages the quantum nature of light\nfor information-theoretically secure multiparty computation using only\nconventional telecommunication components. We apply this linear algebra engine\nto deep learning and derive rigorous upper bounds on the information leakage of\nboth the deep neural network weights and the client's data via the Holevo and\nthe Cram\\'er-Rao bounds, respectively. Applied to the MNIST classification\ntask, we obtain test accuracies exceeding $96\\%$ while leaking less than $0.1$\nbits per weight symbol and $0.01$ bits per data symbol. This weight leakage is\nan order of magnitude below the minimum bit precision required for accurate\ndeep learning using state-of-the-art quantization techniques. Our work lays the\nfoundation for practical quantum-secure computation and unlocks secure cloud\ndeep learning as a field.", "arxiv_id": "2408.05629v1", "pdf_url": "http://arxiv.org/pdf/2408.05629v1", "abstract_url": "http://arxiv.org/abs/2408.05629v1", "primary_category": "quant-ph", "published_date": "2024-08-10", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Quantum-secure multiparty deep learning", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:44.103267"}
{"title": "Forecasting Day-Ahead Electricity Prices in the Integrated Single Electricity Market: Addressing Volatility with Comparative Machine Learning Methods", "authors": "Ben Harkin, Xueqin Liu", "abstract": "This paper undertakes a comprehensive investigation of electricity price\nforecasting methods, focused on the Irish Integrated Single Electricity Market,\nparticularly on changes during recent periods of high volatility. The primary\nobjective of this research is to evaluate and compare the performance of\nvarious forecasting models, ranging from traditional machine learning models to\nmore complex neural networks, as well as the impact of different lengths of\ntraining periods. The performance metrics, mean absolute error, root mean\nsquare error, and relative mean absolute error, are utilized to assess and\ncompare the accuracy of each model. A comprehensive set of input features was\ninvestigated and selected from data recorded between October 2018 and September\n2022. The paper demonstrates that the daily EU Natural Gas price is a more\nuseful feature for electricity price forecasting in Ireland than the daily\nHenry Hub Natural Gas price. This study also shows that the correlation of\nfeatures to the day-ahead market price has changed in recent years. The price\nof natural gas on the day and the amount of wind energy on the grid that hour\nare significantly more important than any other features. More specifically\nspeaking, the input fuel for electricity has become a more important driver of\nthe price of it, than the total generation or demand. In addition, it can be\nseen that System Non-Synchronous Penetration (SNSP) is highly correlated with\nthe day-ahead market price, and that renewables are pushing down the price of\nelectricity.", "arxiv_id": "2408.05628v1", "pdf_url": "http://arxiv.org/pdf/2408.05628v1", "abstract_url": "http://arxiv.org/abs/2408.05628v1", "primary_category": "cs.LG", "published_date": "2024-08-10", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Forecasting Day-Ahead Electricity Prices in the Integrated Single Electricity Market: Addressing Volatility with Comparative Machine Learning Methods", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:44.867801"}
{"title": "Hierarchical Multi-Armed Bandits for the Concurrent Intelligent Tutoring of Concepts and Problems of Varying Difficulty Levels", "authors": "Blake Castleman, Uzay Macar, Ansaf Salleb-Aouissi", "abstract": "Remote education has proliferated in the twenty-first century, yielding rise\nto intelligent tutoring systems. In particular, research has found multi-armed\nbandit (MAB) intelligent tutors to have notable abilities in traversing the\nexploration-exploitation trade-off landscape for student problem\nrecommendations. Prior literature, however, contains a significant lack of\nopen-sourced MAB intelligent tutors, which impedes potential applications of\nthese educational MAB recommendation systems. In this paper, we combine recent\nliterature on MAB intelligent tutoring techniques into an open-sourced and\nsimply deployable hierarchical MAB algorithm, capable of progressing students\nconcurrently through concepts and problems, determining ideal recommended\nproblem difficulties, and assessing latent memory decay. We evaluate our\nalgorithm using simulated groups of 500 students, utilizing Bayesian Knowledge\nTracing to estimate students' content mastery. Results suggest that our\nalgorithm, when turned difficulty-agnostic, significantly boosts student\nsuccess, and that the further addition of problem-difficulty adaptation notably\nimproves this metric.", "arxiv_id": "2408.07208v1", "pdf_url": "http://arxiv.org/pdf/2408.07208v1", "abstract_url": "http://arxiv.org/abs/2408.07208v1", "primary_category": "cs.CY", "published_date": "2024-08-10", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Hierarchical Multi-Armed Bandits for the Concurrent Intelligent Tutoring of Concepts and Problems of Varying Difficulty Levels", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:45.536722"}
{"title": "An Information-Theoretic Analysis of Temporal GNNs", "authors": "Amirmohammad Farzaneh", "abstract": "Temporal Graph Neural Networks, a new and trending area of machine learning,\nsuffers from a lack of formal analysis. In this paper, information theory is\nused as the primary tool to provide a framework for the analysis of temporal\nGNNs. For this reason, the concept of information bottleneck is used and\nadjusted to be suitable for a temporal analysis of such networks. To this end,\na new definition for Mutual Information Rate is provided, and the potential use\nof this new metric in the analysis of temporal GNNs is studied.", "arxiv_id": "2408.05624v1", "pdf_url": "http://arxiv.org/pdf/2408.05624v1", "abstract_url": "http://arxiv.org/abs/2408.05624v1", "primary_category": "cs.IT", "published_date": "2024-08-10", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "An Information-Theoretic Analysis of Temporal GNNs", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:46.481490"}
{"title": "Residual-INR: Communication Efficient On-Device Learning Using Implicit Neural Representation", "authors": "Hanqiu Chen, Xuebin Yao, Pradeep Subedi, Cong Hao", "abstract": "Edge computing is a distributed computing paradigm that collects and\nprocesses data at or near the source of data generation. The on-device learning\nat edge relies on device-to-device wireless communication to facilitate\nreal-time data sharing and collaborative decision-making among multiple\ndevices. This significantly improves the adaptability of the edge computing\nsystem to the changing environments. However, as the scale of the edge\ncomputing system is getting larger, communication among devices is becoming the\nbottleneck because of the limited bandwidth of wireless communication leads to\nlarge data transfer latency. To reduce the amount of device-to-device data\ntransmission and accelerate on-device learning, in this paper, we propose\nResidual-INR, a fog computing-based communication-efficient on-device learning\nframework by utilizing implicit neural representation (INR) to compress\nimages/videos into neural network weights. Residual-INR enhances data transfer\nefficiency by collecting JPEG images from edge devices, compressing them into\nINR format at the fog node, and redistributing them for on-device learning. By\nusing a smaller INR for full image encoding and a separate object INR for\nhigh-quality object region reconstruction through residual encoding, our\ntechnique can reduce the encoding redundancy while maintaining the object\nquality. Residual-INR is a promising solution for edge on-device learning\nbecause it reduces data transmission by up to 5.16 x across a network of 10\nedge devices. It also facilitates CPU-free accelerated on-device learning,\nachieving up to 2.9 x speedup without sacrificing accuracy. Our code is\navailable at: https://github.com/sharclab/Residual-INR.", "arxiv_id": "2408.05617v1", "pdf_url": "http://arxiv.org/pdf/2408.05617v1", "abstract_url": "http://arxiv.org/abs/2408.05617v1", "primary_category": "cs.LG", "published_date": "2024-08-10", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Residual-INR: Communication Efficient On-Device Learning Using Implicit Neural Representation", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:47.218950"}
{"title": "Mitigating Metropolitan Carbon Emissions with Dynamic Eco-driving at Scale", "authors": "Vindula Jayawardana, Baptiste Freydt, Ao Qu, Cameron Hickert, Edgar Sanchez, Catherine Tang, Mark Taylor, Blaine Leonard, Cathy Wu", "abstract": "The sheer scale and diversity of transportation make it a formidable sector\nto decarbonize. Here, we consider an emerging opportunity to reduce carbon\nemissions: the growing adoption of semi-autonomous vehicles, which can be\nprogrammed to mitigate stop-and-go traffic through intelligent speed commands\nand, thus, reduce emissions. But would such dynamic eco-driving move the needle\non climate change? A comprehensive impact analysis has been out of reach due to\nthe vast array of traffic scenarios and the complexity of vehicle emissions. We\naddress this challenge with large-scale scenario modeling efforts and by using\nmulti-task deep reinforcement learning with a carefully designed network\ndecomposition strategy. We perform an in-depth prospective impact assessment of\ndynamic eco-driving at 6,011 signalized intersections across three major US\nmetropolitan cities, simulating a million traffic scenarios. Overall, we find\nthat vehicle trajectories optimized for emissions can cut city-wide\nintersection carbon emissions by 11-22%, without harming throughput or safety,\nand with reasonable assumptions, equivalent to the national emissions of Israel\nand Nigeria, respectively. We find that 10% eco-driving adoption yields 25%-50%\nof the total reduction, and nearly 70% of the benefits come from 20% of\nintersections, suggesting near-term implementation pathways. However, the\ncomposition of this high-impact subset of intersections varies considerably\nacross different adoption levels, with minimal overlap, calling for careful\nstrategic planning for eco-driving deployments. Moreover, the impact of\neco-driving, when considered jointly with projections of vehicle\nelectrification and hybrid vehicle adoption remains significant. More broadly,\nthis work paves the way for large-scale analysis of traffic externalities, such\nas time, safety, and air quality, and the potential impact of solution\nstrategies.", "arxiv_id": "2408.05609v1", "pdf_url": "http://arxiv.org/pdf/2408.05609v1", "abstract_url": "http://arxiv.org/abs/2408.05609v1", "primary_category": "eess.SY", "published_date": "2024-08-10", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Mitigating Metropolitan Carbon Emissions with Dynamic Eco-driving at Scale", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:48.040505"}
{"title": "Exploring Applications of State Space Models and Advanced Training Techniques in Sequential Recommendations: A Comparative Study on Efficiency and Performance", "authors": "Mark Obozov, Makar Baderko, Stepan Kulibaba, Nikolay Kutuzov, Alexander Gasnikov", "abstract": "Recommender systems aim to estimate the dynamically changing user preferences\nand sequential dependencies between historical user behaviour and metadata.\nAlthough transformer-based models have proven to be effective in sequential\nrecommendations, their state growth is proportional to the length of the\nsequence that is being processed, which makes them expensive in terms of memory\nand inference costs. Our research focused on three promising directions in\nsequential recommendations: enhancing speed through the use of State Space\nModels (SSM), as they can achieve SOTA results in the sequential\nrecommendations domain with lower latency, memory, and inference costs, as\nproposed by arXiv:2403.03900 improving the quality of recommendations with\nLarge Language Models (LLMs) via Monolithic Preference Optimization without\nReference Model (ORPO); and implementing adaptive batch- and step-size\nalgorithms to reduce costs and accelerate training processes.", "arxiv_id": "2408.05606v1", "pdf_url": "http://arxiv.org/pdf/2408.05606v1", "abstract_url": "http://arxiv.org/abs/2408.05606v1", "primary_category": "cs.IR", "published_date": "2024-08-10", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Exploring Applications of State Space Models and Advanced Training Techniques in Sequential Recommendations: A Comparative Study on Efficiency and Performance", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:48.681406"}
{"title": "Safety Enhancement in Planetary Rovers: Early Detection of Tip-over Risks Using Autoencoders", "authors": "Mariela De Lucas Alvarez", "abstract": "Autonomous robots consistently encounter unforeseen dangerous situations\nduring exploration missions. The characteristic rimless wheels in the AsguardIV\nrover allow it to overcome challenging terrains. However, steep slopes or\ndifficult maneuvers can cause the rover to tip over and threaten the completion\nof a mission. This work focuses on identifying early signs or initial stages\nfor potential tip-over events to predict and detect these critical moments\nbefore they fully occur, possibly preventing accidents and enhancing the safety\nand stability of the rover during its exploration mission. Inertial Measurement\nUnits (IMU) readings are used to develop compact, robust, and efficient\nAutoencoders that combine the power of sequence processing of Long Short-Term\nMemory Networks (LSTM). By leveraging LSTM-based Autoencoders, this work\ncontributes predictive capabilities for detecting tip-over risks and developing\nsafety measures for more reliable exploration missions.", "arxiv_id": "2408.05602v1", "pdf_url": "http://arxiv.org/pdf/2408.05602v1", "abstract_url": "http://arxiv.org/abs/2408.05602v1", "primary_category": "cs.RO", "published_date": "2024-08-10", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Safety Enhancement in Planetary Rovers: Early Detection of Tip-over Risks Using Autoencoders", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:49.510422"}
{"title": "Sequential Representation Learning via Static-Dynamic Conditional Disentanglement", "authors": "Mathieu Cyrille Simon, Pascal Frossard, Christophe De Vleeschouwer", "abstract": "This paper explores self-supervised disentangled representation learning\nwithin sequential data, focusing on separating time-independent and\ntime-varying factors in videos. We propose a new model that breaks the usual\nindependence assumption between those factors by explicitly accounting for the\ncausal relationship between the static/dynamic variables and that improves the\nmodel expressivity through additional Normalizing Flows. A formal definition of\nthe factors is proposed. This formalism leads to the derivation of sufficient\nconditions for the ground truth factors to be identifiable, and to the\nintroduction of a novel theoretically grounded disentanglement constraint that\ncan be directly and efficiently incorporated into our new framework. The\nexperiments show that the proposed approach outperforms previous complex\nstate-of-the-art techniques in scenarios where the dynamics of a scene are\ninfluenced by its content.", "arxiv_id": "2408.05599v1", "pdf_url": "http://arxiv.org/pdf/2408.05599v1", "abstract_url": "http://arxiv.org/abs/2408.05599v1", "primary_category": "cs.LG", "published_date": "2024-08-10", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Sequential Representation Learning via Static-Dynamic Conditional Disentanglement", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:50.330553"}
{"title": "Meta Clustering of Neural Bandits", "authors": "Yikun Ban, Yunzhe Qi, Tianxin Wei, Lihui Liu, Jingrui He", "abstract": "The contextual bandit has been identified as a powerful framework to\nformulate the recommendation process as a sequential decision-making process,\nwhere each item is regarded as an arm and the objective is to minimize the\nregret of $T$ rounds. In this paper, we study a new problem, Clustering of\nNeural Bandits, by extending previous work to the arbitrary reward function, to\nstrike a balance between user heterogeneity and user correlations in the\nrecommender system. To solve this problem, we propose a novel algorithm called\nM-CNB, which utilizes a meta-learner to represent and rapidly adapt to dynamic\nclusters, along with an informative Upper Confidence Bound (UCB)-based\nexploration strategy. We provide an instance-dependent performance guarantee\nfor the proposed algorithm that withstands the adversarial context, and we\nfurther prove the guarantee is at least as good as state-of-the-art (SOTA)\napproaches under the same assumptions. In extensive experiments conducted in\nboth recommendation and online classification scenarios, M-CNB outperforms SOTA\nbaselines. This shows the effectiveness of the proposed approach in improving\nonline recommendation and online classification performance.", "arxiv_id": "2408.05586v1", "pdf_url": "http://arxiv.org/pdf/2408.05586v1", "abstract_url": "http://arxiv.org/abs/2408.05586v1", "primary_category": "cs.LG", "published_date": "2024-08-10", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Meta Clustering of Neural Bandits", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:51.010660"}
{"title": "Dynamical causality under invisible confounders", "authors": "Jinling Yan, Shao-Wu Zhang, Chihao Zhang, Weitian Huang, Jifan Shi, Luonan Chen", "abstract": "Causality inference is prone to spurious causal interactions, due to the\nsubstantial confounders in a complex system. While many existing methods based\non the statistical methods or dynamical methods attempt to address\nmisidentification challenges, there remains a notable lack of effective methods\nto infer causality, in particular in the presence of invisible/unobservable\nconfounders. As a result, accurately inferring causation with invisible\nconfounders remains a largely unexplored and outstanding issue in data science\nand AI fields. In this work, we propose a method to overcome such challenges to\ninfer dynamical causality under invisible confounders (CIC method) and further\nreconstruct the invisible confounders from time-series data by developing an\northogonal decomposition theorem in a delay embedding space. The core of our\nCIC method lies in its ability to decompose the observed variables not in their\noriginal space but in their delay embedding space into the common and private\nsubspaces respectively, thereby quantifying causality between those variables\nboth theoretically and computationally. This theoretical foundation ensures the\ncausal detection for any high-dimensional system even with only two observed\nvariables under many invisible confounders, which is actually a long-standing\nproblem in the field. In addition to the invisible confounder problem, such a\ndecomposition actually makes the intertwined variables separable in the\nembedding space, thus also solving the non-separability problem of causal\ninference. Extensive validation of the CIC method is carried out using various\nreal datasets, and the experimental results demonstrates its effectiveness to\nreconstruct real biological networks even with unobserved confounders.", "arxiv_id": "2408.05584v1", "pdf_url": "http://arxiv.org/pdf/2408.05584v1", "abstract_url": "http://arxiv.org/abs/2408.05584v1", "primary_category": "cs.LG", "published_date": "2024-08-10", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Dynamical causality under invisible confounders", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:52.133094"}
{"title": "Incremental Gauss-Newton Descent for Machine Learning", "authors": "Mikalai Korbit, Mario Zanon", "abstract": "Stochastic Gradient Descent (SGD) is a popular technique used to solve\nproblems arising in machine learning. While very effective, SGD also has some\nweaknesses and various modifications of the basic algorithm have been proposed\nin order to at least partially tackle them, mostly yielding accelerated\nversions of SGD. Filling a gap in the literature, we present a modification of\nthe SGD algorithm exploiting approximate second-order information based on the\nGauss-Newton approach. The new method, which we call Incremental Gauss-Newton\nDescent (IGND), has essentially the same computational burden as standard SGD,\nappears to converge faster on certain classes of problems, and can also be\naccelerated. The key intuition making it possible to implement IGND efficiently\nis that, in the incremental case, approximate second-order information can be\ncondensed into a scalar value that acts as a scaling constant of the update. We\nderive IGND starting from the theory supporting Gauss-Newton methods in a\ngeneral setting and then explain how IGND can also be interpreted as a\nwell-scaled version of SGD, which makes tuning the algorithm simpler, and\nprovides increased robustness. Finally, we show how IGND can be used in\npractice by solving supervised learning tasks as well as reinforcement learning\nproblems. The simulations show that IGND can significantly outperform SGD while\nperforming at least as well as SGD in the worst case.", "arxiv_id": "2408.05560v1", "pdf_url": "http://arxiv.org/pdf/2408.05560v1", "abstract_url": "http://arxiv.org/abs/2408.05560v1", "primary_category": "cs.LG", "published_date": "2024-08-10", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Incremental Gauss-Newton Descent for Machine Learning", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:54.900771"}
{"title": "Evolutionary Neural Architecture Search for 3D Point Cloud Analysis", "authors": "Yisheng Yang, Guodong Du, Chean Khim Toa, Ho-Kin Tang, Sim Kuan Goh", "abstract": "Neural architecture search (NAS) automates neural network design by using\noptimization algorithms to navigate architecture spaces, reducing the burden of\nmanual architecture design. While NAS has achieved success, applying it to\nemerging domains, such as analyzing unstructured 3D point clouds, remains\nunderexplored due to the data lying in non-Euclidean spaces, unlike images.\nThis paper presents Success-History-based Self-adaptive Differential Evolution\nwith a Joint Point Interaction Dimension Search (SHSADE-PIDS), an evolutionary\nNAS framework that encodes discrete deep neural network architectures to\ncontinuous spaces and performs searches in the continuous spaces for efficient\npoint cloud neural architectures. Comprehensive experiments on challenging 3D\nsegmentation and classification benchmarks demonstrate SHSADE-PIDS's\ncapabilities. It discovered highly efficient architectures with higher\naccuracy, significantly advancing prior NAS techniques. For segmentation on\nSemanticKITTI, SHSADE-PIDS attained 64.51% mean IoU using only 0.55M parameters\nand 4.5GMACs, reducing overhead by over 22-26X versus other top methods. For\nModelNet40 classification, it achieved 93.4% accuracy with just 1.31M\nparameters, surpassing larger models. SHSADE-PIDS provided valuable insights\ninto bridging evolutionary algorithms with neural architecture optimization,\nparticularly for emerging frontiers like point cloud learning.", "arxiv_id": "2408.05556v1", "pdf_url": "http://arxiv.org/pdf/2408.05556v1", "abstract_url": "http://arxiv.org/abs/2408.05556v1", "primary_category": "cs.CV", "published_date": "2024-08-10", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Evolutionary Neural Architecture Search for 3D Point Cloud Analysis", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:55.924616"}
{"title": "Convergence Analysis for Deep Sparse Coding via Convolutional Neural Networks", "authors": "Jianfei Li, Han Feng, Ding-Xuan Zhou", "abstract": "In this work, we explore the intersection of sparse coding theory and deep\nlearning to enhance our understanding of feature extraction capabilities in\nadvanced neural network architectures. We begin by introducing a novel class of\nDeep Sparse Coding (DSC) models and establish a thorough theoretical analysis\nof their uniqueness and stability properties. By applying iterative algorithms\nto these DSC models, we derive convergence rates for convolutional neural\nnetworks (CNNs) in their ability to extract sparse features. This provides a\nstrong theoretical foundation for the use of CNNs in sparse feature learning\ntasks. We additionally extend this convergence analysis to more general neural\nnetwork architectures, including those with diverse activation functions, as\nwell as self-attention and transformer-based models. This broadens the\napplicability of our findings to a wide range of deep learning methods for deep\nsparse feature extraction. Inspired by the strong connection between sparse\ncoding and CNNs, we also explore training strategies to encourage neural\nnetworks to learn more sparse features. Through numerical experiments, we\ndemonstrate the effectiveness of these approaches, providing valuable insights\nfor the design of efficient and interpretable deep learning models.", "arxiv_id": "2408.05540v1", "pdf_url": "http://arxiv.org/pdf/2408.05540v1", "abstract_url": "http://arxiv.org/abs/2408.05540v1", "primary_category": "cs.LG", "published_date": "2024-08-10", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Convergence Analysis for Deep Sparse Coding via Convolutional Neural Networks", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:56.641082"}
{"title": "S-SIRUS: an explainability algorithm for spatial regression Random Forest", "authors": "Luca Patelli, Natalia Golini, Rosaria Ignaccolo, Michela Cameletti", "abstract": "Random Forest (RF) is a widely used machine learning algorithm known for its\nflexibility, user-friendliness, and high predictive performance across various\ndomains. However, it is non-interpretable. This can limit its usefulness in\napplied sciences, where understanding the relationships between predictors and\nresponse variable is crucial from a decision-making perspective. In the\nliterature, several methods have been proposed to explain RF, but none of them\naddresses the challenge of explaining RF in the context of spatially dependent\ndata. Therefore, this work aims to explain regression RF in the case of\nspatially dependent data by extracting a compact and simple list of rules. In\nthis respect, we propose S-SIRUS, a spatial extension of SIRUS, the latter\nbeing a well-established regression rule algorithm able to extract a stable and\nshort list of rules from the classical regression RF algorithm. A simulation\nstudy was conducted to evaluate the explainability capability of the proposed\nS-SIRUS, in comparison to SIRUS, by considering different levels of spatial\ndependence among the data. The results suggest that S-SIRUS exhibits a higher\ntest predictive accuracy than SIRUS when spatial correlation is present.\nMoreover, for higher levels of spatial correlation, S-SIRUS produces a shorter\nlist of rules, easing the explanation of the mechanism behind the predictions.", "arxiv_id": "2408.05537v1", "pdf_url": "http://arxiv.org/pdf/2408.05537v1", "abstract_url": "http://arxiv.org/abs/2408.05537v1", "primary_category": "stat.ML", "published_date": "2024-08-10", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "S-SIRUS: an explainability algorithm for spatial regression Random Forest", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:57.544249"}
{"title": "Latent class analysis for multi-layer categorical data", "authors": "Huan Qing", "abstract": "Traditional categorical data, often collected in psychological tests and\neducational assessments, are typically single-layer and gathered only once.This\npaper considers a more general case, multi-layer categorical data with\npolytomous responses. To model such data, we present a novel statistical model,\nthe multi-layer latent class model (multi-layer LCM). This model assumes that\nall layers share common subjects and items. To discover subjects' latent\nclasses and other model parameters under this model, we develop three efficient\nspectral methods based on the sum of response matrices, the sum of Gram\nmatrices, and the debiased sum of Gram matrices, respectively. Within the\nframework of multi-layer LCM, we demonstrate the estimation consistency of\nthese methods under mild conditions regarding data sparsity. Our theoretical\nfindings reveal two key insights: (1) increasing the number of layers can\nenhance the performance of the proposed methods, highlighting the advantages of\nconsidering multiple layers in latent class analysis; (2) we theoretically show\nthat the algorithm based on the debiased sum of Gram matrices usually performs\nbest. Additionally, we propose an approach that combines the averaged\nmodularity metric with our methods to determine the number of latent classes.\nExtensive experiments are conducted to support our theoretical results and show\nthe powerfulness of our methods in the task of learning latent classes and\nestimating the number of latent classes in multi-layer categorical data with\npolytomous responses.", "arxiv_id": "2408.05535v1", "pdf_url": "http://arxiv.org/pdf/2408.05535v1", "abstract_url": "http://arxiv.org/abs/2408.05535v1", "primary_category": "stat.ML", "published_date": "2024-08-10", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Latent class analysis for multi-layer categorical data", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:58.335476"}
{"title": "Can LLMs Replace Manual Annotation of Software Engineering Artifacts?", "authors": "Toufique Ahmed, Premkumar Devanbu, Christoph Treude, Michael Pradel", "abstract": "Experimental evaluations of software engineering innovations, e.g., tools and\nprocesses, often include human-subject studies as a component of a\nmulti-pronged strategy to obtain greater generalizability of the findings.\nHowever, human-subject studies in our field are challenging, due to the cost\nand difficulty of finding and employing suitable subjects, ideally,\nprofessional programmers with varying degrees of experience. Meanwhile, large\nlanguage models (LLMs) have recently started to demonstrate human-level\nperformance in several areas. This paper explores the possibility of\nsubstituting costly human subjects with much cheaper LLM queries in evaluations\nof code and code-related artifacts. We study this idea by applying six\nstate-of-the-art LLMs to ten annotation tasks from five datasets created by\nprior work, such as judging the accuracy of a natural language summary of a\nmethod or deciding whether a code change fixes a static analysis warning. Our\nresults show that replacing some human annotation effort with LLMs can produce\ninter-rater agreements equal or close to human-rater agreement. To help decide\nwhen and how to use LLMs in human-subject studies, we propose model-model\nagreement as a predictor of whether a given task is suitable for LLMs at all,\nand model confidence as a means to select specific samples where LLMs can\nsafely replace human annotators. Overall, our work is the first step toward\nmixed human-LLM evaluations in software engineering.", "arxiv_id": "2408.05534v1", "pdf_url": "http://arxiv.org/pdf/2408.05534v1", "abstract_url": "http://arxiv.org/abs/2408.05534v1", "primary_category": "cs.SE", "published_date": "2024-08-10", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Can LLMs Replace Manual Annotation of Software Engineering Artifacts?", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:59.096142"}
{"title": "Dilated Convolution with Learnable Spacings", "authors": "Ismail Khalfaoui-Hassani", "abstract": "This thesis presents and evaluates the Dilated Convolution with Learnable\nSpacings (DCLS) method. Through various supervised learning experiments in the\nfields of computer vision, audio, and speech processing, the DCLS method proves\nto outperform both standard and advanced convolution techniques. The research\nis organized into several steps, starting with an analysis of the literature\nand existing convolution techniques that preceded the development of the DCLS\nmethod. We were particularly interested in the methods that are closely related\nto our own and that remain essential to capture the nuances and uniqueness of\nour approach. The cornerstone of our study is the introduction and application\nof the DCLS method to convolutional neural networks (CNNs), as well as to\nhybrid architectures that rely on both convolutional and visual attention\napproaches. DCLS is shown to be particularly effective in tasks such as\nclassification, semantic segmentation, and object detection. Initially using\nbilinear interpolation, the study also explores other interpolation methods,\nfinding that Gaussian interpolation slightly improves performance. The DCLS\nmethod is further applied to spiking neural networks (SNNs) to enable synaptic\ndelay learning within a neural network that could eventually be transferred to\nso-called neuromorphic chips. The results show that the DCLS method stands out\nas a new state-of-the-art technique in SNN audio classification for certain\nbenchmark tasks in this field. These tasks involve datasets with a high\ntemporal component. In addition, we show that DCLS can significantly improve\nthe accuracy of artificial neural networks for the multi-label audio\nclassification task. We conclude with a discussion of the chosen experimental\nsetup, its limitations, the limitations of our method, and our results.", "arxiv_id": "2408.06383v1", "pdf_url": "http://arxiv.org/pdf/2408.06383v1", "abstract_url": "http://arxiv.org/abs/2408.06383v1", "primary_category": "cs.LG", "published_date": "2024-08-10", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Dilated Convolution with Learnable Spacings", "response": "RELEVANT", "timestamp": "2024-08-19T13:38:59.771183"}
{"title": "CryoBench: Diverse and challenging datasets for the heterogeneity problem in cryo-EM", "authors": "Minkyu Jeon, Rishwanth Raghu, Miro Astore, Geoffrey Woollard, Ryan Feathers, Alkin Kaz, Sonya M. Hanson, Pilar Cossio, Ellen D. Zhong", "abstract": "Cryo-electron microscopy (cryo-EM) is a powerful technique for determining\nhigh-resolution 3D biomolecular structures from imaging data. As this technique\ncan capture dynamic biomolecular complexes, 3D reconstruction methods are\nincreasingly being developed to resolve this intrinsic structural\nheterogeneity. However, the absence of standardized benchmarks with ground\ntruth structures and validation metrics limits the advancement of the field.\nHere, we propose CryoBench, a suite of datasets, metrics, and performance\nbenchmarks for heterogeneous reconstruction in cryo-EM. We propose five\ndatasets representing different sources of heterogeneity and degrees of\ndifficulty. These include conformational heterogeneity generated from simple\nmotions and random configurations of antibody complexes and from tens of\nthousands of structures sampled from a molecular dynamics simulation. We also\ndesign datasets containing compositional heterogeneity from mixtures of\nribosome assembly states and 100 common complexes present in cells. We then\nperform a comprehensive analysis of state-of-the-art heterogeneous\nreconstruction tools including neural and non-neural methods and their\nsensitivity to noise, and propose new metrics for quantitative comparison of\nmethods. We hope that this benchmark will be a foundational resource for\nanalyzing existing methods and new algorithmic development in both the cryo-EM\nand machine learning communities.", "arxiv_id": "2408.05526v1", "pdf_url": "http://arxiv.org/pdf/2408.05526v1", "abstract_url": "http://arxiv.org/abs/2408.05526v1", "primary_category": "cs.CV", "published_date": "2024-08-10", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "CryoBench: Diverse and challenging datasets for the heterogeneity problem in cryo-EM", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:00.564359"}
{"title": "PointNCBW: Towards Dataset Ownership Verification for Point Clouds via Negative Clean-label Backdoor Watermark", "authors": "Cheng Wei, Yang Wang, Kuofeng Gao, Shuo Shao, Yiming Li, Zhibo Wang, Zhan Qin", "abstract": "Recently, point clouds have been widely used in computer vision, whereas\ntheir collection is time-consuming and expensive. As such, point cloud datasets\nare the valuable intellectual property of their owners and deserve protection.\nTo detect and prevent unauthorized use of these datasets, especially for\ncommercial or open-sourced ones that cannot be sold again or used commercially\nwithout permission, we intend to identify whether a suspicious third-party\nmodel is trained on our protected dataset under the black-box setting. We\nachieve this goal by designing a scalable clean-label backdoor-based dataset\nwatermark for point clouds that ensures both effectiveness and stealthiness.\nUnlike existing clean-label watermark schemes, which are susceptible to the\nnumber of categories, our method could watermark samples from all classes\ninstead of only from the target one. Accordingly, it can still preserve high\neffectiveness even on large-scale datasets with many classes. Specifically, we\nperturb selected point clouds with non-target categories in both shape-wise and\npoint-wise manners before inserting trigger patterns without changing their\nlabels. The features of perturbed samples are similar to those of benign\nsamples from the target class. As such, models trained on the watermarked\ndataset will have a distinctive yet stealthy backdoor behavior, i.e.,\nmisclassifying samples from the target class whenever triggers appear, since\nthe trained DNNs will treat the inserted trigger pattern as a signal to deny\npredicting the target label. We also design a hypothesis-test-guided dataset\nownership verification based on the proposed watermark. Extensive experiments\non benchmark datasets are conducted, verifying the effectiveness of our method\nand its resistance to potential removal methods.", "arxiv_id": "2408.05500v1", "pdf_url": "http://arxiv.org/pdf/2408.05500v1", "abstract_url": "http://arxiv.org/abs/2408.05500v1", "primary_category": "cs.CR", "published_date": "2024-08-10", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "PointNCBW: Towards Dataset Ownership Verification for Point Clouds via Negative Clean-label Backdoor Watermark", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:01.455396"}
{"title": "A Laplacian-based Quantum Graph Neural Network for Semi-Supervised Learning", "authors": "Hamed Gholipour, Farid Bozorgnia, Kailash Hambarde, Hamzeh Mohammadigheymasi, Javier Mancilla, Andre Sequeira, Joao Neves, Hugo Proen\u00e7a", "abstract": "Laplacian learning method is a well-established technique in classical\ngraph-based semi-supervised learning, but its potential in the quantum domain\nremains largely unexplored. This study investigates the performance of the\nLaplacian-based Quantum Semi-Supervised Learning (QSSL) method across four\nbenchmark datasets -- Iris, Wine, Breast Cancer Wisconsin, and Heart Disease.\nFurther analysis explores the impact of increasing Qubit counts, revealing that\nadding more Qubits to a quantum system doesn't always improve performance. The\neffectiveness of additional Qubits depends on the quantum algorithm and how\nwell it matches the dataset. Additionally, we examine the effects of varying\nentangling layers on entanglement entropy and test accuracy. The performance of\nLaplacian learning is highly dependent on the number of entangling layers, with\noptimal configurations varying across different datasets. Typically, moderate\nlevels of entanglement offer the best balance between model complexity and\ngeneralization capabilities. These observations highlight the crucial need for\nprecise hyperparameter tuning tailored to each dataset to achieve optimal\nperformance in Laplacian learning methods.", "arxiv_id": "2408.05498v2", "pdf_url": "http://arxiv.org/pdf/2408.05498v2", "abstract_url": "http://arxiv.org/abs/2408.05498v2", "primary_category": "cs.LG", "published_date": "2024-08-10", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "A Laplacian-based Quantum Graph Neural Network for Semi-Supervised Learning", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:02.169010"}
{"title": "Variational Inference Failures Under Model Symmetries: Permutation Invariant Posteriors for Bayesian Neural Networks", "authors": "Yoav Gelberg, Tycho F. A. van der Ouderaa, Mark van der Wilk, Yarin Gal", "abstract": "Weight space symmetries in neural network architectures, such as permutation\nsymmetries in MLPs, give rise to Bayesian neural network (BNN) posteriors with\nmany equivalent modes. This multimodality poses a challenge for variational\ninference (VI) techniques, which typically rely on approximating the posterior\nwith a unimodal distribution. In this work, we investigate the impact of weight\nspace permutation symmetries on VI. We demonstrate, both theoretically and\nempirically, that these symmetries lead to biases in the approximate posterior,\nwhich degrade predictive performance and posterior fit if not explicitly\naccounted for. To mitigate this behavior, we leverage the symmetric structure\nof the posterior and devise a symmetrization mechanism for constructing\npermutation invariant variational posteriors. We show that the symmetrized\ndistribution has a strictly better fit to the true posterior, and that it can\nbe trained using the original ELBO objective with a modified KL regularization\nterm. We demonstrate experimentally that our approach mitigates the\naforementioned biases and results in improved predictions and a higher ELBO.", "arxiv_id": "2408.05496v1", "pdf_url": "http://arxiv.org/pdf/2408.05496v1", "abstract_url": "http://arxiv.org/abs/2408.05496v1", "primary_category": "cs.LG", "published_date": "2024-08-10", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Variational Inference Failures Under Model Symmetries: Permutation Invariant Posteriors for Bayesian Neural Networks", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:03.208906"}
{"title": "Topological Blind Spots: Understanding and Extending Topological Deep Learning Through the Lens of Expressivity", "authors": "Yam Eitan, Yoav Gelberg, Guy Bar-Shalom, Fabrizio Frasca, Michael Bronstein, Haggai Maron", "abstract": "Topological deep learning (TDL) facilitates learning from data represented by\ntopological structures. The primary model utilized in this setting is\nhigher-order message-passing (HOMP), which extends traditional graph\nmessage-passing neural networks (MPNN) to diverse topological domains. Given\nthe significant expressivity limitations of MPNNs, our paper aims to explore\nboth the strengths and weaknesses of HOMP's expressive power and subsequently\ndesign novel architectures to address these limitations. We approach this from\nseveral perspectives: First, we demonstrate HOMP's inability to distinguish\nbetween topological objects based on fundamental topological and metric\nproperties such as diameter, orientability, planarity, and homology. Second, we\nshow HOMP's limitations in fully leveraging the topological structure of\nobjects constructed using common lifting and pooling operators on graphs.\nFinally, we compare HOMP's expressive power to hypergraph networks, which are\nthe most extensively studied TDL methods. We then develop two new classes of\nTDL models: multi-cellular networks (MCN) and scalable multi-cellular networks\n(SMCN). These models draw inspiration from expressive graph architectures.\nWhile MCN can reach full expressivity but is highly unscalable, SMCN offers a\nmore scalable alternative that still mitigates many of HOMP's expressivity\nlimitations. Finally, we construct a synthetic dataset, where TDL models are\ntasked with separating pairs of topological objects based on basic topological\nproperties. We demonstrate that while HOMP is unable to distinguish between any\nof the pairs in the dataset, SMCN successfully distinguishes all pairs,\nempirically validating our theoretical findings. Our work opens a new design\nspace and new opportunities for TDL, paving the way for more expressive and\nversatile models.", "arxiv_id": "2408.05486v1", "pdf_url": "http://arxiv.org/pdf/2408.05486v1", "abstract_url": "http://arxiv.org/abs/2408.05486v1", "primary_category": "cs.LG", "published_date": "2024-08-10", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Topological Blind Spots: Understanding and Extending Topological Deep Learning Through the Lens of Expressivity", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:03.911439"}
{"title": "A Structural Feature-Based Approach for Comprehensive Graph Classification", "authors": "Saiful Islam, Md. Nahid Hasan, Pitambar Khanra", "abstract": "The increasing prevalence of graph-structured data across various domains has\nintensified greater interest in graph classification tasks. While numerous\nsophisticated graph learning methods have emerged, their complexity often\nhinders practical implementation. In this article, we address this challenge by\nproposing a method that constructs feature vectors based on fundamental graph\nstructural properties. We demonstrate that these features, despite their\nsimplicity, are powerful enough to capture the intrinsic characteristics of\ngraphs within the same class. We explore the efficacy of our approach using\nthree distinct machine learning methods, highlighting how our feature-based\nclassification leverages the inherent structural similarities of graphs within\nthe same class to achieve accurate classification. A key advantage of our\napproach is its simplicity, which makes it accessible and adaptable to a broad\nrange of applications, including social network analysis, bioinformatics, and\ncybersecurity. Furthermore, we conduct extensive experiments to validate the\nperformance of our method, showing that it not only reveals a competitive\nperformance but in some cases surpasses the accuracy of more complex,\nstate-of-the-art techniques. Our findings suggest that a focus on fundamental\ngraph features can provide a robust and efficient alternative for graph\nclassification, offering significant potential for both research and practical\napplications.", "arxiv_id": "2408.05474v1", "pdf_url": "http://arxiv.org/pdf/2408.05474v1", "abstract_url": "http://arxiv.org/abs/2408.05474v1", "primary_category": "cs.LG", "published_date": "2024-08-10", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "A Structural Feature-Based Approach for Comprehensive Graph Classification", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:04.640403"}
{"title": "FuXi Weather: An end-to-end machine learning weather data assimilation and forecasting system", "authors": "Xiuyu Sun, Xiaohui Zhong, Xiaoze Xu, Yuanqing Huang, Hao Li, Jie Feng, Wei Han, Libo Wu, Yuan Qi", "abstract": "Operational numerical weather prediction systems consist of three fundamental\ncomponents: the global observing system for data collection, data assimilation\nfor generating initial conditions, and the forecasting model to predict future\nweather conditions. While NWP have undergone a quiet revolution, with forecast\nskills progressively improving over the past few decades, their advancement has\nslowed due to challenges such as high computational costs and the complexities\nassociated with assimilating an increasing volume of observational data and\nmanaging finer spatial grids. Advances in machine learning offer an alternative\npath towards more efficient and accurate weather forecasts. The rise of machine\nlearning based weather forecasting models has also spurred the development of\nmachine learning based DA models or even purely machine learning based weather\nforecasting systems. This paper introduces FuXi Weather, an end-to-end machine\nlearning based weather forecasting system. FuXi Weather employs specialized\ndata preprocessing and multi-modal data fusion techniques to integrate\ninformation from diverse sources under all-sky conditions, including microwave\nsounders from 3 polar-orbiting satellites and radio occultation data from\nGlobal Navigation Satellite System. Operating on a 6-hourly DA and forecasting\ncycle, FuXi Weather independently generates robust and accurate 10-day global\nweather forecasts at a spatial resolution of 0.25\\textdegree. It surpasses the\nEuropean Centre for Medium-range Weather Forecasts high-resolution forecasts in\nterms of predictability, extending the skillful forecast lead times for several\nkey weather variables such as the geopotential height at 500 hPa from 9.25 days\nto 9.5 days. The system's high computational efficiency and robust performance,\neven with limited observations, demonstrates its potential as a promising\nalternative to traditional NWP systems.", "arxiv_id": "2408.05472v1", "pdf_url": "http://arxiv.org/pdf/2408.05472v1", "abstract_url": "http://arxiv.org/abs/2408.05472v1", "primary_category": "cs.LG", "published_date": "2024-08-10", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "FuXi Weather: An end-to-end machine learning weather data assimilation and forecasting system", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:05.368842"}
{"title": "A Versatile Framework for Attributed Network Clustering via K-Nearest Neighbor Augmentation", "authors": "Yiran Li, Gongyao Guo, Jieming Shi, Renchi Yang, Shiqi Shen, Qing Li, Jun Luo", "abstract": "Attributed networks containing entity-specific information in node attributes\nare ubiquitous in modeling social networks, e-commerce, bioinformatics, etc.\nTheir inherent network topology ranges from simple graphs to hypergraphs with\nhigh-order interactions and multiplex graphs with separate layers. An important\ngraph mining task is node clustering, aiming to partition the nodes of an\nattributed network into k disjoint clusters such that intra-cluster nodes are\nclosely connected and share similar attributes, while inter-cluster nodes are\nfar apart and dissimilar. It is highly challenging to capture multi-hop\nconnections via nodes or attributes for effective clustering on multiple types\nof attributed networks. In this paper, we first present AHCKA as an efficient\napproach to attributed hypergraph clustering (AHC). AHCKA includes a\ncarefully-crafted K-nearest neighbor augmentation strategy for the optimized\nexploitation of attribute information on hypergraphs, a joint hypergraph random\nwalk model to devise an effective AHC objective, and an efficient solver with\nspeedup techniques for the objective optimization. The proposed techniques are\nextensible to various types of attributed networks, and thus, we develop ANCKA\nas a versatile attributed network clustering framework, capable of attributed\ngraph clustering (AGC), attributed multiplex graph clustering (AMGC), and AHC.\nMoreover, we devise ANCKA with algorithmic designs tailored for GPU\nacceleration to boost efficiency. We have conducted extensive experiments to\ncompare our methods with 19 competitors on 8 attributed hypergraphs, 16\ncompetitors on 6 attributed graphs, and 16 competitors on 3 attributed\nmultiplex graphs, all demonstrating the superb clustering quality and\nefficiency of our methods.", "arxiv_id": "2408.05459v1", "pdf_url": "http://arxiv.org/pdf/2408.05459v1", "abstract_url": "http://arxiv.org/abs/2408.05459v1", "primary_category": "cs.SI", "published_date": "2024-08-10", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "A Versatile Framework for Attributed Network Clustering via K-Nearest Neighbor Augmentation", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:06.168074"}
{"title": "Mathematical Models of Computation in Superposition", "authors": "Kaarel H\u00e4nni, Jake Mendel, Dmitry Vaintrob, Lawrence Chan", "abstract": "Superposition -- when a neural network represents more ``features'' than it\nhas dimensions -- seems to pose a serious challenge to mechanistically\ninterpreting current AI systems. Existing theory work studies\n\\emph{representational} superposition, where superposition is only used when\npassing information through bottlenecks. In this work, we present mathematical\nmodels of \\emph{computation} in superposition, where superposition is actively\nhelpful for efficiently accomplishing the task.\n  We first construct a task of efficiently emulating a circuit that takes the\nAND of the $\\binom{m}{2}$ pairs of each of $m$ features. We construct a 1-layer\nMLP that uses superposition to perform this task up to $\\varepsilon$-error,\nwhere the network only requires $\\tilde{O}(m^{\\frac{2}{3}})$ neurons, even when\nthe input features are \\emph{themselves in superposition}. We generalize this\nconstruction to arbitrary sparse boolean circuits of low depth, and then\nconstruct ``error correction'' layers that allow deep fully-connected networks\nof width $d$ to emulate circuits of width $\\tilde{O}(d^{1.5})$ and \\emph{any}\npolynomial depth. We conclude by providing some potential applications of our\nwork for interpreting neural networks that implement computation in\nsuperposition.", "arxiv_id": "2408.05451v1", "pdf_url": "http://arxiv.org/pdf/2408.05451v1", "abstract_url": "http://arxiv.org/abs/2408.05451v1", "primary_category": "cs.LG", "published_date": "2024-08-10", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Mathematical Models of Computation in Superposition", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:07.068865"}
{"title": "Preserving Privacy in Large Language Models: A Survey on Current Threats and Solutions", "authors": "Michele Miranda, Elena Sofia Ruzzetti, Andrea Santilli, Fabio Massimo Zanzotto, S\u00e9bastien Brati\u00e8res, Emanuele Rodol\u00e0", "abstract": "Large Language Models (LLMs) represent a significant advancement in\nartificial intelligence, finding applications across various domains. However,\ntheir reliance on massive internet-sourced datasets for training brings notable\nprivacy issues, which are exacerbated in critical domains (e.g., healthcare).\nMoreover, certain application-specific scenarios may require fine-tuning these\nmodels on private data. This survey critically examines the privacy threats\nassociated with LLMs, emphasizing the potential for these models to memorize\nand inadvertently reveal sensitive information. We explore current threats by\nreviewing privacy attacks on LLMs and propose comprehensive solutions for\nintegrating privacy mechanisms throughout the entire learning pipeline. These\nsolutions range from anonymizing training datasets to implementing differential\nprivacy during training or inference and machine unlearning after training. Our\ncomprehensive review of existing literature highlights ongoing challenges,\navailable tools, and future directions for preserving privacy in LLMs. This\nwork aims to guide the development of more secure and trustworthy AI systems by\nproviding a thorough understanding of privacy preservation methods and their\neffectiveness in mitigating risks.", "arxiv_id": "2408.05212v1", "pdf_url": "http://arxiv.org/pdf/2408.05212v1", "abstract_url": "http://arxiv.org/abs/2408.05212v1", "primary_category": "cs.CR", "published_date": "2024-08-10", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Preserving Privacy in Large Language Models: A Survey on Current Threats and Solutions", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:07.785142"}
{"title": "Predicting Long-Term Allograft Survival in Liver Transplant Recipients", "authors": "Xiang Gao, Michael Cooper, Maryam Naghibzadeh, Amirhossein Azhie, Mamatha Bhat, Rahul G. Krishnan", "abstract": "Liver allograft failure occurs in approximately 20% of liver transplant\nrecipients within five years post-transplant, leading to mortality or the need\nfor retransplantation. Providing an accurate and interpretable model for\nindividualized risk estimation of graft failure is essential for improving\npost-transplant care. To this end, we introduce the Model for Allograft\nSurvival (MAS), a simple linear risk score that outperforms other advanced\nsurvival models. Using longitudinal patient follow-up data from the United\nStates (U.S.), we develop our models on 82,959 liver transplant recipients and\nconduct multi-site evaluations on 11 regions. Additionally, by testing on a\nseparate non-U.S. cohort, we explore the out-of-distribution generalization\nperformance of various models without additional fine-tuning, a crucial\nproperty for clinical deployment. We find that the most complex models are also\nthe ones most vulnerable to distribution shifts despite achieving the best\nin-distribution performance. Our findings not only provide a strong risk score\nfor predicting long-term graft failure but also suggest that the routine\nmachine learning pipeline with only in-distribution held-out validation could\ncreate harmful consequences for patients at deployment.", "arxiv_id": "2408.05437v1", "pdf_url": "http://arxiv.org/pdf/2408.05437v1", "abstract_url": "http://arxiv.org/abs/2408.05437v1", "primary_category": "cs.LG", "published_date": "2024-08-10", "votes": 0, "preferences": "LLM reasoning", "response": "NOT_ENOUGH_RELATED"}
{"title": "Predicting Long-Term Allograft Survival in Liver Transplant Recipients", "response": "NOT_ENOUGH_RELATED", "timestamp": "2024-08-19T13:39:08.772885"}
{"title": "SuperEncoder: Towards Universal Neural Approximate Quantum State Preparation", "authors": "Yilun Zhao, Bingmeng Wang, Wenle Jiang, Xiwei Pan, Bing Li, Yinhe Han, Ying Wang", "abstract": "Numerous quantum algorithms operate under the assumption that classical data\nhas already been converted into quantum states, a process termed Quantum State\nPreparation (QSP). However, achieving precise QSP requires a circuit depth that\nscales exponentially with the number of qubits, making it a substantial\nobstacle in harnessing quantum advantage. Recent research suggests using a\nParameterized Quantum Circuit (PQC) to approximate a target state, offering a\nmore scalable solution with reduced circuit depth compared to precise QSP.\nDespite this, the need for iterative updates of circuit parameters results in a\nlengthy runtime, limiting its practical application. In this work, we\ndemonstrate that it is possible to leverage a pre-trained neural network to\ndirectly generate the QSP circuit for arbitrary quantum state, thereby\neliminating the significant overhead of online iterations. Our study makes a\nsteady step towards a universal neural designer for approximate QSP.", "arxiv_id": "2408.05435v1", "pdf_url": "http://arxiv.org/pdf/2408.05435v1", "abstract_url": "http://arxiv.org/abs/2408.05435v1", "primary_category": "quant-ph", "published_date": "2024-08-10", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "SuperEncoder: Towards Universal Neural Approximate Quantum State Preparation", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:09.582603"}
{"title": "Simple and Nearly-Optimal Sampling for Rank-1 Tensor Completion via Gauss-Jordan", "authors": "Alejandro Gomez-Leos, Oscar L\u00f3pez", "abstract": "We revisit the sample and computational complexity of completing a rank-1\ntensor in $\\otimes_{i=1}^{N} \\mathbb{R}^{d}$, given a uniformly sampled subset\nof its entries. We present a characterization of the problem (i.e. nonzero\nentries) which admits an algorithm amounting to Gauss-Jordan on a pair of\nrandom linear systems. For example, when $N = \\Theta(1)$, we prove it uses no\nmore than $m = O(d^2 \\log d)$ samples and runs in $O(md^2)$ time. Moreover, we\nshow any algorithm requires $\\Omega(d\\log d)$ samples.\n  By contrast, existing upper bounds on the sample complexity are at least as\nlarge as $d^{1.5} \\mu^{\\Omega(1)} \\log^{\\Omega(1)} d$, where $\\mu$ can be\n$\\Theta(d)$ in the worst case. Prior work obtained these looser guarantees in\nhigher rank versions of our problem, and tend to involve more complicated\nalgorithms.", "arxiv_id": "2408.05431v1", "pdf_url": "http://arxiv.org/pdf/2408.05431v1", "abstract_url": "http://arxiv.org/abs/2408.05431v1", "primary_category": "cs.DS", "published_date": "2024-08-10", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Simple and Nearly-Optimal Sampling for Rank-1 Tensor Completion via Gauss-Jordan", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:10.413222"}
{"title": "HoME: Hierarchy of Multi-Gate Experts for Multi-Task Learning at Kuaishou", "authors": "Xu Wang, Jiangxia Cao, Zhiyi Fu, Kun Gai, Guorui Zhou", "abstract": "In this paper, we present the practical problems and the lessons learned at\nshort-video services from Kuaishou. In industry, a widely-used multi-task\nframework is the Mixture-of-Experts (MoE) paradigm, which always introduces\nsome shared and specific experts for each task and then uses gate networks to\nmeasure related experts' contributions. Although the MoE achieves remarkable\nimprovements, we still observe three anomalies that seriously affect model\nperformances in our iteration: (1) Expert Collapse: We found that experts'\noutput distributions are significantly different, and some experts have over\n90% zero activations with ReLU, making it hard for gate networks to assign fair\nweights to balance experts. (2) Expert Degradation: Ideally, the shared-expert\naims to provide predictive information for all tasks simultaneously.\nNevertheless, we find that some shared-experts are occupied by only one task,\nwhich indicates that shared-experts lost their ability but degenerated into\nsome specific-experts. (3) Expert Underfitting: In our services, we have dozens\nof behavior tasks that need to be predicted, but we find that some data-sparse\nprediction tasks tend to ignore their specific-experts and assign large weights\nto shared-experts. The reason might be that the shared-experts can perceive\nmore gradient updates and knowledge from dense tasks, while specific-experts\neasily fall into underfitting due to their sparse behaviors. Motivated by those\nobservations, we propose HoME to achieve a simple, efficient and balanced MoE\nsystem for multi-task learning.", "arxiv_id": "2408.05430v1", "pdf_url": "http://arxiv.org/pdf/2408.05430v1", "abstract_url": "http://arxiv.org/abs/2408.05430v1", "primary_category": "cs.IR", "published_date": "2024-08-10", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "HoME: Hierarchy of Multi-Gate Experts for Multi-Task Learning at Kuaishou", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:11.337460"}
{"title": "Generalized Encouragement-Based Instrumental Variables for Counterfactual Regression", "authors": "Anpeng Wu, Kun Kuang, Ruoxuan Xiong, Xiangwei Chen, Zexu Sun, Fei Wu, Kun Zhang", "abstract": "In causal inference, encouragement designs (EDs) are widely used to analyze\ncausal effects, when randomized controlled trials (RCTs) are impractical or\ncompliance to treatment cannot be perfectly enforced. Unlike RCTs, which\ndirectly allocate treatments, EDs randomly assign encouragement policies that\npositively motivate individuals to engage in a specific treatment. These random\nencouragements act as instrumental variables (IVs), facilitating the\nidentification of causal effects through leveraging exogenous perturbations in\ndiscrete treatment scenarios. However, real-world applications of encouragement\ndesigns often face challenges such as incomplete randomization, limited\nexperimental data, and significantly fewer encouragements compared to\ntreatments, hindering precise causal effect estimation. To address this, this\npaper introduces novel theories and algorithms for identifying the Conditional\nAverage Treatment Effect (CATE) using variations in encouragement. Further, by\nleveraging both observational and encouragement data, we propose a generalized\nIV estimator, named Encouragement-based Counterfactual Regression (EnCounteR),\nto effectively estimate the causal effects. Extensive experiments on both\nsynthetic and real-world datasets demonstrate the superiority of EnCounteR over\nexisting methods.", "arxiv_id": "2408.05428v1", "pdf_url": "http://arxiv.org/pdf/2408.05428v1", "abstract_url": "http://arxiv.org/abs/2408.05428v1", "primary_category": "cs.LG", "published_date": "2024-08-10", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Generalized Encouragement-Based Instrumental Variables for Counterfactual Regression", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:13.399514"}
{"title": "Detecting Masquerade Attacks in Controller Area Networks Using Graph Machine Learning", "authors": "William Marfo, Pablo Moriano, Deepak K. Tosh, Shirley V. Moore", "abstract": "Modern vehicles rely on a myriad of electronic control units (ECUs)\ninterconnected via controller area networks (CANs) for critical operations.\nDespite their ubiquitous use and reliability, CANs are susceptible to\nsophisticated cyberattacks, particularly masquerade attacks, which inject false\ndata that mimic legitimate messages at the expected frequency. These attacks\npose severe risks such as unintended acceleration, brake deactivation, and\nrogue steering. Traditional intrusion detection systems (IDS) often struggle to\ndetect these subtle intrusions due to their seamless integration into normal\ntraffic. This paper introduces a novel framework for detecting masquerade\nattacks in the CAN bus using graph machine learning (ML). We hypothesize that\nthe integration of shallow graph embeddings with time series features derived\nfrom CAN frames enhances the detection of masquerade attacks. We show that by\nrepresenting CAN bus frames as message sequence graphs (MSGs) and enriching\neach node with contextual statistical attributes from time series, we can\nenhance detection capabilities across various attack patterns compared to using\nonly graph-based features. Our method ensures a comprehensive and dynamic\nanalysis of CAN frame interactions, improving robustness and efficiency.\nExtensive experiments on the ROAD dataset validate the effectiveness of our\napproach, demonstrating statistically significant improvements in the detection\nrates of masquerade attacks compared to a baseline that uses only graph-based\nfeatures, as confirmed by Mann-Whitney U and Kolmogorov-Smirnov tests (p <\n0.05).", "arxiv_id": "2408.05427v1", "pdf_url": "http://arxiv.org/pdf/2408.05427v1", "abstract_url": "http://arxiv.org/abs/2408.05427v1", "primary_category": "cs.CR", "published_date": "2024-08-10", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Detecting Masquerade Attacks in Controller Area Networks Using Graph Machine Learning", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:14.205292"}
{"title": "Modeling Multi-Step Scientific Processes with Graph Transformer Networks", "authors": "Amanda A. Volk, Robert W. Epps, Jeffrey G. Ethier, Luke A. Baldwin", "abstract": "This work presents the use of graph learning for the prediction of multi-step\nexperimental outcomes for applications across experimental research, including\nmaterial science, chemistry, and biology. The viability of geometric learning\nfor regression tasks was benchmarked against a collection of linear models\nthrough a combination of simulated and real-world data training studies. First,\na selection of five arbitrarily designed multi-step surrogate functions were\ndeveloped to reflect various features commonly found within experimental\nprocesses. A graph transformer network outperformed all tested linear models in\nscenarios that featured hidden interactions between process steps and sequence\ndependent features, while retaining equivalent performance in sequence agnostic\nscenarios. Then, a similar comparison was applied to real-world literature data\non algorithm guided colloidal atomic layer deposition. Using the complete\nreaction sequence as training data, the graph neural network outperformed all\nlinear models in predicting the three spectral properties for most training set\nsizes. Further implementation of graph neural networks and geometric\nrepresentation of scientific processes for the prediction of experiment\noutcomes could lead to algorithm driven navigation of higher dimension\nparameter spaces and efficient exploration of more dynamic systems.", "arxiv_id": "2408.05425v1", "pdf_url": "http://arxiv.org/pdf/2408.05425v1", "abstract_url": "http://arxiv.org/abs/2408.05425v1", "primary_category": "cs.LG", "published_date": "2024-08-10", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Modeling Multi-Step Scientific Processes with Graph Transformer Networks", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:15.331645"}
{"title": "Interface Laplace Learning: Learnable Interface Term Helps Semi-Supervised Learning", "authors": "Tangjun Wang, Chenglong Bao, Zuoqiang Shi", "abstract": "We introduce a novel framework, called Interface Laplace learning, for\ngraph-based semi-supervised learning. Motivated by the observation that an\ninterface should exist between different classes where the function value is\nnon-smooth, we introduce a Laplace learning model that incorporates an\ninterface term. This model challenges the long-standing assumption that\nfunctions are smooth at all unlabeled points. In the proposed approach, we add\nan interface term to the Laplace learning model at the interface positions. We\nprovide a practical algorithm to approximate the interface positions using\nk-hop neighborhood indices, and to learn the interface term from labeled data\nwithout artificial design. Our method is efficient and effective, and we\npresent extensive experiments demonstrating that Interface Laplace learning\nachieves better performance than other recent semi-supervised learning\napproaches at extremely low label rates on the MNIST, FashionMNIST, and\nCIFAR-10 datasets.", "arxiv_id": "2408.05419v1", "pdf_url": "http://arxiv.org/pdf/2408.05419v1", "abstract_url": "http://arxiv.org/abs/2408.05419v1", "primary_category": "cs.LG", "published_date": "2024-08-10", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Interface Laplace Learning: Learnable Interface Term Helps Semi-Supervised Learning", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:16.173478"}
{"title": "Efficient Quantum Gradient and Higher-order Derivative Estimation via Generalized Hadamard Test", "authors": "Dantong Li, Dikshant Dulal, Mykhailo Ohorodnikov, Hanrui Wang, Yongshan Ding", "abstract": "In the context of Noisy Intermediate-Scale Quantum (NISQ) computing,\nparameterized quantum circuits (PQCs) represent a promising paradigm for\ntackling challenges in quantum sensing, optimal control, optimization, and\nmachine learning on near-term quantum hardware. Gradient-based methods are\ncrucial for understanding the behavior of PQCs and have demonstrated\nsubstantial advantages in the convergence rates of Variational Quantum\nAlgorithms (VQAs) compared to gradient-free methods. However, existing gradient\nestimation methods, such as Finite Difference, Parameter Shift Rule, Hadamard\nTest, and Direct Hadamard Test, often yield suboptimal gradient circuits for\ncertain PQCs. To address these limitations, we introduce the Flexible Hadamard\nTest, which, when applied to first-order gradient estimation methods, can\ninvert the roles of ansatz generators and observables. This inversion\nfacilitates the use of measurement optimization techniques to efficiently\ncompute PQC gradients. Additionally, to overcome the exponential cost of\nevaluating higher-order partial derivatives, we propose the $k$-fold Hadamard\nTest, which computes the $k^{th}$-order partial derivative using a single\ncircuit. Furthermore, we introduce Quantum Automatic Differentiation (QAD), a\nunified gradient method that adaptively selects the best gradient estimation\ntechnique for individual parameters within a PQC. This represents the first\nimplementation, to our knowledge, that departs from the conventional practice\nof uniformly applying a single method to all parameters. Through rigorous\nnumerical experiments, we demonstrate the effectiveness of our proposed\nfirst-order gradient methods, showing up to an $O(N)$ factor improvement in\ncircuit execution count for real PQC applications. Our research contributes to\nthe acceleration of VQA computations, offering practical utility in the NISQ\nera of quantum computing.", "arxiv_id": "2408.05406v1", "pdf_url": "http://arxiv.org/pdf/2408.05406v1", "abstract_url": "http://arxiv.org/abs/2408.05406v1", "primary_category": "quant-ph", "published_date": "2024-08-10", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Efficient Quantum Gradient and Higher-order Derivative Estimation via Generalized Hadamard Test", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:17.013733"}
{"title": "Pretrained-Guided Conditional Diffusion Models for Microbiome Data Analysis", "authors": "Xinyuan Shi, Fangfang Zhu, Wenwen Min", "abstract": "Emerging evidence indicates that human cancers are intricately linked to\nhuman microbiomes, forming an inseparable connection. However, due to limited\nsample sizes and significant data loss during collection for various reasons,\nsome machine learning methods have been proposed to address the issue of\nmissing data. These methods have not fully utilized the known clinical\ninformation of patients to enhance the accuracy of data imputation. Therefore,\nwe introduce mbVDiT, a novel pre-trained conditional diffusion model for\nmicrobiome data imputation and denoising, which uses the unmasked data and\npatient metadata as conditional guidance for imputating missing values. It is\nalso uses VAE to integrate the the other public microbiome datasets to enhance\nmodel performance. The results on the microbiome datasets from three different\ncancer types demonstrate the performance of our methods in comparison with\nexisting methods.", "arxiv_id": "2408.07709v1", "pdf_url": "http://arxiv.org/pdf/2408.07709v1", "abstract_url": "http://arxiv.org/abs/2408.07709v1", "primary_category": "q-bio.GN", "published_date": "2024-08-10", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Pretrained-Guided Conditional Diffusion Models for Microbiome Data Analysis", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:17.892089"}
{"title": "FedRobo: Federated Learning Driven Autonomous Inter Robots Communication For Optimal Chemical Sprays", "authors": "Jannatul Ferdaus, Sameera Pisupati, Mahedi Hasan, Sathwick Paladugu", "abstract": "Federated Learning enables robots to learn from each other's experiences\nwithout relying on centralized data collection. Each robot independently\nmaintains a model of crop conditions and chemical spray effectiveness, which is\nperiodically shared with other robots in the fleet. A communication protocol is\ndesigned to optimize chemical spray applications by facilitating the exchange\nof information about crop conditions, weather, and other critical factors. The\nfederated learning algorithm leverages this shared data to continuously refine\nthe chemical spray strategy, reducing waste and improving crop yields. This\napproach has the potential to revolutionize the agriculture industry by\noffering a scalable and efficient solution for crop protection. However,\nsignificant challenges remain, including the development of a secure and robust\ncommunication protocol, the design of a federated learning algorithm that\neffectively integrates data from multiple sources, and ensuring the safety and\nreliability of autonomous robots. The proposed cluster-based federated learning\napproach also effectively reduces the computational load on the global server\nand minimizes communication overhead among clients.", "arxiv_id": "2408.06382v2", "pdf_url": "http://arxiv.org/pdf/2408.06382v2", "abstract_url": "http://arxiv.org/abs/2408.06382v2", "primary_category": "cs.LG", "published_date": "2024-08-10", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "FedRobo: Federated Learning Driven Autonomous Inter Robots Communication For Optimal Chemical Sprays", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:18.708697"}
{"title": "fastkqr: A Fast Algorithm for Kernel Quantile Regression", "authors": "Qian Tang, Yuwen Gu, Boxiang Wang", "abstract": "Quantile regression is a powerful tool for robust and heterogeneous learning\nthat has seen applications in a diverse range of applied areas. However, its\nbroader application is often hindered by the substantial computational demands\narising from the non-smooth quantile loss function. In this paper, we introduce\na novel algorithm named fastkqr, which significantly advances the computation\nof quantile regression in reproducing kernel Hilbert spaces. The core of\nfastkqr is a finite smoothing algorithm that magically produces exact\nregression quantiles, rather than approximations. To further accelerate the\nalgorithm, we equip fastkqr with a novel spectral technique that carefully\nreutilizes matrix computations. In addition, we extend fastkqr to accommodate a\nflexible kernel quantile regression with a data-driven crossing penalty,\naddressing the interpretability challenges of crossing quantile curves at\nmultiple levels. We have implemented fastkqr in a publicly available R package.\nExtensive simulations and real applications show that fastkqr matches the\naccuracy of state-of-the-art algorithms but can operate up to an order of\nmagnitude faster.", "arxiv_id": "2408.05393v1", "pdf_url": "http://arxiv.org/pdf/2408.05393v1", "abstract_url": "http://arxiv.org/abs/2408.05393v1", "primary_category": "stat.ML", "published_date": "2024-08-10", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "fastkqr: A Fast Algorithm for Kernel Quantile Regression", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:19.795372"}
{"title": "SAMSA: Efficient Transformer for Many Data Modalities", "authors": "Minh Lenhat, Viet Anh Nguyen, Khoa Nguyen, Duong Duc Hieu, Dao Huu Hung, Truong Son Hy", "abstract": "The versatility of self-attention mechanism earned transformers great success\nin almost all data modalities, with limitations on the quadratic complexity and\ndifficulty of training. Efficient transformers, on the other hand, often rely\non clever data-modality-dependent construction to get over the quadratic\ncomplexity of transformers. This greatly hinders their applications on\ndifferent data modalities, which is one of the pillars of contemporary\nfoundational modeling. In this paper, we lay the groundwork for efficient\nfoundational modeling by proposing SAMSA - SAMpling-Self-Attention, a\ncontext-aware linear complexity self-attention mechanism that works well on\nmultiple data modalities. Our mechanism is based on a differentiable sampling\nwithout replacement method we discovered. This enables the self-attention\nmodule to attend to the most important token set, where the importance is\ndefined by data. Moreover, as differentiability is not needed in inference, the\nsparse formulation of our method costs little time overhead, further lowering\ncomputational costs. In short, SAMSA achieved competitive or even SOTA results\non many benchmarks, while being faster in inference, compared to other very\nspecialized models. Against full self-attention, real inference time\nsignificantly decreases while performance ranges from negligible degradation to\noutperformance. We release our source code in the repository:\nhttps://github.com/HySonLab/SAMSA", "arxiv_id": "2408.05391v1", "pdf_url": "http://arxiv.org/pdf/2408.05391v1", "abstract_url": "http://arxiv.org/abs/2408.05391v1", "primary_category": "cs.LG", "published_date": "2024-08-10", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "SAMSA: Efficient Transformer for Many Data Modalities", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:20.547938"}
{"title": "EclipseNETs: a differentiable description of irregular eclipse conditions", "authors": "Giacomo Acciarini, Francesco Biscani, Dario Izzo", "abstract": "In the field of spaceflight mechanics and astrodynamics, determining eclipse\nregions is a frequent and critical challenge. This determination impacts\nvarious factors, including the acceleration induced by solar radiation\npressure, the spacecraft power input, and its thermal state all of which must\nbe accounted for in various phases of the mission design. This study leverages\nrecent advances in neural image processing to develop fully differentiable\nmodels of eclipse regions for highly irregular celestial bodies. By utilizing\ntest cases involving Solar System bodies previously visited by spacecraft, such\nas 433 Eros, 25143 Itokawa, 67P/Churyumov--Gerasimenko, and 101955 Bennu, we\npropose and study an implicit neural architecture defining the shape of the\neclipse cone based on the Sun's direction. Employing periodic activation\nfunctions, we achieve high precision in modeling eclipse conditions.\nFurthermore, we discuss the potential applications of these differentiable\nmodels in spaceflight mechanics computations.", "arxiv_id": "2408.05387v1", "pdf_url": "http://arxiv.org/pdf/2408.05387v1", "abstract_url": "http://arxiv.org/abs/2408.05387v1", "primary_category": "cs.LG", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "EclipseNETs: a differentiable description of irregular eclipse conditions", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:21.579474"}
{"title": "Optimizing Portfolio with Two-Sided Transactions and Lending: A Reinforcement Learning Framework", "authors": "Ali Habibnia, Mahdi Soltanzadeh", "abstract": "This study presents a Reinforcement Learning (RL)-based portfolio management\nmodel tailored for high-risk environments, addressing the limitations of\ntraditional RL models and exploiting market opportunities through two-sided\ntransactions and lending. Our approach integrates a new environmental\nformulation with a Profit and Loss (PnL)-based reward function, enhancing the\nRL agent's ability in downside risk management and capital optimization. We\nimplemented the model using the Soft Actor-Critic (SAC) agent with a\nConvolutional Neural Network with Multi-Head Attention (CNN-MHA). This setup\neffectively manages a diversified 12-crypto asset portfolio in the Binance\nperpetual futures market, leveraging USDT for both granting and receiving loans\nand rebalancing every 4 hours, utilizing market data from the preceding 48\nhours. Tested over two 16-month periods of varying market volatility, the model\nsignificantly outperformed benchmarks, particularly in high-volatility\nscenarios, achieving higher return-to-risk ratios and demonstrating robust\nprofitability. These results confirm the model's effectiveness in leveraging\nmarket dynamics and managing risks in volatile environments like the\ncryptocurrency market.", "arxiv_id": "2408.05382v1", "pdf_url": "http://arxiv.org/pdf/2408.05382v1", "abstract_url": "http://arxiv.org/abs/2408.05382v1", "primary_category": "q-fin.PM", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Optimizing Portfolio with Two-Sided Transactions and Lending: A Reinforcement Learning Framework", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:22.377496"}
{"title": "Hybrid Efficient Unsupervised Anomaly Detection for Early Pandemic Case Identification", "authors": "Ghazal Ghajari, Mithun Kumar PK, Fathi Amsaad", "abstract": "Unsupervised anomaly detection is a promising technique for identifying\nunusual patterns in data without the need for labeled training examples. This\napproach is particularly valuable for early case detection in epidemic\nmanagement, especially when early-stage data are scarce. This research\nintroduces a novel hybrid method for anomaly detection that combines distance\nand density measures, enhancing its applicability across various infectious\ndiseases. Our method is especially relevant in pandemic situations, as\ndemonstrated during the COVID-19 crisis, where traditional supervised\nclassification methods fall short due to limited data. The efficacy of our\nmethod is evaluated using COVID-19 chest X-ray data, where it significantly\noutperforms established unsupervised techniques. It achieves an average AUC of\n77.43%, surpassing the AUC of Isolation Forest at 73.66% and KNN at 52.93%.\nThese results highlight the potential of our hybrid anomaly detection method to\nimprove early detection capabilities in diverse epidemic scenarios, thereby\nfacilitating more effective and timely responses.", "arxiv_id": "2408.05347v1", "pdf_url": "http://arxiv.org/pdf/2408.05347v1", "abstract_url": "http://arxiv.org/abs/2408.05347v1", "primary_category": "cs.LG", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Hybrid Efficient Unsupervised Anomaly Detection for Early Pandemic Case Identification", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:23.319511"}
{"title": "AI-assisted Coding with Cody: Lessons from Context Retrieval and Evaluation for Code Recommendations", "authors": "Jan Hartman, Rishabh Mehrotra, Hitesh Sagtani, Dominic Cooney, Rafal Gajdulewicz, Beyang Liu, Julie Tibshirani, Quinn Slack", "abstract": "In this work, we discuss a recently popular type of recommender system: an\nLLM-based coding assistant. Connecting the task of providing code\nrecommendations in multiple formats to traditional RecSys challenges, we\noutline several similarities and differences due to domain specifics. We\nemphasize the importance of providing relevant context to an LLM for this use\ncase and discuss lessons learned from context enhancements & offline and online\nevaluation of such AI-assisted coding systems.", "arxiv_id": "2408.05344v1", "pdf_url": "http://arxiv.org/pdf/2408.05344v1", "abstract_url": "http://arxiv.org/abs/2408.05344v1", "primary_category": "cs.IR", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "AI-assisted Coding with Cody: Lessons from Context Retrieval and Evaluation for Code Recommendations", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:24.385337"}
{"title": "rule4ml: An Open-Source Tool for Resource Utilization and Latency Estimation for ML Models on FPGA", "authors": "Mohammad Mehdi Rahimifar, Hamza Ezzaoui Rahali, Audrey C. Therrien", "abstract": "Implementing Machine Learning (ML) models on Field-Programmable Gate Arrays\n(FPGAs) is becoming increasingly popular across various domains as a\nlow-latency and low-power solution that helps manage large data rates generated\nby continuously improving detectors. However, developing ML models for FPGAs is\ntime-consuming, as optimization requires synthesis to evaluate FPGA area and\nlatency, making the process slow and repetitive. This paper introduces a novel\nmethod to predict the resource utilization and inference latency of Neural\nNetworks (NNs) before their synthesis and implementation on FPGA. We leverage\nHLS4ML, a tool-flow that helps translate NNs into high-level synthesis (HLS)\ncode, to synthesize a diverse dataset of NN architectures and train resource\nutilization and inference latency predictors. While HLS4ML requires full\nsynthesis to obtain resource and latency insights, our method uses trained\nregression models for immediate pre-synthesis predictions. The prediction\nmodels estimate the usage of Block RAM (BRAM), Digital Signal Processors (DSP),\nFlip-Flops (FF), and Look-Up Tables (LUT), as well as the inference clock\ncycles. The predictors were evaluated on both synthetic and existing benchmark\narchitectures and demonstrated high accuracy with R2 scores ranging between 0.8\nand 0.98 on the validation set and sMAPE values between 10% and 30%. Overall,\nour approach provides valuable preliminary insights, enabling users to quickly\nassess the feasibility and efficiency of NNs on FPGAs, accelerating the\ndevelopment and deployment processes. The open-source repository can be found\nat https://github.com/IMPETUS-UdeS/rule4ml, while the datasets are publicly\navailable at https://borealisdata.ca/dataverse/rule4ml.", "arxiv_id": "2408.05314v1", "pdf_url": "http://arxiv.org/pdf/2408.05314v1", "abstract_url": "http://arxiv.org/abs/2408.05314v1", "primary_category": "cs.LG", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "rule4ml: An Open-Source Tool for Resource Utilization and Latency Estimation for ML Models on FPGA", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:25.215844"}
{"title": "Audio-visual cross-modality knowledge transfer for machine learning-based in-situ monitoring in laser additive manufacturing", "authors": "Jiarui Xie, Mutahar Safdar, Lequn Chen, Seung Ki Moon, Yaoyao Fiona Zhao", "abstract": "Various machine learning (ML)-based in-situ monitoring systems have been\ndeveloped to detect laser additive manufacturing (LAM) process anomalies and\ndefects. Multimodal fusion can improve in-situ monitoring performance by\nacquiring and integrating data from multiple modalities, including visual and\naudio data. However, multimodal fusion employs multiple sensors of different\ntypes, which leads to higher hardware, computational, and operational costs.\nThis paper proposes a cross-modality knowledge transfer (CMKT) methodology that\ntransfers knowledge from a source to a target modality for LAM in-situ\nmonitoring. CMKT enhances the usefulness of the features extracted from the\ntarget modality during the training phase and removes the sensors of the source\nmodality during the prediction phase. This paper proposes three CMKT methods:\nsemantic alignment, fully supervised mapping, and semi-supervised mapping.\nSemantic alignment establishes a shared encoded space between modalities to\nfacilitate knowledge transfer. It utilizes a semantic alignment loss to align\nthe distributions of the same classes (e.g., visual defective and audio\ndefective classes) and a separation loss to separate the distributions of\ndifferent classes (e.g., visual defective and audio defect-free classes). The\ntwo mapping methods transfer knowledge by deriving the features of one modality\nfrom the other modality using fully supervised and semi-supervised learning.\nThe proposed CMKT methods were implemented and compared with multimodal\naudio-visual fusion in an LAM in-situ anomaly detection case study. The\nsemantic alignment method achieves a 98.4% accuracy while removing the audio\nmodality during the prediction phase, which is comparable to the accuracy of\nmultimodal fusion (98.2%).", "arxiv_id": "2408.05307v1", "pdf_url": "http://arxiv.org/pdf/2408.05307v1", "abstract_url": "http://arxiv.org/abs/2408.05307v1", "primary_category": "cs.CE", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Audio-visual cross-modality knowledge transfer for machine learning-based in-situ monitoring in laser additive manufacturing", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:26.183215"}
{"title": "The impact of internal variability on benchmarking deep learning climate emulators", "authors": "Bj\u00f6rn L\u00fctjens, Raffaele Ferrari, Duncan Watson-Parris, Noelle Selin", "abstract": "Full-complexity Earth system models (ESMs) are computationally very\nexpensive, limiting their use in exploring the climate outcomes of multiple\nemission pathways. More efficient emulators that approximate ESMs can directly\nmap emissions onto climate outcomes, and benchmarks are being used to evaluate\ntheir accuracy on standardized tasks and datasets. We investigate a popular\nbenchmark in data-driven climate emulation, ClimateBench, on which deep\nlearning-based emulators are currently achieving the best performance. We\nimplement a linear regression-based emulator, akin to pattern scaling, and find\nthat it outperforms the incumbent 100M-parameter deep learning foundation\nmodel, ClimaX, on 3 out of 4 regionally-resolved surface-level climate\nvariables. While emulating surface temperature is expected to be predominantly\nlinear, this result is surprising for emulating precipitation. We identify that\nthis outcome is a result of high levels of internal variability in the\nbenchmark targets. To address internal variability, we update the benchmark\ntargets with ensemble averages from the MPI-ESM1.2-LR model that contain 50\ninstead of 3 climate simulations per emission pathway. Using the new targets,\nwe show that linear pattern scaling continues to be more accurate on\ntemperature, but can be outperformed by a deep learning-based model for\nemulating precipitation. We publish our code, data, and an interactive tutorial\nat github.com/blutjens/climate-emulator.", "arxiv_id": "2408.05288v1", "pdf_url": "http://arxiv.org/pdf/2408.05288v1", "abstract_url": "http://arxiv.org/abs/2408.05288v1", "primary_category": "cs.LG", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "The impact of internal variability on benchmarking deep learning climate emulators", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:27.384791"}
{"title": "Semi-Supervised One-Shot Imitation Learning", "authors": "Philipp Wu, Kourosh Hakhamaneshi, Yuqing Du, Igor Mordatch, Aravind Rajeswaran, Pieter Abbeel", "abstract": "One-shot Imitation Learning~(OSIL) aims to imbue AI agents with the ability\nto learn a new task from a single demonstration. To supervise the learning,\nOSIL typically requires a prohibitively large number of paired expert\ndemonstrations -- i.e. trajectories corresponding to different variations of\nthe same semantic task. To overcome this limitation, we introduce the\nsemi-supervised OSIL problem setting, where the learning agent is presented\nwith a large dataset of trajectories with no task labels (i.e. an unpaired\ndataset), along with a small dataset of multiple demonstrations per semantic\ntask (i.e. a paired dataset). This presents a more realistic and practical\nembodiment of few-shot learning and requires the agent to effectively leverage\nweak supervision from a large dataset of trajectories. Subsequently, we develop\nan algorithm specifically applicable to this semi-supervised OSIL setting. Our\napproach first learns an embedding space where different tasks cluster\nuniquely. We utilize this embedding space and the clustering it supports to\nself-generate pairings between trajectories in the large unpaired dataset.\nThrough empirical results on simulated control tasks, we demonstrate that OSIL\nmodels trained on such self-generated pairings are competitive with OSIL models\ntrained with ground-truth labels, presenting a major advancement in the\nlabel-efficiency of OSIL.", "arxiv_id": "2408.05285v1", "pdf_url": "http://arxiv.org/pdf/2408.05285v1", "abstract_url": "http://arxiv.org/abs/2408.05285v1", "primary_category": "cs.LG", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Semi-Supervised One-Shot Imitation Learning", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:29.254980"}
{"title": "Can a Bayesian Oracle Prevent Harm from an Agent?", "authors": "Yoshua Bengio, Michael K. Cohen, Nikolay Malkin, Matt MacDermott, Damiano Fornasiere, Pietro Greiner, Younesse Kaddar", "abstract": "Is there a way to design powerful AI systems based on machine learning\nmethods that would satisfy probabilistic safety guarantees? With the long-term\ngoal of obtaining a probabilistic guarantee that would apply in every context,\nwe consider estimating a context-dependent bound on the probability of\nviolating a given safety specification. Such a risk evaluation would need to be\nperformed at run-time to provide a guardrail against dangerous actions of an\nAI. Noting that different plausible hypotheses about the world could produce\nvery different outcomes, and because we do not know which one is right, we\nderive bounds on the safety violation probability predicted under the true but\nunknown hypothesis. Such bounds could be used to reject potentially dangerous\nactions. Our main results involve searching for cautious but plausible\nhypotheses, obtained by a maximization that involves Bayesian posteriors over\nhypotheses. We consider two forms of this result, in the iid case and in the\nnon-iid case, and conclude with open problems towards turning such theoretical\nresults into practical AI guardrails.", "arxiv_id": "2408.05284v1", "pdf_url": "http://arxiv.org/pdf/2408.05284v1", "abstract_url": "http://arxiv.org/abs/2408.05284v1", "primary_category": "cs.AI", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Can a Bayesian Oracle Prevent Harm from an Agent?", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:30.173020"}
{"title": "Cell Morphology-Guided Small Molecule Generation with GFlowNets", "authors": "Stephen Zhewen Lu, Ziqing Lu, Ehsan Hajiramezanali, Tommaso Biancalani, Yoshua Bengio, Gabriele Scalia, Micha\u0142 Koziarski", "abstract": "High-content phenotypic screening, including high-content imaging (HCI), has\ngained popularity in the last few years for its ability to characterize novel\ntherapeutics without prior knowledge of the protein target. When combined with\ndeep learning techniques to predict and represent molecular-phenotype\ninteractions, these advancements hold the potential to significantly accelerate\nand enhance drug discovery applications. This work focuses on the novel task of\nHCI-guided molecular design. Generative models for molecule design could be\nguided by HCI data, for example with a supervised model that links molecules to\nphenotypes of interest as a reward function. However, limited labeled data,\ncombined with the high-dimensional readouts, can make training these methods\nchallenging and impractical. We consider an alternative approach in which we\nleverage an unsupervised multimodal joint embedding to define a latent\nsimilarity as a reward for GFlowNets. The proposed model learns to generate new\nmolecules that could produce phenotypic effects similar to those of the given\nimage target, without relying on pre-annotated phenotypic labels. We\ndemonstrate that the proposed method generates molecules with high\nmorphological and structural similarity to the target, increasing the\nlikelihood of similar biological activity, as confirmed by an independent\noracle model.", "arxiv_id": "2408.05196v1", "pdf_url": "http://arxiv.org/pdf/2408.05196v1", "abstract_url": "http://arxiv.org/abs/2408.05196v1", "primary_category": "cs.LG", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Cell Morphology-Guided Small Molecule Generation with GFlowNets", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:32.107034"}
{"title": "HistoKernel: Whole Slide Image Level Maximum Mean Discrepancy Kernels for Pan-Cancer Predictive Modelling", "authors": "Piotr Keller, Muhammad Dawood, Brinder Singh Chohan, Fayyaz ul Amir Afsar Minhas", "abstract": "Machine learning in computational pathology (CPath) often aggregates\npatch-level predictions from multi-gigapixel Whole Slide Images (WSIs) to\ngenerate WSI-level prediction scores for crucial tasks such as survival\nprediction and drug effect prediction. However, current methods do not\nexplicitly characterize distributional differences between patch sets within\nWSIs. We introduce HistoKernel, a novel Maximum Mean Discrepancy (MMD) kernel\nthat measures distributional similarity between WSIs for enhanced prediction\nperformance on downstream prediction tasks.\n  Our comprehensive analysis demonstrates HistoKernel's effectiveness across\nvarious machine learning tasks, including retrieval (n = 9,362), drug\nsensitivity regression (n = 551), point mutation classification (n = 3,419),\nand survival analysis (n = 2,291), outperforming existing deep learning\nmethods. Additionally, HistoKernel seamlessly integrates multi-modal data and\noffers a novel perturbation-based method for patch-level explainability. This\nwork pioneers the use of kernel-based methods for WSI-level predictive\nmodeling, opening new avenues for research. Code is available at\nhttps://github.com/pkeller00/HistoKernel.", "arxiv_id": "2408.05195v1", "pdf_url": "http://arxiv.org/pdf/2408.05195v1", "abstract_url": "http://arxiv.org/abs/2408.05195v1", "primary_category": "cs.LG", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "HistoKernel: Whole Slide Image Level Maximum Mean Discrepancy Kernels for Pan-Cancer Predictive Modelling", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:32.838531"}
{"title": "ECG-FM: An Open Electrocardiogram Foundation Model", "authors": "Kaden McKeen, Laura Oliva, Sameer Masood, Augustin Toma, Barry Rubin, Bo Wang", "abstract": "The electrocardiogram (ECG) is a ubiquitous diagnostic test. Conventional\ntask-specific ECG analysis models require large numbers of expensive ECG\nannotations or associated labels to train. Transfer learning techniques have\nbeen shown to improve generalization and reduce reliance on labeled data. We\npresent ECG-FM, an open foundation model for ECG analysis, and conduct a\ncomprehensive study performed on a dataset of 1.66 million ECGs sourced from\nboth publicly available and private institutional sources. ECG-FM adopts a\ntransformer-based architecture and is pretrained on 2.5 million samples using\nECG-specific augmentations and contrastive learning, as well as a continuous\nsignal masking objective. Our transparent evaluation includes a diverse range\nof downstream tasks, where we predict ECG interpretation labels, reduced left\nventricular ejection fraction, and abnormal cardiac troponin. Affirming\nECG-FM's effectiveness as a foundation model, we demonstrate how its command of\ncontextual information results in strong performance, rich pretrained\nembeddings, and reliable interpretability. Due to a lack of open-weight\npractices, we highlight how ECG analysis is lagging behind other medical\nmachine learning subfields in terms of foundation model adoption. Our code is\navailable at https://github.com/bowang-lab/ECG-FM/.", "arxiv_id": "2408.05178v1", "pdf_url": "http://arxiv.org/pdf/2408.05178v1", "abstract_url": "http://arxiv.org/abs/2408.05178v1", "primary_category": "cs.LG", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "ECG-FM: An Open Electrocardiogram Foundation Model", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:33.861840"}
{"title": "Beyond Closure Models: Learning Chaotic-Systems via Physics-Informed Neural Operators", "authors": "Chuwei Wang, Julius Berner, Zongyi Li, Di Zhou, Jiayun Wang, Jane Bae, Anima Anandkumar", "abstract": "Accurately predicting the long-term behavior of chaotic systems is crucial\nfor various applications such as climate modeling. However, achieving such\npredictions typically requires iterative computations over a dense\nspatiotemporal grid to account for the unstable nature of chaotic systems,\nwhich is expensive and impractical in many real-world situations. An\nalternative approach to such a full-resolved simulation is using a coarse grid\nand then correcting its errors through a \\textit{closure model}, which\napproximates the overall information from fine scales not captured in the\ncoarse-grid simulation. Recently, ML approaches have been used for closure\nmodeling, but they typically require a large number of training samples from\nexpensive fully-resolved simulations (FRS). In this work, we prove an even more\nfundamental limitation, i.e., the standard approach to learning closure models\nsuffers from a large approximation error for generic problems, no matter how\nlarge the model is, and it stems from the non-uniqueness of the mapping. We\npropose an alternative end-to-end learning approach using a physics-informed\nneural operator (PINO) that overcomes this limitation by not using a closure\nmodel or a coarse-grid solver. We first train the PINO model on data from a\ncoarse-grid solver and then fine-tune it with (a small amount of) FRS and\nphysics-based losses on a fine grid. The discretization-free nature of neural\noperators means that they do not suffer from the restriction of a coarse grid\nthat closure models face, and they can provably approximate the long-term\nstatistics of chaotic systems. In our experiments, our PINO model achieves a\n120x speedup compared to FRS with a relative error $\\sim 5\\%$. In contrast, the\nclosure model coupled with a coarse-grid solver is $58$x slower than PINO while\nhaving a much higher error $\\sim205\\%$ when the closure model is trained on the\nsame FRS dataset.", "arxiv_id": "2408.05177v1", "pdf_url": "http://arxiv.org/pdf/2408.05177v1", "abstract_url": "http://arxiv.org/abs/2408.05177v1", "primary_category": "cs.LG", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Beyond Closure Models: Learning Chaotic-Systems via Physics-Informed Neural Operators", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:34.681686"}
{"title": "Decoding Quantum LDPC Codes Using Graph Neural Networks", "authors": "Vukan Ninkovic, Ognjen Kundacina, Dejan Vukobratovic, Christian H\u00e4ger, Alexandre Graell i Amat", "abstract": "In this paper, we propose a novel decoding method for Quantum Low-Density\nParity-Check (QLDPC) codes based on Graph Neural Networks (GNNs). Similar to\nthe Belief Propagation (BP)-based QLDPC decoders, the proposed GNN-based QLDPC\ndecoder exploits the sparse graph structure of QLDPC codes and can be\nimplemented as a message-passing decoding algorithm. We compare the proposed\nGNN-based decoding algorithm against selected classes of both conventional and\nneural-enhanced QLDPC decoding algorithms across several QLDPC code designs.\nThe simulation results demonstrate excellent performance of GNN-based decoders\nalong with their low complexity compared to competing methods.", "arxiv_id": "2408.05170v1", "pdf_url": "http://arxiv.org/pdf/2408.05170v1", "abstract_url": "http://arxiv.org/abs/2408.05170v1", "primary_category": "quant-ph", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Decoding Quantum LDPC Codes Using Graph Neural Networks", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:35.641731"}
{"title": "Federated Hypergraph Learning with Hyperedge Completion", "authors": "Linfeng Luo, Fengxiao Tang, Xiyu Liu, Zhiqi Guo, Zihao Qiu, Ming Zhao", "abstract": "Hypergraph neural networks enhance conventional graph neural networks by\ncapturing high-order relationships among nodes, which proves vital in data-rich\nenvironments where interactions are not merely pairwise. As data complexity and\ninterconnectivity grow, it is common for graph-structured data to be split and\nstored in a distributed manner, underscoring the necessity of federated\nlearning on subgraphs. In this work, we propose FedHGN, a novel algorithm for\nfederated hypergraph learning. Our algorithm utilizes subgraphs of a hypergraph\nstored on distributed devices to train local HGNN models in a federated\nmanner:by collaboratively developing an effective global HGNN model through\nsharing model parameters while preserving client privacy. Additionally,\nconsidering that hyperedges may span multiple clients, a pre-training step is\nemployed before the training process in which cross-client hyperedge feature\ngathering is performed at the central server. In this way, the missing\ncross-client information can be supplemented from the central server during the\nnode feature aggregation phase. Experimental results on seven real-world\ndatasets confirm the effectiveness of our approach and demonstrate its\nperformance advantages over traditional federated graph learning methods.", "arxiv_id": "2408.05160v1", "pdf_url": "http://arxiv.org/pdf/2408.05160v1", "abstract_url": "http://arxiv.org/abs/2408.05160v1", "primary_category": "cs.LG", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Federated Hypergraph Learning with Hyperedge Completion", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:36.478865"}
{"title": "Meta-Learning Guided Label Noise Distillation for Robust Signal Modulation Classification", "authors": "Xiaoyang Hao, Zhixi Feng, Tongqing Peng, Shuyuan Yang", "abstract": "Automatic modulation classification (AMC) is an effective way to deal with\nphysical layer threats of the internet of things (IoT). However, there is often\nlabel mislabeling in practice, which significantly impacts the performance and\nrobustness of deep neural networks (DNNs). In this paper, we propose a\nmeta-learning guided label noise distillation method for robust AMC.\nSpecifically, a teacher-student heterogeneous network (TSHN) framework is\nproposed to distill and reuse label noise. Based on the idea that labels are\nrepresentations, the teacher network with trusted meta-learning divides and\nconquers untrusted label samples and then guides the student network to learn\nbetter by reassessing and correcting labels. Furthermore, we propose a\nmulti-view signal (MVS) method to further improve the performance of\nhard-to-classify categories with few-shot trusted label samples. Extensive\nexperimental results show that our methods can significantly improve the\nperformance and robustness of signal AMC in various and complex label noise\nscenarios, which is crucial for securing IoT applications.", "arxiv_id": "2408.05151v1", "pdf_url": "http://arxiv.org/pdf/2408.05151v1", "abstract_url": "http://arxiv.org/abs/2408.05151v1", "primary_category": "cs.LG", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Meta-Learning Guided Label Noise Distillation for Robust Signal Modulation Classification", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:37.153070"}
{"title": "Impacts of floating-point non-associativity on reproducibility for HPC and deep learning applications", "authors": "Sanjif Shanmugavelu, Mathieu Taillefumier, Christopher Culver, Oscar Hernandez, Mark Coletti, Ada Sedova", "abstract": "Run-by-run variability in parallel programs caused by floating-point\nnon-associativity (FPNA) has been known to significantly affect reproducibility\nin iterative algorithms, due to accumulating errors. Non-reproducibility\nnegatively affects efficiency and effectiveness of correctness testing for\nstochastic programs. Recently, the sensitivity of deep learning (DL) training\nand inference pipelines to FPNA have been found to be extreme, and can prevent\ncertification for commercial applications, accurate assessment of robustness\nand sensitivity, and bug detection. New approaches in scientific computing\napplications have coupled DL models with high-performance computing (HPC)\nsimulations, leading to an aggravation of debugging and testing challenges.\nHere we perform an investigation of the statistical properties of FPNA within\nmodern parallel programming models, analyze performance and productivity\nimpacts of replacing atomic operations with deterministic alternatives on GPUs,\nand examine the recently-added deterministic options within the PyTorch\nframework within the context of GPU deployment, uncovering and quantifying the\nimpacts of input parameters triggering run-by-run variability and reporting on\nthe reliability and completeness of the documentation. Finally, we evaluate the\nstrategy of exploiting automatic determinism provided by deterministic\nhardware, using the Groq LPU$^{TM}$ accelerator for inference portions of the\nDL pipeline. We demonstrate the benefits that this strategy can provide within\nreproducibility and correctness efforts.", "arxiv_id": "2408.05148v1", "pdf_url": "http://arxiv.org/pdf/2408.05148v1", "abstract_url": "http://arxiv.org/abs/2408.05148v1", "primary_category": "cs.DC", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Impacts of floating-point non-associativity on reproducibility for HPC and deep learning applications", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:38.246554"}
{"title": "Gemma Scope: Open Sparse Autoencoders Everywhere All At Once on Gemma 2", "authors": "Tom Lieberum, Senthooran Rajamanoharan, Arthur Conmy, Lewis Smith, Nicolas Sonnerat, Vikrant Varma, J\u00e1nos Kram\u00e1r, Anca Dragan, Rohin Shah, Neel Nanda", "abstract": "Sparse autoencoders (SAEs) are an unsupervised method for learning a sparse\ndecomposition of a neural network's latent representations into seemingly\ninterpretable features. Despite recent excitement about their potential,\nresearch applications outside of industry are limited by the high cost of\ntraining a comprehensive suite of SAEs. In this work, we introduce Gemma Scope,\nan open suite of JumpReLU SAEs trained on all layers and sub-layers of Gemma 2\n2B and 9B and select layers of Gemma 2 27B base models. We primarily train SAEs\non the Gemma 2 pre-trained models, but additionally release SAEs trained on\ninstruction-tuned Gemma 2 9B for comparison. We evaluate the quality of each\nSAE on standard metrics and release these results. We hope that by releasing\nthese SAE weights, we can help make more ambitious safety and interpretability\nresearch easier for the community. Weights and a tutorial can be found at\nhttps://huggingface.co/google/gemma-scope and an interactive demo can be found\nat https://www.neuronpedia.org/gemma-scope", "arxiv_id": "2408.05147v1", "pdf_url": "http://arxiv.org/pdf/2408.05147v1", "abstract_url": "http://arxiv.org/abs/2408.05147v1", "primary_category": "cs.LG", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Gemma Scope: Open Sparse Autoencoders Everywhere All At Once on Gemma 2", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:39.089837"}
{"title": "Performative Prediction on Games and Mechanism Design", "authors": "Ant\u00f3nio G\u00f3is, Mehrnaz Mofakhami, Fernando P. Santos, Simon Lacoste-Julien, Gauthier Gidel", "abstract": "Predictions often influence the reality which they aim to predict, an effect\nknown as performativity. Existing work focuses on accuracy maximization under\nthis effect, but model deployment may have important unintended impacts,\nespecially in multiagent scenarios. In this work, we investigate performative\nprediction in a concrete game-theoretic setting where social welfare is an\nalternative objective to accuracy maximization. We explore a collective risk\ndilemma scenario where maximising accuracy can negatively impact social\nwelfare, when predicting collective behaviours. By assuming knowledge of a\nBayesian agent behavior model, we then show how to achieve better trade-offs\nand use them for mechanism design.", "arxiv_id": "2408.05146v1", "pdf_url": "http://arxiv.org/pdf/2408.05146v1", "abstract_url": "http://arxiv.org/abs/2408.05146v1", "primary_category": "cs.LG", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Performative Prediction on Games and Mechanism Design", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:39.887997"}
{"title": "Cycle-Configuration: A Novel Graph-theoretic Descriptor Set for Molecular Inference", "authors": "Bowen Song, Jianshen Zhu, Naveed Ahmed Azam, Kazuya Haraguchi, Liang Zhao, Tatsuya Akutsu", "abstract": "In this paper, we propose a novel family of descriptors of chemical graphs,\nnamed cycle-configuration (CC), that can be used in the standard \"two-layered\n(2L) model\" of mol-infer, a molecular inference framework based on mixed\ninteger linear programming (MILP) and machine learning (ML). Proposed\ndescriptors capture the notion of ortho/meta/para patterns that appear in\naromatic rings, which has been impossible in the framework so far.\nComputational experiments show that, when the new descriptors are supplied, we\ncan construct prediction functions of similar or better performance for all of\nthe 27 tested chemical properties. We also provide an MILP formulation that\nasks for a chemical graph with desired properties under the 2L model with CC\ndescriptors (2L+CC model). We show that a chemical graph with up to 50\nnon-hydrogen vertices can be inferred in a practical time.", "arxiv_id": "2408.05136v1", "pdf_url": "http://arxiv.org/pdf/2408.05136v1", "abstract_url": "http://arxiv.org/abs/2408.05136v1", "primary_category": "cs.LG", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Cycle-Configuration: A Novel Graph-theoretic Descriptor Set for Molecular Inference", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:41.238836"}
{"title": "Range Membership Inference Attacks", "authors": "Jiashu Tao, Reza Shokri", "abstract": "Machine learning models can leak private information about their training\ndata, but the standard methods to measure this risk, based on membership\ninference attacks (MIAs), have a major limitation. They only check if a given\ndata point \\textit{exactly} matches a training point, neglecting the potential\nof similar or partially overlapping data revealing the same private\ninformation. To address this issue, we introduce the class of range membership\ninference attacks (RaMIAs), testing if the model was trained on any data in a\nspecified range (defined based on the semantics of privacy). We formulate the\nRaMIAs game and design a principled statistical test for its complex\nhypotheses. We show that RaMIAs can capture privacy loss more accurately and\ncomprehensively than MIAs on various types of data, such as tabular, image, and\nlanguage. RaMIA paves the way for a more comprehensive and meaningful privacy\nauditing of machine learning algorithms.", "arxiv_id": "2408.05131v1", "pdf_url": "http://arxiv.org/pdf/2408.05131v1", "abstract_url": "http://arxiv.org/abs/2408.05131v1", "primary_category": "cs.LG", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Range Membership Inference Attacks", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:42.059167"}
{"title": "Cautious Calibration in Binary Classification", "authors": "Mari-Liis Allikivi, Joonas J\u00e4rve, Meelis Kull", "abstract": "Being cautious is crucial for enhancing the trustworthiness of machine\nlearning systems integrated into decision-making pipelines. Although calibrated\nprobabilities help in optimal decision-making, perfect calibration remains\nunattainable, leading to estimates that fluctuate between under- and\noverconfidence. This becomes a critical issue in high-risk scenarios, where\neven occasional overestimation can lead to extreme expected costs. In these\nscenarios, it is important for each predicted probability to lean towards\nunderconfidence, rather than just achieving an average balance. In this study,\nwe introduce the novel concept of cautious calibration in binary\nclassification. This approach aims to produce probability estimates that are\nintentionally underconfident for each predicted probability. We highlight the\nimportance of this approach in a high-risk scenario and propose a theoretically\ngrounded method for learning cautious calibration maps. Through experiments, we\nexplore and compare our method to various approaches, including methods\noriginally not devised for cautious calibration but applicable in this context.\nWe show that our approach is the most consistent in providing cautious\nestimates. Our work establishes a strong baseline for further developments in\nthis novel framework.", "arxiv_id": "2408.05120v1", "pdf_url": "http://arxiv.org/pdf/2408.05120v1", "abstract_url": "http://arxiv.org/abs/2408.05120v1", "primary_category": "cs.LG", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Cautious Calibration in Binary Classification", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:43.081496"}
{"title": "Concept learning of parameterized quantum models from limited measurements", "authors": "Beng Yee Gan, Po-Wei Huang, Elies Gil-Fuster, Patrick Rebentrost", "abstract": "Classical learning of the expectation values of observables for quantum\nstates is a natural variant of learning quantum states or channels. While\nlearning-theoretic frameworks establish the sample complexity and the number of\nmeasurement shots per sample required for learning such statistical quantities,\nthe interplay between these two variables has not been adequately quantified\nbefore. In this work, we take the probabilistic nature of quantum measurements\ninto account in classical modelling and discuss these quantities under a single\nunified learning framework. We provide provable guarantees for learning\nparameterized quantum models that also quantify the asymmetrical effects and\ninterplay of the two variables on the performance of learning algorithms. These\nresults show that while increasing the sample size enhances the learning\nperformance of classical machines, even with single-shot estimates, the\nimprovements from increasing measurements become asymptotically trivial beyond\na constant factor. We further apply our framework and theoretical guarantees to\nstudy the impact of measurement noise on the classical surrogation of\nparameterized quantum circuit models. Our work provides new tools to analyse\nthe operational influence of finite measurement noise in the classical learning\nof quantum systems.", "arxiv_id": "2408.05116v1", "pdf_url": "http://arxiv.org/pdf/2408.05116v1", "abstract_url": "http://arxiv.org/abs/2408.05116v1", "primary_category": "quant-ph", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Concept learning of parameterized quantum models from limited measurements", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:44.281536"}
{"title": "Node Level Graph Autoencoder: Unified Pretraining for Textual Graph Learning", "authors": "Wenbin Hu, Huihao Jing, Qi Hu, Haoran Li, Yangqiu Song", "abstract": "Textual graphs are ubiquitous in real-world applications, featuring rich text\ninformation with complex relationships, which enables advanced research across\nvarious fields. Textual graph representation learning aims to generate\nlow-dimensional feature embeddings from textual graphs that can improve the\nperformance of downstream tasks. A high-quality feature embedding should\neffectively capture both the structural and the textual information in a\ntextual graph. However, most textual graph dataset benchmarks rely on word2vec\ntechniques to generate feature embeddings, which inherently limits their\ncapabilities. Recent works on textual graph representation learning can be\ncategorized into two folds: supervised and unsupervised methods. Supervised\nmethods finetune a language model on labeled nodes, which have limited\ncapabilities when labeled data is scarce. Unsupervised methods, on the other\nhand, extract feature embeddings by developing complex training pipelines. To\naddress these limitations, we propose a novel unified unsupervised learning\nautoencoder framework, named Node Level Graph AutoEncoder (NodeGAE). We employ\nlanguage models as the backbone of the autoencoder, with pretraining on text\nreconstruction. Additionally, we add an auxiliary loss term to make the feature\nembeddings aware of the local graph structure. Our method maintains simplicity\nin the training process and demonstrates generalizability across diverse\ntextual graphs and downstream tasks. We evaluate our method on two core graph\nrepresentation learning downstream tasks: node classification and link\nprediction. Comprehensive experiments demonstrate that our approach\nsubstantially enhances the performance of diverse graph neural networks (GNNs)\nacross multiple textual graph datasets.", "arxiv_id": "2408.07091v1", "pdf_url": "http://arxiv.org/pdf/2408.07091v1", "abstract_url": "http://arxiv.org/abs/2408.07091v1", "primary_category": "cs.LG", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Node Level Graph Autoencoder: Unified Pretraining for Textual Graph Learning", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:45.233732"}
{"title": "AI-driven Java Performance Testing: Balancing Result Quality with Testing Time", "authors": "Luca Traini, Federico Di Menna, Vittorio Cortellessa", "abstract": "Performance testing aims at uncovering efficiency issues of software systems.\nIn order to be both effective and practical, the design of a performance test\nmust achieve a reasonable trade-off between result quality and testing time.\nThis becomes particularly challenging in Java context, where the software\nundergoes a warm-up phase of execution, due to just-in-time compilation. During\nthis phase, performance measurements are subject to severe fluctuations, which\nmay adversely affect quality of performance test results. However, these\napproaches often provide suboptimal estimates of the warm-up phase, resulting\nin either insufficient or excessive warm-up iterations, which may degrade\nresult quality or increase testing time. There is still a lack of consensus on\nhow to properly address this problem. Here, we propose and study an AI-based\nframework to dynamically halt warm-up iterations at runtime. Specifically, our\nframework leverages recent advances in AI for Time Series Classification (TSC)\nto predict the end of the warm-up phase during test execution. We conduct\nexperiments by training three different TSC models on half a million of\nmeasurement segments obtained from JMH microbenchmark executions. We find that\nour framework significantly improves the accuracy of the warm-up estimates\nprovided by state-of-practice and state-of-the-art methods. This higher\nestimation accuracy results in a net improvement in either result quality or\ntesting time for up to +35.3% of the microbenchmarks. Our study highlights that\nintegrating AI to dynamically estimate the end of the warm-up phase can enhance\nthe cost-effectiveness of Java performance testing.", "arxiv_id": "2408.05100v1", "pdf_url": "http://arxiv.org/pdf/2408.05100v1", "abstract_url": "http://arxiv.org/abs/2408.05100v1", "primary_category": "cs.SE", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "AI-driven Java Performance Testing: Balancing Result Quality with Testing Time", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:46.046959"}
{"title": "Hyperbolic Learning with Multimodal Large Language Models", "authors": "Paolo Mandica, Luca Franco, Konstantinos Kallidromitis, Suzanne Petryk, Fabio Galasso", "abstract": "Hyperbolic embeddings have demonstrated their effectiveness in capturing\nmeasures of uncertainty and hierarchical relationships across various\ndeep-learning tasks, including image segmentation and active learning. However,\ntheir application in modern vision-language models (VLMs) has been limited. A\nnotable exception is MERU, which leverages the hierarchical properties of\nhyperbolic space in the CLIP ViT-large model, consisting of hundreds of\nmillions parameters. In our work, we address the challenges of scaling\nmulti-modal hyperbolic models by orders of magnitude in terms of parameters\n(billions) and training complexity using the BLIP-2 architecture. Although\nhyperbolic embeddings offer potential insights into uncertainty not present in\nEuclidean embeddings, our analysis reveals that scaling these models is\nparticularly difficult. We propose a novel training strategy for a hyperbolic\nversion of BLIP-2, which allows to achieve comparable performance to its\nEuclidean counterpart, while maintaining stability throughout the training\nprocess and showing a meaningful indication of uncertainty with each embedding.", "arxiv_id": "2408.05097v1", "pdf_url": "http://arxiv.org/pdf/2408.05097v1", "abstract_url": "http://arxiv.org/abs/2408.05097v1", "primary_category": "cs.LG", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Hyperbolic Learning with Multimodal Large Language Models", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:46.978203"}
{"title": "PriPHiT: Privacy-Preserving Hierarchical Training of Deep Neural Networks", "authors": "Yamin Sepehri, Pedram Pad, Pascal Frossard, L. Andrea Dunbar", "abstract": "The training phase of deep neural networks requires substantial resources and\nas such is often performed on cloud servers. However, this raises privacy\nconcerns when the training dataset contains sensitive content, e.g., face\nimages. In this work, we propose a method to perform the training phase of a\ndeep learning model on both an edge device and a cloud server that prevents\nsensitive content being transmitted to the cloud while retaining the desired\ninformation. The proposed privacy-preserving method uses adversarial early\nexits to suppress the sensitive content at the edge and transmits the\ntask-relevant information to the cloud. This approach incorporates noise\naddition during the training phase to provide a differential privacy guarantee.\nWe extensively test our method on different facial datasets with diverse face\nattributes using various deep learning architectures, showcasing its\noutstanding performance. We also demonstrate the effectiveness of privacy\npreservation through successful defenses against different white-box and deep\nreconstruction attacks.", "arxiv_id": "2408.05092v1", "pdf_url": "http://arxiv.org/pdf/2408.05092v1", "abstract_url": "http://arxiv.org/abs/2408.05092v1", "primary_category": "cs.CV", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "PriPHiT: Privacy-Preserving Hierarchical Training of Deep Neural Networks", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:47.652111"}
{"title": "Bootstrap Latents of Nodes and Neighbors for Graph Self-Supervised Learning", "authors": "Yunhui Liu, Huaisong Zhang, Tieke He, Tao Zheng, Jianhua Zhao", "abstract": "Contrastive learning is a significant paradigm in graph self-supervised\nlearning. However, it requires negative samples to prevent model collapse and\nlearn discriminative representations. These negative samples inevitably lead to\nheavy computation, memory overhead and class collision, compromising the\nrepresentation learning. Recent studies present that methods obviating negative\nsamples can attain competitive performance and scalability enhancements,\nexemplified by bootstrapped graph latents (BGRL). However, BGRL neglects the\ninherent graph homophily, which provides valuable insights into underlying\npositive pairs. Our motivation arises from the observation that subtly\nintroducing a few ground-truth positive pairs significantly improves BGRL.\nAlthough we can't obtain ground-truth positive pairs without labels under the\nself-supervised setting, edges in the graph can reflect noisy positive pairs,\ni.e., neighboring nodes often share the same label. Therefore, we propose to\nexpand the positive pair set with node-neighbor pairs. Subsequently, we\nintroduce a cross-attention module to predict the supportiveness score of a\nneighbor with respect to the anchor node. This score quantifies the positive\nsupport from each neighboring node, and is encoded into the training objective.\nConsequently, our method mitigates class collision from negative and noisy\npositive samples, concurrently enhancing intra-class compactness. Extensive\nexperiments are conducted on five benchmark datasets and three downstream task\nnode classification, node clustering, and node similarity search. The results\ndemonstrate that our method generates node representations with enhanced\nintra-class compactness and achieves state-of-the-art performance.", "arxiv_id": "2408.05087v1", "pdf_url": "http://arxiv.org/pdf/2408.05087v1", "abstract_url": "http://arxiv.org/abs/2408.05087v1", "primary_category": "cs.LG", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Bootstrap Latents of Nodes and Neighbors for Graph Self-Supervised Learning", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:48.386376"}
{"title": "Persistence kernels for classification: A comparative study", "authors": "Cinzia Bandiziol, Stefano De Marchi", "abstract": "The aim of the present work is a comparative study of different persistence\nkernels applied to various classification problems. After some necessary\npreliminaries on homology and persistence diagrams, we introduce five different\nkernels that are then used to compare their performances of classification on\nvarious datasets. We also provide the Python codes for the reproducibility of\nresults.", "arxiv_id": "2408.07090v1", "pdf_url": "http://arxiv.org/pdf/2408.07090v1", "abstract_url": "http://arxiv.org/abs/2408.07090v1", "primary_category": "cs.LG", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "NOT_ENOUGH_RELATED"}
{"title": "Persistence kernels for classification: A comparative study", "response": "NOT_ENOUGH_RELATED", "timestamp": "2024-08-19T13:39:49.123919"}
{"title": "Generalizing Few Data to Unseen Domains Flexibly Based on Label Smoothing Integrated with Distributionally Robust Optimization", "authors": "Yangdi Wang, Zhi-Hai Zhang, Su Xiu Xu, Wenming Guo", "abstract": "Overfitting commonly occurs when applying deep neural networks (DNNs) on\nsmall-scale datasets, where DNNs do not generalize well from existing data to\nunseen data. The main reason resulting in overfitting is that small-scale\ndatasets cannot reflect the situations of the real world. Label smoothing (LS)\nis an effective regularization method to prevent overfitting, avoiding it by\nmixing one-hot labels with uniform label vectors. However, LS only focuses on\nlabels while ignoring the distribution of existing data. In this paper, we\nintroduce the distributionally robust optimization (DRO) to LS, achieving shift\nthe existing data distribution flexibly to unseen domains when training DNNs.\nSpecifically, we prove that the regularization of LS can be extended to a\nregularization term for the DNNs parameters when integrating DRO. The\nregularization term can be utilized to shift existing data to unseen domains\nand generate new data. Furthermore, we propose an approximate\ngradient-iteration label smoothing algorithm (GI-LS) to achieve the findings\nand train DNNs. We prove that the shift for the existing data does not\ninfluence the convergence of GI-LS. Since GI-LS incorporates a series of\nhyperparameters, we further consider using Bayesian optimization (BO) to find\nthe relatively optimal combinations of these hyperparameters. Taking\nsmall-scale anomaly classification tasks as a case, we evaluate GI-LS, and the\nresults clearly demonstrate its superior performance.", "arxiv_id": "2408.05082v1", "pdf_url": "http://arxiv.org/pdf/2408.05082v1", "abstract_url": "http://arxiv.org/abs/2408.05082v1", "primary_category": "cs.LG", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Generalizing Few Data to Unseen Domains Flexibly Based on Label Smoothing Integrated with Distributionally Robust Optimization", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:49.938606"}
{"title": "Masked adversarial neural network for cell type deconvolution in spatial transcriptomics", "authors": "Lin Huang, Xiaofei Liu, Shunfang Wang, Wenwen Min", "abstract": "Accurately determining cell type composition in disease-relevant tissues is\ncrucial for identifying disease targets. Most existing spatial transcriptomics\n(ST) technologies cannot achieve single-cell resolution, making it challenging\nto accurately determine cell types. To address this issue, various\ndeconvolution methods have been developed. Most of these methods use\nsingle-cell RNA sequencing (scRNA-seq) data from the same tissue as a reference\nto infer cell types in ST data spots. However, they often overlook the\ndifferences between scRNA-seq and ST data. To overcome this limitation, we\npropose a Masked Adversarial Neural Network (MACD). MACD employs adversarial\nlearning to align real ST data with simulated ST data generated from scRNA-seq\ndata. By mapping them into a unified latent space, it can minimize the\ndifferences between the two types of data. Additionally, MACD uses masking\ntechniques to effectively learn the features of real ST data and mitigate\nnoise. We evaluated MACD on 32 simulated datasets and 2 real datasets,\ndemonstrating its accuracy in performing cell type deconvolution. All code and\npublic datasets used in this paper are available at\nhttps://github.com/wenwenmin/MACD and https://zenodo.org/records/12804822.", "arxiv_id": "2408.05065v1", "pdf_url": "http://arxiv.org/pdf/2408.05065v1", "abstract_url": "http://arxiv.org/abs/2408.05065v1", "primary_category": "cs.LG", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Masked adversarial neural network for cell type deconvolution in spatial transcriptomics", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:50.598452"}
{"title": "GLEAMS: Bridging the Gap Between Local and Global Explanations", "authors": "Giorgio Visani, Vincenzo Stanzione, Damien Garreau", "abstract": "The explainability of machine learning algorithms is crucial, and numerous\nmethods have emerged recently. Local, post-hoc methods assign an attribution\nscore to each feature, indicating its importance for the prediction. However,\nthese methods require recalculating explanations for each example. On the other\nside, while there exist global approaches they often produce explanations that\nare either overly simplistic and unreliable or excessively complex. To bridge\nthis gap, we propose GLEAMS, a novel method that partitions the input space and\nlearns an interpretable model within each sub-region, thereby providing both\nfaithful local and global surrogates. We demonstrate GLEAMS' effectiveness on\nboth synthetic and real-world data, highlighting its desirable properties and\nhuman-understandable insights.", "arxiv_id": "2408.05060v1", "pdf_url": "http://arxiv.org/pdf/2408.05060v1", "abstract_url": "http://arxiv.org/abs/2408.05060v1", "primary_category": "cs.LG", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "GLEAMS: Bridging the Gap Between Local and Global Explanations", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:54.756660"}
{"title": "Variational Bayesian Phylogenetic Inference with Semi-implicit Branch Length Distributions", "authors": "Tianyu Xie, Frederick A. Matsen IV, Marc A. Suchard, Cheng Zhang", "abstract": "Reconstructing the evolutionary history relating a collection of molecular\nsequences is the main subject of modern Bayesian phylogenetic inference.\nHowever, the commonly used Markov chain Monte Carlo methods can be inefficient\ndue to the complicated space of phylogenetic trees, especially when the number\nof sequences is large. An alternative approach is variational Bayesian\nphylogenetic inference (VBPI) which transforms the inference problem into an\noptimization problem. While effective, the default diagonal lognormal\napproximation for the branch lengths of the tree used in VBPI is often\ninsufficient to capture the complexity of the exact posterior. In this work, we\npropose a more flexible family of branch length variational posteriors based on\nsemi-implicit hierarchical distributions using graph neural networks. We show\nthat this semi-implicit construction emits straightforward permutation\nequivariant distributions, and therefore can handle the non-Euclidean branch\nlength space across different tree topologies with ease. To deal with the\nintractable marginal probability of semi-implicit variational distributions, we\ndevelop several alternative lower bounds for stochastic optimization. We\ndemonstrate the effectiveness of our proposed method over baseline methods on\nbenchmark data examples, in terms of both marginal likelihood estimation and\nbranch length posterior approximation.", "arxiv_id": "2408.05058v1", "pdf_url": "http://arxiv.org/pdf/2408.05058v1", "abstract_url": "http://arxiv.org/abs/2408.05058v1", "primary_category": "stat.ML", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Variational Bayesian Phylogenetic Inference with Semi-implicit Branch Length Distributions", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:55.978964"}
{"title": "Graph Neural Networks as Ordering Heuristics for Parallel Graph Coloring", "authors": "Kenneth Langedal, Fredrik Manne", "abstract": "The graph coloring problem asks for an assignment of the minimum number of\ndistinct colors to vertices in an undirected graph with the constraint that no\npair of adjacent vertices share the same color. The problem is a thoroughly\nstudied NP-hard combinatorial problem with several real-world applications. As\nsuch, a number of greedy heuristics have been suggested that strike a good\nbalance between coloring quality, execution time, and also parallel\nscalability. In this work, we introduce a graph neural network (GNN) based\nordering heuristic and demonstrate that it outperforms existing greedy ordering\nheuristics both on quality and performance. Previous results have demonstrated\nthat GNNs can produce high-quality colorings but at the expense of excessive\nrunning time. The current paper is the first that brings the execution time\ndown to compete with existing greedy heuristics. Our GNN model is trained using\nboth supervised and unsupervised techniques. The experimental results show that\na 2-layer GNN model can achieve execution times between the largest degree\nfirst (LF) and smallest degree last (SL) ordering heuristics while\noutperforming both on coloring quality. Increasing the number of layers\nimproves the coloring quality further, and it is only at four layers that SL\nbecomes faster than the GNN. Finally, our GNN-based coloring heuristic achieves\nsuperior scaling in the parallel setting compared to both SL and LF.", "arxiv_id": "2408.05054v1", "pdf_url": "http://arxiv.org/pdf/2408.05054v1", "abstract_url": "http://arxiv.org/abs/2408.05054v1", "primary_category": "cs.LG", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Graph Neural Networks as Ordering Heuristics for Parallel Graph Coloring", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:57.001962"}
{"title": "Integrating Edge Information into Ground Truth for the Segmentation of the Optic Disc and Cup from Fundus Images", "authors": "Yoga Sri Varshan V, Hitesh Gupta Kattamuri, Subin Sahayam, Umarani Jayaraman", "abstract": "Optic disc and cup segmentation helps in the diagnosis of glaucoma,\nmyocardial infarction, and diabetic retinopathy. Most deep learning methods\ndeveloped to perform segmentation tasks are built on top of a U-Net-based model\narchitecture. Nevertheless, U-Net and its variants have a tendency to\nover-segment/ under-segment the required regions of interest. Since the most\nimportant outcome is the value of cup-to-disc ratio and not the segmented\nregions themselves, we are more concerned about the boundaries rather than the\nregions under the boundaries. This makes learning edges important as compared\nto learning the regions. In the proposed work, the authors aim to extract both\nedges of the optic disc and cup from the ground truth using a Laplacian filter.\nNext, edges are reconstructed to obtain an edge ground truth in addition to the\noptic disc-cup ground truth. Utilizing both ground truths, the authors study\nseveral U-Net and its variant architectures with and without optic disc and cup\nedges as target, along with the optic disc-cup ground truth for segmentation.\nThe authors have used the REFUGE benchmark dataset and the Drishti-GS dataset\nto perform the study, and the results are tabulated for the dice and the\nHausdorff distance metrics. In the case of the REFUGE dataset, the optic disc\nmean dice score has improved from 0.7425 to 0.8859 while the mean Hausdorff\ndistance has reduced from 6.5810 to 3.0540 for the baseline U-Net model.\nSimilarly, the optic cup mean dice score has improved from 0.6970 to 0.8639\nwhile the mean Hausdorff distance has reduced from 5.2340 to 2.6323 for the\nsame model. Similar improvement has been observed for the Drishti-GS dataset as\nwell. Compared to the baseline U-Net and its variants (i.e) the Attention U-Net\nand the U-Net++, the models that learn integrated edges along with the optic\ndisc and cup regions performed well in both validation and testing datasets.", "arxiv_id": "2408.05052v1", "pdf_url": "http://arxiv.org/pdf/2408.05052v1", "abstract_url": "http://arxiv.org/abs/2408.05052v1", "primary_category": "eess.IV", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Integrating Edge Information into Ground Truth for the Segmentation of the Optic Disc and Cup from Fundus Images", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:57.828400"}
{"title": "BoFire: Bayesian Optimization Framework Intended for Real Experiments", "authors": "Johannes P. D\u00fcrholt, Thomas S. Asche, Johanna Kleinekorte, Gabriel Mancino-Ball, Benjamin Schiller, Simon Sung, Julian Keupp, Aaron Osburg, Toby Boyne, Ruth Misener, Rosona Eldred, Wagner Steuer Costa, Chrysoula Kappatou, Robert M. Lee, Dominik Linzner, David Walz, Niklas Wulkow, Behrang Shafei", "abstract": "Our open-source Python package BoFire combines Bayesian Optimization (BO)\nwith other design of experiments (DoE) strategies focusing on developing and\noptimizing new chemistry. Previous BO implementations, for example as they\nexist in the literature or software, require substantial adaptation for\neffective real-world deployment in chemical industry. BoFire provides a rich\nfeature-set with extensive configurability and realizes our vision of\nfast-tracking research contributions into industrial use via maintainable\nopen-source software. Owing to quality-of-life features like\nJSON-serializability of problem formulations, BoFire enables seamless\nintegration of BO into RESTful APIs, a common architecture component for both\nself-driving laboratories and human-in-the-loop setups. This paper discusses\nthe differences between BoFire and other BO implementations and outlines ways\nthat BO research needs to be adapted for real-world use in a chemistry setting.", "arxiv_id": "2408.05040v1", "pdf_url": "http://arxiv.org/pdf/2408.05040v1", "abstract_url": "http://arxiv.org/abs/2408.05040v1", "primary_category": "cs.LG", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "BoFire: Bayesian Optimization Framework Intended for Real Experiments", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:58.743984"}
{"title": "A conformalized learning of a prediction set with applications to medical imaging classification", "authors": "Roy Hirsch, Jacob Goldberger", "abstract": "Medical imaging classifiers can achieve high predictive accuracy, but\nquantifying their uncertainty remains an unresolved challenge, which prevents\ntheir deployment in medical clinics. We present an algorithm that can modify\nany classifier to produce a prediction set containing the true label with a\nuser-specified probability, such as 90%. We train a network to predict an\ninstance-based version of the Conformal Prediction threshold. The threshold is\nthen conformalized to ensure the required coverage. We applied the proposed\nalgorithm to several standard medical imaging classification datasets. The\nexperimental results demonstrate that our method outperforms current approaches\nin terms of smaller average size of the prediction set while maintaining the\ndesired coverage.", "arxiv_id": "2408.05037v1", "pdf_url": "http://arxiv.org/pdf/2408.05037v1", "abstract_url": "http://arxiv.org/abs/2408.05037v1", "primary_category": "cs.LG", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "A conformalized learning of a prediction set with applications to medical imaging classification", "response": "RELEVANT", "timestamp": "2024-08-19T13:39:59.499242"}
{"title": "Retrieval-augmented code completion for local projects using large language models", "authors": "Marko Hostnik, Marko Robnik-\u0160ikonja", "abstract": "The use of large language models (LLMs) is becoming increasingly widespread\namong software developers. However, privacy and computational requirements are\nproblematic with commercial solutions and the use of LLMs. In this work, we\nfocus on using LLMs with around 160 million parameters that are suitable for\nlocal execution and augmentation with retrieval from local projects. We train\ntwo models based on the transformer architecture, the generative model GPT-2\nand the retrieval-adapted RETRO model, on open-source Python files, and\nempirically evaluate and compare them, confirming the benefits of vector\nembedding based retrieval. Further, we improve our models' performance with\nIn-context retrieval-augmented generation, which retrieves code snippets based\non the Jaccard similarity of tokens. We evaluate In-context retrieval-augmented\ngeneration on larger models and conclude that, despite its simplicity, the\napproach is more suitable than using the RETRO architecture. We highlight the\nkey role of proper tokenization in achieving the full potential of LLMs in code\ncompletion.", "arxiv_id": "2408.05026v1", "pdf_url": "http://arxiv.org/pdf/2408.05026v1", "abstract_url": "http://arxiv.org/abs/2408.05026v1", "primary_category": "cs.SE", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Retrieval-augmented code completion for local projects using large language models", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:00.387904"}
{"title": "On the use of neurosymbolic AI for defending against cyber attacks", "authors": "Gudmund Grov, Jonas Halvorsen, Magnus Wiik Eckhoff, Bj\u00f8rn Jervell Hansen, Martin Eian, Vasileios Mavroeidis", "abstract": "It is generally accepted that all cyber attacks cannot be prevented, creating\na need for the ability to detect and respond to cyber attacks. Both\nconnectionist and symbolic AI are currently being used to support such\ndetection and response. In this paper, we make the case for combining them\nusing neurosymbolic AI. We identify a set of challenges when using AI today and\npropose a set of neurosymbolic use cases we believe are both interesting\nresearch directions for the neurosymbolic AI community and can have an impact\non the cyber security field. We demonstrate feasibility through two\nproof-of-concept experiments.", "arxiv_id": "2408.04996v1", "pdf_url": "http://arxiv.org/pdf/2408.04996v1", "abstract_url": "http://arxiv.org/abs/2408.04996v1", "primary_category": "cs.AI", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "On the use of neurosymbolic AI for defending against cyber attacks", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:01.208315"}
{"title": "Towards aerodynamic surrogate modeling based on $\u03b2$-variational autoencoders", "authors": "V\u00edctor Franc\u00e9s-Belda, Alberto Solera-Rico, Javier Nieto-Centenero, Esther Andr\u00e9s, Carlos Sanmiguel Vila, Rodrigo Castellanos", "abstract": "Surrogate models combining dimensionality reduction and regression techniques\nare essential to reduce the need for costly high-fidelity CFD data. New\napproaches using $\\beta$-Variational Autoencoder ($\\beta$-VAE) architectures\nhave shown promise in obtaining high-quality low-dimensional representations of\nhigh-dimensional flow data while enabling physical interpretation of their\nlatent spaces. We propose a surrogate model based on latent space regression to\npredict pressure distributions on a transonic wing given the flight conditions:\nMach number and angle of attack. The $\\beta$-VAE model, enhanced with Principal\nComponent Analysis (PCA), maps high-dimensional data to a low-dimensional\nlatent space, showing a direct correlation with flight conditions.\nRegularization through $\\beta$ requires careful tuning to improve the overall\nperformance, while PCA pre-processing aids in constructing an effective latent\nspace, improving autoencoder training and performance. Gaussian Process\nRegression is used to predict latent space variables from flight conditions,\nshowing robust behavior independent of $\\beta$, and the decoder reconstructs\nthe high-dimensional pressure field data. This pipeline provides insight into\nunexplored flight conditions. Additionally, a fine-tuning process of the\ndecoder further refines the model, reducing dependency on $\\beta$ and enhancing\naccuracy. The structured latent space, robust regression performance, and\nsignificant improvements from fine-tuning collectively create a highly accurate\nand efficient surrogate model. Our methodology demonstrates the effectiveness\nof $\\beta$-VAEs for aerodynamic surrogate modeling, offering a rapid,\ncost-effective, and reliable alternative for aerodynamic data prediction.", "arxiv_id": "2408.04969v1", "pdf_url": "http://arxiv.org/pdf/2408.04969v1", "abstract_url": "http://arxiv.org/abs/2408.04969v1", "primary_category": "cs.LG", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Towards aerodynamic surrogate modeling based on $\u03b2$-variational autoencoders", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:02.047367"}
{"title": "LiD-FL: Towards List-Decodable Federated Learning", "authors": "Hong Liu, Liren Shan, Han Bao, Ronghui You, Yuhao Yi, Jiancheng Lv", "abstract": "Federated learning is often used in environments with many unverified\nparticipants. Therefore, federated learning under adversarial attacks receives\nsignificant attention. This paper proposes an algorithmic framework for\nlist-decodable federated learning, where a central server maintains a list of\nmodels, with at least one guaranteed to perform well. The framework has no\nstrict restriction on the fraction of honest workers, extending the\napplicability of Byzantine federated learning to the scenario with more than\nhalf adversaries. Under proper assumptions on the loss function, we prove a\nconvergence theorem for our method. Experimental results, including image\nclassification tasks with both convex and non-convex losses, demonstrate that\nthe proposed algorithm can withstand the malicious majority under various\nattacks.", "arxiv_id": "2408.04963v2", "pdf_url": "http://arxiv.org/pdf/2408.04963v2", "abstract_url": "http://arxiv.org/abs/2408.04963v2", "primary_category": "cs.LG", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "LiD-FL: Towards List-Decodable Federated Learning", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:02.847859"}
{"title": "Model Debiasing by Learnable Data Augmentation", "authors": "Pietro Morerio, Ruggero Ragonesi, Vittorio Murino", "abstract": "Deep Neural Networks are well known for efficiently fitting training data,\nyet experiencing poor generalization capabilities whenever some kind of bias\ndominates over the actual task labels, resulting in models learning\n\"shortcuts\". In essence, such models are often prone to learn spurious\ncorrelations between data and labels. In this work, we tackle the problem of\nlearning from biased data in the very realistic unsupervised scenario, i.e.,\nwhen the bias is unknown. This is a much harder task as compared to the\nsupervised case, where auxiliary, bias-related annotations, can be exploited in\nthe learning process. This paper proposes a novel 2-stage learning pipeline\nfeaturing a data augmentation strategy able to regularize the training. First,\nbiased/unbiased samples are identified by training over-biased models. Second,\nsuch subdivision (typically noisy) is exploited within a data augmentation\nframework, properly combining the original samples while learning mixing\nparameters, which has a regularization effect. Experiments on synthetic and\nrealistic biased datasets show state-of-the-art classification accuracy,\noutperforming competing methods, ultimately proving robust performance on both\nbiased and unbiased examples. Notably, being our training method totally\nagnostic to the level of bias, it also positively affects performance for any,\neven apparently unbiased, dataset, thus improving the model generalization\nregardless of the level of bias (or its absence) in the data.", "arxiv_id": "2408.04955v1", "pdf_url": "http://arxiv.org/pdf/2408.04955v1", "abstract_url": "http://arxiv.org/abs/2408.04955v1", "primary_category": "cs.LG", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Model Debiasing by Learnable Data Augmentation", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:03.868129"}
{"title": "scASDC: Attention Enhanced Structural Deep Clustering for Single-cell RNA-seq Data", "authors": "Wenwen Min, Zhen Wang, Fangfang Zhu, Taosheng Xu, Shunfang Wang", "abstract": "Single-cell RNA sequencing (scRNA-seq) data analysis is pivotal for\nunderstanding cellular heterogeneity. However, the high sparsity and complex\nnoise patterns inherent in scRNA-seq data present significant challenges for\ntraditional clustering methods. To address these issues, we propose a deep\nclustering method, Attention-Enhanced Structural Deep Embedding Graph\nClustering (scASDC), which integrates multiple advanced modules to improve\nclustering accuracy and robustness.Our approach employs a multi-layer graph\nconvolutional network (GCN) to capture high-order structural relationships\nbetween cells, termed as the graph autoencoder module. To mitigate the\noversmoothing issue in GCNs, we introduce a ZINB-based autoencoder module that\nextracts content information from the data and learns latent representations of\ngene expression. These modules are further integrated through an attention\nfusion mechanism, ensuring effective combination of gene expression and\nstructural information at each layer of the GCN. Additionally, a\nself-supervised learning module is incorporated to enhance the robustness of\nthe learned embeddings. Extensive experiments demonstrate that scASDC\noutperforms existing state-of-the-art methods, providing a robust and effective\nsolution for single-cell clustering tasks. Our method paves the way for more\naccurate and meaningful analysis of single-cell RNA sequencing data,\ncontributing to better understanding of cellular heterogeneity and biological\nprocesses. All code and public datasets used in this paper are available at\n\\url{https://github.com/wenwenmin/scASDC} and\n\\url{https://zenodo.org/records/12814320}.", "arxiv_id": "2408.05258v1", "pdf_url": "http://arxiv.org/pdf/2408.05258v1", "abstract_url": "http://arxiv.org/abs/2408.05258v1", "primary_category": "q-bio.GN", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "scASDC: Attention Enhanced Structural Deep Clustering for Single-cell RNA-seq Data", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:04.925933"}
{"title": "CROCODILE: Causality aids RObustness via COntrastive DIsentangled LEarning", "authors": "Gianluca Carloni, Sotirios A Tsaftaris, Sara Colantonio", "abstract": "Due to domain shift, deep learning image classifiers perform poorly when\napplied to a domain different from the training one. For instance, a classifier\ntrained on chest X-ray (CXR) images from one hospital may not generalize to\nimages from another hospital due to variations in scanner settings or patient\ncharacteristics. In this paper, we introduce our CROCODILE framework, showing\nhow tools from causality can foster a model's robustness to domain shift via\nfeature disentanglement, contrastive learning losses, and the injection of\nprior knowledge. This way, the model relies less on spurious correlations,\nlearns the mechanism bringing from images to prediction better, and outperforms\nbaselines on out-of-distribution (OOD) data. We apply our method to multi-label\nlung disease classification from CXRs, utilizing over 750000 images from four\ndatasets. Our bias-mitigation method improves domain generalization and\nfairness, broadening the applicability and reliability of deep learning models\nfor a safer medical image analysis. Find our code at:\nhttps://github.com/gianlucarloni/crocodile.", "arxiv_id": "2408.04949v1", "pdf_url": "http://arxiv.org/pdf/2408.04949v1", "abstract_url": "http://arxiv.org/abs/2408.04949v1", "primary_category": "eess.IV", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "CROCODILE: Causality aids RObustness via COntrastive DIsentangled LEarning", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:08.990089"}
{"title": "HybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction", "authors": "Bhaskarjit Sarmah, Benika Hall, Rohan Rao, Sunil Patel, Stefano Pasquali, Dhagash Mehta", "abstract": "Extraction and interpretation of intricate information from unstructured text\ndata arising in financial applications, such as earnings call transcripts,\npresent substantial challenges to large language models (LLMs) even using the\ncurrent best practices to use Retrieval Augmented Generation (RAG) (referred to\nas VectorRAG techniques which utilize vector databases for information\nretrieval) due to challenges such as domain specific terminology and complex\nformats of the documents. We introduce a novel approach based on a combination,\ncalled HybridRAG, of the Knowledge Graphs (KGs) based RAG techniques (called\nGraphRAG) and VectorRAG techniques to enhance question-answer (Q&A) systems for\ninformation extraction from financial documents that is shown to be capable of\ngenerating accurate and contextually relevant answers. Using experiments on a\nset of financial earning call transcripts documents which come in the form of\nQ&A format, and hence provide a natural set of pairs of ground-truth Q&As, we\nshow that HybridRAG which retrieves context from both vector database and KG\noutperforms both traditional VectorRAG and GraphRAG individually when evaluated\nat both the retrieval and generation stages in terms of retrieval accuracy and\nanswer generation. The proposed technique has applications beyond the financial\ndomain", "arxiv_id": "2408.04948v1", "pdf_url": "http://arxiv.org/pdf/2408.04948v1", "abstract_url": "http://arxiv.org/abs/2408.04948v1", "primary_category": "cs.CL", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "HybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:09.865517"}
{"title": "Variance-based sensitivity analysis in the presence of correlated input variables", "authors": "Thomas Most", "abstract": "In this paper we propose an extension of the classical Sobol' estimator for\nthe estimation of variance based sensitivity indices. The approach assumes a\nlinear correlation model between the input variables which is used to decompose\nthe contribution of an input variable into a correlated and an uncorrelated\npart. This method provides sampling matrices following the original joint\nprobability distribution which are used directly to compute the model output\nwithout any assumptions or approximations of the model response function.", "arxiv_id": "2408.04933v1", "pdf_url": "http://arxiv.org/pdf/2408.04933v1", "abstract_url": "http://arxiv.org/abs/2408.04933v1", "primary_category": "stat.ME", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Variance-based sensitivity analysis in the presence of correlated input variables", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:10.937190"}
{"title": "Privacy-Preserved Taxi Demand Prediction System Utilizing Distributed Data", "authors": "Ren Ozeki, Haruki Yonekura, Hamada Rizk, Hirozumi Yamaguchi", "abstract": "Accurate taxi-demand prediction is essential for optimizing taxi operations\nand enhancing urban transportation services. However, using customers' data in\nthese systems raises significant privacy and security concerns. Traditional\nfederated learning addresses some privacy issues by enabling model training\nwithout direct data exchange but often struggles with accuracy due to varying\ndata distributions across different regions or service providers. In this\npaper, we propose CC-Net: a novel approach using collaborative learning\nenhanced with contrastive learning for taxi-demand prediction. Our method\nensures high performance by enabling multiple parties to collaboratively train\na demand-prediction model through hierarchical federated learning. In this\napproach, similar parties are clustered together, and federated learning is\napplied within each cluster. The similarity is defined without data exchange,\nensuring privacy and security. We evaluated our approach using real-world data\nfrom five taxi service providers in Japan over fourteen months. The results\ndemonstrate that CC-Net maintains the privacy of customers' data while\nimproving prediction accuracy by at least 2.2% compared to existing techniques.", "arxiv_id": "2408.04931v1", "pdf_url": "http://arxiv.org/pdf/2408.04931v1", "abstract_url": "http://arxiv.org/abs/2408.04931v1", "primary_category": "cs.LG", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Privacy-Preserved Taxi Demand Prediction System Utilizing Distributed Data", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:11.750586"}
{"title": "InfinityMATH: A Scalable Instruction Tuning Dataset in Programmatic Mathematical Reasoning", "authors": "Bo-Wen Zhang, Yan Yan, Lin Li, Guang Liu", "abstract": "Recent advancements in Chain-of-Thoughts (CoT) and Program-of-Thoughts (PoT)\nmethods have greatly enhanced language models' mathematical reasoning\ncapabilities, facilitating their integration into instruction tuning datasets\nwith LLMs. However, existing methods for large-scale dataset creation require\nsubstantial seed data and high computational costs for data synthesis, posing\nsignificant challenges for scalability. We introduce InfinityMATH, a scalable\ninstruction tuning dataset for programmatic mathematical reasoning. The\nconstruction pipeline emphasizes decoupling numbers from mathematical problems\nto synthesize number-independent programs, enabling efficient and flexible\nscaling while minimizing dependency on specific numerical values. Fine-tuning\nexperiments with open-source language and code models, such as Llama2 and\nCodeLlama, demonstrate the practical benefits of InfinityMATH. These fine-tuned\nmodels, showed significant relative improvements on both in-domain and\nout-of-domain benchmarks, ranging from 184.7% to 514.3% on average.\nAdditionally, these models exhibited high robustness on the GSM8K+ and MATH+\nbenchmarks, which are enhanced version of test sets with simply the number\nvariations. InfinityMATH ensures that models are more versatile and effective\nacross a broader range of mathematical problems. The data is available at\nhttps://huggingface.co/datasets/flagopen/InfinityMATH.", "arxiv_id": "2408.07089v1", "pdf_url": "http://arxiv.org/pdf/2408.07089v1", "abstract_url": "http://arxiv.org/abs/2408.07089v1", "primary_category": "cs.LG", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "InfinityMATH: A Scalable Instruction Tuning Dataset in Programmatic Mathematical Reasoning", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:12.465097"}
{"title": "UAV-Enhanced Combination to Application: Comprehensive Analysis and Benchmarking of a Human Detection Dataset for Disaster Scenarios", "authors": "Ragib Amin Nihal, Benjamin Yen, Katsutoshi Itoyama, Kazuhiro Nakadai", "abstract": "Unmanned aerial vehicles (UAVs) have revolutionized search and rescue (SAR)\noperations, but the lack of specialized human detection datasets for training\nmachine learning models poses a significant challenge.To address this gap, this\npaper introduces the Combination to Application (C2A) dataset, synthesized by\noverlaying human poses onto UAV-captured disaster scenes. Through extensive\nexperimentation with state-of-the-art detection models, we demonstrate that\nmodels fine-tuned on the C2A dataset exhibit substantial performance\nimprovements compared to those pre-trained on generic aerial datasets.\nFurthermore, we highlight the importance of combining the C2A dataset with\ngeneral human datasets to achieve optimal performance and generalization across\nvarious scenarios. This points out the crucial need for a tailored dataset to\nenhance the effectiveness of SAR operations. Our contributions also include\ndeveloping dataset creation pipeline and integrating diverse human poses and\ndisaster scenes information to assess the severity of disaster scenarios. Our\nfindings advocate for future developments, to ensure that SAR operations\nbenefit from the most realistic and effective AI-assisted interventions\npossible.", "arxiv_id": "2408.04922v1", "pdf_url": "http://arxiv.org/pdf/2408.04922v1", "abstract_url": "http://arxiv.org/abs/2408.04922v1", "primary_category": "cs.CV", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "UAV-Enhanced Combination to Application: Comprehensive Analysis and Benchmarking of a Human Detection Dataset for Disaster Scenarios", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:13.257449"}
{"title": "PTrajM: Efficient and Semantic-rich Trajectory Learning with Pretrained Trajectory-Mamba", "authors": "Yan Lin, Yichen Liu, Zeyu Zhou, Haomin Wen, Erwen Zheng, Shengnan Guo, Youfang Lin, Huaiyu Wan", "abstract": "Vehicle trajectories provide crucial movement information for various\nreal-world applications. To better utilize vehicle trajectories, it is\nessential to develop a trajectory learning approach that can effectively and\nefficiently extract rich semantic information, including movement behavior and\ntravel purposes, to support accurate downstream applications. However, creating\nsuch an approach presents two significant challenges. First, movement behavior\nare inherently spatio-temporally continuous, making them difficult to extract\nefficiently from irregular and discrete trajectory points. Second, travel\npurposes are related to the functionalities of areas and road segments\ntraversed by vehicles. These functionalities are not available from the raw\nspatio-temporal trajectory features and are hard to extract directly from\ncomplex textual features associated with these areas and road segments.\n  To address these challenges, we propose PTrajM, a novel method capable of\nefficient and semantic-rich vehicle trajectory learning. To support efficient\nmodeling of movement behavior, we introduce Trajectory-Mamba as the learnable\nmodel of PTrajM, which effectively extracts continuous movement behavior while\nbeing more computationally efficient than existing structures. To facilitate\nefficient extraction of travel purposes, we propose a travel purpose-aware\npre-training procedure, which enables PTrajM to discern the travel purposes of\ntrajectories without additional computational resources during its embedding\nprocess. Extensive experiments on two real-world datasets and comparisons with\nseveral state-of-the-art trajectory learning methods demonstrate the\neffectiveness of PTrajM. Code is available at\nhttps://anonymous.4open.science/r/PTrajM-C973.", "arxiv_id": "2408.04916v1", "pdf_url": "http://arxiv.org/pdf/2408.04916v1", "abstract_url": "http://arxiv.org/abs/2408.04916v1", "primary_category": "cs.LG", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "PTrajM: Efficient and Semantic-rich Trajectory Learning with Pretrained Trajectory-Mamba", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:14.141467"}
{"title": "AcousAF: Acoustic Sensing-Based Atrial Fibrillation Detection System for Mobile Phones", "authors": "Xuanyu Liu, Haoxian Liu, Jiao Li, Zongqi Yang, Yi Huang, Jin Zhang", "abstract": "Atrial fibrillation (AF) is characterized by irregular electrical impulses\noriginating in the atria, which can lead to severe complications and even\ndeath. Due to the intermittent nature of the AF, early and timely monitoring of\nAF is critical for patients to prevent further exacerbation of the condition.\nAlthough ambulatory ECG Holter monitors provide accurate monitoring, the high\ncost of these devices hinders their wider adoption. Current mobile-based AF\ndetection systems offer a portable solution. However, these systems have\nvarious applicability issues, such as being easily affected by environmental\nfactors and requiring significant user effort. To overcome the above\nlimitations, we present AcousAF, a novel AF detection system based on acoustic\nsensors of smartphones. Particularly, we explore the potential of pulse wave\nacquisition from the wrist using smartphone speakers and microphones. In\naddition, we propose a well-designed framework comprised of pulse wave probing,\npulse wave extraction, and AF detection to ensure accurate and reliable AF\ndetection. We collect data from 20 participants utilizing our custom data\ncollection application on the smartphone. Extensive experimental results\ndemonstrate the high performance of our system, with 92.8% accuracy, 86.9%\nprecision, 87.4% recall, and 87.1% F1 Score.", "arxiv_id": "2408.04912v1", "pdf_url": "http://arxiv.org/pdf/2408.04912v1", "abstract_url": "http://arxiv.org/abs/2408.04912v1", "primary_category": "cs.SD", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "AcousAF: Acoustic Sensing-Based Atrial Fibrillation Detection System for Mobile Phones", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:15.004726"}
{"title": "A Geometric Nash Approach in Tuning the Learning Rate in Q-Learning Algorithm", "authors": "Kwadwo Osei Bonsu", "abstract": "This paper proposes a geometric approach for estimating the $\\alpha$ value in\nQ learning. We establish a systematic framework that optimizes the {\\alpha}\nparameter, thereby enhancing learning efficiency and stability. Our results\nshow that there is a relationship between the learning rate and the angle\nbetween a vector T (total time steps in each episode of learning) and R (the\nreward vector for each episode). The concept of angular bisector between\nvectors T and R and Nash Equilibrium provide insight into estimating $\\alpha$\nsuch that the algorithm minimizes losses arising from exploration-exploitation\ntrade-off.", "arxiv_id": "2408.04911v1", "pdf_url": "http://arxiv.org/pdf/2408.04911v1", "abstract_url": "http://arxiv.org/abs/2408.04911v1", "primary_category": "cs.LG", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "A Geometric Nash Approach in Tuning the Learning Rate in Q-Learning Algorithm", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:15.725409"}
{"title": "Causal Discovery of Linear Non-Gaussian Causal Models with Unobserved Confounding", "authors": "Daniela Schkoda, Elina Robeva, Mathias Drton", "abstract": "We consider linear non-Gaussian structural equation models that involve\nlatent confounding. In this setting, the causal structure is identifiable, but,\nin general, it is not possible to identify the specific causal effects.\nInstead, a finite number of different causal effects result in the same\nobservational distribution. Most existing algorithms for identifying these\ncausal effects use overcomplete independent component analysis (ICA), which\noften suffers from convergence to local optima. Furthermore, the number of\nlatent variables must be known a priori. To address these issues, we propose an\nalgorithm that operates recursively rather than using overcomplete ICA. The\nalgorithm first infers a source, estimates the effect of the source and its\nlatent parents on their descendants, and then eliminates their influence from\nthe data. For both source identification and effect size estimation, we use\nrank conditions on matrices formed from higher-order cumulants. We prove\nasymptotic correctness under the mild assumption that locally, the number of\nlatent variables never exceeds the number of observed variables. Simulation\nstudies demonstrate that our method achieves comparable performance to\novercomplete ICA even though it does not know the number of latents in advance.", "arxiv_id": "2408.04907v1", "pdf_url": "http://arxiv.org/pdf/2408.04907v1", "abstract_url": "http://arxiv.org/abs/2408.04907v1", "primary_category": "stat.ML", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Causal Discovery of Linear Non-Gaussian Causal Models with Unobserved Confounding", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:16.367848"}
{"title": "Axiomatic Characterisations of Sample-based Explainers", "authors": "Leila Amgoud, Martin C. Cooper, Salim Debbaoui", "abstract": "Explaining decisions of black-box classifiers is both important and\ncomputationally challenging. In this paper, we scrutinize explainers that\ngenerate feature-based explanations from samples or datasets. We start by\npresenting a set of desirable properties that explainers would ideally satisfy,\ndelve into their relationships, and highlight incompatibilities of some of\nthem. We identify the entire family of explainers that satisfy two key\nproperties which are compatible with all the others. Its instances provide\nsufficient reasons, called weak abductive explanations.We then unravel its\nvarious subfamilies that satisfy subsets of compatible properties. Indeed, we\nfully characterize all the explainers that satisfy any subset of compatible\nproperties. In particular, we introduce the first (broad family of) explainers\nthat guarantee the existence of explanations and their global consistency.We\ndiscuss some of its instances including the irrefutable explainer and the\nsurrogate explainer whose explanations can be found in polynomial time.", "arxiv_id": "2408.04903v2", "pdf_url": "http://arxiv.org/pdf/2408.04903v2", "abstract_url": "http://arxiv.org/abs/2408.04903v2", "primary_category": "cs.AI", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Axiomatic Characterisations of Sample-based Explainers", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:17.006040"}
{"title": "Better Not to Propagate: Understanding Edge Uncertainty and Over-smoothing in Signed Graph Neural Networks", "authors": "Yoonhyuk Choi, Jiho Choi, Taewook Ko, Chong-Kwon Kim", "abstract": "Traditional Graph Neural Networks (GNNs) rely on network homophily, which can\nlead to performance degradation due to over-smoothing in many real-world\nheterophily scenarios. Recent studies analyze the smoothing effect\n(separability) after message-passing (MP), depending on the expectation of node\nfeatures. Regarding separability gain, they provided theoretical backgrounds on\nover-smoothing caused by various propagation schemes, including positive,\nsigned, and blocked MPs. More recently, by extending these theorems, some works\nhave suggested improvements in signed propagation under multiple classes.\nHowever, prior works assume that the error ratio of all propagation schemes is\nfixed, failing to investigate this phenomenon correctly. To solve this problem,\nwe propose a novel method for estimating homophily and edge error ratio,\nintegrated with dynamic selection between blocked and signed propagation during\ntraining. Our theoretical analysis, supported by extensive experiments,\ndemonstrates that blocking MP can be more effective than signed propagation\nunder high edge error ratios, improving the performance in both homophilic and\nheterophilic graphs.", "arxiv_id": "2408.04895v1", "pdf_url": "http://arxiv.org/pdf/2408.04895v1", "abstract_url": "http://arxiv.org/abs/2408.04895v1", "primary_category": "cs.LG", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Better Not to Propagate: Understanding Edge Uncertainty and Over-smoothing in Signed Graph Neural Networks", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:17.980583"}
{"title": "Clustering-friendly Representation Learning for Enhancing Salient Features", "authors": "Toshiyuki Oshima, Kentaro Takagi, Kouta Nakata", "abstract": "Recently, representation learning with contrastive learning algorithms has\nbeen successfully applied to challenging unlabeled datasets. However, these\nmethods are unable to distinguish important features from unimportant ones\nunder simply unsupervised settings, and definitions of importance vary\naccording to the type of downstream task or analysis goal, such as the\nidentification of objects or backgrounds. In this paper, we focus on\nunsupervised image clustering as the downstream task and propose a\nrepresentation learning method that enhances features critical to the\nclustering task. We extend a clustering-friendly contrastive learning method\nand incorporate a contrastive analysis approach, which utilizes a reference\ndataset to separate important features from unimportant ones, into the design\nof loss functions. Conducting an experimental evaluation of image clustering\nfor three datasets with characteristic backgrounds, we show that for all\ndatasets, our method achieves higher clustering scores compared with\nconventional contrastive analysis and deep clustering methods.", "arxiv_id": "2408.04891v1", "pdf_url": "http://arxiv.org/pdf/2408.04891v1", "abstract_url": "http://arxiv.org/abs/2408.04891v1", "primary_category": "cs.CV", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Clustering-friendly Representation Learning for Enhancing Salient Features", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:19.022700"}
{"title": "UCB Exploration for Fixed-Budget Bayesian Best Arm Identification", "authors": "Rong J. B. Zhu, Yanqi Qiu", "abstract": "We study best-arm identification (BAI) in the fixed-budget setting. Adaptive\nallocations based on upper confidence bounds (UCBs), such as UCBE, are known to\nwork well in BAI. However, it is well-known that its optimal regret is\ntheoretically dependent on instances, which we show to be an artifact in many\nfixed-budget BAI problems. In this paper we propose an UCB exploration\nalgorithm that is both theoretically and empirically efficient for the fixed\nbudget BAI problem under a Bayesian setting. The key idea is to learn prior\ninformation, which can enhance the performance of UCB-based BAI algorithm as it\nhas done in the cumulative regret minimization problem. We establish bounds on\nthe failure probability and the simple regret for the Bayesian BAI problem,\nproviding upper bounds of order $\\tilde{O}(\\sqrt{K/n})$, up to logarithmic\nfactors, where $n$ represents the budget and $K$ denotes the number of arms.\nFurthermore, we demonstrate through empirical results that our approach\nconsistently outperforms state-of-the-art baselines.", "arxiv_id": "2408.04869v1", "pdf_url": "http://arxiv.org/pdf/2408.04869v1", "abstract_url": "http://arxiv.org/abs/2408.04869v1", "primary_category": "cs.LG", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "UCB Exploration for Fixed-Budget Bayesian Best Arm Identification", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:19.825701"}
{"title": "An Evaluation of Standard Statistical Models and LLMs on Time Series Forecasting", "authors": "Rui Cao, Qiao Wang", "abstract": "This research examines the use of Large Language Models (LLMs) in predicting\ntime series, with a specific focus on the LLMTIME model. Despite the\nestablished effectiveness of LLMs in tasks such as text generation, language\ntranslation, and sentiment analysis, this study highlights the key challenges\nthat large language models encounter in the context of time series prediction.\nWe assess the performance of LLMTIME across multiple datasets and introduce\nclassical almost periodic functions as time series to gauge its effectiveness.\nThe empirical results indicate that while large language models can perform\nwell in zero-shot forecasting for certain datasets, their predictive accuracy\ndiminishes notably when confronted with diverse time series data and\ntraditional signals. The primary finding of this study is that the predictive\ncapacity of LLMTIME, similar to other LLMs, significantly deteriorates when\ndealing with time series data that contain both periodic and trend components,\nas well as when the signal comprises complex frequency components.", "arxiv_id": "2408.04867v1", "pdf_url": "http://arxiv.org/pdf/2408.04867v1", "abstract_url": "http://arxiv.org/abs/2408.04867v1", "primary_category": "cs.LG", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "An Evaluation of Standard Statistical Models and LLMs on Time Series Forecasting", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:20.559310"}
{"title": "High dimensional Bayesian Optimization via Condensing-Expansion Projection", "authors": "Jiaming Lu, Rong J. B. Zhu", "abstract": "In high-dimensional settings, Bayesian optimization (BO) can be expensive and\ninfeasible. The random embedding Bayesian optimization algorithm is commonly\nused to address high-dimensional BO challenges. However, this method relies on\nthe effective subspace assumption on the optimization problem's objective\nfunction, which limits its applicability. In this paper, we introduce\nCondensing-Expansion Projection Bayesian optimization (CEPBO), a novel random\nprojection-based approach for high-dimensional BO that does not reply on the\neffective subspace assumption. The approach is both simple to implement and\nhighly practical. We present two algorithms based on different random\nprojection matrices: the Gaussian projection matrix and the hashing projection\nmatrix. Experimental results demonstrate that both algorithms outperform\nexisting random embedding-based algorithms in most cases, achieving superior\nperformance on high-dimensional BO problems. The code is available in\n\\url{https://anonymous.4open.science/r/CEPBO-14429}.", "arxiv_id": "2408.04860v1", "pdf_url": "http://arxiv.org/pdf/2408.04860v1", "abstract_url": "http://arxiv.org/abs/2408.04860v1", "primary_category": "cs.LG", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "High dimensional Bayesian Optimization via Condensing-Expansion Projection", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:21.305287"}
{"title": "Your Classifier Can Be Secretly a Likelihood-Based OOD Detector", "authors": "Jirayu Burapacheep, Yixuan Li", "abstract": "The ability to detect out-of-distribution (OOD) inputs is critical to\nguarantee the reliability of classification models deployed in an open\nenvironment. A fundamental challenge in OOD detection is that a discriminative\nclassifier is typically trained to estimate the posterior probability p(y|z)\nfor class y given an input z, but lacks the explicit likelihood estimation of\np(z) ideally needed for OOD detection. While numerous OOD scoring functions\nhave been proposed for classification models, these estimate scores are often\nheuristic-driven and cannot be rigorously interpreted as likelihood. To bridge\nthe gap, we propose Intrinsic Likelihood (INK), which offers rigorous\nlikelihood interpretation to modern discriminative-based classifiers.\nSpecifically, our proposed INK score operates on the constrained latent\nembeddings of a discriminative classifier, which are modeled as a mixture of\nhyperspherical embeddings with constant norm. We draw a novel connection\nbetween the hyperspherical distribution and the intrinsic likelihood, which can\nbe effectively optimized in modern neural networks. Extensive experiments on\nthe OpenOOD benchmark empirically demonstrate that INK establishes a new\nstate-of-the-art in a variety of OOD detection setups, including both far-OOD\nand near-OOD. Code is available at https://github.com/deeplearning-wisc/ink.", "arxiv_id": "2408.04851v1", "pdf_url": "http://arxiv.org/pdf/2408.04851v1", "abstract_url": "http://arxiv.org/abs/2408.04851v1", "primary_category": "cs.LG", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Your Classifier Can Be Secretly a Likelihood-Based OOD Detector", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:22.299199"}
{"title": "A Pipeline for Data-Driven Learning of Topological Features with Applications to Protein Stability Prediction", "authors": "Amish Mishra, Francis Motta", "abstract": "In this paper, we propose a data-driven method to learn interpretable\ntopological features of biomolecular data and demonstrate the efficacy of\nparsimonious models trained on topological features in predicting the stability\nof synthetic mini proteins. We compare models that leverage\nautomatically-learned structural features against models trained on a large set\nof biophysical features determined by subject-matter experts (SME). Our models,\nbased only on topological features of the protein structures, achieved 92%-99%\nof the performance of SME-based models in terms of the average precision score.\nBy interrogating model performance and feature importance metrics, we extract\nnumerous insights that uncover high correlations between topological features\nand SME features. We further showcase how combining topological features and\nSME features can lead to improved model performance over either feature set\nused in isolation, suggesting that, in some settings, topological features may\nprovide new discriminating information not captured in existing SME features\nthat are useful for protein stability prediction.", "arxiv_id": "2408.04847v1", "pdf_url": "http://arxiv.org/pdf/2408.04847v1", "abstract_url": "http://arxiv.org/abs/2408.04847v1", "primary_category": "stat.ML", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "A Pipeline for Data-Driven Learning of Topological Features with Applications to Protein Stability Prediction", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:23.235524"}
{"title": "UGrid: An Efficient-And-Rigorous Neural Multigrid Solver for Linear PDEs", "authors": "Xi Han, Fei Hou, Hong Qin", "abstract": "Numerical solvers of Partial Differential Equations (PDEs) are of fundamental\nsignificance to science and engineering. To date, the historical reliance on\nlegacy techniques has circumscribed possible integration of big data knowledge\nand exhibits sub-optimal efficiency for certain PDE formulations, while\ndata-driven neural methods typically lack mathematical guarantee of convergence\nand correctness. This paper articulates a mathematically rigorous neural solver\nfor linear PDEs. The proposed UGrid solver, built upon the principled\nintegration of U-Net and MultiGrid, manifests a mathematically rigorous proof\nof both convergence and correctness, and showcases high numerical accuracy, as\nwell as strong generalization power to various input geometry/values and\nmultiple PDE formulations. In addition, we devise a new residual loss metric,\nwhich enables unsupervised training and affords more stability and a larger\nsolution space over the legacy losses.", "arxiv_id": "2408.04846v1", "pdf_url": "http://arxiv.org/pdf/2408.04846v1", "abstract_url": "http://arxiv.org/abs/2408.04846v1", "primary_category": "math.NA", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "UGrid: An Efficient-And-Rigorous Neural Multigrid Solver for Linear PDEs", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:24.147842"}
{"title": "MDS-GNN: A Mutual Dual-Stream Graph Neural Network on Graphs with Incomplete Features and Structure", "authors": "Peng Yuan, Peng Tang", "abstract": "Graph Neural Networks (GNNs) have emerged as powerful tools for analyzing and\nlearning representations from graph-structured data. A crucial prerequisite for\nthe outstanding performance of GNNs is the availability of complete graph\ninformation, i.e., node features and graph structure, which is frequently unmet\nin real-world scenarios since graphs are often incomplete due to various\nuncontrollable factors. Existing approaches only focus on dealing with either\nincomplete features or incomplete structure, which leads to performance loss\ninevitably. To address this issue, this study proposes a mutual dual-stream\ngraph neural network (MDS-GNN), which implements a mutual benefit learning\nbetween features and structure. Its main ideas are as follows: a)\nreconstructing the missing node features based on the initial incomplete graph\nstructure; b) generating an augmented global graph based on the reconstructed\nnode features, and propagating the incomplete node features on this global\ngraph; and c) utilizing contrastive learning to make the dual-stream process\nmutually benefit from each other. Extensive experiments on six real-world\ndatasets demonstrate the effectiveness of our proposed MDS-GNN on incomplete\ngraphs.", "arxiv_id": "2408.04845v1", "pdf_url": "http://arxiv.org/pdf/2408.04845v1", "abstract_url": "http://arxiv.org/abs/2408.04845v1", "primary_category": "cs.LG", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "MDS-GNN: A Mutual Dual-Stream Graph Neural Network on Graphs with Incomplete Features and Structure", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:25.371024"}
{"title": "Counterfactual Explanations with Probabilistic Guarantees on their Robustness to Model Change", "authors": "Ignacy St\u0119pka, Mateusz Lango, Jerzy Stefanowski", "abstract": "Counterfactual explanations (CFEs) guide users on how to adjust inputs to\nmachine learning models to achieve desired outputs. While existing research\nprimarily addresses static scenarios, real-world applications often involve\ndata or model changes, potentially invalidating previously generated CFEs and\nrendering user-induced input changes ineffective. Current methods addressing\nthis issue often support only specific models or change types, require\nextensive hyperparameter tuning, or fail to provide probabilistic guarantees on\nCFE robustness to model changes. This paper proposes a novel approach for\ngenerating CFEs that provides probabilistic guarantees for any model and change\ntype, while offering interpretable and easy-to-select hyperparameters. We\nestablish a theoretical framework for probabilistically defining robustness to\nmodel change and demonstrate how our BetaRCE method directly stems from it.\nBetaRCE is a post-hoc method applied alongside a chosen base CFE generation\nmethod to enhance the quality of the explanation beyond robustness. It\nfacilitates a transition from the base explanation to a more robust one with\nuser-adjusted probability bounds. Through experimental comparisons with\nbaselines, we show that BetaRCE yields robust, most plausible, and closest to\nbaseline counterfactual explanations.", "arxiv_id": "2408.04842v1", "pdf_url": "http://arxiv.org/pdf/2408.04842v1", "abstract_url": "http://arxiv.org/abs/2408.04842v1", "primary_category": "cs.LG", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Counterfactual Explanations with Probabilistic Guarantees on their Robustness to Model Change", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:26.282806"}
{"title": "Kolmogorov-Arnold Network for Online Reinforcement Learning", "authors": "Victor Augusto Kich, Jair Augusto Bottega, Raul Steinmetz, Ricardo Bedin Grando, Ayano Yorozu, Akihisa Ohya", "abstract": "Kolmogorov-Arnold Networks (KANs) have shown potential as an alternative to\nMulti-Layer Perceptrons (MLPs) in neural networks, providing universal function\napproximation with fewer parameters and reduced memory usage. In this paper, we\nexplore the use of KANs as function approximators within the Proximal Policy\nOptimization (PPO) algorithm. We evaluate this approach by comparing its\nperformance to the original MLP-based PPO using the DeepMind Control Proprio\nRobotics benchmark. Our results indicate that the KAN-based reinforcement\nlearning algorithm can achieve comparable performance to its MLP-based\ncounterpart, often with fewer parameters. These findings suggest that KANs may\noffer a more efficient option for reinforcement learning models.", "arxiv_id": "2408.04841v1", "pdf_url": "http://arxiv.org/pdf/2408.04841v1", "abstract_url": "http://arxiv.org/abs/2408.04841v1", "primary_category": "cs.LG", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Kolmogorov-Arnold Network for Online Reinforcement Learning", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:27.321116"}
{"title": "mPLUG-Owl3: Towards Long Image-Sequence Understanding in Multi-Modal Large Language Models", "authors": "Jiabo Ye, Haiyang Xu, Haowei Liu, Anwen Hu, Ming Yan, Qi Qian, Ji Zhang, Fei Huang, Jingren Zhou", "abstract": "Multi-modal Large Language Models (MLLMs) have demonstrated remarkable\ncapabilities in executing instructions for a variety of single-image tasks.\nDespite this progress, significant challenges remain in modeling long image\nsequences. In this work, we introduce the versatile multi-modal large language\nmodel, mPLUG-Owl3, which enhances the capability for long image-sequence\nunderstanding in scenarios that incorporate retrieved image-text knowledge,\ninterleaved image-text, and lengthy videos. Specifically, we propose novel\nhyper attention blocks to efficiently integrate vision and language into a\ncommon language-guided semantic space, thereby facilitating the processing of\nextended multi-image scenarios. Extensive experimental results suggest that\nmPLUG-Owl3 achieves state-of-the-art performance among models with a similar\nsize on single-image, multi-image, and video benchmarks. Moreover, we propose a\nchallenging long visual sequence evaluation named Distractor Resistance to\nassess the ability of models to maintain focus amidst distractions. Finally,\nwith the proposed architecture, mPLUG-Owl3 demonstrates outstanding performance\non ultra-long visual sequence inputs. We hope that mPLUG-Owl3 can contribute to\nthe development of more efficient and powerful multimodal large language\nmodels.", "arxiv_id": "2408.04840v2", "pdf_url": "http://arxiv.org/pdf/2408.04840v2", "abstract_url": "http://arxiv.org/abs/2408.04840v2", "primary_category": "cs.CV", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "mPLUG-Owl3: Towards Long Image-Sequence Understanding in Multi-Modal Large Language Models", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:28.242772"}
{"title": "Adversarially Robust Industrial Anomaly Detection Through Diffusion Model", "authors": "Yuanpu Cao, Lu Lin, Jinghui Chen", "abstract": "Deep learning-based industrial anomaly detection models have achieved\nremarkably high accuracy on commonly used benchmark datasets. However, the\nrobustness of those models may not be satisfactory due to the existence of\nadversarial examples, which pose significant threats to the practical\ndeployment of deep anomaly detectors. Recently, it has been shown that\ndiffusion models can be used to purify the adversarial noises and thus build a\nrobust classifier against adversarial attacks. Unfortunately, we found that\nnaively applying this strategy in anomaly detection (i.e., placing a purifier\nbefore an anomaly detector) will suffer from a high anomaly miss rate since the\npurifying process can easily remove both the anomaly signal and the adversarial\nperturbations, causing the later anomaly detector failed to detect anomalies.\nTo tackle this issue, we explore the possibility of performing anomaly\ndetection and adversarial purification simultaneously. We propose a simple yet\neffective adversarially robust anomaly detection method, \\textit{AdvRAD}, that\nallows the diffusion model to act both as an anomaly detector and adversarial\npurifier. We also extend our proposed method for certified robustness to $l_2$\nnorm bounded perturbations. Through extensive experiments, we show that our\nproposed method exhibits outstanding (certified) adversarial robustness while\nalso maintaining equally strong anomaly detection performance on par with the\nstate-of-the-art methods on industrial anomaly detection benchmark datasets.", "arxiv_id": "2408.04839v1", "pdf_url": "http://arxiv.org/pdf/2408.04839v1", "abstract_url": "http://arxiv.org/abs/2408.04839v1", "primary_category": "cs.LG", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Adversarially Robust Industrial Anomaly Detection Through Diffusion Model", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:29.094544"}
{"title": "Dual-Channel Latent Factor Analysis Enhanced Graph Contrastive Learning for Recommendation", "authors": "Junfeng Long, Hao Wu", "abstract": "Graph Neural Networks (GNNs) are powerful learning methods for recommender\nsystems owing to their robustness in handling complicated user-item\ninteractions. Recently, the integration of contrastive learning with GNNs has\ndemonstrated remarkable performance in recommender systems to handle the issue\nof highly sparse user-item interaction data. Yet, some available graph\ncontrastive learning (GCL) techniques employ stochastic augmentation, i.e.,\nnodes or edges are randomly perturbed on the user-item bipartite graph to\nconstruct contrastive views. Such a stochastic augmentation strategy not only\nbrings noise perturbation but also cannot utilize global collaborative signals\neffectively. To address it, this study proposes a latent factor analysis (LFA)\nenhanced GCL approach, named LFA-GCL. Our model exclusively incorporates LFA to\nimplement the unconstrained structural refinement, thereby obtaining an\naugmented global collaborative graph accurately without introducing noise\nsignals. Experiments on four public datasets show that the proposed LFA-GCL\noutperforms the state-of-the-art models.", "arxiv_id": "2408.04838v1", "pdf_url": "http://arxiv.org/pdf/2408.04838v1", "abstract_url": "http://arxiv.org/abs/2408.04838v1", "primary_category": "cs.LG", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Dual-Channel Latent Factor Analysis Enhanced Graph Contrastive Learning for Recommendation", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:30.100187"}
{"title": "Masked Graph Autoencoders with Contrastive Augmentation for Spatially Resolved Transcriptomics Data", "authors": "Donghai Fang, Fangfang Zhu, Dongting Xie, Wenwen Min", "abstract": "With the rapid advancement of Spatial Resolved Transcriptomics (SRT)\ntechnology, it is now possible to comprehensively measure gene transcription\nwhile preserving the spatial context of tissues. Spatial domain identification\nand gene denoising are key objectives in SRT data analysis. We propose a\nContrastively Augmented Masked Graph Autoencoder (STMGAC) to learn\nlow-dimensional latent representations for domain identification. In the latent\nspace, persistent signals for representations are obtained through\nself-distillation to guide self-supervised matching. At the same time, positive\nand negative anchor pairs are constructed using triplet learning to augment the\ndiscriminative ability. We evaluated the performance of STMGAC on five\ndatasets, achieving results superior to those of existing baseline methods. All\ncode and public datasets used in this paper are available at\nhttps://github.com/wenwenmin/STMGAC and https://zenodo.org/records/13253801.", "arxiv_id": "2408.06377v1", "pdf_url": "http://arxiv.org/pdf/2408.06377v1", "abstract_url": "http://arxiv.org/abs/2408.06377v1", "primary_category": "q-bio.GN", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Masked Graph Autoencoders with Contrastive Augmentation for Spatially Resolved Transcriptomics Data", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:31.276362"}
{"title": "Performance Prediction of Hub-Based Swarms", "authors": "Puneet Jain, Chaitanya Dwivedi, Vigynesh Bhatt, Nick Smith, Michael A Goodrich", "abstract": "A hub-based colony consists of multiple agents who share a common nest site\ncalled the hub. Agents perform tasks away from the hub like foraging for food\nor gathering information about future nest sites. Modeling hub-based colonies\nis challenging because the size of the collective state space grows rapidly as\nthe number of agents grows. This paper presents a graph-based representation of\nthe colony that can be combined with graph-based encoders to create\nlow-dimensional representations of collective state that can scale to many\nagents for a best-of-N colony problem. We demonstrate how the information in\nthe low-dimensional embedding can be used with two experiments. First, we show\nhow the information in the tensor can be used to cluster collective states by\nthe probability of choosing the best site for a very small problem. Second, we\nshow how structured collective trajectories emerge when a graph encoder is used\nto learn the low-dimensional embedding, and these trajectories have information\nthat can be used to predict swarm performance.", "arxiv_id": "2408.04822v1", "pdf_url": "http://arxiv.org/pdf/2408.04822v1", "abstract_url": "http://arxiv.org/abs/2408.04822v1", "primary_category": "cs.MA", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Performance Prediction of Hub-Based Swarms", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:32.134655"}
{"title": "Learning Rule-Induced Subgraph Representations for Inductive Relation Prediction", "authors": "Tianyu Liu, Qitan Lv, Jie Wang, Shuling Yang, Hanzhu Chen", "abstract": "Inductive relation prediction (IRP) -- where entities can be different during\ntraining and inference -- has shown great power for completing evolving\nknowledge graphs. Existing works mainly focus on using graph neural networks\n(GNNs) to learn the representation of the subgraph induced from the target\nlink, which can be seen as an implicit rule-mining process to measure the\nplausibility of the target link. However, these methods cannot differentiate\nthe target link and other links during message passing, hence the final\nsubgraph representation will contain irrelevant rule information to the target\nlink, which reduces the reasoning performance and severely hinders the\napplications for real-world scenarios. To tackle this problem, we propose a\nnovel \\textit{single-source edge-wise} GNN model to learn the\n\\textbf{R}ule-induc\\textbf{E}d \\textbf{S}ubgraph represen\\textbf{T}ations\n(\\textbf{REST}), which encodes relevant rules and eliminates irrelevant rules\nwithin the subgraph. Specifically, we propose a \\textit{single-source}\ninitialization approach to initialize edge features only for the target link,\nwhich guarantees the relevance of mined rules and target link. Then we propose\nseveral RNN-based functions for \\textit{edge-wise} message passing to model the\nsequential property of mined rules. REST is a simple and effective approach\nwith theoretical support to learn the \\textit{rule-induced subgraph\nrepresentation}. Moreover, REST does not need node labeling, which\nsignificantly accelerates the subgraph preprocessing time by up to\n\\textbf{11.66$\\times$}. Experiments on inductive relation prediction benchmarks\ndemonstrate the effectiveness of our REST. Our code is available at\nhttps://github.com/smart-lty/REST.", "arxiv_id": "2408.07088v1", "pdf_url": "http://arxiv.org/pdf/2408.07088v1", "abstract_url": "http://arxiv.org/abs/2408.07088v1", "primary_category": "cs.LG", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Learning Rule-Induced Subgraph Representations for Inductive Relation Prediction", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:32.953495"}
{"title": "Natural Language Outlines for Code: Literate Programming in the LLM Era", "authors": "Kensen Shi, Deniz Alt\u0131nb\u00fcken, Saswat Anand, Mihai Christodorescu, Katja Gr\u00fcnwedel, Alexa Koenings, Sai Naidu, Anurag Pathak, Marc Rasi, Fredde Ribeiro, Brandon Ruffin, Siddhant Sanyam, Maxim Tabachnyk, Sara Toth, Roy Tu, Tobias Welp, Pengcheng Yin, Manzil Zaheer, Satish Chandra, Charles Sutton", "abstract": "We propose using natural language outlines as a novel modality and\ninteraction surface for providing AI assistance to developers throughout the\nsoftware development process. An NL outline for a code function comprises\nmultiple statements written in concise prose, which partition the code and\nsummarize its main ideas in the style of literate programming. Crucially, we\nfind that modern LLMs can generate accurate and high-quality NL outlines in\npractice. Moreover, NL outlines enable a bidirectional sync between code and\nNL, allowing changes in one to be automatically reflected in the other. We\ndiscuss many use cases for NL outlines: they can accelerate understanding and\nnavigation of code and diffs, simplify code maintenance, augment code search,\nsteer code generation, and more. We then propose and compare multiple LLM\nprompting techniques for generating outlines and ask professional developers to\njudge outline quality. Finally, we present two case studies applying NL\noutlines toward code review and the difficult task of malware detection.", "arxiv_id": "2408.04820v1", "pdf_url": "http://arxiv.org/pdf/2408.04820v1", "abstract_url": "http://arxiv.org/abs/2408.04820v1", "primary_category": "cs.SE", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Natural Language Outlines for Code: Literate Programming in the LLM Era", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:33.905544"}
{"title": "Interventional Causal Structure Discovery over Graphical Models with Convergence and Optimality Guarantees", "authors": "Qiu Chengbo, Yang Kai", "abstract": "Learning causal structure from sampled data is a fundamental problem with\napplications in various fields, including healthcare, machine learning and\nartificial intelligence. Traditional methods predominantly rely on\nobservational data, but there exist limits regarding the identifiability of\ncausal structures with only observational data. Interventional data, on the\nother hand, helps establish a cause-and-effect relationship by breaking the\ninfluence of confounding variables. It remains to date under-explored to\ndevelop a mathematical framework that seamlessly integrates both observational\nand interventional data in causal structure learning. Furthermore, existing\nstudies often focus on centralized approaches, necessitating the transfer of\nentire datasets to a single server, which lead to considerable communication\noverhead and heightened risks to privacy. To tackle these challenges, we\ndevelop a bilevel polynomial optimization (Bloom) framework. Bloom not only\nprovides a powerful mathematical modeling framework, underpinned by theoretical\nsupport, for causal structure discovery from both interventional and\nobservational data, but also aspires to an efficient causal discovery algorithm\nwith convergence and optimality guarantees. We further extend Bloom to a\ndistributed setting to reduce the communication overhead and mitigate data\nprivacy risks. It is seen through experiments on both synthetic and real-world\ndatasets that Bloom markedly surpasses other leading learning algorithms.", "arxiv_id": "2408.04819v1", "pdf_url": "http://arxiv.org/pdf/2408.04819v1", "abstract_url": "http://arxiv.org/abs/2408.04819v1", "primary_category": "cs.LG", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Interventional Causal Structure Discovery over Graphical Models with Convergence and Optimality Guarantees", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:34.599786"}
{"title": "Performance Metric for Multiple Anomaly Score Distributions with Discrete Severity Levels", "authors": "Wonjun Yi, Yong-Hwa Park, Wonho Jung", "abstract": "The rise of smart factories has heightened the demand for automated\nmaintenance, and normal-data-based anomaly detection has proved particularly\neffective in environments where anomaly data are scarce. This method, which\ndoes not require anomaly data during training, has prompted researchers to\nfocus not only on detecting anomalies but also on classifying severity levels\nby using anomaly scores. However, the existing performance metrics, such as the\narea under the receiver operating characteristic curve (AUROC), do not\neffectively reflect the performance of models in classifying severity levels\nbased on anomaly scores. To address this limitation, we propose the weighted\nsum of the area under the receiver operating characteristic curve (WS-AUROC),\nwhich combines AUROC with a penalty for severity level differences. We\nconducted various experiments using different penalty assignment methods:\nuniform penalty regardless of severity level differences, penalty based on\nseverity level index differences, and penalty based on actual physical\nquantities that cause anomalies. The latter method was the most sensitive.\nAdditionally, we propose an anomaly detector that achieves clear separation of\ndistributions and outperforms the ablation models on the WS-AUROC and AUROC\nmetrics.", "arxiv_id": "2408.04817v1", "pdf_url": "http://arxiv.org/pdf/2408.04817v1", "abstract_url": "http://arxiv.org/abs/2408.04817v1", "primary_category": "cs.LG", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Performance Metric for Multiple Anomaly Score Distributions with Discrete Severity Levels", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:35.515088"}
{"title": "FUSE-ing Language Models: Zero-Shot Adapter Discovery for Prompt Optimization Across Tokenizers", "authors": "Joshua Nathaniel Williams, J. Zico Kolter", "abstract": "The widespread use of large language models has resulted in a multitude of\ntokenizers and embedding spaces, making knowledge transfer in prompt discovery\ntasks difficult. In this work, we propose FUSE (Flexible Unification of\nSemantic Embeddings), an inexpensive approach to approximating an adapter layer\nthat maps from one model's textual embedding space to another, even across\ndifferent tokenizers. We introduce a third-order tensor-based representation of\na model's embedding space that aligns semantic embeddings that have been split\napart by different tokenizers, and use this representation to derive an\napproximation of the gradient of one model's outputs with respect to another\nmodel's embedding space. We show the efficacy of our approach via\nmulti-objective optimization over vision-language and causal language models\nfor image captioning and sentiment-based image captioning.", "arxiv_id": "2408.04816v1", "pdf_url": "http://arxiv.org/pdf/2408.04816v1", "abstract_url": "http://arxiv.org/abs/2408.04816v1", "primary_category": "cs.CL", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "FUSE-ing Language Models: Zero-Shot Adapter Discovery for Prompt Optimization Across Tokenizers", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:37.526864"}
{"title": "Towards improving Alzheimer's intervention: a machine learning approach for biomarker detection through combining MEG and MRI pipelines", "authors": "Alwani Liyana Ahmad, Jose Sanchez-Bornot, Roberto C. Sotero, Damien Coyle, Zamzuri Idris, Ibrahima Faye", "abstract": "MEG are non invasive neuroimaging techniques with excellent temporal and\nspatial resolution, crucial for studying brain function in dementia and\nAlzheimer Disease. They identify changes in brain activity at various Alzheimer\nstages, including preclinical and prodromal phases. MEG may detect pathological\nchanges before clinical symptoms, offering potential biomarkers for\nintervention. This study evaluates classification techniques using MEG features\nto distinguish between healthy controls and mild cognitive impairment\nparticipants from the BioFIND study. We compare MEG based biomarkers with MRI\nbased anatomical features, both independently and combined. We used 3 Tesla MRI\nand MEG data from 324 BioFIND participants;158 MCI and 166 HC. Analyses were\nperformed using MATLAB with SPM12 and OSL toolboxes. Machine learning analyses,\nincluding 100 Monte Carlo replications of 10 fold cross validation, were\nconducted on sensor and source spaces. Combining MRI with MEG features achieved\nthe best performance; 0.76 accuracy and AUC of 0.82 for GLMNET using LCMV\nsource based MEG. MEG only analyses using LCMV and eLORETA also performed well,\nsuggesting that combining uncorrected MEG with z-score-corrected MRI features\nis optimal.", "arxiv_id": "2408.04815v1", "pdf_url": "http://arxiv.org/pdf/2408.04815v1", "abstract_url": "http://arxiv.org/abs/2408.04815v1", "primary_category": "cs.LG", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Towards improving Alzheimer's intervention: a machine learning approach for biomarker detection through combining MEG and MRI pipelines", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:38.276042"}
{"title": "A Novel Spatiotemporal Coupling Graph Convolutional Network", "authors": "Fanghui Bi", "abstract": "Dynamic Quality-of-Service (QoS) data capturing temporal variations in\nuser-service interactions, are essential source for service selection and user\nbehavior understanding. Approaches based on Latent Feature Analysis (LFA) have\nshown to be beneficial for discovering effective temporal patterns in QoS data.\nHowever, existing methods cannot well model the spatiality and temporality\nimplied in dynamic interactions in a unified form, causing abundant accuracy\nloss for missing QoS estimation. To address the problem, this paper presents a\nnovel Graph Convolutional Networks (GCNs)-based dynamic QoS estimator namely\nSpatiotemporal Coupling GCN (SCG) model with the three-fold ideas as below.\nFirst, SCG builds its dynamic graph convolution rules by incorporating\ngeneralized tensor product framework, for unified modeling of spatial and\ntemporal patterns. Second, SCG combines the heterogeneous GCN layer with tensor\nfactorization, for effective representation learning on bipartite user-service\ngraphs. Third, it further simplifies the dynamic GCN structure to lower the\ntraining difficulties. Extensive experiments have been conducted on two\nlarge-scale widely-adopted QoS datasets describing throughput and response\ntime. The results demonstrate that SCG realizes higher QoS estimation accuracy\ncompared with the state-of-the-arts, illustrating it can learn powerful\nrepresentations to users and cloud services.", "arxiv_id": "2408.07087v1", "pdf_url": "http://arxiv.org/pdf/2408.07087v1", "abstract_url": "http://arxiv.org/abs/2408.07087v1", "primary_category": "cs.LG", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "A Novel Spatiotemporal Coupling Graph Convolutional Network", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:39.095904"}
{"title": "UniBench: Visual Reasoning Requires Rethinking Vision-Language Beyond Scaling", "authors": "Haider Al-Tahan, Quentin Garrido, Randall Balestriero, Diane Bouchacourt, Caner Hazirbas, Mark Ibrahim", "abstract": "Significant research efforts have been made to scale and improve\nvision-language model (VLM) training approaches. Yet, with an ever-growing\nnumber of benchmarks, researchers are tasked with the heavy burden of\nimplementing each protocol, bearing a non-trivial computational cost, and\nmaking sense of how all these benchmarks translate into meaningful axes of\nprogress. To facilitate a systematic evaluation of VLM progress, we introduce\nUniBench: a unified implementation of 50+ VLM benchmarks spanning a\ncomprehensive range of carefully categorized capabilities from object\nrecognition to spatial awareness, counting, and much more. We showcase the\nutility of UniBench for measuring progress by evaluating nearly 60 publicly\navailable vision-language models, trained on scales of up to 12.8B samples. We\nfind that while scaling training data or model size can boost many\nvision-language model capabilities, scaling offers little benefit for reasoning\nor relations. Surprisingly, we also discover today's best VLMs struggle on\nsimple digit recognition and counting tasks, e.g. MNIST, which much simpler\nnetworks can solve. Where scale falls short, we find that more precise\ninterventions, such as data quality or tailored-learning objectives offer more\npromise. For practitioners, we also offer guidance on selecting a suitable VLM\nfor a given application. Finally, we release an easy-to-run UniBench code-base\nwith the full set of 50+ benchmarks and comparisons across 59 models as well as\na distilled, representative set of benchmarks that runs in 5 minutes on a\nsingle GPU.", "arxiv_id": "2408.04810v1", "pdf_url": "http://arxiv.org/pdf/2408.04810v1", "abstract_url": "http://arxiv.org/abs/2408.04810v1", "primary_category": "cs.CV", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "UniBench: Visual Reasoning Requires Rethinking Vision-Language Beyond Scaling", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:41.040980"}
{"title": "On the Geometry of Deep Learning", "authors": "Randall Balestriero, Ahmed Imtiaz Humayun, Richard Baraniuk", "abstract": "In this paper, we overview one promising avenue of progress at the\nmathematical foundation of deep learning: the connection between deep networks\nand function approximation by affine splines (continuous piecewise linear\nfunctions in multiple dimensions). In particular, we will overview work over\nthe past decade on understanding certain geometrical properties of a deep\nnetwork's affine spline mapping, in particular how it tessellates its input\nspace. As we will see, the affine spline connection and geometrical viewpoint\nprovide a powerful portal through which to view, analyze, and improve the inner\nworkings of a deep network.", "arxiv_id": "2408.04809v1", "pdf_url": "http://arxiv.org/pdf/2408.04809v1", "abstract_url": "http://arxiv.org/abs/2408.04809v1", "primary_category": "cs.LG", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "On the Geometry of Deep Learning", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:41.860256"}
{"title": "Scaling Deep Learning Computation over the Inter-Core Connected Intelligence Processor", "authors": "Yiqi Liu, Yuqi Xue, Yu Cheng, Lingxiao Ma, Ziming Miao, Jilong Xue, Jian Huang", "abstract": "As AI chips incorporate numerous parallelized cores to scale deep learning\n(DL) computing, inter-core communication is enabled recently by employing\nhigh-bandwidth and low-latency interconnect links on the chip (e.g., Graphcore\nIPU). It allows each core to directly access the fast scratchpad memory in\nother cores, which enables new parallel computing paradigms. However, without\nproper support for the scalable inter-core connections in current DL compilers,\nit is hard for developers to exploit the benefits of this new architecture.\n  We present T10, the first DL compiler to exploit the inter-core communication\nbandwidth and distributed on-chip memory on AI chips. To formulate the\ncomputation and communication patterns of tensor operators in this new\narchitecture, T10 introduces a distributed tensor abstraction rTensor. T10 maps\na DNN model to execution plans with a generalized compute-shift pattern, by\npartitioning DNN computation into sub-operators and mapping them to cores, so\nthat the cores can exchange data following predictable patterns. T10 makes\nglobally optimized trade-offs between on-chip memory consumption and inter-core\ncommunication overhead, selects the best execution plan from a vast\noptimization space, and alleviates unnecessary inter-core communications. Our\nevaluation with a real inter-core connected AI chip, the Graphcore IPU, shows\nup to 3.3$\\times$ performance improvement, and scalability support for larger\nmodels, compared to state-of-the-art DL compilers and vendor libraries.", "arxiv_id": "2408.04808v1", "pdf_url": "http://arxiv.org/pdf/2408.04808v1", "abstract_url": "http://arxiv.org/abs/2408.04808v1", "primary_category": "cs.DC", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Scaling Deep Learning Computation over the Inter-Core Connected Intelligence Processor", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:42.885186"}
{"title": "Improved Robustness for Deep Learning-based Segmentation of Multi-Center Myocardial Perfusion MRI Datasets Using Data Adaptive Uncertainty-guided Space-time Analysis", "authors": "Dilek M. Yalcinkaya, Khalid Youssef, Bobak Heydari, Janet Wei, Noel Bairey Merz, Robert Judd, Rohan Dharmakumar, Orlando P. Simonetti, Jonathan W. Weinsaft, Subha V. Raman, Behzad Sharif", "abstract": "Background. Fully automatic analysis of myocardial perfusion MRI datasets\nenables rapid and objective reporting of stress/rest studies in patients with\nsuspected ischemic heart disease. Developing deep learning techniques that can\nanalyze multi-center datasets despite limited training data and variations in\nsoftware and hardware is an ongoing challenge.\n  Methods. Datasets from 3 medical centers acquired at 3T (n = 150 subjects)\nwere included: an internal dataset (inD; n = 95) and two external datasets\n(exDs; n = 55) used for evaluating the robustness of the trained deep neural\nnetwork (DNN) models against differences in pulse sequence (exD-1) and scanner\nvendor (exD-2). A subset of inD (n = 85) was used for training/validation of a\npool of DNNs for segmentation, all using the same spatiotemporal U-Net\narchitecture and hyperparameters but with different parameter initializations.\nWe employed a space-time sliding-patch analysis approach that automatically\nyields a pixel-wise \"uncertainty map\" as a byproduct of the segmentation\nprocess. In our approach, a given test case is segmented by all members of the\nDNN pool and the resulting uncertainty maps are leveraged to automatically\nselect the \"best\" one among the pool of solutions.\n  Results. The proposed DAUGS analysis approach performed similarly to the\nestablished approach on the internal dataset (p = n.s.) whereas it\nsignificantly outperformed on the external datasets (p < 0.005 for exD-1 and\nexD-2). Moreover, the number of image series with \"failed\" segmentation was\nsignificantly lower for the proposed vs. the established approach (4.3% vs.\n17.1%, p < 0.0005).\n  Conclusions. The proposed DAUGS analysis approach has the potential to\nimprove the robustness of deep learning methods for segmentation of\nmulti-center stress perfusion datasets with variations in the choice of pulse\nsequence, site location or scanner vendor.", "arxiv_id": "2408.04805v1", "pdf_url": "http://arxiv.org/pdf/2408.04805v1", "abstract_url": "http://arxiv.org/abs/2408.04805v1", "primary_category": "eess.IV", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Improved Robustness for Deep Learning-based Segmentation of Multi-Center Myocardial Perfusion MRI Datasets Using Data Adaptive Uncertainty-guided Space-time Analysis", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:44.728439"}
{"title": "AI and Machine Learning Driven Indoor Localization and Navigation with Mobile Embedded Systems", "authors": "Sudeep Pasricha", "abstract": "Indoor navigation is a foundational technology to assist the tracking and\nlocalization of humans, autonomous vehicles, drones, and robots in indoor\nspaces. Due to the lack of penetration of GPS signals in buildings,\nsubterranean locales, and dense urban environments, indoor navigation solutions\ntypically make use of ubiquitous wireless signals (e.g., WiFi) and sensors in\nmobile embedded systems to perform tracking and localization. This article\nprovides an overview of the many challenges facing state-of-the-art indoor\nnavigation solutions, and then describes how AI algorithms deployed on mobile\nembedded systems can overcome these challenges.", "arxiv_id": "2408.04797v1", "pdf_url": "http://arxiv.org/pdf/2408.04797v1", "abstract_url": "http://arxiv.org/abs/2408.04797v1", "primary_category": "cs.LG", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "AI and Machine Learning Driven Indoor Localization and Navigation with Mobile Embedded Systems", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:45.595971"}
{"title": "A Density Ratio Super Learner", "authors": "Wencheng Wu, David Benkeser", "abstract": "The estimation of the ratio of two density probability functions is of great\ninterest in many statistics fields, including causal inference. In this study,\nwe develop an ensemble estimator of density ratios with a novel loss function\nbased on super learning. We show that this novel loss function is qualified for\nbuilding super learners. Two simulations corresponding to mediation analysis\nand longitudinal modified treatment policy in causal inference, where density\nratios are nuisance parameters, are conducted to show our density ratio super\nlearner's performance empirically.", "arxiv_id": "2408.04796v1", "pdf_url": "http://arxiv.org/pdf/2408.04796v1", "abstract_url": "http://arxiv.org/abs/2408.04796v1", "primary_category": "stat.ML", "published_date": "2024-08-09", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "A Density Ratio Super Learner", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:47.186090"}
{"title": "Segmentation of Mental Foramen in Orthopantomographs: A Deep Learning Approach", "authors": "Haider Raza, Mohsin Ali, Vishal Krishna Singh, Agustin Wahjuningrum, Rachel Sarig, Akhilanand Chaurasia", "abstract": "Precise identification and detection of the Mental Foramen are crucial in\ndentistry, impacting procedures such as impacted tooth removal, cyst surgeries,\nand implants. Accurately identifying this anatomical feature facilitates\npost-surgery issues and improves patient outcomes. Moreover, this study aims to\naccelerate dental procedures, elevating patient care and healthcare efficiency\nin dentistry. This research used Deep Learning methods to accurately detect and\nsegment the Mental Foramen from panoramic radiograph images. Two mask types,\ncircular and square, were used during model training. Multiple segmentation\nmodels were employed to identify and segment the Mental Foramen, and their\neffectiveness was evaluated using diverse metrics. An in-house dataset\ncomprising 1000 panoramic radiographs was created for this study. Our\nexperiments demonstrated that the Classical UNet model performed exceptionally\nwell on the test data, achieving a Dice Coefficient of 0.79 and an Intersection\nover Union (IoU) of 0.67. Moreover, ResUNet++ and UNet Attention models showed\ncompetitive performance, with Dice scores of 0.675 and 0.676, and IoU values of\n0.683 and 0.671, respectively. We also investigated transfer learning models\nwith varied backbone architectures, finding LinkNet to produce the best\noutcomes. In conclusion, our research highlights the efficacy of the classical\nUnet model in accurately identifying and outlining the Mental Foramen in\npanoramic radiographs. While vital, this task is comparatively simpler than\nsegmenting complex medical datasets such as brain tumours or skin cancer, given\ntheir diverse sizes and shapes. This research also holds value in optimizing\ndental practice, benefiting practitioners and patients.", "arxiv_id": "2408.04763v1", "pdf_url": "http://arxiv.org/pdf/2408.04763v1", "abstract_url": "http://arxiv.org/abs/2408.04763v1", "primary_category": "eess.IV", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Segmentation of Mental Foramen in Orthopantomographs: A Deep Learning Approach", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:48.312238"}
{"title": "Confident magnitude-based neural network pruning", "authors": "Joaquin Alvarez", "abstract": "Pruning neural networks has proven to be a successful approach to increase\nthe efficiency and reduce the memory storage of deep learning models without\ncompromising performance. Previous literature has shown that it is possible to\nachieve a sizable reduction in the number of parameters of a deep neural\nnetwork without deteriorating its predictive capacity in one-shot pruning\nregimes. Our work builds beyond this background in order to provide rigorous\nuncertainty quantification for pruning neural networks reliably, which has not\nbeen addressed to a great extent in previous literature focusing on pruning\nmethods in computer vision settings. We leverage recent techniques on\ndistribution-free uncertainty quantification to provide finite-sample\nstatistical guarantees to compress deep neural networks, while maintaining high\nperformance. Moreover, this work presents experiments in computer vision tasks\nto illustrate how uncertainty-aware pruning is a useful approach to deploy\nsparse neural networks safely.", "arxiv_id": "2408.04759v1", "pdf_url": "http://arxiv.org/pdf/2408.04759v1", "abstract_url": "http://arxiv.org/abs/2408.04759v1", "primary_category": "cs.LG", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Confident magnitude-based neural network pruning", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:49.553215"}
{"title": "Quantifying the Corpus Bias Problem in Automatic Music Transcription Systems", "authors": "Luk\u00e1\u0161 Samuel Mart\u00e1k, Patricia Hu, Gerhard Widmer", "abstract": "Automatic Music Transcription (AMT) is the task of recognizing notes in audio\nrecordings of music. The State-of-the-Art (SotA) benchmarks have been dominated\nby deep learning systems. Due to the scarcity of high quality data, they are\nusually trained and evaluated exclusively or predominantly on classical piano\nmusic. Unfortunately, that hinders our ability to understand how they\ngeneralize to other music. Previous works have revealed several aspects of\nmemorization and overfitting in these systems. We identify two primary sources\nof distribution shift: the music, and the sound. Complementing recent results\non the sound axis (i.e. acoustics, timbre), we investigate the musical one\n(i.e. note combinations, dynamics, genre). We evaluate the performance of\nseveral SotA AMT systems on two new experimental test sets which we carefully\nconstruct to emulate different levels of musical distribution shift. Our\nresults reveal a stark performance gap, shedding further light on the Corpus\nBias problem, and the extent to which it continues to trouble these systems.", "arxiv_id": "2408.04737v1", "pdf_url": "http://arxiv.org/pdf/2408.04737v1", "abstract_url": "http://arxiv.org/abs/2408.04737v1", "primary_category": "cs.SD", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Quantifying the Corpus Bias Problem in Automatic Music Transcription Systems", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:50.328666"}
{"title": "Learning the Simplicity of Scattering Amplitudes", "authors": "Clifford Cheung, Aur\u00e9lien Dersy, Matthew D. Schwartz", "abstract": "The simplification and reorganization of complex expressions lies at the core\nof scientific progress, particularly in theoretical high-energy physics. This\nwork explores the application of machine learning to a particular facet of this\nchallenge: the task of simplifying scattering amplitudes expressed in terms of\nspinor-helicity variables. We demonstrate that an encoder-decoder transformer\narchitecture achieves impressive simplification capabilities for expressions\ncomposed of handfuls of terms. Lengthier expressions are implemented in an\nadditional embedding network, trained using contrastive learning, which\nisolates subexpressions that are more likely to simplify. The resulting\nframework is capable of reducing expressions with hundreds of terms - a regular\noccurrence in quantum field theory calculations - to vastly simpler equivalent\nexpressions. Starting from lengthy input expressions, our networks can generate\nthe Parke-Taylor formula for five-point gluon scattering, as well as new\ncompact expressions for five-point amplitudes involving scalars and gravitons.\nAn interactive demonstration can be found at\nhttps://spinorhelicity.streamlit.app .", "arxiv_id": "2408.04720v1", "pdf_url": "http://arxiv.org/pdf/2408.04720v1", "abstract_url": "http://arxiv.org/abs/2408.04720v1", "primary_category": "hep-th", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Learning the Simplicity of Scattering Amplitudes", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:51.179527"}
{"title": "Zero-Shot Uncertainty Quantification using Diffusion Probabilistic Models", "authors": "Dule Shu, Amir Barati Farimani", "abstract": "The success of diffusion probabilistic models in generative tasks, such as\ntext-to-image generation, has motivated the exploration of their application to\nregression problems commonly encountered in scientific computing and various\nother domains. In this context, the use of diffusion regression models for\nensemble prediction is becoming a practice with increasing popularity. Under\nsuch background, we conducted a study to quantitatively evaluate the\neffectiveness of ensemble methods on solving different regression problems\nusing diffusion models. We consider the ensemble prediction of a diffusion\nmodel as a means for zero-shot uncertainty quantification, since the diffusion\nmodels in our study are not trained with a loss function containing any\nuncertainty estimation. Through extensive experiments on 1D and 2D data, we\ndemonstrate that ensemble methods consistently improve model prediction\naccuracy across various regression tasks. Notably, we observed a larger\naccuracy gain in auto-regressive prediction compared with point-wise\nprediction, and that enhancements take place in both the mean-square error and\nthe physics-informed loss. Additionally, we reveal a statistical correlation\nbetween ensemble prediction error and ensemble variance, offering insights into\nbalancing computational complexity with prediction accuracy and monitoring\nprediction confidence in practical applications where the ground truth is\nunknown. Our study provides a comprehensive view of the utility of diffusion\nensembles, serving as a useful reference for practitioners employing diffusion\nmodels in regression problem-solving.", "arxiv_id": "2408.04718v1", "pdf_url": "http://arxiv.org/pdf/2408.04718v1", "abstract_url": "http://arxiv.org/abs/2408.04718v1", "primary_category": "cs.LG", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Zero-Shot Uncertainty Quantification using Diffusion Probabilistic Models", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:51.998788"}
{"title": "DyGMamba: Efficiently Modeling Long-Term Temporal Dependency on Continuous-Time Dynamic Graphs with State Space Models", "authors": "Zifeng Ding, Yifeng Li, Yuan He, Antonio Norelli, Jingcheng Wu, Volker Tresp, Yunpu Ma, Michael Bronstein", "abstract": "Learning useful representations for continuous-time dynamic graphs (CTDGs) is\nchallenging, due to the concurrent need to span long node interaction histories\nand grasp nuanced temporal details. In particular, two problems emerge: (1)\nEncoding longer histories requires more computational resources, making it\ncrucial for CTDG models to maintain low computational complexity to ensure\nefficiency; (2) Meanwhile, more powerful models are needed to identify and\nselect the most critical temporal information within the extended context\nprovided by longer histories. To address these problems, we propose a CTDG\nrepresentation learning model named DyGMamba, originating from the popular\nMamba state space model (SSM). DyGMamba first leverages a node-level SSM to\nencode the sequence of historical node interactions. Another time-level SSM is\nthen employed to exploit the temporal patterns hidden in the historical graph,\nwhere its output is used to dynamically select the critical information from\nthe interaction history. We validate DyGMamba experimentally on the dynamic\nlink prediction task. The results show that our model achieves state-of-the-art\nin most cases. DyGMamba also maintains high efficiency in terms of\ncomputational resources, making it possible to capture long temporal\ndependencies with a limited computation budget.", "arxiv_id": "2408.04713v1", "pdf_url": "http://arxiv.org/pdf/2408.04713v1", "abstract_url": "http://arxiv.org/abs/2408.04713v1", "primary_category": "cs.LG", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "DyGMamba: Efficiently Modeling Long-Term Temporal Dependency on Continuous-Time Dynamic Graphs with State Space Models", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:53.024422"}
{"title": "Overlay-based Decentralized Federated Learning in Bandwidth-limited Networks", "authors": "Yudi Huang, Tingyang Sun, Ting He", "abstract": "The emerging machine learning paradigm of decentralized federated learning\n(DFL) has the promise of greatly boosting the deployment of artificial\nintelligence (AI) by directly learning across distributed agents without\ncentralized coordination. Despite significant efforts on improving the\ncommunication efficiency of DFL, most existing solutions were based on the\nsimplistic assumption that neighboring agents are physically adjacent in the\nunderlying communication network, which fails to correctly capture the\ncommunication cost when learning over a general bandwidth-limited network, as\nencountered in many edge networks. In this work, we address this gap by\nleveraging recent advances in network tomography to jointly design the\ncommunication demands and the communication schedule for overlay-based DFL in\nbandwidth-limited networks without requiring explicit cooperation from the\nunderlying network. By carefully analyzing the structure of our problem, we\ndecompose it into a series of optimization problems that can each be solved\nefficiently, to collectively minimize the total training time. Extensive\ndata-driven simulations show that our solution can significantly accelerate DFL\nin comparison with state-of-the-art designs.", "arxiv_id": "2408.04705v1", "pdf_url": "http://arxiv.org/pdf/2408.04705v1", "abstract_url": "http://arxiv.org/abs/2408.04705v1", "primary_category": "cs.LG", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Overlay-based Decentralized Federated Learning in Bandwidth-limited Networks", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:53.843095"}
{"title": "Transformer Explainer: Interactive Learning of Text-Generative Models", "authors": "Aeree Cho, Grace C. Kim, Alexander Karpekov, Alec Helbling, Zijie J. Wang, Seongmin Lee, Benjamin Hoover, Duen Horng Chau", "abstract": "Transformers have revolutionized machine learning, yet their inner workings\nremain opaque to many. We present Transformer Explainer, an interactive\nvisualization tool designed for non-experts to learn about Transformers through\nthe GPT-2 model. Our tool helps users understand complex Transformer concepts\nby integrating a model overview and enabling smooth transitions across\nabstraction levels of mathematical operations and model structures. It runs a\nlive GPT-2 instance locally in the user's browser, empowering users to\nexperiment with their own input and observe in real-time how the internal\ncomponents and parameters of the Transformer work together to predict the next\ntokens. Our tool requires no installation or special hardware, broadening the\npublic's education access to modern generative AI techniques. Our open-sourced\ntool is available at https://poloclub.github.io/transformer-explainer/. A video\ndemo is available at https://youtu.be/ECR4oAwocjs.", "arxiv_id": "2408.04619v1", "pdf_url": "http://arxiv.org/pdf/2408.04619v1", "abstract_url": "http://arxiv.org/abs/2408.04619v1", "primary_category": "cs.LG", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Transformer Explainer: Interactive Learning of Text-Generative Models", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:54.559453"}
{"title": "Better Alignment with Instruction Back-and-Forth Translation", "authors": "Thao Nguyen, Jeffrey Li, Sewoong Oh, Ludwig Schmidt, Jason Weston, Luke Zettlemoyer, Xian Li", "abstract": "We propose a new method, instruction back-and-forth translation, to construct\nhigh-quality synthetic data grounded in world knowledge for aligning large\nlanguage models (LLMs). Given documents from a web corpus, we generate and\ncurate synthetic instructions using the backtranslation approach proposed by Li\net al.(2023a), and rewrite the responses to improve their quality further based\non the initial documents. Fine-tuning with the resulting (backtranslated\ninstruction, rewritten response) pairs yields higher win rates on AlpacaEval\nthan using other common instruction datasets such as Humpback, ShareGPT, Open\nOrca, Alpaca-GPT4 and Self-instruct. We also demonstrate that rewriting the\nresponses with an LLM outperforms direct distillation, and the two generated\ntext distributions exhibit significant distinction in embedding space. Further\nanalysis shows that our backtranslated instructions are of higher quality than\nother sources of synthetic instructions, while our responses are more diverse\nand complex than those obtained from distillation. Overall we find that\ninstruction back-and-forth translation combines the best of both worlds --\nmaking use of the information diversity and quantity found on the web, while\nensuring the quality of the responses which is necessary for effective\nalignment.", "arxiv_id": "2408.04614v2", "pdf_url": "http://arxiv.org/pdf/2408.04614v2", "abstract_url": "http://arxiv.org/abs/2408.04614v2", "primary_category": "cs.CL", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Better Alignment with Instruction Back-and-Forth Translation", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:55.992850"}
{"title": "Risk and cross validation in ridge regression with correlated samples", "authors": "Alexander Atanasov, Jacob A. Zavatone-Veth, Cengiz Pehlevan", "abstract": "Recent years have seen substantial advances in our understanding of\nhigh-dimensional ridge regression, but existing theories assume that training\nexamples are independent. By leveraging recent techniques from random matrix\ntheory and free probability, we provide sharp asymptotics for the in- and\nout-of-sample risks of ridge regression when the data points have arbitrary\ncorrelations. We demonstrate that in this setting, the generalized cross\nvalidation estimator (GCV) fails to correctly predict the out-of-sample risk.\nHowever, in the case where the noise residuals have the same correlations as\nthe data points, one can modify the GCV to yield an efficiently-computable\nunbiased estimator that concentrates in the high-dimensional limit, which we\ndub CorrGCV. We further extend our asymptotic analysis to the case where the\ntest point has nontrivial correlations with the training set, a setting often\nencountered in time series forecasting. Assuming knowledge of the correlation\nstructure of the time series, this again yields an extension of the GCV\nestimator, and sharply characterizes the degree to which such test points yield\nan overly optimistic prediction of long-time risk. We validate the predictions\nof our theory across a variety of high dimensional data.", "arxiv_id": "2408.04607v2", "pdf_url": "http://arxiv.org/pdf/2408.04607v2", "abstract_url": "http://arxiv.org/abs/2408.04607v2", "primary_category": "stat.ML", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Risk and cross validation in ridge regression with correlated samples", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:56.912315"}
{"title": "Inference with the Upper Confidence Bound Algorithm", "authors": "Koulik Khamaru, Cun-Hui Zhang", "abstract": "In this paper, we discuss the asymptotic behavior of the Upper Confidence\nBound (UCB) algorithm in the context of multiarmed bandit problems and discuss\nits implication in downstream inferential tasks. While inferential tasks become\nchallenging when data is collected in a sequential manner, we argue that this\nproblem can be alleviated when the sequential algorithm at hand satisfies\ncertain stability property. This notion of stability is motivated from the\nseminal work of Lai and Wei (1982). Our first main result shows that such a\nstability property is always satisfied for the UCB algorithm, and as a result\nthe sample means for each arm are asymptotically normal. Next, we examine the\nstability properties of the UCB algorithm when the number of arms $K$ is\nallowed to grow with the number of arm pulls $T$. We show that in such a case\nthe arms are stable when $\\frac{\\log K}{\\log T} \\rightarrow 0$, and the number\nof near-optimal arms are large.", "arxiv_id": "2408.04595v1", "pdf_url": "http://arxiv.org/pdf/2408.04595v1", "abstract_url": "http://arxiv.org/abs/2408.04595v1", "primary_category": "stat.ML", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Inference with the Upper Confidence Bound Algorithm", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:57.839033"}
{"title": "Learn To Learn More Precisely", "authors": "Runxi Cheng, Yongxian Wei, Xianglong He, Wanyun Zhu, Songsong Huang, Fei Richard Yu, Fei Ma, Chun Yuan", "abstract": "Meta-learning has been extensively applied in the domains of few-shot\nlearning and fast adaptation, achieving remarkable performance. While\nMeta-learning methods like Model-Agnostic Meta-Learning (MAML) and its variants\nprovide a good set of initial parameters for the model, the model still tends\nto learn shortcut features, which leads to poor generalization. In this paper,\nwe propose the formal conception of \"learn to learn more precisely\", which aims\nto make the model learn precise target knowledge from data and reduce the\neffect of noisy knowledge, such as background and noise. To achieve this\ntarget, we proposed a simple and effective meta-learning framework named Meta\nSelf-Distillation(MSD) to maximize the consistency of learned knowledge,\nenhancing the models' ability to learn precise target knowledge. In the inner\nloop, MSD uses different augmented views of the same support data to update the\nmodel respectively. Then in the outer loop, MSD utilizes the same query data to\noptimize the consistency of learned knowledge, enhancing the model's ability to\nlearn more precisely. Our experiment demonstrates that MSD exhibits remarkable\nperformance in few-shot classification tasks in both standard and augmented\nscenarios, effectively boosting the accuracy and consistency of knowledge\nlearned by the model.", "arxiv_id": "2408.04590v1", "pdf_url": "http://arxiv.org/pdf/2408.04590v1", "abstract_url": "http://arxiv.org/abs/2408.04590v1", "primary_category": "cs.LG", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Learn To Learn More Precisely", "response": "RELEVANT", "timestamp": "2024-08-19T13:40:58.757181"}
{"title": "Sampling for View Synthesis: From Local Light Field Fusion to Neural Radiance Fields and Beyond", "authors": "Ravi Ramamoorthi", "abstract": "Capturing and rendering novel views of complex real-world scenes is a\nlong-standing problem in computer graphics and vision, with applications in\naugmented and virtual reality, immersive experiences and 3D photography. The\nadvent of deep learning has enabled revolutionary advances in this area,\nclassically known as image-based rendering. However, previous approaches\nrequire intractably dense view sampling or provide little or no guidance for\nhow users should sample views of a scene to reliably render high-quality novel\nviews. Local light field fusion proposes an algorithm for practical view\nsynthesis from an irregular grid of sampled views that first expands each\nsampled view into a local light field via a multiplane image scene\nrepresentation, then renders novel views by blending adjacent local light\nfields. Crucially, we extend traditional plenoptic sampling theory to derive a\nbound that specifies precisely how densely users should sample views of a given\nscene when using our algorithm. We achieve the perceptual quality of Nyquist\nrate view sampling while using up to 4000x fewer views. Subsequent developments\nhave led to new scene representations for deep learning with view synthesis,\nnotably neural radiance fields, but the problem of sparse view synthesis from a\nsmall number of images has only grown in importance. We reprise some of the\nrecent results on sparse and even single image view synthesis, while posing the\nquestion of whether prescriptive sampling guidelines are feasible for the new\ngeneration of image-based rendering algorithms.", "arxiv_id": "2408.04586v1", "pdf_url": "http://arxiv.org/pdf/2408.04586v1", "abstract_url": "http://arxiv.org/abs/2408.04586v1", "primary_category": "cs.GR", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Sampling for View Synthesis: From Local Light Field Fusion to Neural Radiance Fields and Beyond", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:00.066638"}
{"title": "Unveiling the Power of Sparse Neural Networks for Feature Selection", "authors": "Zahra Atashgahi, Tennison Liu, Mykola Pechenizkiy, Raymond Veldhuis, Decebal Constantin Mocanu, Mihaela van der Schaar", "abstract": "Sparse Neural Networks (SNNs) have emerged as powerful tools for efficient\nfeature selection. Leveraging the dynamic sparse training (DST) algorithms\nwithin SNNs has demonstrated promising feature selection capabilities while\ndrastically reducing computational overheads. Despite these advancements,\nseveral critical aspects remain insufficiently explored for feature selection.\nQuestions persist regarding the choice of the DST algorithm for network\ntraining, the choice of metric for ranking features/neurons, and the\ncomparative performance of these methods across diverse datasets when compared\nto dense networks. This paper addresses these gaps by presenting a\ncomprehensive systematic analysis of feature selection with sparse neural\nnetworks. Moreover, we introduce a novel metric considering sparse neural\nnetwork characteristics, which is designed to quantify feature importance\nwithin the context of SNNs. Our findings show that feature selection with SNNs\ntrained with DST algorithms can achieve, on average, more than $50\\%$ memory\nand $55\\%$ FLOPs reduction compared to the dense networks, while outperforming\nthem in terms of the quality of the selected features. Our code and the\nsupplementary material are available on GitHub\n(\\url{https://github.com/zahraatashgahi/Neuron-Attribution}).", "arxiv_id": "2408.04583v1", "pdf_url": "http://arxiv.org/pdf/2408.04583v1", "abstract_url": "http://arxiv.org/abs/2408.04583v1", "primary_category": "cs.LG", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Unveiling the Power of Sparse Neural Networks for Feature Selection", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:00.909999"}
{"title": "Mathematical Programming For Adaptive Experiments", "authors": "Ethan Che, Daniel R. Jiang, Hongseok Namkoong, Jimmy Wang", "abstract": "Adaptive experimentation can significantly improve statistical power, but\nstandard algorithms overlook important practical issues including batched and\ndelayed feedback, personalization, non-stationarity, multiple objectives, and\nconstraints. To address these issues, the current algorithm design paradigm\ncrafts tailored methods for each problem instance. Since it is infeasible to\ndevise novel algorithms for every real-world instance, practitioners often have\nto resort to suboptimal approximations that do not address all of their\nchallenges. Moving away from developing bespoke algorithms for each setting, we\npresent a mathematical programming view of adaptive experimentation that can\nflexibly incorporate a wide range of objectives, constraints, and statistical\nprocedures. By formulating a dynamic program in the batched limit, our modeling\nframework enables the use of scalable optimization methods (e.g., SGD and\nauto-differentiation) to solve for treatment allocations. We evaluate our\nframework on benchmarks modeled after practical challenges such as\nnon-stationarity, personalization, multi-objectives, and constraints. Unlike\nbespoke algorithms such as modified variants of Thomson sampling, our\nmathematical programming approach provides remarkably robust performance across\ninstances.", "arxiv_id": "2408.04570v1", "pdf_url": "http://arxiv.org/pdf/2408.04570v1", "abstract_url": "http://arxiv.org/abs/2408.04570v1", "primary_category": "cs.LG", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Mathematical Programming For Adaptive Experiments", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:01.939436"}
{"title": "Activation thresholds and expressiveness of polynomial neural networks", "authors": "Bella Finkel, Jose Israel Rodriguez, Chenxi Wu, Thomas Yahl", "abstract": "Polynomial neural networks have been implemented in a range of applications\nand present an advantageous framework for theoretical machine learning. A\npolynomial neural network of fixed architecture and activation degree gives an\nalgebraic map from the network's weights to a set of polynomials. The image of\nthis map is the space of functions representable by the network. Its Zariski\nclosure is an affine variety known as a neurovariety. The dimension of a\npolynomial neural network's neurovariety provides a measure of its\nexpressivity. In this work, we introduce the notion of the activation threshold\nof a network architecture which expresses when the dimension of a neurovariety\nachieves its theoretical maximum. In addition, we prove expressiveness results\nfor polynomial neural networks with equi-width~architectures.", "arxiv_id": "2408.04569v1", "pdf_url": "http://arxiv.org/pdf/2408.04569v1", "abstract_url": "http://arxiv.org/abs/2408.04569v1", "primary_category": "cs.LG", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Activation thresholds and expressiveness of polynomial neural networks", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:02.955029"}
{"title": "Understanding the Performance and Estimating the Cost of LLM Fine-Tuning", "authors": "Yuchen Xia, Jiho Kim, Yuhan Chen, Haojie Ye, Souvik Kundu, Cong Hao, Nishil Talati", "abstract": "Due to the cost-prohibitive nature of training Large Language Models (LLMs),\nfine-tuning has emerged as an attractive alternative for specializing LLMs for\nspecific tasks using limited compute resources in a cost-effective manner. In\nthis paper, we characterize sparse Mixture of Experts (MoE) based LLM\nfine-tuning to understand their accuracy and runtime performance on a single\nGPU. Our evaluation provides unique insights into the training efficacy of\nsparse and dense versions of MoE models, as well as their runtime\ncharacteristics, including maximum batch size, execution time breakdown,\nend-to-end throughput, GPU hardware utilization, and load distribution. Our\nstudy identifies the optimization of the MoE layer as crucial for further\nimproving the performance of LLM fine-tuning. Using our profiling results, we\nalso develop and validate an analytical model to estimate the cost of LLM\nfine-tuning on the cloud. This model, based on parameters of the model and GPU\narchitecture, estimates LLM throughput and the cost of training, aiding\npractitioners in industry and academia to budget the cost of fine-tuning a\nspecific model.", "arxiv_id": "2408.04693v1", "pdf_url": "http://arxiv.org/pdf/2408.04693v1", "abstract_url": "http://arxiv.org/abs/2408.04693v1", "primary_category": "cs.CL", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Understanding the Performance and Estimating the Cost of LLM Fine-Tuning", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:04.103345"}
{"title": "Bias-Aware Low-Rank Adaptation: Mitigating Catastrophic Inheritance of Large Language Models", "authors": "Yupeng Chang, Yi Chang, Yuan Wu", "abstract": "Large language models (LLMs) have exhibited remarkable proficiency across a\ndiverse array of natural language processing (NLP) tasks. However, adapting\nLLMs to downstream applications typically necessitates computationally\nintensive and memory-demanding fine-tuning procedures. To mitigate these\nburdens, parameter-efficient fine-tuning (PEFT) techniques have emerged as a\npromising approach to tailor LLMs with minimal computational overhead. While\nPEFT methods offer substantial advantages, they do not fully address the\npervasive issue of bias propagation from pre-training data. In this work, we\nintroduce Bias-Aware Low-Rank Adaptation (BA-LoRA), a novel PEFT method\ndesigned to counteract bias inheritance. BA-LoRA incorporates three distinct\nregularization terms: (1) consistency regularizer, (2) diversity regularizer,\nand (3) singular vector decomposition regularizer. These regularizers\ncollectively aim to improve the generative models' consistency, diversity, and\ngeneralization capabilities during the fine-tuning process. Through extensive\nexperiments on a variety of natural language understanding (NLU) and natural\nlanguage generation (NLG) tasks, employing prominent LLMs such as LLaMA,\nMistral, and Gemma, we demonstrate that BA-LoRA surpasses the performance of\nLoRA and its state-of-the-art variants. Moreover, our method effectively\nmitigates the deleterious effects of pre-training bias, leading to more\nreliable and robust model outputs. The code is available at\nhttps://github.com/cyp-jlu-ai/BA-LoRA.", "arxiv_id": "2408.04556v1", "pdf_url": "http://arxiv.org/pdf/2408.04556v1", "abstract_url": "http://arxiv.org/abs/2408.04556v1", "primary_category": "cs.CL", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Bias-Aware Low-Rank Adaptation: Mitigating Catastrophic Inheritance of Large Language Models", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:05.083668"}
{"title": "Quantum Machine Learning: Performance and Security Implications in Real-World Applications", "authors": "Zhengping Jay Luo, Tyler Stewart, Mourya Narasareddygari, Rui Duan, Shangqing Zhao", "abstract": "Quantum computing has garnered significant attention in recent years from\nboth academia and industry due to its potential to achieve a \"quantum\nadvantage\" over classical computers. The advent of quantum computing introduces\nnew challenges for security and privacy. This poster explores the performance\nand security implications of quantum computing through a case study of machine\nlearning in a real-world application. We compare the performance of quantum\nmachine learning (QML) algorithms to their classical counterparts using the\nAlzheimer's disease dataset. Our results indicate that QML algorithms show\npromising potential while they still have not surpassed classical algorithms in\nterms of learning capability and convergence difficulty, and running quantum\nalgorithms through simulations on classical computers requires significantly\nlarge memory space and CPU time. Our study also indicates that QMLs have\ninherited vulnerabilities from classical machine learning algorithms while also\nintroduce new attack vectors.", "arxiv_id": "2408.04543v1", "pdf_url": "http://arxiv.org/pdf/2408.04543v1", "abstract_url": "http://arxiv.org/abs/2408.04543v1", "primary_category": "quant-ph", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Quantum Machine Learning: Performance and Security Implications in Real-World Applications", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:05.924338"}
{"title": "How Transformers Utilize Multi-Head Attention in In-Context Learning? A Case Study on Sparse Linear Regression", "authors": "Xingwu Chen, Lei Zhao, Difan Zou", "abstract": "Despite the remarkable success of transformer-based models in various\nreal-world tasks, their underlying mechanisms remain poorly understood. Recent\nstudies have suggested that transformers can implement gradient descent as an\nin-context learner for linear regression problems and have developed various\ntheoretical analyses accordingly. However, these works mostly focus on the\nexpressive power of transformers by designing specific parameter constructions,\nlacking a comprehensive understanding of their inherent working mechanisms\npost-training. In this study, we consider a sparse linear regression problem\nand investigate how a trained multi-head transformer performs in-context\nlearning. We experimentally discover that the utilization of multi-heads\nexhibits different patterns across layers: multiple heads are utilized and\nessential in the first layer, while usually only a single head is sufficient\nfor subsequent layers. We provide a theoretical explanation for this\nobservation: the first layer preprocesses the context data, and the following\nlayers execute simple optimization steps based on the preprocessed context.\nMoreover, we demonstrate that such a preprocess-then-optimize algorithm can\nsignificantly outperform naive gradient descent and ridge regression\nalgorithms. Further experimental results support our explanations. Our findings\noffer insights into the benefits of multi-head attention and contribute to\nunderstanding the more intricate mechanisms hidden within trained transformers.", "arxiv_id": "2408.04532v1", "pdf_url": "http://arxiv.org/pdf/2408.04532v1", "abstract_url": "http://arxiv.org/abs/2408.04532v1", "primary_category": "cs.LG", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "How Transformers Utilize Multi-Head Attention in In-Context Learning? A Case Study on Sparse Linear Regression", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:06.952017"}
{"title": "AExGym: Benchmarks and Environments for Adaptive Experimentation", "authors": "Jimmy Wang, Ethan Che, Daniel R. Jiang, Hongseok Namkoong", "abstract": "Innovations across science and industry are evaluated using randomized trials\n(a.k.a. A/B tests). While simple and robust, such static designs are\ninefficient or infeasible for testing many hypotheses. Adaptive designs can\ngreatly improve statistical power in theory, but they have seen limited\nadoption due to their fragility in practice. We present a benchmark for\nadaptive experimentation based on real-world datasets, highlighting prominent\npractical challenges to operationalizing adaptivity: non-stationarity,\nbatched/delayed feedback, multiple outcomes and objectives, and external\nvalidity. Our benchmark aims to spur methodological development that puts\npractical performance (e.g., robustness) as a central concern, rather than\nmathematical guarantees on contrived instances. We release an open source\nlibrary, AExGym, which is designed with modularity and extensibility in mind to\nallow experimentation practitioners to develop custom environments and\nalgorithms.", "arxiv_id": "2408.04531v1", "pdf_url": "http://arxiv.org/pdf/2408.04531v1", "abstract_url": "http://arxiv.org/abs/2408.04531v1", "primary_category": "cs.LG", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "AExGym: Benchmarks and Environments for Adaptive Experimentation", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:08.895668"}
{"title": "Exploring Scalability in Large-Scale Time Series in DeepVATS framework", "authors": "Inmaculada Santamaria-Valenzuela, Victor Rodriguez-Fernandez, David Camacho", "abstract": "Visual analytics is essential for studying large time series due to its\nability to reveal trends, anomalies, and insights. DeepVATS is a tool that\nmerges Deep Learning (Deep) with Visual Analytics (VA) for the analysis of\nlarge time series data (TS). It has three interconnected modules. The Deep\nLearning module, developed in R, manages the load of datasets and Deep Learning\nmodels from and to the Storage module. This module also supports models\ntraining and the acquisition of the embeddings from the latent space of the\ntrained model. The Storage module operates using the Weights and Biases system.\nSubsequently, these embeddings can be analyzed in the Visual Analytics module.\nThis module, based on an R Shiny application, allows the adjustment of the\nparameters related to the projection and clustering of the embeddings space.\nOnce these parameters are set, interactive plots representing both the\nembeddings, and the time series are shown. This paper introduces the tool and\nexamines its scalability through log analytics. The execution time evolution is\nexamined while the length of the time series is varied. This is achieved by\nresampling a large data series into smaller subsets and logging the main\nexecution and rendering times for later analysis of scalability.", "arxiv_id": "2408.04692v1", "pdf_url": "http://arxiv.org/pdf/2408.04692v1", "abstract_url": "http://arxiv.org/abs/2408.04692v1", "primary_category": "cs.LG", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "NOT_ENOUGH_RELATED"}
{"title": "Exploring Scalability in Large-Scale Time Series in DeepVATS framework", "response": "NOT_ENOUGH_RELATED", "timestamp": "2024-08-19T13:41:09.943250"}
{"title": "Hybrid Reinforcement Learning Breaks Sample Size Barriers in Linear MDPs", "authors": "Kevin Tan, Wei Fan, Yuting Wei", "abstract": "Hybrid Reinforcement Learning (RL), where an agent learns from both an\noffline dataset and online explorations in an unknown environment, has garnered\nsignificant recent interest. A crucial question posed by Xie et al. (2022) is\nwhether hybrid RL can improve upon the existing lower bounds established in\npurely offline and purely online RL without relying on the single-policy\nconcentrability assumption. While Li et al. (2023) provided an affirmative\nanswer to this question in the tabular PAC RL case, the question remains\nunsettled for both the regret-minimizing RL case and the non-tabular case.\n  In this work, building upon recent advancements in offline RL and\nreward-agnostic exploration, we develop computationally efficient algorithms\nfor both PAC and regret-minimizing RL with linear function approximation,\nwithout single-policy concentrability. We demonstrate that these algorithms\nachieve sharper error or regret bounds that are no worse than, and can improve\non, the optimal sample complexity in offline RL (the first algorithm, for PAC\nRL) and online RL (the second algorithm, for regret-minimizing RL) in linear\nMarkov decision processes (MDPs), regardless of the quality of the behavior\npolicy. To our knowledge, this work establishes the tightest theoretical\nguarantees currently available for hybrid RL in linear MDPs.", "arxiv_id": "2408.04526v1", "pdf_url": "http://arxiv.org/pdf/2408.04526v1", "abstract_url": "http://arxiv.org/abs/2408.04526v1", "primary_category": "stat.ML", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Hybrid Reinforcement Learning Breaks Sample Size Barriers in Linear MDPs", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:10.739458"}
{"title": "Advancing Molecular Machine (Learned) Representations with Stereoelectronics-Infused Molecular Graphs", "authors": "Daniil A. Boiko, Thiago Resch\u00fctzegger, Benjamin Sanchez-Lengeling, Samuel M. Blau, Gabe Gomes", "abstract": "Molecular representation is a foundational element in our understanding of\nthe physical world. Its importance ranges from the fundamentals of chemical\nreactions to the design of new therapies and materials. Previous molecular\nmachine learning models have employed strings, fingerprints, global features,\nand simple molecular graphs that are inherently information-sparse\nrepresentations. However, as the complexity of prediction tasks increases, the\nmolecular representation needs to encode higher fidelity information. This work\nintroduces a novel approach to infusing quantum-chemical-rich information into\nmolecular graphs via stereoelectronic effects. We show that the explicit\naddition of stereoelectronic interactions significantly improves the\nperformance of molecular machine learning models. Furthermore,\nstereoelectronics-infused representations can be learned and deployed with a\ntailored double graph neural network workflow, enabling its application to any\ndownstream molecular machine learning task. Finally, we show that the learned\nrepresentations allow for facile stereoelectronic evaluation of previously\nintractable systems, such as entire proteins, opening new avenues of molecular\ndesign.", "arxiv_id": "2408.04520v1", "pdf_url": "http://arxiv.org/pdf/2408.04520v1", "abstract_url": "http://arxiv.org/abs/2408.04520v1", "primary_category": "cs.LG", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Advancing Molecular Machine (Learned) Representations with Stereoelectronics-Infused Molecular Graphs", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:12.067176"}
{"title": "Knowledge-Aided Semantic Communication Leveraging Probabilistic Graphical Modeling", "authors": "Haowen Wan, Qianqian Yang, Jiancheng Tang, Zhiguo shi", "abstract": "In this paper, we propose a semantic communication approach based on\nprobabilistic graphical model (PGM). The proposed approach involves\nconstructing a PGM from a training dataset, which is then shared as common\nknowledge between the transmitter and receiver. We evaluate the importance of\nvarious semantic features and present a PGM-based compression algorithm\ndesigned to eliminate predictable portions of semantic information.\nFurthermore, we introduce a technique to reconstruct the discarded semantic\ninformation at the receiver end, generating approximate results based on the\nPGM. Simulation results indicate a significant improvement in transmission\nefficiency over existing methods, while maintaining the quality of the\ntransmitted images.", "arxiv_id": "2408.04499v1", "pdf_url": "http://arxiv.org/pdf/2408.04499v1", "abstract_url": "http://arxiv.org/abs/2408.04499v1", "primary_category": "cs.LG", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Knowledge-Aided Semantic Communication Leveraging Probabilistic Graphical Modeling", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:12.857680"}
{"title": "Model-Based Transfer Learning for Contextual Reinforcement Learning", "authors": "Jung-Hoon Cho, Vindula Jayawardana, Sirui Li, Cathy Wu", "abstract": "Deep reinforcement learning is a powerful approach to complex decision\nmaking. However, one issue that limits its practical application is its\nbrittleness, sometimes failing to train in the presence of small changes in the\nenvironment. This work is motivated by the empirical observation that directly\napplying an already trained model to a related task often works remarkably\nwell, also called zero-shot transfer. We take this practical trick one step\nfurther to consider how to systematically select good tasks to train,\nmaximizing overall performance across a range of tasks. Given the high cost of\ntraining, it is critical to choose a small set of training tasks. The key idea\nbehind our approach is to explicitly model the performance loss (generalization\ngap) incurred by transferring a trained model. We hence introduce Model-Based\nTransfer Learning (MBTL) for solving contextual RL problems. In this work, we\nmodel the performance loss as a simple linear function of task context\nsimilarity. Furthermore, we leverage Bayesian optimization techniques to\nefficiently model and estimate the unknown training performance of the task\nspace. We theoretically show that the method exhibits regret that is sublinear\nin the number of training tasks and discuss conditions to further tighten\nregret bounds. We experimentally validate our methods using urban traffic and\nstandard control benchmarks. Despite the conceptual simplicity, the\nexperimental results suggest that MBTL can achieve greater performance than\nstrong baselines, including exhaustive training on all tasks, multi-task\ntraining, and random selection of training tasks. This work lays the\nfoundations for investigating explicit modeling of generalization, thereby\nenabling principled yet effective methods for contextual RL.", "arxiv_id": "2408.04498v1", "pdf_url": "http://arxiv.org/pdf/2408.04498v1", "abstract_url": "http://arxiv.org/abs/2408.04498v1", "primary_category": "cs.LG", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Model-Based Transfer Learning for Contextual Reinforcement Learning", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:13.911595"}
{"title": "Advancing oncology with federated learning: transcending boundaries in breast, lung, and prostate cancer. A systematic review", "authors": "Anshu Ankolekar, Sebastian Boie, Maryam Abdollahyan, Emanuela Gadaleta, Seyed Alireza Hasheminasab, Guang Yang, Charles Beauville, Nikolaos Dikaios, George Anthony Kastis, Michael Bussmann, Sara Khalid, Hagen Kruger, Philippe Lambin, Giorgos Papanastasiou", "abstract": "Federated Learning (FL) has emerged as a promising solution to address the\nlimitations of centralised machine learning (ML) in oncology, particularly in\novercoming privacy concerns and harnessing the power of diverse, multi-center\ndata. This systematic review synthesises current knowledge on the\nstate-of-the-art FL in oncology, focusing on breast, lung, and prostate cancer.\nDistinct from previous surveys, our comprehensive review critically evaluates\nthe real-world implementation and impact of FL on cancer care, demonstrating\nits effectiveness in enhancing ML generalisability, performance and data\nprivacy in clinical settings and data. We evaluated state-of-the-art advances\nin FL, demonstrating its growing adoption amid tightening data privacy\nregulations. FL outperformed centralised ML in 15 out of the 25 studies\nreviewed, spanning diverse ML models and clinical applications, and\nfacilitating integration of multi-modal information for precision medicine.\nDespite the current challenges identified in reproducibility, standardisation\nand methodology across studies, the demonstrable benefits of FL in harnessing\nreal-world data and addressing clinical needs highlight its significant\npotential for advancing cancer research. We propose that future research should\nfocus on addressing these limitations and investigating further advanced FL\nmethods, to fully harness data diversity and realise the transformative power\nof cutting-edge FL in cancer care.", "arxiv_id": "2408.05249v1", "pdf_url": "http://arxiv.org/pdf/2408.05249v1", "abstract_url": "http://arxiv.org/abs/2408.05249v1", "primary_category": "cs.LG", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Advancing oncology with federated learning: transcending boundaries in breast, lung, and prostate cancer. A systematic review", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:14.634477"}
{"title": "Ensemble everything everywhere: Multi-scale aggregation for adversarial robustness", "authors": "Stanislav Fort, Balaji Lakshminarayanan", "abstract": "Adversarial examples pose a significant challenge to the robustness,\nreliability and alignment of deep neural networks. We propose a novel,\neasy-to-use approach to achieving high-quality representations that lead to\nadversarial robustness through the use of multi-resolution input\nrepresentations and dynamic self-ensembling of intermediate layer predictions.\nWe demonstrate that intermediate layer predictions exhibit inherent robustness\nto adversarial attacks crafted to fool the full classifier, and propose a\nrobust aggregation mechanism based on Vickrey auction that we call\n\\textit{CrossMax} to dynamically ensemble them. By combining multi-resolution\ninputs and robust ensembling, we achieve significant adversarial robustness on\nCIFAR-10 and CIFAR-100 datasets without any adversarial training or extra data,\nreaching an adversarial accuracy of $\\approx$72% (CIFAR-10) and $\\approx$48%\n(CIFAR-100) on the RobustBench AutoAttack suite ($L_\\infty=8/255)$ with a\nfinetuned ImageNet-pretrained ResNet152. This represents a result comparable\nwith the top three models on CIFAR-10 and a +5 % gain compared to the best\ncurrent dedicated approach on CIFAR-100. Adding simple adversarial training on\ntop, we get $\\approx$78% on CIFAR-10 and $\\approx$51% on CIFAR-100, improving\nSOTA by 5 % and 9 % respectively and seeing greater gains on the harder\ndataset. We validate our approach through extensive experiments and provide\ninsights into the interplay between adversarial robustness, and the\nhierarchical nature of deep representations. We show that simple gradient-based\nattacks against our model lead to human-interpretable images of the target\nclasses as well as interpretable image changes. As a byproduct, using our\nmulti-resolution prior, we turn pre-trained classifiers and CLIP models into\ncontrollable image generators and develop successful transferable attacks on\nlarge vision language models.", "arxiv_id": "2408.05446v1", "pdf_url": "http://arxiv.org/pdf/2408.05446v1", "abstract_url": "http://arxiv.org/abs/2408.05446v1", "primary_category": "cs.CV", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Ensemble everything everywhere: Multi-scale aggregation for adversarial robustness", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:15.324980"}
{"title": "SegXAL: Explainable Active Learning for Semantic Segmentation in Driving Scene Scenarios", "authors": "Sriram Mandalika, Athira Nambiar", "abstract": "Most of the sophisticated AI models utilize huge amounts of annotated data\nand heavy training to achieve high-end performance. However, there are certain\nchallenges that hinder the deployment of AI models \"in-the-wild\" scenarios,\ni.e., inefficient use of unlabeled data, lack of incorporation of human\nexpertise, and lack of interpretation of the results. To mitigate these\nchallenges, we propose a novel Explainable Active Learning (XAL) model,\nXAL-based semantic segmentation model \"SegXAL\", that can (i) effectively\nutilize the unlabeled data, (ii) facilitate the \"Human-in-the-loop\" paradigm,\nand (iii) augment the model decisions in an interpretable way. In particular,\nwe investigate the application of the SegXAL model for semantic segmentation in\ndriving scene scenarios. The SegXAL model proposes the image regions that\nrequire labeling assistance from Oracle by dint of explainable AI (XAI) and\nuncertainty measures in a weakly-supervised manner. Specifically, we propose a\nnovel Proximity-aware Explainable-AI (PAE) module and Entropy-based Uncertainty\n(EBU) module to get an Explainable Error Mask, which enables the machine\nteachers/human experts to provide intuitive reasoning behind the results and to\nsolicit feedback to the AI system via an active learning strategy. Such a\nmechanism bridges the semantic gap between man and machine through\ncollaborative intelligence, where humans and AI actively enhance each other's\ncomplementary strengths. A novel high-confidence sample selection technique\nbased on the DICE similarity coefficient is also presented within the SegXAL\nframework. Extensive quantitative and qualitative analyses are carried out in\nthe benchmarking Cityscape dataset. Results show the outperformance of our\nproposed SegXAL against other state-of-the-art models.", "arxiv_id": "2408.04482v1", "pdf_url": "http://arxiv.org/pdf/2408.04482v1", "abstract_url": "http://arxiv.org/abs/2408.04482v1", "primary_category": "cs.CV", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "SegXAL: Explainable Active Learning for Semantic Segmentation in Driving Scene Scenarios", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:16.267106"}
{"title": "NFDI4Health workflow and service for synthetic data generation, assessment and risk management", "authors": "Sobhan Moazemi, Tim Adams, Hwei Geok NG, Lisa K\u00fchnel, Julian Schneider, Anatol-Fiete N\u00e4her, Juliane Fluck, Holger Fr\u00f6hlich", "abstract": "Individual health data is crucial for scientific advancements, particularly\nin developing Artificial Intelligence (AI); however, sharing real patient\ninformation is often restricted due to privacy concerns. A promising solution\nto this challenge is synthetic data generation. This technique creates entirely\nnew datasets that mimic the statistical properties of real data, while\npreserving confidential patient information. In this paper, we present the\nworkflow and different services developed in the context of Germany's National\nData Infrastructure project NFDI4Health. First, two state-of-the-art AI tools\n(namely, VAMBN and MultiNODEs) for generating synthetic health data are\noutlined. Further, we introduce SYNDAT (a public web-based tool) which allows\nusers to visualize and assess the quality and risk of synthetic data provided\nby desired generative models. Additionally, the utility of the proposed methods\nand the web-based tool is showcased using data from Alzheimer's Disease\nNeuroimaging Initiative (ADNI) and the Center for Cancer Registry Data of the\nRobert Koch Institute (RKI).", "arxiv_id": "2408.04478v1", "pdf_url": "http://arxiv.org/pdf/2408.04478v1", "abstract_url": "http://arxiv.org/abs/2408.04478v1", "primary_category": "cs.LG", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "NFDI4Health workflow and service for synthetic data generation, assessment and risk management", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:17.291086"}
{"title": "Random Walk Diffusion for Efficient Large-Scale Graph Generation", "authors": "Tobias Bernecker, Ghalia Rehawi, Francesco Paolo Casale, Janine Knauer-Arloth, Annalisa Marsico", "abstract": "Graph generation addresses the problem of generating new graphs that have a\ndata distribution similar to real-world graphs. While previous diffusion-based\ngraph generation methods have shown promising results, they often struggle to\nscale to large graphs. In this work, we propose ARROW-Diff (AutoRegressive\nRandOm Walk Diffusion), a novel random walk-based diffusion approach for\nefficient large-scale graph generation. Our method encompasses two components\nin an iterative process of random walk sampling and graph pruning. We\ndemonstrate that ARROW-Diff can scale to large graphs efficiently, surpassing\nother baseline methods in terms of both generation time and multiple graph\nstatistics, reflecting the high quality of the generated graphs.", "arxiv_id": "2408.04461v1", "pdf_url": "http://arxiv.org/pdf/2408.04461v1", "abstract_url": "http://arxiv.org/abs/2408.04461v1", "primary_category": "cs.LG", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Random Walk Diffusion for Efficient Large-Scale Graph Generation", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:18.557875"}
{"title": "An experimental comparative study of backpropagation and alternatives for training binary neural networks for image classification", "authors": "Ben Crulis, Barthelemy Serres, Cyril de Runz, Gilles Venturini", "abstract": "Current artificial neural networks are trained with parameters encoded as\nfloating point numbers that occupy lots of memory space at inference time. Due\nto the increase in the size of deep learning models, it is becoming very\ndifficult to consider training and using artificial neural networks on edge\ndevices. Binary neural networks promise to reduce the size of deep neural\nnetwork models, as well as to increase inference speed while decreasing energy\nconsumption. Thus, they may allow the deployment of more powerful models on\nedge devices. However, binary neural networks are still proven to be difficult\nto train using the backpropagation-based gradient descent scheme. This paper\nextends the work of \\cite{crulis2023alternatives}, which proposed adapting to\nbinary neural networks two promising alternatives to backpropagation originally\ndesigned for continuous neural networks, and experimented with them on simple\nimage classification datasets. This paper proposes new experiments on the\nImageNette dataset, compares three different model architectures for image\nclassification, and adds two additional alternatives to backpropagation.", "arxiv_id": "2408.04460v1", "pdf_url": "http://arxiv.org/pdf/2408.04460v1", "abstract_url": "http://arxiv.org/abs/2408.04460v1", "primary_category": "cs.LG", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "An experimental comparative study of backpropagation and alternatives for training binary neural networks for image classification", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:19.397853"}
{"title": "FedAD-Bench: A Unified Benchmark for Federated Unsupervised Anomaly Detection in Tabular Data", "authors": "Ahmed Anwar, Brian Moser, Dayananda Herurkar, Federico Raue, Vinit Hegiste, Tatjana Legler, Andreas Dengel", "abstract": "The emergence of federated learning (FL) presents a promising approach to\nleverage decentralized data while preserving privacy. Furthermore, the\ncombination of FL and anomaly detection is particularly compelling because it\nallows for detecting rare and critical anomalies (usually also rare in locally\ngathered data) in sensitive data from multiple sources, such as cybersecurity\nand healthcare. However, benchmarking the performance of anomaly detection\nmethods in FL environments remains an underexplored area. This paper introduces\nFedAD-Bench, a unified benchmark for evaluating unsupervised anomaly detection\nalgorithms within the context of FL. We systematically analyze and compare the\nperformance of recent deep learning anomaly detection models under federated\nsettings, which were typically assessed solely in centralized settings.\nFedAD-Bench encompasses diverse datasets and metrics to provide a holistic\nevaluation. Through extensive experiments, we identify key challenges such as\nmodel aggregation inefficiencies and metric unreliability. We present insights\ninto FL's regularization effects, revealing scenarios in which it outperforms\ncentralized approaches due to its inherent ability to mitigate overfitting. Our\nwork aims to establish a standardized benchmark to guide future research and\ndevelopment in federated anomaly detection, promoting reproducibility and fair\ncomparison across studies.", "arxiv_id": "2408.04442v1", "pdf_url": "http://arxiv.org/pdf/2408.04442v1", "abstract_url": "http://arxiv.org/abs/2408.04442v1", "primary_category": "cs.LG", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "FedAD-Bench: A Unified Benchmark for Federated Unsupervised Anomaly Detection in Tabular Data", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:20.261271"}
{"title": "Deep Learning for identifying systolic complexes in SCG traces: a cross-dataset analysis", "authors": "Michele Craighero, Sarah Solbiati, Federica Mozzini, Enrico Caiani, Giacomo Boracchi", "abstract": "The seismocardiographic signal is a promising alternative to the traditional\nECG in the analysis of the cardiac activity. In particular, the systolic\ncomplex is known to be the most informative part of the seismocardiogram, thus\nrequiring further analysis. State-of-art solutions to detect the systolic\ncomplex are based on Deep Learning models, which have been proven effective in\npioneering studies. However, these solutions have only been tested in a\ncontrolled scenario considering only clean signals acquired from users\nmaintained still in supine position. On top of that, all these studies consider\ndata coming from a single dataset, ignoring the benefits and challenges related\nto a cross-dataset scenario. In this work, a cross-dataset experimental\nanalysis was performed considering also data from a real-world scenario. Our\nfindings prove the effectiveness of a deep learning solution, while showing the\nimportance of a personalization step to contrast the domain shift, namely a\nchange in data distribution between training and testing data. Finally, we\ndemonstrate the benefits of a multi-channels approach, leveraging the\ninformation extracted from both accelerometers and gyroscopes data.", "arxiv_id": "2408.04439v1", "pdf_url": "http://arxiv.org/pdf/2408.04439v1", "abstract_url": "http://arxiv.org/abs/2408.04439v1", "primary_category": "cs.CV", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Deep Learning for identifying systolic complexes in SCG traces: a cross-dataset analysis", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:22.715533"}
{"title": "Large Language Models for cross-language code clone detection", "authors": "Micheline B\u00e9n\u00e9dicte Moumoula, Abdoul Kader Kabore, Jacques Klein, Tegawend\u00e9 Bissyande", "abstract": "With the involvement of multiple programming languages in modern software\ndevelopment, cross-lingual code clone detection has gained traction with the\nsoftware engineering community. Numerous studies have explored this topic,\nproposing various promising approaches. Inspired by the significant advances in\nmachine learning in recent years, particularly Large Language Models (LLMs),\nwhich have demonstrated their ability to tackle various tasks, this paper\nrevisits cross-lingual code clone detection.\n  We investigate the capabilities of four (04) LLMs and eight (08) prompts for\nthe identification of cross-lingual code clones. Additionally, we evaluate a\npre-trained embedding model to assess the effectiveness of the generated\nrepresentations for classifying clone and non-clone pairs. Both studies (based\non LLMs and Embedding models) are evaluated using two widely used cross-lingual\ndatasets, XLCoST and CodeNet. Our results show that LLMs can achieve high F1\nscores, up to 0.98, for straightforward programming examples (e.g., from\nXLCoST). However, they not only perform less well on programs associated with\ncomplex programming challenges but also do not necessarily understand the\nmeaning of code clones in a cross-lingual setting. We show that embedding\nmodels used to represent code fragments from different programming languages in\nthe same representation space enable the training of a basic classifier that\noutperforms all LLMs by ~2 and ~24 percentage points on the XLCoST and CodeNet\ndatasets, respectively. This finding suggests that, despite the apparent\ncapabilities of LLMs, embeddings provided by embedding models offer suitable\nrepresentations to achieve state-of-the-art performance in cross-lingual code\nclone detection.", "arxiv_id": "2408.04430v1", "pdf_url": "http://arxiv.org/pdf/2408.04430v1", "abstract_url": "http://arxiv.org/abs/2408.04430v1", "primary_category": "cs.SE", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Large Language Models for cross-language code clone detection", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:23.947157"}
{"title": "Detection of Animal Movement from Weather Radar using Self-Supervised Learning", "authors": "Mubin Ul Haque, Joel Janek Dabrowski, Rebecca M. Rogers, Hazel Parry", "abstract": "Detecting flying animals (e.g., birds, bats, and insects) using weather radar\nhelps gain insights into animal movement and migration patterns, aids in\nmanagement efforts (such as biosecurity) and enhances our understanding of the\necosystem.The conventional approach to detecting animals in weather radar\ninvolves thresholding: defining and applying thresholds for the radar\nvariables, based on expert opinion. More recently, Deep Learning approaches\nhave been shown to provide improved performance in detection. However,\nobtaining sufficient labelled weather radar data for flying animals to build\nlearning-based models is time-consuming and labor-intensive. To address the\nchallenge of data labelling, we propose a self-supervised learning method for\ndetecting animal movement. In our proposed method, we pre-train our model on a\nlarge dataset with noisy labels produced by a threshold approach. The key\nadvantage is that the pre-trained dataset size is limited only by the number of\nradar images available. We then fine-tune the model on a small human-labelled\ndataset. Our experiments on Australian weather radar data for waterbird\nsegmentation show that the proposed method outperforms the current state-of-the\nart approach by 43.53% in the dice co-efficient statistic.", "arxiv_id": "2408.04424v1", "pdf_url": "http://arxiv.org/pdf/2408.04424v1", "abstract_url": "http://arxiv.org/abs/2408.04424v1", "primary_category": "cs.LG", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Detection of Animal Movement from Weather Radar using Self-Supervised Learning", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:24.760682"}
{"title": "Deeploy: Enabling Energy-Efficient Deployment of Small Language Models On Heterogeneous Microcontrollers", "authors": "Moritz Scherer, Luka Macan, Victor Jung, Philip Wiese, Luca Bompani, Alessio Burrello, Francesco Conti, Luca Benini", "abstract": "With the rise of Embodied Foundation Models (EFMs), most notably Small\nLanguage Models (SLMs), adapting Transformers for edge applications has become\na very active field of research. However, achieving end-to-end deployment of\nSLMs on microcontroller (MCU)-class chips without high-bandwidth off-chip main\nmemory access is still an open challenge. In this paper, we demonstrate\nhigh-efficiency end-to-end SLM deployment on a multicore RISC-V (RV32) MCU\naugmented with ML instruction extensions and a hardware neural processing unit\n(NPU). To automate the exploration of the constrained, multi-dimensional memory\nvs. computation tradeoffs involved in aggressive SLM deployment on\nheterogeneous (multicore+NPU) resources, we introduce Deeploy, a novel Deep\nNeural Network (DNN) compiler, which generates highly-optimized C code\nrequiring minimal runtime support. We demonstrate that Deeploy generates\nend-to-end code for executing SLMs, fully exploiting the RV32 cores'\ninstruction extensions and the NPU: We achieve leading-edge energy and\nthroughput of \\SI{490}{\\micro\\joule \\per Token}, at \\SI{340}{Token \\per\n\\second} for an SLM trained on the TinyStories dataset, running for the first\ntime on an MCU-class device without external memory.", "arxiv_id": "2408.04413v1", "pdf_url": "http://arxiv.org/pdf/2408.04413v1", "abstract_url": "http://arxiv.org/abs/2408.04413v1", "primary_category": "cs.LG", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Deeploy: Enabling Energy-Efficient Deployment of Small Language Models On Heterogeneous Microcontrollers", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:25.605110"}
{"title": "Clutter Classification Using Deep Learning in Multiple Stages", "authors": "Ryan Dempsey, Jonathan Ethier", "abstract": "Path loss prediction for wireless communications is highly dependent on the\nlocal environment. Propagation models including clutter information have been\nshown to significantly increase model accuracy. This paper explores the\napplication of deep learning to satellite imagery to identify environmental\nclutter types automatically. Recognizing these clutter types has numerous uses,\nbut our main application is to use clutter information to enhance propagation\nprediction models. Knowing the type of obstruction (tree, building, and further\nclassifications) can improve the prediction accuracy of key propagation metrics\nsuch as path loss.", "arxiv_id": "2408.04407v1", "pdf_url": "http://arxiv.org/pdf/2408.04407v1", "abstract_url": "http://arxiv.org/abs/2408.04407v1", "primary_category": "cs.LG", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "NOT_ENOUGH_RELATED"}
{"title": "Clutter Classification Using Deep Learning in Multiple Stages", "response": "NOT_ENOUGH_RELATED", "timestamp": "2024-08-19T13:41:26.452645"}
{"title": "Finite sample learning of moving targets", "authors": "Nikolaus Vertovec, Kostas Margellos, Maria Prandini", "abstract": "We consider a moving target that we seek to learn from samples. Our results\nextend randomized techniques developed in control and optimization for a\nconstant target to the case where the target is changing. We derive a novel\nbound on the number of samples that are required to construct a probably\napproximately correct (PAC) estimate of the target. Furthermore, when the\nmoving target is a convex polytope, we provide a constructive method of\ngenerating the PAC estimate using a mixed integer linear program (MILP). The\nproposed method is demonstrated on an application to autonomous emergency\nbraking.", "arxiv_id": "2408.04406v1", "pdf_url": "http://arxiv.org/pdf/2408.04406v1", "abstract_url": "http://arxiv.org/abs/2408.04406v1", "primary_category": "math.OC", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Finite sample learning of moving targets", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:27.326871"}
{"title": "Probabilistic energy forecasting through quantile regression in reproducing kernel Hilbert spaces", "authors": "Luca Pernigo, Rohan Sen, Davide Baroli", "abstract": "Accurate energy demand forecasting is crucial for sustainable and resilient\nenergy development. To meet the Net Zero Representative Concentration Pathways\n(RCP) $4.5$ scenario in the DACH countries, increased renewable energy\nproduction, energy storage, and reduced commercial building consumption are\nneeded. This scenario's success depends on hydroelectric capacity and climatic\nfactors. Informed decisions require quantifying uncertainty in forecasts. This\nstudy explores a non-parametric method based on \\emph{reproducing kernel\nHilbert spaces (RKHS)}, known as kernel quantile regression, for energy\nprediction. Our experiments demonstrate its reliability and sharpness, and we\nbenchmark it against state-of-the-art methods in load and price forecasting for\nthe DACH region. We offer our implementation in conjunction with additional\nscripts to ensure the reproducibility of our research.", "arxiv_id": "2408.04405v1", "pdf_url": "http://arxiv.org/pdf/2408.04405v1", "abstract_url": "http://arxiv.org/abs/2408.04405v1", "primary_category": "cs.LG", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Probabilistic energy forecasting through quantile regression in reproducing kernel Hilbert spaces", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:28.043726"}
{"title": "DIVE: Subgraph Disagreement for Graph Out-of-Distribution Generalization", "authors": "Xin Sun, Liang Wang, Qiang Liu, Shu Wu, Zilei Wang, Liang Wang", "abstract": "This paper addresses the challenge of out-of-distribution (OOD)\ngeneralization in graph machine learning, a field rapidly advancing yet\ngrappling with the discrepancy between source and target data distributions.\nTraditional graph learning algorithms, based on the assumption of uniform\ndistribution between training and test data, falter in real-world scenarios\nwhere this assumption fails, resulting in suboptimal performance. A principal\nfactor contributing to this suboptimal performance is the inherent simplicity\nbias of neural networks trained through Stochastic Gradient Descent (SGD),\nwhich prefer simpler features over more complex yet equally or more predictive\nones. This bias leads to a reliance on spurious correlations, adversely\naffecting OOD performance in various tasks such as image recognition, natural\nlanguage understanding, and graph classification. Current methodologies,\nincluding subgraph-mixup and information bottleneck approaches, have achieved\npartial success but struggle to overcome simplicity bias, often reinforcing\nspurious correlations. To tackle this, we propose DIVE, training a collection\nof models to focus on all label-predictive subgraphs by encouraging the models\nto foster divergence on the subgraph mask, which circumvents the limitation of\na model solely focusing on the subgraph corresponding to simple structural\npatterns. Specifically, we employs a regularizer to punish overlap in extracted\nsubgraphs across models, thereby encouraging different models to concentrate on\ndistinct structural patterns. Model selection for robust OOD performance is\nachieved through validation accuracy. Tested across four datasets from GOOD\nbenchmark and one dataset from DrugOOD benchmark, our approach demonstrates\nsignificant improvement over existing methods, effectively addressing the\nsimplicity bias and enhancing generalization in graph machine learning.", "arxiv_id": "2408.04400v1", "pdf_url": "http://arxiv.org/pdf/2408.04400v1", "abstract_url": "http://arxiv.org/abs/2408.04400v1", "primary_category": "cs.LG", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "DIVE: Subgraph Disagreement for Graph Out-of-Distribution Generalization", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:28.966398"}
{"title": "Evaluating the Impact of Pulse Oximetry Bias in Machine Learning under Counterfactual Thinking", "authors": "In\u00eas Martins, Jo\u00e3o Matos, Tiago Gon\u00e7alves, Leo A. Celi, A. Ian Wong, Jaime S. Cardoso", "abstract": "Algorithmic bias in healthcare mirrors existing data biases. However, the\nfactors driving unfairness are not always known. Medical devices capture\nsignificant amounts of data but are prone to errors; for instance, pulse\noximeters overestimate the arterial oxygen saturation of darker-skinned\nindividuals, leading to worse outcomes. The impact of this bias in machine\nlearning (ML) models remains unclear. This study addresses the technical\nchallenges of quantifying the impact of medical device bias in downstream ML.\nOur experiments compare a \"perfect world\", without pulse oximetry bias, using\nSaO2 (blood-gas), to the \"actual world\", with biased measurements, using SpO2\n(pulse oximetry). Under this counterfactual design, two models are trained with\nidentical data, features, and settings, except for the method of measuring\noxygen saturation: models using SaO2 are a \"control\" and models using SpO2 a\n\"treatment\". The blood-gas oximetry linked dataset was a suitable test-bed,\ncontaining 163,396 nearly-simultaneous SpO2 - SaO2 paired measurements, aligned\nwith a wide array of clinical features and outcomes. We studied three\nclassification tasks: in-hospital mortality, respiratory SOFA score in the next\n24 hours, and SOFA score increase by two points. Models using SaO2 instead of\nSpO2 generally showed better performance. Patients with overestimation of O2 by\npulse oximetry of > 3% had significant decreases in mortality prediction\nrecall, from 0.63 to 0.59, P < 0.001. This mirrors clinical processes where\nbiased pulse oximetry readings provide clinicians with false reassurance of\npatients' oxygen levels. A similar degradation happened in ML models, with\npulse oximetry biases leading to more false negatives in predicting adverse\noutcomes.", "arxiv_id": "2408.04396v1", "pdf_url": "http://arxiv.org/pdf/2408.04396v1", "abstract_url": "http://arxiv.org/abs/2408.04396v1", "primary_category": "cs.LG", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Evaluating the Impact of Pulse Oximetry Bias in Machine Learning under Counterfactual Thinking", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:29.784138"}
{"title": "Early-Exit meets Model-Distributed Inference at Edge Networks", "authors": "Marco Colocrese, Erdem Koyuncu, Hulya Seferoglu", "abstract": "Distributed inference techniques can be broadly classified into\ndata-distributed and model-distributed schemes. In data-distributed inference\n(DDI), each worker carries the entire deep neural network (DNN) model but\nprocesses only a subset of the data. However, feeding the data to workers\nresults in high communication costs, especially when the data is large. An\nemerging paradigm is model-distributed inference (MDI), where each worker\ncarries only a subset of DNN layers. In MDI, a source device that has data\nprocesses a few layers of DNN and sends the output to a neighboring device,\ni.e., offloads the rest of the layers. This process ends when all layers are\nprocessed in a distributed manner. In this paper, we investigate the design and\ndevelopment of MDI with early-exit, which advocates that there is no need to\nprocess all the layers of a model for some data to reach the desired accuracy,\ni.e., we can exit the model without processing all the layers if target\naccuracy is reached. We design a framework MDI-Exit that adaptively determines\nearly-exit and offloading policies as well as data admission at the source.\nExperimental results on a real-life testbed of NVIDIA Nano edge devices show\nthat MDI-Exit processes more data when accuracy is fixed and results in higher\naccuracy for the fixed data rate.", "arxiv_id": "2408.05247v1", "pdf_url": "http://arxiv.org/pdf/2408.05247v1", "abstract_url": "http://arxiv.org/abs/2408.05247v1", "primary_category": "cs.DC", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Early-Exit meets Model-Distributed Inference at Edge Networks", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:30.810191"}
{"title": "Robustness investigation of quality measures for the assessment of machine learning models", "authors": "Thomas Most, Lars Gr\u00e4ning, Sebastian Wolff", "abstract": "In this paper the accuracy and robustness of quality measures for the\nassessment of machine learning models are investigated. The prediction quality\nof a machine learning model is evaluated model-independent based on a\ncross-validation approach, where the approximation error is estimated for\nunknown data. The presented measures quantify the amount of explained variation\nin the model prediction. The reliability of these measures is assessed by means\nof several numerical examples, where an additional data set for the\nverification of the estimated prediction error is available. Furthermore, the\nconfidence bounds of the presented quality measures are estimated and local\nquality measures are derived from the prediction residuals obtained by the\ncross-validation approach.", "arxiv_id": "2408.04391v1", "pdf_url": "http://arxiv.org/pdf/2408.04391v1", "abstract_url": "http://arxiv.org/abs/2408.04391v1", "primary_category": "stat.ML", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "NOT_ENOUGH_RELATED"}
{"title": "Robustness investigation of quality measures for the assessment of machine learning models", "response": "NOT_ENOUGH_RELATED", "timestamp": "2024-08-19T13:41:31.832527"}
{"title": "Deep Generative Models in Robotics: A Survey on Learning from Multimodal Demonstrations", "authors": "Julen Urain, Ajay Mandlekar, Yilun Du, Mahi Shafiullah, Danfei Xu, Katerina Fragkiadaki, Georgia Chalvatzaki, Jan Peters", "abstract": "Learning from Demonstrations, the field that proposes to learn robot behavior\nmodels from data, is gaining popularity with the emergence of deep generative\nmodels. Although the problem has been studied for years under names such as\nImitation Learning, Behavioral Cloning, or Inverse Reinforcement Learning,\nclassical methods have relied on models that don't capture complex data\ndistributions well or don't scale well to large numbers of demonstrations. In\nrecent years, the robot learning community has shown increasing interest in\nusing deep generative models to capture the complexity of large datasets. In\nthis survey, we aim to provide a unified and comprehensive review of the last\nyear's progress in the use of deep generative models in robotics. We present\nthe different types of models that the community has explored, such as\nenergy-based models, diffusion models, action value maps, or generative\nadversarial networks. We also present the different types of applications in\nwhich deep generative models have been used, from grasp generation to\ntrajectory generation or cost learning. One of the most important elements of\ngenerative models is the generalization out of distributions. In our survey, we\nreview the different decisions the community has made to improve the\ngeneralization of the learned models. Finally, we highlight the research\nchallenges and propose a number of future directions for learning deep\ngenerative models in robotics.", "arxiv_id": "2408.04380v1", "pdf_url": "http://arxiv.org/pdf/2408.04380v1", "abstract_url": "http://arxiv.org/abs/2408.04380v1", "primary_category": "cs.RO", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Deep Generative Models in Robotics: A Survey on Learning from Multimodal Demonstrations", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:32.856336"}
{"title": "Anomaly Prediction: A Novel Approach with Explicit Delay and Horizon", "authors": "Jiang You, Arben Cela, Ren\u00e9 Natowicz, Jacob Ouanounou, Patrick Siarry", "abstract": "Anomaly detection in time series data is a critical challenge across various\ndomains. Traditional methods typically focus on identifying anomalies in\nimmediate subsequent steps, often underestimating the significance of temporal\ndynamics such as delay time and horizons of anomalies, which generally require\nextensive post-analysis. This paper introduces a novel approach for detecting\ntime series anomalies called Anomaly Prediction, incorporating temporal\ninformation directly into the prediction results. We propose a new dataset\nspecifically designed to evaluate this approach and conduct comprehensive\nexperiments using several state-of-the-art time series forecasting methods. The\nresults demonstrate the efficacy of our approach in providing timely and\naccurate anomaly predictions, setting a new benchmark for future research in\nthis field.", "arxiv_id": "2408.04377v2", "pdf_url": "http://arxiv.org/pdf/2408.04377v2", "abstract_url": "http://arxiv.org/abs/2408.04377v2", "primary_category": "cs.LG", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Anomaly Prediction: A Novel Approach with Explicit Delay and Horizon", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:34.188974"}
{"title": "Deep Reinforcement Learning for the Design of Metamaterial Mechanisms with Functional Compliance Control", "authors": "Yejun Choi, Yeoneung Kim, Keun Park", "abstract": "Metamaterial mechanisms are micro-architectured compliant structures that\noperate through the elastic deformation of specially designed flexible members.\nThis study develops an efficient design methodology for compliant mechanisms\nusing deep reinforcement learning (RL). For this purpose, design domains are\ndigitized into finite cells with various hinge connections, and finite element\nanalyses (FEAs) are conducted to evaluate the deformation behaviors of the\ncompliance mechanism with different cell combinations. The FEA data are learned\nthrough the RL method to obtain optimal compliant mechanisms for desired\nfunctional requirements. The RL algorithm is applied to the design of a\ncompliant door-latch mechanism, exploring the effect of human guidance and\ntiling direction. The optimal result is achieved with minimal human guidance\nand inward tiling, resulting in a threefold increase in the predefined reward\ncompared to human-designed mechanisms. The proposed approach is extended to the\ndesign of a soft gripper mechanism, where the effect of hinge connections is\nadditionally considered. The optimal design under hinge penalization reveals\nremarkably enhanced compliance, and its performance is validated by\nexperimental tests using an additively manufactured gripper. These findings\ndemonstrate that RL-optimized designs outperform those developed with human\ninsight, providing an efficient design methodology for cell-based compliant\nmechanisms in practical applications.", "arxiv_id": "2408.04376v1", "pdf_url": "http://arxiv.org/pdf/2408.04376v1", "abstract_url": "http://arxiv.org/abs/2408.04376v1", "primary_category": "cs.LG", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Deep Reinforcement Learning for the Design of Metamaterial Mechanisms with Functional Compliance Control", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:35.006741"}
{"title": "Analyzing Consumer Reviews for Understanding Drivers of Hotels Ratings: An Indian Perspective", "authors": "Subhasis Dasgupta, Soumya Roy, Jaydip Sen", "abstract": "In the internet era, almost every business entity is trying to have its\ndigital footprint in digital media and other social media platforms. For these\nentities, word of mouse is also very important. Particularly, this is quite\ncrucial for the hospitality sector dealing with hotels, restaurants etc.\nConsumers do read other consumers reviews before making final decisions. This\nis where it becomes very important to understand which aspects are affecting\nmost in the minds of the consumers while giving their ratings. The current\nstudy focuses on the consumer reviews of Indian hotels to extract aspects\nimportant for final ratings. The study involves gathering data using web\nscraping methods, analyzing the texts using Latent Dirichlet Allocation for\ntopic extraction and sentiment analysis for aspect-specific sentiment mapping.\nFinally, it incorporates Random Forest to understand the importance of the\naspects in predicting the final rating of a user.", "arxiv_id": "2408.04369v1", "pdf_url": "http://arxiv.org/pdf/2408.04369v1", "abstract_url": "http://arxiv.org/abs/2408.04369v1", "primary_category": "cs.CL", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Analyzing Consumer Reviews for Understanding Drivers of Hotels Ratings: An Indian Perspective", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:35.957162"}
{"title": "Detecting Car Speed using Object Detection and Depth Estimation: A Deep Learning Framework", "authors": "Subhasis Dasgupta, Arshi Naaz, Jayeeta Choudhury, Nancy Lahiri", "abstract": "Road accidents are quite common in almost every part of the world, and, in\nmajority, fatal accidents are attributed to over speeding of vehicles. The\ntendency to over speeding is usually tried to be controlled using check points\nat various parts of the road but not all traffic police have the device to\ncheck speed with existing speed estimating devices such as LIDAR based, or\nRadar based guns. The current project tries to address the issue of vehicle\nspeed estimation with handheld devices such as mobile phones or wearable\ncameras with network connection to estimate the speed using deep learning\nframeworks.", "arxiv_id": "2408.04360v1", "pdf_url": "http://arxiv.org/pdf/2408.04360v1", "abstract_url": "http://arxiv.org/abs/2408.04360v1", "primary_category": "cs.LG", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Detecting Car Speed using Object Detection and Depth Estimation: A Deep Learning Framework", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:36.667962"}
{"title": "Self-Supervised Contrastive Graph Clustering Network via Structural Information Fusion", "authors": "Xiaoyang Ji, Yuchen Zhou, Haofu Yang, Shiyue Xu, Jiahao Li", "abstract": "Graph clustering, a classical task in graph learning, involves partitioning\nthe nodes of a graph into distinct clusters. This task has applications in\nvarious real-world scenarios, such as anomaly detection, social network\nanalysis, and community discovery. Current graph clustering methods commonly\nrely on module pre-training to obtain a reliable prior distribution for the\nmodel, which is then used as the optimization objective. However, these methods\noften overlook deeper supervised signals, leading to sub-optimal reliability of\nthe prior distribution. To address this issue, we propose a novel deep graph\nclustering method called CGCN. Our approach introduces contrastive signals and\ndeep structural information into the pre-training process. Specifically, CGCN\nutilizes a contrastive learning mechanism to foster information\ninteroperability among multiple modules and allows the model to adaptively\nadjust the degree of information aggregation for different order structures.\nOur CGCN method has been experimentally validated on multiple real-world graph\ndatasets, showcasing its ability to boost the dependability of prior clustering\ndistributions acquired through pre-training. As a result, we observed notable\nenhancements in the performance of the model.", "arxiv_id": "2408.04339v1", "pdf_url": "http://arxiv.org/pdf/2408.04339v1", "abstract_url": "http://arxiv.org/abs/2408.04339v1", "primary_category": "cs.LG", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Self-Supervised Contrastive Graph Clustering Network via Structural Information Fusion", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:37.548375"}
{"title": "Deep Transfer Learning for Kidney Cancer Diagnosis", "authors": "Yassine Habchi, Hamza Kheddar, Yassine Himeur, Abdelkrim Boukabou, Shadi Atalla, Wathiq Mansoor, Hussain Al-Ahmad", "abstract": "Many incurable diseases prevalent across global societies stem from various\ninfluences, including lifestyle choices, economic conditions, social factors,\nand genetics. Research predominantly focuses on these diseases due to their\nwidespread nature, aiming to decrease mortality, enhance treatment options, and\nimprove healthcare standards. Among these, kidney disease stands out as a\nparticularly severe condition affecting men and women worldwide. Nonetheless,\nthere is a pressing need for continued research into innovative, early\ndiagnostic methods to develop more effective treatments for such diseases.\nRecently, automatic diagnosis of Kidney Cancer has become an important\nchallenge especially when using deep learning (DL) due to the importance of\ntraining medical datasets, which in most cases are difficult and expensive to\nobtain. Furthermore, in most cases, algorithms require data from the same\ndomain and a powerful computer with efficient storage capacity. To overcome\nthis issue, a new type of learning known as transfer learning (TL) has been\nproposed that can produce impressive results based on other different\npre-trained data. This paper presents, to the best of the authors' knowledge,\nthe first comprehensive survey of DL-based TL frameworks for kidney cancer\ndiagnosis. This is a strong contribution to help researchers understand the\ncurrent challenges and perspectives of this topic. Hence, the main limitations\nand advantages of each framework are identified and detailed critical analyses\nare provided. Looking ahead, the article identifies promising directions for\nfuture research. Moving on, the discussion is concluded by reflecting on the\npivotal role of TL in the development of precision medicine and its effects on\nclinical practice and research in oncology.", "arxiv_id": "2408.04318v1", "pdf_url": "http://arxiv.org/pdf/2408.04318v1", "abstract_url": "http://arxiv.org/abs/2408.04318v1", "primary_category": "eess.IV", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Deep Transfer Learning for Kidney Cancer Diagnosis", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:38.376814"}
{"title": "Federated Cubic Regularized Newton Learning with Sparsification-amplified Differential Privacy", "authors": "Wei Huo, Changxin Liu, Kemi Ding, Karl Henrik Johansson, Ling Shi", "abstract": "This paper investigates the use of the cubic-regularized Newton method within\na federated learning framework while addressing two major concerns that\ncommonly arise in federated learning: privacy leakage and communication\nbottleneck. We introduce a federated learning algorithm called Differentially\nPrivate Federated Cubic Regularized Newton (DP-FCRN). By leveraging\nsecond-order techniques, our algorithm achieves lower iteration complexity\ncompared to first-order methods. We also incorporate noise perturbation during\nlocal computations to ensure privacy. Furthermore, we employ sparsification in\nuplink transmission, which not only reduces the communication costs but also\namplifies the privacy guarantee. Specifically, this approach reduces the\nnecessary noise intensity without compromising privacy protection. We analyze\nthe convergence properties of our algorithm and establish the privacy\nguarantee. Finally, we validate the effectiveness of the proposed algorithm\nthrough experiments on a benchmark dataset.", "arxiv_id": "2408.04315v1", "pdf_url": "http://arxiv.org/pdf/2408.04315v1", "abstract_url": "http://arxiv.org/abs/2408.04315v1", "primary_category": "cs.LG", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Federated Cubic Regularized Newton Learning with Sparsification-amplified Differential Privacy", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:39.097808"}
{"title": "Better Locally Private Sparse Estimation Given Multiple Samples Per User", "authors": "Yuheng Ma, Ke Jia, Hanfang Yang", "abstract": "Previous studies yielded discouraging results for item-level locally\ndifferentially private linear regression with $s^*$-sparsity assumption, where\nthe minimax rate for $nm$ samples is $\\mathcal{O}(s^{*}d / nm\\varepsilon^2)$.\nThis can be challenging for high-dimensional data, where the dimension $d$ is\nextremely large. In this work, we investigate user-level locally differentially\nprivate sparse linear regression. We show that with $n$ users each contributing\n$m$ samples, the linear dependency of dimension $d$ can be eliminated, yielding\nan error upper bound of $\\mathcal{O}(s^{*2} / nm\\varepsilon^2)$. We propose a\nframework that first selects candidate variables and then conducts estimation\nin the narrowed low-dimensional space, which is extendable to general sparse\nestimation problems with tight error bounds. Experiments on both synthetic and\nreal datasets demonstrate the superiority of the proposed methods. Both the\ntheoretical and empirical results suggest that, with the same number of\nsamples, locally private sparse estimation is better conducted when multiple\nsamples per user are available.", "arxiv_id": "2408.04313v1", "pdf_url": "http://arxiv.org/pdf/2408.04313v1", "abstract_url": "http://arxiv.org/abs/2408.04313v1", "primary_category": "stat.ML", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Better Locally Private Sparse Estimation Given Multiple Samples Per User", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:39.805150"}
{"title": "Constructing Adversarial Examples for Vertical Federated Learning: Optimal Client Corruption through Multi-Armed Bandit", "authors": "Duanyi Yao, Songze Li, Ye Xue, Jin Liu", "abstract": "Vertical federated learning (VFL), where each participating client holds a\nsubset of data features, has found numerous applications in finance,\nhealthcare, and IoT systems. However, adversarial attacks, particularly through\nthe injection of adversarial examples (AEs), pose serious challenges to the\nsecurity of VFL models. In this paper, we investigate such vulnerabilities\nthrough developing a novel attack to disrupt the VFL inference process, under a\npractical scenario where the adversary is able to adaptively corrupt a subset\nof clients. We formulate the problem of finding optimal attack strategies as an\nonline optimization problem, which is decomposed into an inner problem of\nadversarial example generation (AEG) and an outer problem of corruption pattern\nselection (CPS). Specifically, we establish the equivalence between the\nformulated CPS problem and a multi-armed bandit (MAB) problem, and propose the\nThompson sampling with Empirical maximum reward (E-TS) algorithm for the\nadversary to efficiently identify the optimal subset of clients for corruption.\nThe key idea of E-TS is to introduce an estimation of the expected maximum\nreward for each arm, which helps to specify a small set of competitive arms, on\nwhich the exploration for the optimal arm is performed. This significantly\nreduces the exploration space, which otherwise can quickly become prohibitively\nlarge as the number of clients increases. We analytically characterize the\nregret bound of E-TS, and empirically demonstrate its capability of efficiently\nrevealing the optimal corruption pattern with the highest attack success rate,\nunder various datasets of popular VFL tasks.", "arxiv_id": "2408.04310v1", "pdf_url": "http://arxiv.org/pdf/2408.04310v1", "abstract_url": "http://arxiv.org/abs/2408.04310v1", "primary_category": "cs.LG", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Constructing Adversarial Examples for Vertical Federated Learning: Optimal Client Corruption through Multi-Armed Bandit", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:41.188729"}
{"title": "TheGlueNote: Learned Representations for Robust and Flexible Note Alignment", "authors": "Silvan David Peter, Gerhard Widmer", "abstract": "Note alignment refers to the task of matching individual notes of two\nversions of the same symbolically encoded piece. Methods addressing this task\ncommonly rely on sequence alignment algorithms such as Hidden Markov Models or\nDynamic Time Warping (DTW) applied directly to note or onset sequences. While\nsuccessful in many cases, such methods struggle with large mismatches between\nthe versions. In this work, we learn note-wise representations from data\naugmented with various complex mismatch cases, e.g. repeats, skips, block\ninsertions, and long trills. At the heart of our approach lies a transformer\nencoder network - TheGlueNote - which predicts pairwise note similarities for\ntwo 512 note subsequences. We postprocess the predicted similarities using\nflavors of weightedDTW and pitch-separated onsetDTW to retrieve note matches\nfor two sequences of arbitrary length. Our approach performs on par with the\nstate of the art in terms of note alignment accuracy, is considerably more\nrobust to version mismatches, and works directly on any pair of MIDI files.", "arxiv_id": "2408.04309v1", "pdf_url": "http://arxiv.org/pdf/2408.04309v1", "abstract_url": "http://arxiv.org/abs/2408.04309v1", "primary_category": "cs.SD", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "TheGlueNote: Learned Representations for Robust and Flexible Note Alignment", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:41.971820"}
{"title": "Partial Experts Checkpoint: Efficient Fault Tolerance for Sparse Mixture-of-Experts Model Training", "authors": "Weilin Cai, Le Qin, Jiayi Huang", "abstract": "As large language models continue to scale up, the imperative for fault\ntolerance in distributed deep learning systems intensifies, becoming a focal\narea of AI infrastructure research. Checkpoint has emerged as the predominant\nfault tolerance strategy, with extensive studies dedicated to optimizing its\nefficiency. However, the advent of the sparse Mixture-of-Experts (MoE) model\npresents new challenges for traditional checkpoint techniques due to the\nsubstantial increase in model size, despite comparable computational demands to\ndense models. Breaking new ground in the realm of efficient fault tolerance for\nMoE model training, we introduce a novel Partial Experts Checkpoint (PEC)\nmechanism alongside a corresponding PEC fault-tolerant system. Our approach\nstrategically checkpoints a selected subset of experts, thereby significantly\nreducing the checkpoint size for MoE models to a level comparable with that of\ndense models. The empirical analysis on our 8-expert GPT-MoE model demonstrates\nthat the proposed PEC approach facilitates a substantial 54.2% decrease in the\nsize of non-redundant checkpoint (no data-parallel duplication), without\ncompromising the final model quality. Moreover, our PEC fault-tolerant system\nachieves a 76.9% reduction in checkpoint workload per data-parallel distributed\nrank, thereby correspondingly diminishing the checkpointing time and\nfacilitating complete overlap with the training process.", "arxiv_id": "2408.04307v1", "pdf_url": "http://arxiv.org/pdf/2408.04307v1", "abstract_url": "http://arxiv.org/abs/2408.04307v1", "primary_category": "cs.DC", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Partial Experts Checkpoint: Efficient Fault Tolerance for Sparse Mixture-of-Experts Model Training", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:42.787881"}
{"title": "Differentially Private Data Release on Graphs: Inefficiencies and Unfairness", "authors": "Ferdinando Fioretto, Diptangshu Sen, Juba Ziani", "abstract": "Networks are crucial components of many sectors, including\ntelecommunications, healthcare, finance, energy, and transportation.The\ninformation carried in such networks often contains sensitive user data, like\nlocation data for commuters and packet data for online users. Therefore, when\nconsidering data release for networks, one must ensure that data release\nmechanisms do not leak information about individuals, quantified in a precise\nmathematical sense. Differential Privacy (DP) is the widely accepted, formal,\nstate-of-the-art technique, which has found use in a variety of real-life\nsettings including the 2020 U.S. Census, Apple users' device data, or Google's\nlocation data. Yet, the use of DP comes with new challenges, as the noise added\nfor privacy introduces inaccuracies or biases and further, DP techniques can\nalso distribute these biases disproportionately across different populations,\ninducing fairness issues. The goal of this paper is to characterize the impact\nof DP on bias and unfairness in the context of releasing information about\nnetworks, taking a departure from previous work which has studied these effects\nin the context of private population counts release (such as in the U.S.\nCensus). To this end, we consider a network release problem where the network\nstructure is known to all, but the weights on edges must be released privately.\nWe consider the impact of this private release on a simple downstream\ndecision-making task run by a third-party, which is to find the shortest path\nbetween any two pairs of nodes and recommend the best route to users. This\nsetting is of highly practical relevance, mirroring scenarios in transportation\nnetworks, where preserving privacy while providing accurate routing information\nis crucial. Our work provides theoretical foundations and empirical evidence\ninto the bias and unfairness arising due to privacy in these networked decision\nproblems.", "arxiv_id": "2408.05246v1", "pdf_url": "http://arxiv.org/pdf/2408.05246v1", "abstract_url": "http://arxiv.org/abs/2408.05246v1", "primary_category": "cs.CR", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Differentially Private Data Release on Graphs: Inefficiencies and Unfairness", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:43.645430"}
{"title": "Trans-Tokenization and Cross-lingual Vocabulary Transfers: Language Adaptation of LLMs for Low-Resource NLP", "authors": "Fran\u00e7ois Remy, Pieter Delobelle, Hayastan Avetisyan, Alfiya Khabibullina, Miryam de Lhoneux, Thomas Demeester", "abstract": "The development of monolingual language models for low and mid-resource\nlanguages continues to be hindered by the difficulty in sourcing high-quality\ntraining data. In this study, we present a novel cross-lingual vocabulary\ntransfer strategy, trans-tokenization, designed to tackle this challenge and\nenable more efficient language adaptation. Our approach focuses on adapting a\nhigh-resource monolingual LLM to an unseen target language by initializing the\ntoken embeddings of the target language using a weighted average of\nsemantically similar token embeddings from the source language. For this, we\nleverage a translation resource covering both the source and target languages.\nWe validate our method with the Tweeties, a series of trans-tokenized LLMs, and\ndemonstrate their competitive performance on various downstream tasks across a\nsmall but diverse set of languages. Additionally, we introduce Hydra LLMs,\nmodels with multiple swappable language modeling heads and embedding tables,\nwhich further extend the capabilities of our trans-tokenization strategy. By\ndesigning a Hydra LLM based on the multilingual model TowerInstruct, we\ndeveloped a state-of-the-art machine translation model for Tatar, in a\nzero-shot manner, completely bypassing the need for high-quality parallel data.\nThis breakthrough is particularly significant for low-resource languages like\nTatar, where high-quality parallel data is hard to come by. By lowering the\ndata and time requirements for training high-quality models, our\ntrans-tokenization strategy allows for the development of LLMs for a wider\nrange of languages, especially those with limited resources. We hope that our\nwork will inspire further research and collaboration in the field of\ncross-lingual vocabulary transfer and contribute to the empowerment of\nlanguages on a global scale.", "arxiv_id": "2408.04303v1", "pdf_url": "http://arxiv.org/pdf/2408.04303v1", "abstract_url": "http://arxiv.org/abs/2408.04303v1", "primary_category": "cs.CL", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Trans-Tokenization and Cross-lingual Vocabulary Transfers: Language Adaptation of LLMs for Low-Resource NLP", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:44.427649"}
{"title": "Tackling Noisy Clients in Federated Learning with End-to-end Label Correction", "authors": "Xuefeng Jiang, Sheng Sun, Jia Li, Jingjing Xue, Runhan Li, Zhiyuan Wu, Gang Xu, Yuwei Wang, Min Liu", "abstract": "Recently, federated learning (FL) has achieved wide successes for diverse\nprivacy-sensitive applications without sacrificing the sensitive private\ninformation of clients. However, the data quality of client datasets can not be\nguaranteed since corresponding annotations of different clients often contain\ncomplex label noise of varying degrees, which inevitably causes the performance\ndegradation. Intuitively, the performance degradation is dominated by clients\nwith higher noise rates since their trained models contain more misinformation\nfrom data, thus it is necessary to devise an effective optimization scheme to\nmitigate the negative impacts of these noisy clients. In this work, we propose\na two-stage framework FedELC to tackle this complicated label noise issue. The\nfirst stage aims to guide the detection of noisy clients with higher label\nnoise, while the second stage aims to correct the labels of noisy clients' data\nvia an end-to-end label correction framework which is achieved by learning\npossible ground-truth labels of noisy clients' datasets via back propagation.\nWe implement sixteen related methods and evaluate five datasets with three\ntypes of complicated label noise scenarios for a comprehensive comparison.\nExtensive experimental results demonstrate our proposed framework achieves\nsuperior performance than its counterparts for different scenarios.\nAdditionally, we effectively improve the data quality of detected noisy\nclients' local datasets with our label correction framework. The code is\navailable at https://github.com/Sprinter1999/FedELC.", "arxiv_id": "2408.04301v1", "pdf_url": "http://arxiv.org/pdf/2408.04301v1", "abstract_url": "http://arxiv.org/abs/2408.04301v1", "primary_category": "cs.LG", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Tackling Noisy Clients in Federated Learning with End-to-end Label Correction", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:45.126461"}
{"title": "Assigning Credit with Partial Reward Decoupling in Multi-Agent Proximal Policy Optimization", "authors": "Aditya Kapoor, Benjamin Freed, Howie Choset, Jeff Schneider", "abstract": "Multi-agent proximal policy optimization (MAPPO) has recently demonstrated\nstate-of-the-art performance on challenging multi-agent reinforcement learning\ntasks. However, MAPPO still struggles with the credit assignment problem,\nwherein the sheer difficulty in ascribing credit to individual agents' actions\nscales poorly with team size. In this paper, we propose a multi-agent\nreinforcement learning algorithm that adapts recent developments in credit\nassignment to improve upon MAPPO. Our approach leverages partial reward\ndecoupling (PRD), which uses a learned attention mechanism to estimate which of\na particular agent's teammates are relevant to its learning updates. We use\nthis estimate to dynamically decompose large groups of agents into smaller,\nmore manageable subgroups. We empirically demonstrate that our approach,\nPRD-MAPPO, decouples agents from teammates that do not influence their expected\nfuture reward, thereby streamlining credit assignment. We additionally show\nthat PRD-MAPPO yields significantly higher data efficiency and asymptotic\nperformance compared to both MAPPO and other state-of-the-art methods across\nseveral multi-agent tasks, including StarCraft II. Finally, we propose a\nversion of PRD-MAPPO that is applicable to \\textit{shared} reward settings,\nwhere PRD was previously not applicable, and empirically show that this also\nleads to performance improvements over MAPPO.", "arxiv_id": "2408.04295v1", "pdf_url": "http://arxiv.org/pdf/2408.04295v1", "abstract_url": "http://arxiv.org/abs/2408.04295v1", "primary_category": "cs.MA", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Assigning Credit with Partial Reward Decoupling in Multi-Agent Proximal Policy Optimization", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:46.064746"}
{"title": "Dual-branch PolSAR Image Classification Based on GraphMAE and Local Feature Extraction", "authors": "Yuchen Wang, Ziyi Guo, Haixia Bi, Danfeng Hong, Chen Xu", "abstract": "The annotation of polarimetric synthetic aperture radar (PolSAR) images is a\nlabor-intensive and time-consuming process. Therefore, classifying PolSAR\nimages with limited labels is a challenging task in remote sensing domain. In\nrecent years, self-supervised learning approaches have proven effective in\nPolSAR image classification with sparse labels. However, we observe a lack of\nresearch on generative selfsupervised learning in the studied task. Motivated\nby this, we propose a dual-branch classification model based on generative\nself-supervised learning in this paper. The first branch is a\nsuperpixel-branch, which learns superpixel-level polarimetric representations\nusing a generative self-supervised graph masked autoencoder. To acquire finer\nclassification results, a convolutional neural networks-based pixel-branch is\nfurther incorporated to learn pixel-level features. Classification with fused\ndual-branch features is finally performed to obtain the predictions.\nExperimental results on the benchmark Flevoland dataset demonstrate that our\napproach yields promising classification results.", "arxiv_id": "2408.04294v1", "pdf_url": "http://arxiv.org/pdf/2408.04294v1", "abstract_url": "http://arxiv.org/abs/2408.04294v1", "primary_category": "cs.CV", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Dual-branch PolSAR Image Classification Based on GraphMAE and Local Feature Extraction", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:46.788003"}
{"title": "Efficient and Accurate Pneumonia Detection Using a Novel Multi-Scale Transformer Approach", "authors": "Alireza Saber, Pouria Parhami, Alimihammad Siahkarzadeh, Amirreza Fateh", "abstract": "Pneumonia, a severe respiratory disease, poses significant diagnostic\nchallenges, especially in underdeveloped regions. Traditional diagnostic\nmethods, such as chest X-rays, suffer from variability in interpretation among\nradiologists, necessitating reliable automated tools. In this study, we propose\na novel approach combining deep learning and transformer-based attention\nmechanisms to enhance pneumonia detection from chest X-rays. Our method begins\nwith lung segmentation using a TransUNet model that integrates our specialized\ntransformer module, which has fewer parameters compared to common transformers\nwhile maintaining performance. This model is trained on the \"Chest Xray Masks\nand Labels\" dataset and then applied to the Kermany and Cohen datasets to\nisolate lung regions, enhancing subsequent classification tasks. For\nclassification, we employ pre-trained ResNet models (ResNet-50 and ResNet-101)\nto extract multi-scale feature maps, processed through our modified transformer\nmodule. By employing our specialized transformer, we attain superior results\nwith significantly fewer parameters compared to common transformer models. Our\napproach achieves high accuracy rates of 92.79% on the Kermany dataset and\n95.11% on the Cohen dataset, ensuring robust and efficient performance suitable\nfor resource-constrained environments.\n\"https://github.com/amirrezafateh/Multi-Scale-Transformer-Pneumonia\"", "arxiv_id": "2408.04290v1", "pdf_url": "http://arxiv.org/pdf/2408.04290v1", "abstract_url": "http://arxiv.org/abs/2408.04290v1", "primary_category": "eess.IV", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Efficient and Accurate Pneumonia Detection Using a Novel Multi-Scale Transformer Approach", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:47.633960"}
{"title": "Prompt-Assisted Semantic Interference Cancellation on Moderate Interference Channels", "authors": "Zian Meng, Qiang Li, Ashish Pandharipande, Xiaohu Ge", "abstract": "The performance of conventional interference management strategies degrades\nwhen interference power is comparable to signal power. We consider a new\nperspective on interference management using semantic communication.\nSpecifically, a multi-user semantic communication system is considered on\nmoderate interference channels (ICs), for which a novel framework of deep\nlearning-based prompt-assisted semantic interference cancellation (DeepPASIC)\nis proposed. Each transmitted signal is partitioned into common and private\nparts. The common parts of different users are transmitted simultaneously in a\nshared medium, resulting in superposition. The private part, on the other hand,\nserves as a prompt to assist in canceling the interference suffered by the\ncommon part at the semantic level. Simulation results demonstrate that the\nproposed DeepPASIC outperforms conventional interference management strategies\nunder moderate interference conditions.", "arxiv_id": "2408.04283v1", "pdf_url": "http://arxiv.org/pdf/2408.04283v1", "abstract_url": "http://arxiv.org/abs/2408.04283v1", "primary_category": "eess.SP", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Prompt-Assisted Semantic Interference Cancellation on Moderate Interference Channels", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:48.733803"}
{"title": "Stability Analysis of Equivariant Convolutional Representations Through The Lens of Equivariant Multi-layered CKNs", "authors": "Soutrik Roy Chowdhury", "abstract": "In this paper we construct and theoretically analyse group equivariant\nconvolutional kernel networks (CKNs) which are useful in understanding the\ngeometry of (equivariant) CNNs through the lens of reproducing kernel Hilbert\nspaces (RKHSs). We then proceed to study the stability analysis of such\nequiv-CKNs under the action of diffeomorphism and draw a connection with\nequiv-CNNs, where the goal is to analyse the geometry of inductive biases of\nequiv-CNNs through the lens of reproducing kernel Hilbert spaces (RKHSs).\nTraditional deep learning architectures, including CNNs, trained with\nsophisticated optimization algorithms is vulnerable to perturbations, including\n`adversarial examples'. Understanding the RKHS norm of such models through CKNs\nis useful in designing the appropriate architecture and can be useful in\ndesigning robust equivariant representation learning models.", "arxiv_id": "2408.04277v1", "pdf_url": "http://arxiv.org/pdf/2408.04277v1", "abstract_url": "http://arxiv.org/abs/2408.04277v1", "primary_category": "cs.LG", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Stability Analysis of Equivariant Convolutional Representations Through The Lens of Equivariant Multi-layered CKNs", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:49.855655"}
{"title": "Early Risk Assessment Model for ICA Timing Strategy in Unstable Angina Patients Using Multi-Modal Machine Learning", "authors": "Candi Zheng, Kun Liu, Yang Wang, Shiyi Chen, Hongli Li", "abstract": "Background: Invasive coronary arteriography (ICA) is recognized as the gold\nstandard for diagnosing cardiovascular diseases, including unstable angina\n(UA). The challenge lies in determining the optimal timing for ICA in UA\npatients, balancing the need for revascularization in high-risk patients\nagainst the potential complications in low-risk ones. Unlike myocardial\ninfarction, UA does not have specific indicators like ST-segment deviation or\ncardiac enzymes, making risk assessment complex. Objectives: Our study aims to\nenhance the early risk assessment for UA patients by utilizing machine learning\nalgorithms. These algorithms can potentially identify patients who would\nbenefit most from ICA by analyzing less specific yet related indicators that\nare challenging for human physicians to interpret. Methods: We collected data\nfrom 640 UA patients at Shanghai General Hospital, including medical history\nand electrocardiograms (ECG). Machine learning algorithms were trained using\nmulti-modal demographic characteristics including clinical risk factors,\nsymptoms, biomarker levels, and ECG features extracted by pre-trained neural\nnetworks. The goal was to stratify patients based on their revascularization\nrisk. Additionally, we translated our models into applicable and explainable\nlook-up tables through discretization for practical clinical use. Results: The\nstudy achieved an Area Under the Curve (AUC) of $0.719 \\pm 0.065$ in risk\nstratification, significantly surpassing the widely adopted GRACE score's AUC\nof $0.579 \\pm 0.044$. Conclusions: The results suggest that machine learning\ncan provide superior risk stratification for UA patients. This improved\nstratification could help in balancing the risks, costs, and complications\nassociated with ICA, indicating a potential shift in clinical assessment\npractices for unstable angina.", "arxiv_id": "2408.04276v1", "pdf_url": "http://arxiv.org/pdf/2408.04276v1", "abstract_url": "http://arxiv.org/abs/2408.04276v1", "primary_category": "cs.LG", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Early Risk Assessment Model for ICA Timing Strategy in Unstable Angina Patients Using Multi-Modal Machine Learning", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:50.616622"}
{"title": "Generating Fine-Grained Causality in Climate Time Series Data for Forecasting and Anomaly Detection", "authors": "Dongqi Fu, Yada Zhu, Hanghang Tong, Kommy Weldemariam, Onkar Bhardwaj, Jingrui He", "abstract": "Understanding the causal interaction of time series variables can contribute\nto time series data analysis for many real-world applications, such as climate\nforecasting and extreme weather alerts. However, causal relationships are\ndifficult to be fully observed in real-world complex settings, such as\nspatial-temporal data from deployed sensor networks. Therefore, to capture\nfine-grained causal relations among spatial-temporal variables for further a\nmore accurate and reliable time series analysis, we first design a conceptual\nfine-grained causal model named TBN Granger Causality, which adds\ntime-respecting Bayesian Networks to the previous time-lagged Neural Granger\nCausality to offset the instantaneous effects. Second, we propose an end-to-end\ndeep generative model called TacSas, which discovers TBN Granger Causality in a\ngenerative manner to help forecast time series data and detect possible\nanomalies during the forecast. For evaluations, besides the causality discovery\nbenchmark Lorenz-96, we also test TacSas on climate benchmark ERA5 for climate\nforecasting and the extreme weather benchmark of NOAA for extreme weather\nalerts.", "arxiv_id": "2408.04254v1", "pdf_url": "http://arxiv.org/pdf/2408.04254v1", "abstract_url": "http://arxiv.org/abs/2408.04254v1", "primary_category": "cs.LG", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Generating Fine-Grained Causality in Climate Time Series Data for Forecasting and Anomaly Detection", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:51.489130"}
{"title": "Cooperative Multi-Agent Deep Reinforcement Learning in Content Ranking Optimization", "authors": "Zhou Qin, Kai Yuan, Pratik Lahiri, Wenyang Liu", "abstract": "In a typical e-commerce setting, Content Ranking Optimization (CRO)\nmechanisms are employed to surface content on the search page to fulfill\ncustomers' shopping missions. CRO commonly utilizes models such as contextual\ndeep bandits model to independently rank content at different positions, e.g.,\none optimizer dedicated to organic search results and another to sponsored\nresults. However, this regional optimization approach does not necessarily\ntranslate to whole page optimization, e.g., maximizing revenue at the top of\nthe page may inadvertently diminish the revenue of lower positions. In this\npaper, we propose a reinforcement learning based method for whole page ranking\nto jointly optimize across all positions by: 1) shifting from position level\noptimization to whole page level optimization to achieve an overall optimized\nranking; 2) applying reinforcement learning to optimize for the cumulative\nrewards instead of the instant reward. We formulate page level CRO as a\ncooperative Multi-agent Markov Decision Process , and address it with the novel\nMulti-Agent Deep Deterministic Policy Gradient (MADDPG) model. MADDPG supports\na flexible and scalable joint optimization framework by adopting a \"centralized\ntraining and decentralized execution\" approach. Extensive experiments\ndemonstrate that MADDPG scales to a 2.5 billion action space in the public\nMujoco environment, and outperforms the deep bandits modeling by 25.7% on the\noffline CRO data set from a leading e-commerce company. We foresee that this\nnovel multi-agent optimization is applicable to similar joint optimization\nproblems in the field of information retrieval.", "arxiv_id": "2408.04251v1", "pdf_url": "http://arxiv.org/pdf/2408.04251v1", "abstract_url": "http://arxiv.org/abs/2408.04251v1", "primary_category": "cs.LG", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Cooperative Multi-Agent Deep Reinforcement Learning in Content Ranking Optimization", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:52.414647"}
{"title": "Scalable Transformer for High Dimensional Multivariate Time Series Forecasting", "authors": "Xin Zhou, Weiqing Wang, Wray Buntine, Shilin Qu, Abishek Sriramulu, Weicong Tan, Christoph Bergmeir", "abstract": "Deep models for Multivariate Time Series (MTS) forecasting have recently\ndemonstrated significant success. Channel-dependent models capture complex\ndependencies that channel-independent models cannot capture. However, the\nnumber of channels in real-world applications outpaces the capabilities of\nexisting channel-dependent models, and contrary to common expectations, some\nmodels underperform the channel-independent models in handling high-dimensional\ndata, which raises questions about the performance of channel-dependent models.\nTo address this, our study first investigates the reasons behind the suboptimal\nperformance of these channel-dependent models on high-dimensional MTS data. Our\nanalysis reveals that two primary issues lie in the introduced noise from\nunrelated series that increases the difficulty of capturing the crucial\ninter-channel dependencies, and challenges in training strategies due to\nhigh-dimensional data. To address these issues, we propose STHD, the Scalable\nTransformer for High-Dimensional Multivariate Time Series Forecasting. STHD has\nthree components: a) Relation Matrix Sparsity that limits the noise introduced\nand alleviates the memory issue; b) ReIndex applied as a training strategy to\nenable a more flexible batch size setting and increase the diversity of\ntraining data; and c) Transformer that handles 2-D inputs and captures channel\ndependencies. These components jointly enable STHD to manage the\nhigh-dimensional MTS while maintaining computational feasibility. Furthermore,\nexperimental results show STHD's considerable improvement on three\nhigh-dimensional datasets: Crime-Chicago, Wiki-People, and Traffic. The source\ncode and dataset are publicly available\nhttps://github.com/xinzzzhou/ScalableTransformer4HighDimensionMTSF.git.", "arxiv_id": "2408.04245v1", "pdf_url": "http://arxiv.org/pdf/2408.04245v1", "abstract_url": "http://arxiv.org/abs/2408.04245v1", "primary_category": "cs.LG", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Scalable Transformer for High Dimensional Multivariate Time Series Forecasting", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:54.140038"}
{"title": "The Ungrounded Alignment Problem", "authors": "Marc Pickett, Aakash Kumar Nain, Joseph Modayil, Llion Jones", "abstract": "Modern machine learning systems have demonstrated substantial abilities with\nmethods that either embrace or ignore human-provided knowledge, but combining\nbenefits of both styles remains a challenge. One particular challenge involves\ndesigning learning systems that exhibit built-in responses to specific abstract\nstimulus patterns, yet are still plastic enough to be agnostic about the\nmodality and exact form of their inputs. In this paper, we investigate what we\ncall The Ungrounded Alignment Problem, which asks How can we build in\npredefined knowledge in a system where we don't know how a given stimulus will\nbe grounded? This paper examines a simplified version of the general problem,\nwhere an unsupervised learner is presented with a sequence of images for the\ncharacters in a text corpus, and this learner is later evaluated on its ability\nto recognize specific (possibly rare) sequential patterns. Importantly, the\nlearner is given no labels during learning or evaluation, but must map images\nfrom an unknown font or permutation to its correct class label. That is, at no\npoint is our learner given labeled images, where an image vector is explicitly\nassociated with a class label. Despite ample work in unsupervised and\nself-supervised loss functions, all current methods require a labeled\nfine-tuning phase to map the learned representations to correct classes.\nFinding this mapping in the absence of labels may seem a fool's errand, but our\nmain result resolves this seeming paradox. We show that leveraging only letter\nbigram frequencies is sufficient for an unsupervised learner both to reliably\nassociate images to class labels and to reliably identify trigger words in the\nsequence of inputs. More generally, this method suggests an approach for\nencoding specific desired innate behaviour in modality-agnostic models.", "arxiv_id": "2408.04242v1", "pdf_url": "http://arxiv.org/pdf/2408.04242v1", "abstract_url": "http://arxiv.org/abs/2408.04242v1", "primary_category": "cs.LG", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "The Ungrounded Alignment Problem", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:55.535831"}
{"title": "ToolSandbox: A Stateful, Conversational, Interactive Evaluation Benchmark for LLM Tool Use Capabilities", "authors": "Jiarui Lu, Thomas Holleis, Yizhe Zhang, Bernhard Aumayer, Feng Nan, Felix Bai, Shuang Ma, Shen Ma, Mengyu Li, Guoli Yin, Zirui Wang, Ruoming Pang", "abstract": "Recent large language models (LLMs) advancements sparked a growing research\ninterest in tool assisted LLMs solving real-world challenges, which calls for\ncomprehensive evaluation of tool-use capabilities. While previous works focused\non either evaluating over stateless web services (RESTful API), based on a\nsingle turn user prompt, or an off-policy dialog trajectory, ToolSandbox\nincludes stateful tool execution, implicit state dependencies between tools, a\nbuilt-in user simulator supporting on-policy conversational evaluation and a\ndynamic evaluation strategy for intermediate and final milestones over an\narbitrary trajectory. We show that open source and proprietary models have a\nsignificant performance gap, and complex tasks like State Dependency,\nCanonicalization and Insufficient Information defined in ToolSandbox are\nchallenging even the most capable SOTA LLMs, providing brand-new insights into\ntool-use LLM capabilities. ToolSandbox evaluation framework is released at\nhttps://github.com/apple/ToolSandbox", "arxiv_id": "2408.04682v1", "pdf_url": "http://arxiv.org/pdf/2408.04682v1", "abstract_url": "http://arxiv.org/abs/2408.04682v1", "primary_category": "cs.CL", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "ToolSandbox: A Stateful, Conversational, Interactive Evaluation Benchmark for LLM Tool Use Capabilities", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:56.523152"}
{"title": "Cluster-Wide Task Slowdown Detection in Cloud System", "authors": "Feiyi Chen, Yingying Zhang, Lunting Fan, Yuxuan Liang, Guansong Pang, Qingsong Wen, Shuiguang Deng", "abstract": "Slow task detection is a critical problem in cloud operation and maintenance\nsince it is highly related to user experience and can bring substantial\nliquidated damages. Most anomaly detection methods detect it from a single-task\naspect. However, considering millions of concurrent tasks in large-scale cloud\ncomputing clusters, it becomes impractical and inefficient. Moreover,\nsingle-task slowdowns are very common and do not necessarily indicate a\nmalfunction of a cluster due to its violent fluctuation nature in a virtual\nenvironment. Thus, we shift our attention to cluster-wide task slowdowns by\nutilizing the duration time distribution of tasks across a cluster, so that the\ncomputation complexity is not relevant to the number of tasks.\n  The task duration time distribution often exhibits compound periodicity and\nlocal exceptional fluctuations over time. Though transformer-based methods are\none of the most powerful methods to capture these time series normal variation\npatterns, we empirically find and theoretically explain the flaw of the\nstandard attention mechanism in reconstructing subperiods with low amplitude\nwhen dealing with compound periodicity.\n  To tackle these challenges, we propose SORN (i.e., Skimming Off subperiods in\ndescending amplitude order and Reconstructing Non-slowing fluctuation), which\nconsists of a Skimming Attention mechanism to reconstruct the compound\nperiodicity and a Neural Optimal Transport module to distinguish cluster-wide\nslowdowns from other exceptional fluctuations. Furthermore, since anomalies in\nthe training set are inevitable in a practical scenario, we propose a picky\nloss function, which adaptively assigns higher weights to reliable time slots\nin the training set. Extensive experiments demonstrate that SORN outperforms\nstate-of-the-art methods on multiple real-world industrial datasets.", "arxiv_id": "2408.04236v1", "pdf_url": "http://arxiv.org/pdf/2408.04236v1", "abstract_url": "http://arxiv.org/abs/2408.04236v1", "primary_category": "cs.LG", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Cluster-Wide Task Slowdown Detection in Cloud System", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:57.559044"}
{"title": "Enhanced Traffic Flow Prediction with Multi-Segment Fusion Tensor Graph Convolutional Networks", "authors": "Wei Zhang, Peng Tang", "abstract": "Accurate traffic Flow Prediction can assist in traffic management, route\nplanning, and congestion mitigation, which holds significant importance in\nenhancing the efficiency and reliability of intelligent transportation systems\n(ITS). However, existing traffic flow prediction models suffer from limitations\nin capturing the complex spatial-temporal dependencies within traffic networks.\nIn order to address this issue, this study proposes a multi-segment fusion\ntensor graph convolutional network (MS-FTGCN) for traffic flow prediction with\nthe following three-fold ideas: a) building a unified spatial-temporal graph\nconvolutional framework based on Tensor M-product, which capture the\nspatial-temporal patterns simultaneously; b) incorporating hourly, daily, and\nweekly components to model multi temporal properties of traffic flows,\nrespectively; c) fusing the outputs of the three components by attention\nmechanism to obtain the final traffic flow prediction results. The results of\nexperiments conducted on two traffic flow datasets demonstrate that the\nproposed MS-FTGCN outperforms the state-of-the-art models.", "arxiv_id": "2408.04232v1", "pdf_url": "http://arxiv.org/pdf/2408.04232v1", "abstract_url": "http://arxiv.org/abs/2408.04232v1", "primary_category": "cs.LG", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Enhanced Traffic Flow Prediction with Multi-Segment Fusion Tensor Graph Convolutional Networks", "response": "RELEVANT", "timestamp": "2024-08-19T13:41:59.173728"}
{"title": "Probabilistic Circuits for Cumulative Distribution Functions", "authors": "Oliver Broadrick, William Cao, Benjie Wang, Martin Trapp, Guy Van den Broeck", "abstract": "A probabilistic circuit (PC) succinctly expresses a function that represents\na multivariate probability distribution and, given sufficient structural\nproperties of the circuit, supports efficient probabilistic inference.\nTypically a PC computes the probability mass (or density) function (PMF or PDF)\nof the distribution. We consider PCs instead computing the cumulative\ndistribution function (CDF). We show that for distributions over binary random\nvariables these representations (PMF and CDF) are essentially equivalent, in\nthe sense that one can be transformed to the other in polynomial time. We then\nshow how a similar equivalence holds for distributions over finite discrete\nvariables using a modification of the standard encoding with binary variables\nthat aligns with the CDF semantics. Finally we show that for continuous\nvariables, smooth, decomposable PCs computing PDFs and CDFs can be efficiently\ntransformed to each other by modifying only the leaves of the circuit.", "arxiv_id": "2408.04229v1", "pdf_url": "http://arxiv.org/pdf/2408.04229v1", "abstract_url": "http://arxiv.org/abs/2408.04229v1", "primary_category": "cs.LG", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Probabilistic Circuits for Cumulative Distribution Functions", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:00.197375"}
{"title": "Connective Viewpoints of Signal-to-Noise Diffusion Models", "authors": "Khanh Doan, Long Tung Vuong, Tuan Nguyen, Anh Tuan Bui, Quyen Tran, Thanh-Toan Do, Dinh Phung, Trung Le", "abstract": "Diffusion models (DM) have become fundamental components of generative\nmodels, excelling across various domains such as image creation, audio\ngeneration, and complex data interpolation. Signal-to-Noise diffusion models\nconstitute a diverse family covering most state-of-the-art diffusion models.\nWhile there have been several attempts to study Signal-to-Noise (S2N) diffusion\nmodels from various perspectives, there remains a need for a comprehensive\nstudy connecting different viewpoints and exploring new perspectives. In this\nstudy, we offer a comprehensive perspective on noise schedulers, examining\ntheir role through the lens of the signal-to-noise ratio (SNR) and its\nconnections to information theory. Building upon this framework, we have\ndeveloped a generalized backward equation to enhance the performance of the\ninference process.", "arxiv_id": "2408.04221v1", "pdf_url": "http://arxiv.org/pdf/2408.04221v1", "abstract_url": "http://arxiv.org/abs/2408.04221v1", "primary_category": "cs.CV", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Connective Viewpoints of Signal-to-Noise Diffusion Models", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:01.125686"}
{"title": "Diffusion Guided Language Modeling", "authors": "Justin Lovelace, Varsha Kishore, Yiwei Chen, Kilian Q. Weinberger", "abstract": "Current language models demonstrate remarkable proficiency in text\ngeneration. However, for many applications it is desirable to control\nattributes, such as sentiment, or toxicity, of the generated language --\nideally tailored towards each specific use case and target audience. For\nauto-regressive language models, existing guidance methods are prone to\ndecoding errors that cascade during generation and degrade performance. In\ncontrast, text diffusion models can easily be guided with, for example, a\nsimple linear sentiment classifier -- however they do suffer from significantly\nhigher perplexity than auto-regressive alternatives. In this paper we use a\nguided diffusion model to produce a latent proposal that steers an\nauto-regressive language model to generate text with desired properties. Our\nmodel inherits the unmatched fluency of the auto-regressive approach and the\nplug-and-play flexibility of diffusion. We show that it outperforms previous\nplug-and-play guidance methods across a wide range of benchmark data sets.\nFurther, controlling a new attribute in our framework is reduced to training a\nsingle logistic regression classifier.", "arxiv_id": "2408.04220v1", "pdf_url": "http://arxiv.org/pdf/2408.04220v1", "abstract_url": "http://arxiv.org/abs/2408.04220v1", "primary_category": "cs.CL", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Diffusion Guided Language Modeling", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:01.836192"}
{"title": "Dynamic Hypergraph-Enhanced Prediction of Sequential Medical Visits", "authors": "Wangying Yang, Zhizhong Wu, Zitao Zheng, Bo Zhang, Shi Bo, Yuanfang Yang", "abstract": "This study introduces a pioneering Dynamic Hypergraph Networks (DHCE) model\ndesigned to predict future medical diagnoses from electronic health records\nwith enhanced accuracy. The DHCE model innovates by identifying and\ndifferentiating acute and chronic diseases within a patient's visit history,\nconstructing dynamic hypergraphs that capture the complex, high-order\ninteractions between diseases. It surpasses traditional recurrent neural\nnetworks and graph neural networks by effectively integrating clinical event\ndata, reflected through medical language model-assisted encoding, into a robust\npatient representation. Through extensive experiments on two benchmark\ndatasets, MIMIC-III and MIMIC-IV, the DHCE model exhibits superior performance,\nsignificantly outpacing established baseline models in the precision of\nsequential diagnosis prediction.", "arxiv_id": "2408.07084v1", "pdf_url": "http://arxiv.org/pdf/2408.07084v1", "abstract_url": "http://arxiv.org/abs/2408.07084v1", "primary_category": "cs.LG", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Dynamic Hypergraph-Enhanced Prediction of Sequential Medical Visits", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:02.622060"}
{"title": "DC Algorithm for Estimation of Sparse Gaussian Graphical Models", "authors": "Tomokaze Shiratori, Yuichi Takano", "abstract": "Sparse estimation for Gaussian graphical models is a crucial technique for\nmaking the relationships among numerous observed variables more interpretable\nand quantifiable. Various methods have been proposed, including graphical\nlasso, which utilizes the $\\ell_1$ norm as a regularization term, as well as\nmethods employing non-convex regularization terms. However, most of these\nmethods approximate the $\\ell_0$ norm with convex functions. To estimate more\naccurate solutions, it is desirable to treat the $\\ell_0$ norm directly as a\nregularization term. In this study, we formulate the sparse estimation problem\nfor Gaussian graphical models using the $\\ell_0$ norm and propose a method to\nsolve this problem using the Difference of Convex functions Algorithm (DCA).\nSpecifically, we convert the $\\ell_0$ norm constraint into an equivalent\nlargest-$K$ norm constraint, reformulate the constrained problem into a\npenalized form, and solve it using the DC algorithm (DCA). Furthermore, we\ndesigned an algorithm that efficiently computes using graphical lasso.\nExperimental results with synthetic data show that our method yields results\nthat are equivalent to or better than existing methods. Comparisons of model\nlearning through cross-validation confirm that our method is particularly\nadvantageous in selecting true edges.", "arxiv_id": "2408.04206v1", "pdf_url": "http://arxiv.org/pdf/2408.04206v1", "abstract_url": "http://arxiv.org/abs/2408.04206v1", "primary_category": "cs.LG", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "DC Algorithm for Estimation of Sparse Gaussian Graphical Models", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:03.884610"}
{"title": "Masked EEG Modeling for Driving Intention Prediction", "authors": "Jinzhao Zhou, Justin Sia, Yiqun Duan, Yu-Cheng Chang, Yu-Kai Wang, Chin-Teng Lin", "abstract": "Driving under drowsy conditions significantly escalates the risk of vehicular\naccidents. Although recent efforts have focused on using electroencephalography\nto detect drowsiness, helping prevent accidents caused by driving in such\nstates, seamless human-machine interaction in driving scenarios requires a more\nversatile EEG-based system. This system should be capable of understanding a\ndriver's intention while demonstrating resilience to artifacts induced by\nsudden movements. This paper pioneers a novel research direction in\nBCI-assisted driving, studying the neural patterns related to driving\nintentions and presenting a novel method for driving intention prediction. In\nparticular, our preliminary analysis of the EEG signal using independent\ncomponent analysis suggests a close relation between the intention of driving\nmaneuvers and the neural activities in central-frontal and parietal areas.\nPower spectral density analysis at a group level also reveals a notable\ndistinction among various driving intentions in the frequency domain. To\nexploit these brain dynamics, we propose a novel Masked EEG Modeling framework\nfor predicting human driving intentions, including the intention for left\nturning, right turning, and straight proceeding. Extensive experiments,\nencompassing comprehensive quantitative and qualitative assessments on public\ndataset, demonstrate the proposed method is proficient in predicting driving\nintentions across various vigilance states. Specifically, our model attains an\naccuracy of 85.19% when predicting driving intentions for drowsy subjects,\nwhich shows its promising potential for mitigating traffic accidents related to\ndrowsy driving. Notably, our method maintains over 75% accuracy when more than\nhalf of the channels are missing or corrupted, underscoring its adaptability in\nreal-life driving.", "arxiv_id": "2408.07083v1", "pdf_url": "http://arxiv.org/pdf/2408.07083v1", "abstract_url": "http://arxiv.org/abs/2408.07083v1", "primary_category": "cs.LG", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Masked EEG Modeling for Driving Intention Prediction", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:04.601520"}
{"title": "Towards Linguistic Neural Representation Learning and Sentence Retrieval from Electroencephalogram Recordings", "authors": "Jinzhao Zhou, Yiqun Duan, Ziyi Zhao, Yu-Cheng Chang, Yu-Kai Wang, Thomas Do, Chin-Teng Lin", "abstract": "Decoding linguistic information from non-invasive brain signals using EEG has\ngained increasing research attention due to its vast applicational potential.\nRecently, a number of works have adopted a generative-based framework to decode\nelectroencephalogram (EEG) signals into sentences by utilizing the power\ngenerative capacity of pretrained large language models (LLMs). However, this\napproach has several drawbacks that hinder the further development of\nlinguistic applications for brain-computer interfaces (BCIs). Specifically, the\nability of the EEG encoder to learn semantic information from EEG data remains\nquestionable, and the LLM decoder's tendency to generate sentences based on its\ntraining memory can be hard to avoid. These issues necessitate a novel approach\nfor converting EEG signals into sentences. In this paper, we propose a novel\ntwo-step pipeline that addresses these limitations and enhances the validity of\nlinguistic EEG decoding research. We first confirm that word-level semantic\ninformation can be learned from EEG data recorded during natural reading by\ntraining a Conformer encoder via a masked contrastive objective for word-level\nclassification. To achieve sentence decoding results, we employ a training-free\nretrieval method to retrieve sentences based on the predictions from the EEG\nencoder. Extensive experiments and ablation studies were conducted in this\npaper for a comprehensive evaluation of the proposed approach. Visualization of\nthe top prediction candidates reveals that our model effectively groups EEG\nsegments into semantic categories with similar meanings, thereby validating its\nability to learn patterns from unspoken EEG recordings. Despite the exploratory\nnature of this work, these results suggest that our method holds promise for\nproviding more reliable solutions for converting EEG signals into text.", "arxiv_id": "2408.04679v1", "pdf_url": "http://arxiv.org/pdf/2408.04679v1", "abstract_url": "http://arxiv.org/abs/2408.04679v1", "primary_category": "cs.CL", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Towards Linguistic Neural Representation Learning and Sentence Retrieval from Electroencephalogram Recordings", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:05.384503"}
{"title": "Improved Adaboost Algorithm for Web Advertisement Click Prediction Based on Long Short-Term Memory Networks", "authors": "Qixuan Yu, Xirui Tang, Feiyang Li, Zinan Cao", "abstract": "This paper explores an improved Adaboost algorithm based on Long Short-Term\nMemory Networks (LSTMs), which aims to improve the prediction accuracy of user\nclicks on web page advertisements. By comparing it with several common machine\nlearning algorithms, the paper analyses the advantages of the new model in ad\nclick prediction. It is shown that the improved algorithm proposed in this\npaper performs well in user ad click prediction with an accuracy of 92%, which\nis an improvement of 13.6% compared to the highest of 78.4% among the other\nthree base models. This significant improvement indicates that the algorithm is\nmore capable of capturing user behavioural characteristics and time series\npatterns. In addition, this paper evaluates the model's performance on other\nperformance metrics, including accuracy, recall, and F1 score. The results show\nthat the improved Adaboost algorithm based on LSTM is significantly ahead of\nthe traditional model in all these metrics, which further validates its\neffectiveness and superiority. Especially when facing complex and dynamically\nchanging user behaviours, the model is able to better adapt and make accurate\npredictions. In order to ensure the practicality and reliability of the model,\nthis study also focuses on the accuracy difference between the training set and\nthe test set. After validation, the accuracy of the proposed model on these two\ndatasets only differs by 1.7%, which is a small difference indicating that the\nmodel has good generalisation ability and can be effectively applied to\nreal-world scenarios.", "arxiv_id": "2408.05245v1", "pdf_url": "http://arxiv.org/pdf/2408.05245v1", "abstract_url": "http://arxiv.org/abs/2408.05245v1", "primary_category": "cs.LG", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Improved Adaboost Algorithm for Web Advertisement Click Prediction Based on Long Short-Term Memory Networks", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:06.341691"}
{"title": "Uncertainty-Aware Crime Prediction With Spatial Temporal Multivariate Graph Neural Networks", "authors": "Zepu Wang, Xiaobo Ma, Huajie Yang, Weimin Lvu, Peng Sun, Sharath Chandra Guntuku", "abstract": "Crime forecasting is a critical component of urban analysis and essential for\nstabilizing society today. Unlike other time series forecasting problems, crime\nincidents are sparse, particularly in small regions and within specific time\nperiods. Traditional spatial-temporal deep learning models often struggle with\nthis sparsity, as they typically cannot effectively handle the non-Gaussian\nnature of crime data, which is characterized by numerous zeros and\nover-dispersed patterns. To address these challenges, we introduce a novel\napproach termed Spatial Temporal Multivariate Zero-Inflated Negative Binomial\nGraph Neural Networks (STMGNN-ZINB). This framework leverages diffusion and\nconvolution networks to analyze spatial, temporal, and multivariate\ncorrelations, enabling the parameterization of probabilistic distributions of\ncrime incidents. By incorporating a Zero-Inflated Negative Binomial model,\nSTMGNN-ZINB effectively manages the sparse nature of crime data, enhancing\nprediction accuracy and the precision of confidence intervals. Our evaluation\non real-world datasets confirms that STMGNN-ZINB outperforms existing models,\nproviding a more reliable tool for predicting and understanding crime dynamics.", "arxiv_id": "2408.04193v1", "pdf_url": "http://arxiv.org/pdf/2408.04193v1", "abstract_url": "http://arxiv.org/abs/2408.04193v1", "primary_category": "cs.LG", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Uncertainty-Aware Crime Prediction With Spatial Temporal Multivariate Graph Neural Networks", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:08.413383"}
{"title": "Listwise Reward Estimation for Offline Preference-based Reinforcement Learning", "authors": "Heewoong Choi, Sangwon Jung, Hongjoon Ahn, Taesup Moon", "abstract": "In Reinforcement Learning (RL), designing precise reward functions remains to\nbe a challenge, particularly when aligning with human intent. Preference-based\nRL (PbRL) was introduced to address this problem by learning reward models from\nhuman feedback. However, existing PbRL methods have limitations as they often\noverlook the second-order preference that indicates the relative strength of\npreference. In this paper, we propose Listwise Reward Estimation (LiRE), a\nnovel approach for offline PbRL that leverages second-order preference\ninformation by constructing a Ranked List of Trajectories (RLT), which can be\nefficiently built by using the same ternary feedback type as traditional\nmethods. To validate the effectiveness of LiRE, we propose a new offline PbRL\ndataset that objectively reflects the effect of the estimated rewards. Our\nextensive experiments on the dataset demonstrate the superiority of LiRE, i.e.,\noutperforming state-of-the-art baselines even with modest feedback budgets and\nenjoying robustness with respect to the number of feedbacks and feedback noise.\nOur code is available at https://github.com/chwoong/LiRE", "arxiv_id": "2408.04190v1", "pdf_url": "http://arxiv.org/pdf/2408.04190v1", "abstract_url": "http://arxiv.org/abs/2408.04190v1", "primary_category": "cs.LG", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Listwise Reward Estimation for Offline Preference-based Reinforcement Learning", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:09.466712"}
{"title": "An Upper Confidence Bound Approach to Estimating the Maximum Mean", "authors": "Zhang Kun, Liu Guangwu, Shi Wen", "abstract": "Estimating the maximum mean finds a variety of applications in practice. In\nthis paper, we study estimation of the maximum mean using an upper confidence\nbound (UCB) approach where the sampling budget is adaptively allocated to one\nof the systems. We study in depth the existing grand average (GA) estimator,\nand propose a new largest-size average (LSA) estimator. Specifically, we\nestablish statistical guarantees, including strong consistency, asymptotic mean\nsquared errors, and central limit theorems (CLTs) for both estimators, which\nare new to the literature. We show that LSA is preferable over GA, as the bias\nof the former decays at a rate much faster than that of the latter when sample\nsize increases. By using the CLTs, we further construct asymptotically valid\nconfidence intervals for the maximum mean, and propose a single hypothesis test\nfor a multiple comparison problem with application to clinical trials.\nStatistical efficiency of the resulting point and interval estimates and the\nproposed single hypothesis test is demonstrated via numerical examples.", "arxiv_id": "2408.04179v1", "pdf_url": "http://arxiv.org/pdf/2408.04179v1", "abstract_url": "http://arxiv.org/abs/2408.04179v1", "primary_category": "math.ST", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "An Upper Confidence Bound Approach to Estimating the Maximum Mean", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:10.886674"}
{"title": "pyBregMan: A Python library for Bregman Manifolds", "authors": "Frank Nielsen, Alexander Soen", "abstract": "A Bregman manifold is a synonym for a dually flat space in information\ngeometry which admits as a canonical divergence a Bregman divergence. Bregman\nmanifolds are induced by smooth strictly convex functions like the cumulant or\npartition functions of regular exponential families, the negative entropy of\nmixture families, or the characteristic functions of regular cones just to list\na few such convex Bregman generators. We describe the design of pyBregMan, a\nlibrary which implements generic operations on Bregman manifolds and\ninstantiate several common Bregman manifolds used in information sciences. At\nthe core of the library is the notion of Legendre-Fenchel duality inducing a\ncanonical pair of dual potential functions and dual Bregman divergences. The\nlibrary also implements the Fisher-Rao manifolds of categorical/multinomial\ndistributions and multivariate normal distributions. To demonstrate the use of\nthe pyBregMan kernel manipulating those Bregman and Fisher-Rao manifolds, the\nlibrary also provides several core algorithms for various applications in\nstatistics, machine learning, information fusion, and so on.", "arxiv_id": "2408.04175v1", "pdf_url": "http://arxiv.org/pdf/2408.04175v1", "abstract_url": "http://arxiv.org/abs/2408.04175v1", "primary_category": "cs.LG", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "pyBregMan: A Python library for Bregman Manifolds", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:11.870300"}
{"title": "wav2graph: A Framework for Supervised Learning Knowledge Graph from Speech", "authors": "Khai Le-Duc, Quy-Anh Dang, Tan-Hanh Pham, Truong-Son Hy", "abstract": "Knowledge graphs (KGs) enhance the performance of large language models\n(LLMs) and search engines by providing structured, interconnected data that\nimproves reasoning and context-awareness. However, KGs only focus on text data,\nthereby neglecting other modalities such as speech. In this work, we introduce\nwav2graph, the first framework for supervised learning knowledge graph from\nspeech data. Our pipeline are straightforward: (1) constructing a KG based on\ntranscribed spoken utterances and a named entity database, (2) converting KG\ninto embedding vectors, and (3) training graph neural networks (GNNs) for node\nclassification and link prediction tasks. Through extensive experiments\nconducted in inductive and transductive learning contexts using\nstate-of-the-art GNN models, we provide baseline results and error analysis for\nnode classification and link prediction tasks on human transcripts and\nautomatic speech recognition (ASR) transcripts, including evaluations using\nboth encoder-based and decoder-based node embeddings, as well as monolingual\nand multilingual acoustic pre-trained models. All related code, data, and\nmodels are published online.", "arxiv_id": "2408.04174v1", "pdf_url": "http://arxiv.org/pdf/2408.04174v1", "abstract_url": "http://arxiv.org/abs/2408.04174v1", "primary_category": "cs.CL", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "wav2graph: A Framework for Supervised Learning Knowledge Graph from Speech", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:12.760545"}
{"title": "The Data Addition Dilemma", "authors": "Judy Hanwen Shen, Inioluwa Deborah Raji, Irene Y. Chen", "abstract": "In many machine learning for healthcare tasks, standard datasets are\nconstructed by amassing data across many, often fundamentally dissimilar,\nsources. But when does adding more data help, and when does it hinder progress\non desired model outcomes in real-world settings? We identify this situation as\nthe \\textit{Data Addition Dilemma}, demonstrating that adding training data in\nthis multi-source scaling context can at times result in reduced overall\naccuracy, uncertain fairness outcomes, and reduced worst-subgroup performance.\nWe find that this possibly arises from an empirically observed trade-off\nbetween model performance improvements due to data scaling and model\ndeterioration from distribution shift. We thus establish baseline strategies\nfor navigating this dilemma, introducing distribution shift heuristics to guide\ndecision-making on which data sources to add in data scaling, in order to yield\nthe expected model performance improvements. We conclude with a discussion of\nthe required considerations for data collection and suggestions for studying\ndata composition and scale in the age of increasingly larger models.", "arxiv_id": "2408.04154v1", "pdf_url": "http://arxiv.org/pdf/2408.04154v1", "abstract_url": "http://arxiv.org/abs/2408.04154v1", "primary_category": "cs.LG", "published_date": "2024-08-08", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "The Data Addition Dilemma", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:13.613911"}
{"title": "Heterogeneous Graph Sequence Neural Networks for Dynamic Traffic Assignment", "authors": "Tong Liu, Hadi Meidani", "abstract": "Traffic assignment and traffic flow prediction provide critical insights for\nurban planning, traffic management, and the development of intelligent\ntransportation systems. An efficient model for calculating traffic flows over\nthe entire transportation network could provide a more detailed and realistic\nunderstanding of traffic dynamics. However, existing traffic prediction\napproaches, such as those utilizing graph neural networks, are typically\nlimited to locations where sensors are deployed and cannot predict traffic\nflows beyond sensor locations. To alleviate this limitation, inspired by\nfundamental relationship that exists between link flows and the\norigin-destination (OD) travel demands, we proposed the Heterogeneous\nSpatio-Temporal Graph Sequence Network (HSTGSN). HSTGSN exploits dependency\nbetween origin and destination nodes, even when it is long-range, and learns\nimplicit vehicle route choices under different origin-destination demands. This\nmodel is based on a heterogeneous graph which consists of road links, OD links\n(virtual links connecting origins and destinations) and a spatio-temporal graph\nencoder-decoder that captures the spatio-temporal relationship between OD\ndemands and flow distribution. We will show how the graph encoder-decoder is\nable to recover the incomplete information in the OD demand, by using node\nembedding from the graph decoder to predict the temporal changes in flow\ndistribution. Using extensive experimental studies on real-world networks with\ncomplete/incomplete OD demands, we demonstrate that our method can not only\ncapture the implicit spatio-temporal relationship between link traffic flows\nand OD demands but also achieve accurate prediction performance and\ngeneralization capability.", "arxiv_id": "2408.04131v1", "pdf_url": "http://arxiv.org/pdf/2408.04131v1", "abstract_url": "http://arxiv.org/abs/2408.04131v1", "primary_category": "cs.LG", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Heterogeneous Graph Sequence Neural Networks for Dynamic Traffic Assignment", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:14.633478"}
{"title": "Out-of-Core Dimensionality Reduction for Large Data via Out-of-Sample Extensions", "authors": "Luca Reichmann, David H\u00e4gele, Daniel Weiskopf", "abstract": "Dimensionality reduction (DR) is a well-established approach for the\nvisualization of high-dimensional data sets. While DR methods are often applied\nto typical DR benchmark data sets in the literature, they might suffer from\nhigh runtime complexity and memory requirements, making them unsuitable for\nlarge data visualization especially in environments outside of high-performance\ncomputing. To perform DR on large data sets, we propose the use of\nout-of-sample extensions. Such extensions allow inserting new data into\nexisting projections, which we leverage to iteratively project data into a\nreference projection that consists only of a small manageable subset. This\nprocess makes it possible to perform DR out-of-core on large data, which would\notherwise not be possible due to memory and runtime limitations. For metric\nmultidimensional scaling (MDS), we contribute an implementation with\nout-of-sample projection capability since typical software libraries do not\nsupport it. We provide an evaluation of the projection quality of five common\nDR algorithms (MDS, PCA, t-SNE, UMAP, and autoencoders) using quality metrics\nfrom the literature and analyze the trade-off between the size of the reference\nset and projection quality. The runtime behavior of the algorithms is also\nquantified with respect to reference set size, out-of-sample batch size, and\ndimensionality of the data sets. Furthermore, we compare the out-of-sample\napproach to other recently introduced DR methods, such as PaCMAP and TriMAP,\nwhich claim to handle larger data sets than traditional approaches. To showcase\nthe usefulness of DR on this large scale, we contribute a use case where we\nanalyze ensembles of streamlines amounting to one billion projected instances.", "arxiv_id": "2408.04129v1", "pdf_url": "http://arxiv.org/pdf/2408.04129v1", "abstract_url": "http://arxiv.org/abs/2408.04129v1", "primary_category": "cs.LG", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Out-of-Core Dimensionality Reduction for Large Data via Out-of-Sample Extensions", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:15.353599"}
{"title": "Exploring RAG-based Vulnerability Augmentation with LLMs", "authors": "Seyed Shayan Daneshvar, Yu Nong, Xu Yang, Shaowei Wang, Haipeng Cai", "abstract": "Detecting vulnerabilities is a crucial task for maintaining the integrity,\navailability, and security of software systems. Utilizing DL-based models for\nvulnerability detection has become commonplace in recent years. However, such\ndeep learning-based vulnerability detectors (DLVD) suffer from a shortage of\nsizable datasets to train effectively. Data augmentation can potentially\nalleviate the shortage of data, but augmenting vulnerable code is challenging\nand requires designing a generative solution that maintains vulnerability.\nHence, the work on generating vulnerable code samples has been limited and\nprevious works have only focused on generating samples that contain single\nstatements or specific types of vulnerabilities. Lately, large language models\n(LLMs) are being used for solving various code generation and comprehension\ntasks and have shown inspiring results, especially when fused with retrieval\naugmented generation (RAG). In this study, we explore three different\nstrategies to augment vulnerabilities both single and multi-statement\nvulnerabilities, with LLMs, namely Mutation, Injection, and Extension. We\nconducted an extensive evaluation of our proposed approach on three\nvulnerability datasets and three DLVD models, using two LLMs. Our results show\nthat our injection-based clustering-enhanced RAG method beats the baseline\nsetting (NoAug), Vulgen, and VGX (two SOTA methods), and Random Oversampling\n(ROS) by 30.80\\%, 27.48\\%, 27.93\\%, and 15.41\\% in f1-score with 5K generated\nvulnerable samples on average, and 53.84\\%, 54.10\\%, 69.90\\%, and 40.93\\% with\n15K generated vulnerable samples. Our approach demonstrates its feasibility for\nlarge-scale data augmentation by generating 1K samples at as cheap as US$ 1.88.", "arxiv_id": "2408.04125v1", "pdf_url": "http://arxiv.org/pdf/2408.04125v1", "abstract_url": "http://arxiv.org/abs/2408.04125v1", "primary_category": "cs.SE", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Exploring RAG-based Vulnerability Augmentation with LLMs", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:16.379016"}
{"title": "Overcoming Brittleness in Pareto-Optimal Learning-Augmented Algorithms", "authors": "Spyros Angelopoulos, Christoph D\u00fcrr, Alex Elenter, Yanni Lefki", "abstract": "The study of online algorithms with machine-learned predictions has gained\nconsiderable prominence in recent years. One of the common objectives in the\ndesign and analysis of such algorithms is to attain (Pareto) optimal tradeoffs\nbetween the consistency of the algorithm, i.e., its performance assuming\nperfect predictions, and its robustness, i.e., the performance of the algorithm\nunder adversarial predictions. In this work, we demonstrate that this\noptimization criterion can be extremely brittle, in that the performance of\nPareto-optimal algorithms may degrade dramatically even in the presence of\nimperceptive prediction error. To remedy this drawback, we propose a new\nframework in which the smoothness in the performance of the algorithm is\nenforced by means of a user-specified profile. This allows us to regulate the\nperformance of the algorithm as a function of the prediction error, while\nsimultaneously maintaining the analytical notion of consistency/robustness\ntradeoffs, adapted to the profile setting. We apply this new approach to a\nwell-studied online problem, namely the one-way trading problem. For this\nproblem, we further address another limitation of the state-of-the-art\nPareto-optimal algorithms, namely the fact that they are tailored to\nworst-case, and extremely pessimistic inputs. We propose a new Pareto-optimal\nalgorithm that leverages any deviation from the worst-case input to its\nbenefit, and introduce a new metric that allows us to compare any two\nPareto-optimal algorithms via a dominance relation.", "arxiv_id": "2408.04122v1", "pdf_url": "http://arxiv.org/pdf/2408.04122v1", "abstract_url": "http://arxiv.org/abs/2408.04122v1", "primary_category": "cs.LG", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Overcoming Brittleness in Pareto-Optimal Learning-Augmented Algorithms", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:17.311624"}
{"title": "Combining Neural Architecture Search and Automatic Code Optimization: A Survey", "authors": "Inas Bachiri, Hadjer Benmeziane, Smail Niar, Riyadh Baghdadi, Hamza Ouarnoughi, Abdelkrime Aries", "abstract": "Deep Learning models have experienced exponential growth in complexity and\nresource demands in recent years. Accelerating these models for efficient\nexecution on resource-constrained devices has become more crucial than ever.\nTwo notable techniques employed to achieve this goal are Hardware-aware Neural\nArchitecture Search (HW-NAS) and Automatic Code Optimization (ACO). HW-NAS\nautomatically designs accurate yet hardware-friendly neural networks, while ACO\ninvolves searching for the best compiler optimizations to apply on neural\nnetworks for efficient mapping and inference on the target hardware. This\nsurvey explores recent works that combine these two techniques within a single\nframework. We present the fundamental principles of both domains and\ndemonstrate their sub-optimality when performed independently. We then\ninvestigate their integration into a joint optimization process that we call\nHardware Aware-Neural Architecture and Compiler Optimizations co-Search\n(NACOS).", "arxiv_id": "2408.04116v1", "pdf_url": "http://arxiv.org/pdf/2408.04116v1", "abstract_url": "http://arxiv.org/abs/2408.04116v1", "primary_category": "cs.LG", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Combining Neural Architecture Search and Automatic Code Optimization: A Survey", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:18.126481"}
{"title": "Zero-shot Factual Consistency Evaluation Across Domains", "authors": "Raunak Agarwal", "abstract": "This work addresses the challenge of factual consistency in text generation\nsystems. We unify the tasks of Natural Language Inference, Summarization\nEvaluation, Factuality Verification and Factual Consistency Evaluation to train\nmodels capable of evaluating the factual consistency of source-target pairs\nacross diverse domains. We rigorously evaluate these against eight baselines on\na comprehensive benchmark suite comprising 22 datasets that span various tasks,\ndomains, and document lengths. Results demonstrate that our method achieves\nstate-of-the-art performance on this heterogeneous benchmark while addressing\nefficiency concerns and attaining cross-domain generalization.", "arxiv_id": "2408.04114v1", "pdf_url": "http://arxiv.org/pdf/2408.04114v1", "abstract_url": "http://arxiv.org/abs/2408.04114v1", "primary_category": "cs.CL", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Zero-shot Factual Consistency Evaluation Across Domains", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:19.040019"}
{"title": "UpLIF: An Updatable Self-Tuning Learned Index Framework", "authors": "Alireza Heidari, Amirhossein Ahmadi, Wei Zhang", "abstract": "The emergence of learned indexes has caused a paradigm shift in our\nperception of indexing by considering indexes as predictive models that\nestimate keys' positions within a data set, resulting in notable improvements\nin key search efficiency and index size reduction; however, a significant\nchallenge inherent in learned index modeling is its constrained support for\nupdate operations, necessitated by the requirement for a fixed distribution of\nrecords. Previous studies have proposed various approaches to address this\nissue with the drawback of high overhead due to multiple model retraining. In\nthis paper, we present UpLIF, an adaptive self-tuning learned index that\nadjusts the model to accommodate incoming updates, predicts the distribution of\nupdates for performance improvement, and optimizes its index structure using\nreinforcement learning. We also introduce the concept of balanced model\nadjustment, which determines the model's inherent properties (i.e. bias and\nvariance), enabling the integration of these factors into the existing index\nmodel without the need for retraining with new data. Our comprehensive\nexperiments show that the system surpasses state-of-the-art indexing solutions\n(both traditional and ML-based), achieving an increase in throughput of up to\n3.12 times with 1000 times less memory usage.", "arxiv_id": "2408.04113v1", "pdf_url": "http://arxiv.org/pdf/2408.04113v1", "abstract_url": "http://arxiv.org/abs/2408.04113v1", "primary_category": "cs.DB", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "UpLIF: An Updatable Self-Tuning Learned Index Framework", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:20.265173"}
{"title": "Zero-Delay QKV Compression for Mitigating KV Cache and Network Bottlenecks in LLM Inference", "authors": "Zeyu Zhang, Haiying Shen", "abstract": "In large-language models, memory constraints in the key-value cache (KVC)\npose a challenge during inference, especially with long prompts. In this work,\nwe observed that compressing KV values is more effective than compressing the\nmodel regarding accuracy and job completion time (JCT). However, quantizing KV\nvalues and dropping less-important tokens incur significant runtime\ncomputational time overhead, delaying JCT. These methods also cannot reduce\ncomputation time or high network communication time overhead in\nsequence-parallelism (SP) frameworks for long prompts. To tackle these issues,\nbased on our insightful observations from experimental analysis, we propose\nZeroC, a Zero-delay QKV Compression system that eliminates time overhead and\neven reduces computation and communication time of the model operations. ZeroC\ninnovatively embeds compression and decompression operations within model\noperations and adaptively determines compression ratios at a hybrid layer-token\nlevel. Further, it enables a communication-efficient SP inference framework.\nTrace-driven experiments demonstrate that ZeroC achieves up to 80% lower\naverage JCT, 35% lower average perplexity, and 2.8x higher throughput with the\nsame latency compared to state-of-the-art compression methods. ZeroC also\nreduces the average JCT of current LLM serving systems by up to 91% with the\nconstraint of 0.1 perplexity increase. We open-sourced the code.", "arxiv_id": "2408.04107v1", "pdf_url": "http://arxiv.org/pdf/2408.04107v1", "abstract_url": "http://arxiv.org/abs/2408.04107v1", "primary_category": "cs.LG", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Zero-Delay QKV Compression for Mitigating KV Cache and Network Bottlenecks in LLM Inference", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:21.035944"}
{"title": "Hardware-Assisted Virtualization of Neural Processing Units for Cloud Platforms", "authors": "Yuqi Xue, Yiqi Liu, Lifeng Nai, Jian Huang", "abstract": "Cloud platforms today have been deploying hardware accelerators like neural\nprocessing units (NPUs) for powering machine learning (ML) inference services.\nTo maximize the resource utilization while ensuring reasonable quality of\nservice, a natural approach is to virtualize NPUs for efficient resource\nsharing for multi-tenant ML services. However, virtualizing NPUs for modern\ncloud platforms is not easy. This is not only due to the lack of system\nabstraction support for NPU hardware, but also due to the lack of architectural\nand ISA support for enabling fine-grained dynamic operator scheduling for\nvirtualized NPUs.\n  We present TCloud, a holistic NPU virtualization framework. We investigate\nvirtualization techniques for NPUs across the entire software and hardware\nstack. TCloud consists of (1) a flexible NPU abstraction called vNPU, which\nenables fine-grained virtualization of the heterogeneous compute units in a\nphysical NPU (pNPU); (2) a vNPU resource allocator that enables pay-as-you-go\ncomputing model and flexible vNPU-to-pNPU mappings for improved resource\nutilization and cost-effectiveness; (3) an ISA extension of modern NPU\narchitecture for facilitating fine-grained tensor operator scheduling for\nmultiple vNPUs. We implement TCloud based on a production-level NPU simulator.\nOur experiments show that TCloud improves the throughput of ML inference\nservices by up to 1.4$\\times$ and reduces the tail latency by up to\n4.6$\\times$, while improving the NPU utilization by 1.2$\\times$ on average,\ncompared to state-of-the-art NPU sharing approaches.", "arxiv_id": "2408.04104v1", "pdf_url": "http://arxiv.org/pdf/2408.04104v1", "abstract_url": "http://arxiv.org/abs/2408.04104v1", "primary_category": "cs.AR", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Hardware-Assisted Virtualization of Neural Processing Units for Cloud Platforms", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:21.904828"}
{"title": "Tree Attention: Topology-aware Decoding for Long-Context Attention on GPU clusters", "authors": "Vasudev Shyam, Jonathan Pilault, Emily Shepperd, Quentin Anthony, Beren Millidge", "abstract": "Self-attention is the core mathematical operation of modern transformer\narchitectures and is also a significant computational bottleneck due to its\nquadratic complexity in the sequence length. In this work, we derive the scalar\nenergy function whose gradient computes the self-attention block, thus\nelucidating the theoretical underpinnings of self-attention, providing a\nBayesian interpretation of the operation and linking it closely with\nenergy-based models such as Hopfield Networks. Our formulation reveals that the\nreduction across the sequence axis can be efficiently computed in parallel\nthrough a tree reduction. Our algorithm, for parallelizing attention\ncomputation across multiple GPUs enables cross-device decoding to be performed\nasymptotically faster (up to 8x faster in our experiments) than alternative\napproaches such as Ring Attention, while also requiring significantly less\ncommunication volume and incurring 2x less peak memory. Our code is publicly\navailable here: \\url{https://github.com/Zyphra/tree_attention}.", "arxiv_id": "2408.04093v3", "pdf_url": "http://arxiv.org/pdf/2408.04093v3", "abstract_url": "http://arxiv.org/abs/2408.04093v3", "primary_category": "cs.LG", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Tree Attention: Topology-aware Decoding for Long-Context Attention on GPU clusters", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:22.595549"}
{"title": "Do Sharpness-based Optimizers Improve Generalization in Medical Image Analysis?", "authors": "Mohamed Hassan, Aleksandar Vakanski, Min Xian", "abstract": "Effective clinical deployment of deep learning models in healthcare demands\nhigh generalization performance to ensure accurate diagnosis and treatment\nplanning. In recent years, significant research has focused on improving the\ngeneralization of deep learning models by regularizing the sharpness of the\nloss landscape. Among the optimization approaches that explicitly minimize\nsharpness, Sharpness-Aware Minimization (SAM) has shown potential in enhancing\ngeneralization performance on general domain image datasets. This success has\nled to the development of several advanced sharpness-based algorithms aimed at\naddressing the limitations of SAM, such as Adaptive SAM, surrogate-Gap SAM,\nWeighted SAM, and Curvature Regularized SAM. These sharpness-based optimizers\nhave shown improvements in model generalization compared to conventional\nstochastic gradient descent optimizers and their variants on general domain\nimage datasets, but they have not been thoroughly evaluated on medical images.\nThis work provides a review of recent sharpness-based methods for improving the\ngeneralization of deep learning networks and evaluates the methods performance\non medical breast ultrasound images. Our findings indicate that the initial SAM\nmethod successfully enhances the generalization of various deep learning\nmodels. While Adaptive SAM improves generalization of convolutional neural\nnetworks, it fails to do so for vision transformers. Other sharpness-based\noptimizers, however, do not demonstrate consistent results. The results reveal\nthat, contrary to findings in the non-medical domain, SAM is the only\nrecommended sharpness-based optimizer that consistently improves generalization\nin medical image analysis, and further research is necessary to refine the\nvariants of SAM to enhance generalization performance in this field", "arxiv_id": "2408.04065v2", "pdf_url": "http://arxiv.org/pdf/2408.04065v2", "abstract_url": "http://arxiv.org/abs/2408.04065v2", "primary_category": "eess.IV", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Do Sharpness-based Optimizers Improve Generalization in Medical Image Analysis?", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:23.545782"}
{"title": "SocFedGPT: Federated GPT-based Adaptive Content Filtering System Leveraging User Interactions in Social Networks", "authors": "Sai Puppala, Ismail Hossain, Md Jahangir Alam, Sajedul Talukder", "abstract": "Our study presents a multifaceted approach to enhancing user interaction and\ncontent relevance in social media platforms through a federated learning\nframework. We introduce personalized GPT and Context-based Social Media LLM\nmodels, utilizing federated learning for privacy and security. Four client\nentities receive a base GPT-2 model and locally collected social media data,\nwith federated aggregation ensuring up-to-date model maintenance. Subsequent\nmodules focus on categorizing user posts, computing user persona scores, and\nidentifying relevant posts from friends' lists. A quantifying social engagement\napproach, coupled with matrix factorization techniques, facilitates\npersonalized content suggestions in real-time. An adaptive feedback loop and\nreadability score algorithm also enhance the quality and relevance of content\npresented to users. Our system offers a comprehensive solution to content\nfiltering and recommendation, fostering a tailored and engaging social media\nexperience while safeguarding user privacy.", "arxiv_id": "2408.05243v1", "pdf_url": "http://arxiv.org/pdf/2408.05243v1", "abstract_url": "http://arxiv.org/abs/2408.05243v1", "primary_category": "cs.LG", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "SocFedGPT: Federated GPT-based Adaptive Content Filtering System Leveraging User Interactions in Social Networks", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:24.356806"}
{"title": "PowerPM: Foundation Model for Power Systems", "authors": "Shihao Tu, Yupeng Zhang, Jing Zhang, Yang Yang", "abstract": "The emergence of abundant electricity time series (ETS) data provides ample\nopportunities for various applications in the power systems, including\ndemand-side management, grid stability, and consumer behavior analysis. Deep\nlearning models have advanced ETS modeling by effectively capturing sequence\ndependence. Nevertheless, learning a generic representation of ETS data for\nvarious applications remains challenging due to the inherently complex\nhierarchical structure of ETS data. Moreover, ETS data exhibits intricate\ntemporal dependencies and is suscepti ble to the influence of exogenous\nvariables. Furthermore, different instances exhibit diverse electricity\nconsumption behavior. In this paper, we propose a foundation model PowerPM to\nmodel ETS data, providing a large-scale, off-the-shelf model for power systems.\nPowerPM consists of a temporal encoder and a hierarchical encoder. The temporal\nencoder captures both temporal dependencies in ETS data, considering exogenous\nvariables. The hierarchical encoder models the correlation between hierarchy.\nFurthermore, PowerPM leverages a novel self-supervised pretraining framework\nconsisting of masked ETS modeling and dual-view contrastive learning, which\nenable PowerPM to capture temporal dependency within ETS windows and aware the\ndiscrepancy across ETS windows, providing two different perspectives to learn\ngeneric representation. Our experiments involve five real world scenario\ndatasets, comprising private and public data. Through pre-training on massive\nETS data, PowerPM achieves SOTA performance on diverse downstream tasks within\nthe private dataset. Impressively, when transferred to the public datasets,\nPowerPM maintains its superiority, showcasing its remarkable generalization\nability across various tasks and domains. Moreover, ablation studies, few-shot\nexperiments provide additional evidence of the effectiveness of our model.", "arxiv_id": "2408.04057v1", "pdf_url": "http://arxiv.org/pdf/2408.04057v1", "abstract_url": "http://arxiv.org/abs/2408.04057v1", "primary_category": "cs.LG", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "PowerPM: Foundation Model for Power Systems", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:25.277290"}
{"title": "Machine Learning-Based Reward-Driven Tuning of Scanning Probe Microscopy: Towards Fully Automated Microscopy", "authors": "Yu Liu, Roger Proksch, Jason Bemis, Utkarsh Pratiush, Astita Dubey, Mahshid Ahmadi, Reece Emery, Philip D. Rack, Yu-Chen Liu, Jan-Chi Yang, Sergei V. Kalinin", "abstract": "Since the dawn of scanning probe microscopy (SPM), tapping or intermittent\ncontact mode has been one of the most widely used imaging modes. Manual\noptimization of tapping mode not only takes a lot of instrument and operator\ntime, but also often leads to frequent probe and sample damage, poor image\nquality and reproducibility issues for new types of samples or inexperienced\nusers. Despite wide use, optimization of tapping mode imaging is an extremely\nhard problem, ill-suited to either classical control methods or machine\nlearning. Here we introduce a reward-driven workflow to automate the\noptimization of SPM in the tapping mode. The reward function is defined based\non multiple channels with physical and empirical knowledge of good scans\nencoded, representing a sample-agnostic measure of image quality and imitating\nthe decision-making logic employed by human operators. This automated workflow\ngives optimal scanning parameters for different probes and samples and gives\nhigh-quality SPM images consistently in the attractive mode. This study\nbroadens the application and accessibility of SPM and opens the door for fully\nautomated SPM.", "arxiv_id": "2408.04055v1", "pdf_url": "http://arxiv.org/pdf/2408.04055v1", "abstract_url": "http://arxiv.org/abs/2408.04055v1", "primary_category": "cond-mat.mes-hall", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Machine Learning-Based Reward-Driven Tuning of Scanning Probe Microscopy: Towards Fully Automated Microscopy", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:26.105898"}
{"title": "Deep Generative Models for Subgraph Prediction", "authors": "Erfaneh Mahmoudzadeh, Parmis Naddaf, Kiarash Zahirnia, Oliver Schulte", "abstract": "Graph Neural Networks (GNNs) are important across different domains, such as\nsocial network analysis and recommendation systems, due to their ability to\nmodel complex relational data. This paper introduces subgraph queries as a new\ntask for deep graph learning. Unlike traditional graph prediction tasks that\nfocus on individual components like link prediction or node classification,\nsubgraph queries jointly predict the components of a target subgraph based on\nevidence that is represented by an observed subgraph. For instance, a subgraph\nquery can predict a set of target links and/or node labels. To answer subgraph\nqueries, we utilize a probabilistic deep Graph Generative Model. Specifically,\nwe inductively train a Variational Graph Auto-Encoder (VGAE) model, augmented\nto represent a joint distribution over links, node features and labels.\nBayesian optimization is used to tune a weighting for the relative importance\nof links, node features and labels in a specific domain. We describe a\ndeterministic and a sampling-based inference method for estimating subgraph\nprobabilities from the VGAE generative graph distribution, without retraining,\nin zero-shot fashion. For evaluation, we apply the inference methods on a range\nof subgraph queries on six benchmark datasets. We find that inference from a\nmodel achieves superior predictive performance, surpassing independent\nprediction baselines with improvements in AUC scores ranging from 0.06 to 0.2\npoints, depending on the dataset.", "arxiv_id": "2408.04053v1", "pdf_url": "http://arxiv.org/pdf/2408.04053v1", "abstract_url": "http://arxiv.org/abs/2408.04053v1", "primary_category": "cs.LG", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Deep Generative Models for Subgraph Prediction", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:27.485280"}
{"title": "Learning Rate-Free Reinforcement Learning: A Case for Model Selection with Non-Stationary Objectives", "authors": "Aida Afshar, Aldo Pacchiano", "abstract": "The performance of reinforcement learning (RL) algorithms is sensitive to the\nchoice of hyperparameters, with the learning rate being particularly\ninfluential. RL algorithms fail to reach convergence or demand an extensive\nnumber of samples when the learning rate is not optimally set. In this work, we\nshow that model selection can help to improve the failure modes of RL that are\ndue to suboptimal choices of learning rate. We present a model selection\nframework for Learning Rate-Free Reinforcement Learning that employs model\nselection methods to select the optimal learning rate on the fly. This approach\nof adaptive learning rate tuning neither depends on the underlying RL algorithm\nnor the optimizer and solely uses the reward feedback to select the learning\nrate; hence, the framework can input any RL algorithm and produce a learning\nrate-free version of it. We conduct experiments for policy optimization methods\nand evaluate various model selection strategies within our framework. Our\nresults indicate that data-driven model selection algorithms are better\nalternatives to standard bandit algorithms when the optimal choice of\nhyperparameter is time-dependent and non-stationary.", "arxiv_id": "2408.04046v1", "pdf_url": "http://arxiv.org/pdf/2408.04046v1", "abstract_url": "http://arxiv.org/abs/2408.04046v1", "primary_category": "cs.LG", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Learning Rate-Free Reinforcement Learning: A Case for Model Selection with Non-Stationary Objectives", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:28.768377"}
{"title": "Scaling Law of Sim2Real Transfer Learning in Expanding Computational Materials Databases for Real-World Predictions", "authors": "Shunya Minami, Yoshihiro Hayashi, Stephen Wu, Kenji Fukumizu, Hiroki Sugisawa, Masashi Ishii, Isao Kuwajima, Kazuya Shiratori, Ryo Yoshida", "abstract": "To address the challenge of limited experimental materials data, extensive\nphysical property databases are being developed based on high-throughput\ncomputational experiments, such as molecular dynamics simulations. Previous\nstudies have shown that fine-tuning a predictor pretrained on a computational\ndatabase to a real system can result in models with outstanding generalization\ncapabilities compared to learning from scratch. This study demonstrates the\nscaling law of simulation-to-real (Sim2Real) transfer learning for several\nmachine learning tasks in materials science. Case studies of three prediction\ntasks for polymers and inorganic materials reveal that the prediction error on\nreal systems decreases according to a power-law as the size of the\ncomputational data increases. Observing the scaling behavior offers various\ninsights for database development, such as determining the sample size\nnecessary to achieve a desired performance, identifying equivalent sample sizes\nfor physical and computational experiments, and guiding the design of data\nproduction protocols for downstream real-world tasks.", "arxiv_id": "2408.04042v1", "pdf_url": "http://arxiv.org/pdf/2408.04042v1", "abstract_url": "http://arxiv.org/abs/2408.04042v1", "primary_category": "cond-mat.mtrl-sci", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Scaling Law of Sim2Real Transfer Learning in Expanding Computational Materials Databases for Real-World Predictions", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:29.582654"}
{"title": "Multimodal Gender Fairness in Depression Prediction: Insights on Data from the USA & China", "authors": "Joseph Cameron, Jiaee Cheong, Micol Spitale, Hatice Gunes", "abstract": "Social agents and robots are increasingly being used in wellbeing settings.\nHowever, a key challenge is that these agents and robots typically rely on\nmachine learning (ML) algorithms to detect and analyse an individual's mental\nwellbeing. The problem of bias and fairness in ML algorithms is becoming an\nincreasingly greater source of concern. In concurrence, existing literature has\nalso indicated that mental health conditions can manifest differently across\ngenders and cultures. We hypothesise that the representation of features\n(acoustic, textual, and visual) and their inter-modal relations would vary\namong subjects from different cultures and genders, thus impacting the\nperformance and fairness of various ML models. We present the very first\nevaluation of multimodal gender fairness in depression manifestation by\nundertaking a study on two different datasets from the USA and China. We\nundertake thorough statistical and ML experimentation and repeat the\nexperiments for several different algorithms to ensure that the results are not\nalgorithm-dependent. Our findings indicate that though there are differences\nbetween both datasets, it is not conclusive whether this is due to the\ndifference in depression manifestation as hypothesised or other external\nfactors such as differences in data collection methodology. Our findings\nfurther motivate a call for a more consistent and culturally aware data\ncollection process in order to address the problem of ML bias in depression\ndetection and to promote the development of fairer agents and robots for\nwellbeing.", "arxiv_id": "2408.04026v1", "pdf_url": "http://arxiv.org/pdf/2408.04026v1", "abstract_url": "http://arxiv.org/abs/2408.04026v1", "primary_category": "cs.LG", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Multimodal Gender Fairness in Depression Prediction: Insights on Data from the USA & China", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:30.410894"}
{"title": "MathBridge: A Large Corpus Dataset for Translating Spoken Mathematical Expressions into $LaTeX$ Formulas for Improved Readability", "authors": "Kyudan Jung, Sieun Hyeon, Jeong Youn Kwon, Nam-Joon Kim, Hyun Gon Ryu, Hyuk-Jae Lee, Jaeyoung Do", "abstract": "Improving the readability of mathematical expressions in text-based document\nsuch as subtitle of mathematical video, is an significant task. To achieve\nthis, mathematical expressions should be convert to compiled formulas. For\ninstance, the spoken expression ``x equals minus b plus or minus the square\nroot of b squared minus four a c, all over two a'' from automatic speech\nrecognition is more readily comprehensible when displayed as a compiled formula\n$x = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}$. To convert mathematical spoken\nsentences to compiled formulas, two processes are required: spoken sentences\nare converted into LaTeX formulas, and LaTeX formulas are converted into\ncompiled formulas. The latter can be managed by using LaTeX engines. However,\nthere is no way to do the former effectively. Even if we try to solve this\nusing language models, there is no paired data between spoken sentences and\nLaTeX formulas to train it. In this paper, we introduce MathBridge, the first\nextensive dataset for translating mathematical spoken sentences into LaTeX\nformulas. MathBridge comprises approximately 23 million LaTeX formulas paired\nwith the corresponding mathematical spoken sentences. Through comprehensive\nevaluations, including fine-tuning with proposed data, we discovered that\nMathBridge significantly enhances the capabilities of pretrained language\nmodels for converting to LaTeX formulas from mathematical spoken sentences.\nSpecifically, for the T5-large model, the sacreBLEU score increased from 4.77\nto 46.8, demonstrating substantial enhancement.", "arxiv_id": "2408.07081v3", "pdf_url": "http://arxiv.org/pdf/2408.07081v3", "abstract_url": "http://arxiv.org/abs/2408.07081v3", "primary_category": "cs.LG", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "MathBridge: A Large Corpus Dataset for Translating Spoken Mathematical Expressions into $LaTeX$ Formulas for Improved Readability", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:32.966664"}
{"title": "SLIM-RAFT: A Novel Fine-Tuning Approach to Improve Cross-Linguistic Performance for Mercosur Common Nomenclature", "authors": "Vin\u00edcius Di Oliveira, Yuri Fa\u00e7anha Bezerra, Li Weigang, Pedro Carvalho Brom, Victor Rafael R. Celestino", "abstract": "Natural language processing (NLP) has seen significant advancements with the\nadvent of large language models (LLMs). However, substantial improvements are\nstill needed for languages other than English, especially for specific domains\nlike the applications of Mercosur Common Nomenclature (NCM), a Brazilian\nHarmonized System (HS). To address this gap, this study uses TeenyTineLLaMA, a\nfoundational Portuguese LLM, as an LLM source to implement the NCM application\nprocessing. Additionally, a simplified Retrieval-Augmented Fine-Tuning (RAFT)\ntechnique, termed SLIM-RAFT, is proposed for task-specific fine-tuning of LLMs.\nThis approach retains the chain-of-thought (CoT) methodology for prompt\ndevelopment in a more concise and streamlined manner, utilizing brief and\nfocused documents for training. The proposed model demonstrates an efficient\nand cost-effective alternative for fine-tuning smaller LLMs, significantly\noutperforming TeenyTineLLaMA and ChatGPT-4 in the same task. Although the\nresearch focuses on NCM applications, the methodology can be easily adapted for\nHS applications worldwide.", "arxiv_id": "2408.03936v1", "pdf_url": "http://arxiv.org/pdf/2408.03936v1", "abstract_url": "http://arxiv.org/abs/2408.03936v1", "primary_category": "cs.CL", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "SLIM-RAFT: A Novel Fine-Tuning Approach to Improve Cross-Linguistic Performance for Mercosur Common Nomenclature", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:33.787014"}
{"title": "AutoFAIR : Automatic Data FAIRification via Machine Reading", "authors": "Tingyan Ma, Wei Liu, Bin Lu, Xiaoying Gan, Yunqiang Zhu, Luoyi Fu, Chenghu Zhou", "abstract": "The explosive growth of data fuels data-driven research, facilitating\nprogress across diverse domains. The FAIR principles emerge as a guiding\nstandard, aiming to enhance the findability, accessibility, interoperability,\nand reusability of data. However, current efforts primarily focus on manual\ndata FAIRification, which can only handle targeted data and lack efficiency. To\naddress this issue, we propose AutoFAIR, an architecture designed to enhance\ndata FAIRness automately. Firstly, We align each data and metadata operation\nwith specific FAIR indicators to guide machine-executable actions. Then, We\nutilize Web Reader to automatically extract metadata based on language models,\neven in the absence of structured data webpage schemas. Subsequently, FAIR\nAlignment is employed to make metadata comply with FAIR principles by ontology\nguidance and semantic matching. Finally, by applying AutoFAIR to various data,\nespecially in the field of mountain hazards, we observe significant\nimprovements in findability, accessibility, interoperability, and reusability\nof data. The FAIRness scores before and after applying AutoFAIR indicate\nenhanced data value.", "arxiv_id": "2408.04673v1", "pdf_url": "http://arxiv.org/pdf/2408.04673v1", "abstract_url": "http://arxiv.org/abs/2408.04673v1", "primary_category": "cs.CL", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "AutoFAIR : Automatic Data FAIRification via Machine Reading", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:34.596125"}
{"title": "Hard to Explain: On the Computational Hardness of In-Distribution Model Interpretation", "authors": "Guy Amir, Shahaf Bassan, Guy Katz", "abstract": "The ability to interpret Machine Learning (ML) models is becoming\nincreasingly essential. However, despite significant progress in the field,\nthere remains a lack of rigorous characterization regarding the innate\ninterpretability of different models. In an attempt to bridge this gap, recent\nwork has demonstrated that it is possible to formally assess interpretability\nby studying the computational complexity of explaining the decisions of various\nmodels. In this setting, if explanations for a particular model can be obtained\nefficiently, the model is considered interpretable (since it can be explained\n``easily''). However, if generating explanations over an ML model is\ncomputationally intractable, it is considered uninterpretable. Prior research\nidentified two key factors that influence the complexity of interpreting an ML\nmodel: (i) the type of the model (e.g., neural networks, decision trees, etc.);\nand (ii) the form of explanation (e.g., contrastive explanations, Shapley\nvalues, etc.). In this work, we claim that a third, important factor must also\nbe considered for this analysis -- the underlying distribution over which the\nexplanation is obtained. Considering the underlying distribution is key in\navoiding explanations that are socially misaligned, i.e., convey information\nthat is biased and unhelpful to users. We demonstrate the significant influence\nof the underlying distribution on the resulting overall interpretation\ncomplexity, in two settings: (i) prediction models paired with an external\nout-of-distribution (OOD) detector; and (ii) prediction models designed to\ninherently generate socially aligned explanations. Our findings prove that the\nexpressiveness of the distribution can significantly influence the overall\ncomplexity of interpretation, and identify essential prerequisites that a model\nmust possess to generate socially aligned explanations.", "arxiv_id": "2408.03915v1", "pdf_url": "http://arxiv.org/pdf/2408.03915v1", "abstract_url": "http://arxiv.org/abs/2408.03915v1", "primary_category": "cs.LG", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Hard to Explain: On the Computational Hardness of In-Distribution Model Interpretation", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:36.565056"}
{"title": "AdapMTL: Adaptive Pruning Framework for Multitask Learning Model", "authors": "Mingcan Xiang, Steven Jiaxun Tang, Qizheng Yang, Hui Guan, Tongping Liu", "abstract": "In the domain of multimedia and multimodal processing, the efficient handling\nof diverse data streams such as images, video, and sensor data is paramount.\nModel compression and multitask learning (MTL) are crucial in this field,\noffering the potential to address the resource-intensive demands of processing\nand interpreting multiple forms of media simultaneously. However, effectively\ncompressing a multitask model presents significant challenges due to the\ncomplexities of balancing sparsity allocation and accuracy performance across\nmultiple tasks. To tackle these challenges, we propose AdapMTL, an adaptive\npruning framework for MTL models. AdapMTL leverages multiple learnable soft\nthresholds independently assigned to the shared backbone and the task-specific\nheads to capture the nuances in different components' sensitivity to pruning.\nDuring training, it co-optimizes the soft thresholds and MTL model weights to\nautomatically determine the suitable sparsity level at each component to\nachieve both high task accuracy and high overall sparsity. It further\nincorporates an adaptive weighting mechanism that dynamically adjusts the\nimportance of task-specific losses based on each task's robustness to pruning.\nWe demonstrate the effectiveness of AdapMTL through comprehensive experiments\non popular multitask datasets, namely NYU-v2 and Tiny-Taskonomy, with different\narchitectures, showcasing superior performance compared to state-of-the-art\npruning methods.", "arxiv_id": "2408.03913v1", "pdf_url": "http://arxiv.org/pdf/2408.03913v1", "abstract_url": "http://arxiv.org/abs/2408.03913v1", "primary_category": "cs.CV", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "AdapMTL: Adaptive Pruning Framework for Multitask Learning Model", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:38.188790"}
{"title": "LaFA: Latent Feature Attacks on Non-negative Matrix Factorization", "authors": "Minh Vu, Ben Nebgen, Erik Skau, Geigh Zollicoffer, Juan Castorena, Kim Rasmussen, Boian Alexandrov, Manish Bhattarai", "abstract": "As Machine Learning (ML) applications rapidly grow, concerns about\nadversarial attacks compromising their reliability have gained significant\nattention. One unsupervised ML method known for its resilience to such attacks\nis Non-negative Matrix Factorization (NMF), an algorithm that decomposes input\ndata into lower-dimensional latent features. However, the introduction of\npowerful computational tools such as Pytorch enables the computation of\ngradients of the latent features with respect to the original data, raising\nconcerns about NMF's reliability. Interestingly, naively deriving the\nadversarial loss for NMF as in the case of ML would result in the\nreconstruction loss, which can be shown theoretically to be an ineffective\nattacking objective. In this work, we introduce a novel class of attacks in NMF\ntermed Latent Feature Attacks (LaFA), which aim to manipulate the latent\nfeatures produced by the NMF process. Our method utilizes the Feature Error\n(FE) loss directly on the latent features. By employing FE loss, we generate\nperturbations in the original data that significantly affect the extracted\nlatent features, revealing vulnerabilities akin to those found in other ML\ntechniques. To handle large peak-memory overhead from gradient back-propagation\nin FE attacks, we develop a method based on implicit differentiation which\nenables their scaling to larger datasets. We validate NMF vulnerabilities and\nFE attacks effectiveness through extensive experiments on synthetic and\nreal-world data.", "arxiv_id": "2408.03909v1", "pdf_url": "http://arxiv.org/pdf/2408.03909v1", "abstract_url": "http://arxiv.org/abs/2408.03909v1", "primary_category": "cs.LG", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "LaFA: Latent Feature Attacks on Non-negative Matrix Factorization", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:39.110890"}
{"title": "Knowledge Probing for Graph Representation Learning", "authors": "Mingyu Zhao, Xingyu Huang, Ziyu Lyu, Yanlin Wang, Lixin Cui, Lu Bai", "abstract": "Graph learning methods have been extensively applied in diverse application\nareas. However, what kind of inherent graph properties e.g. graph proximity,\ngraph structural information has been encoded into graph representation\nlearning for downstream tasks is still under-explored. In this paper, we\npropose a novel graph probing framework (GraphProbe) to investigate and\ninterpret whether the family of graph learning methods has encoded different\nlevels of knowledge in graph representation learning. Based on the intrinsic\nproperties of graphs, we design three probes to systematically investigate the\ngraph representation learning process from different perspectives, respectively\nthe node-wise level, the path-wise level, and the structural level. We\nconstruct a thorough evaluation benchmark with nine representative graph\nlearning methods from random walk based approaches, basic graph neural networks\nand self-supervised graph methods, and probe them on six benchmark datasets for\nnode classification, link prediction and graph classification. The experimental\nevaluation verify that GraphProbe can estimate the capability of graph\nrepresentation learning. Remaking results have been concluded: GCN and\nWeightedGCN methods are relatively versatile methods achieving better results\nwith respect to different tasks.", "arxiv_id": "2408.03877v1", "pdf_url": "http://arxiv.org/pdf/2408.03877v1", "abstract_url": "http://arxiv.org/abs/2408.03877v1", "primary_category": "cs.LG", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Knowledge Probing for Graph Representation Learning", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:40.134612"}
{"title": "Inter-Series Transformer: Attending to Products in Time Series Forecasting", "authors": "Rares Cristian, Pavithra Harsha, Clemente Ocejo, Georgia Perakis, Brian Quanz, Ioannis Spantidakis, Hamza Zerhouni", "abstract": "Time series forecasting is an important task in many fields ranging from\nsupply chain management to weather forecasting. Recently, Transformer neural\nnetwork architectures have shown promising results in forecasting on common\ntime series benchmark datasets. However, application to supply chain demand\nforecasting, which can have challenging characteristics such as sparsity and\ncross-series effects, has been limited.\n  In this work, we explore the application of Transformer-based models to\nsupply chain demand forecasting. In particular, we develop a new\nTransformer-based forecasting approach using a shared, multi-task per-time\nseries network with an initial component applying attention across time series,\nto capture interactions and help address sparsity. We provide a case study\napplying our approach to successfully improve demand prediction for a medical\ndevice manufacturing company. To further validate our approach, we also apply\nit to public demand forecasting datasets as well and demonstrate competitive to\nsuperior performance compared to a variety of baseline and state-of-the-art\nforecast methods across the private and public datasets.", "arxiv_id": "2408.03872v1", "pdf_url": "http://arxiv.org/pdf/2408.03872v1", "abstract_url": "http://arxiv.org/abs/2408.03872v1", "primary_category": "cs.LG", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Inter-Series Transformer: Attending to Products in Time Series Forecasting", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:41.106022"}
{"title": "PackMamba: Efficient Processing of Variable-Length Sequences in Mamba training", "authors": "Haoran Xu, Ziqian Liu, Rong Fu, Zhongling Su, Zerui Wang, Zheng Cai, Zhilin Pei, Xingcheng Zhang", "abstract": "With the evolution of large language models, traditional Transformer models\nbecome computationally demanding for lengthy sequences due to the quadratic\ngrowth in computation with respect to the sequence length. Mamba, emerging as a\ngroundbreaking architecture in the field of generative AI, demonstrates\nremarkable proficiency in handling elongated sequences with reduced\ncomputational and memory complexity. Nevertheless, the existing training\nframework of Mamba presents inefficiency with variable-length sequence inputs.\nEither single-sequence training results in low GPU utilization, or batched\nprocessing of variable-length sequences to a maximum length incurs considerable\nmemory and computational overhead. To address this problem, we analyze the\nperformance of bottleneck operators in Mamba under diverse tensor shapes and\nproposed PackMamba, a high-throughput Mamba that efficiently handles\nvariable-length sequences. Diving deep into state-space models (SSMs), we\nmodify the parallel operators to avoid passing information between individual\nsequences while maintaining high performance. Experimental results on an NVIDIA\nA100 GPU demonstrate throughput exceeding the baseline single-sequence\nprocessing scheme: 3.06x speedup on the 1.4B model and 2.62x on the 2.8B model.", "arxiv_id": "2408.03865v1", "pdf_url": "http://arxiv.org/pdf/2408.03865v1", "abstract_url": "http://arxiv.org/abs/2408.03865v1", "primary_category": "cs.LG", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "PackMamba: Efficient Processing of Variable-Length Sequences in Mamba training", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:41.977856"}
{"title": "Hate Speech Detection and Classification in Amharic Text with Deep Learning", "authors": "Samuel Minale Gashe, Seid Muhie Yimam, Yaregal Assabie", "abstract": "Hate speech is a growing problem on social media. It can seriously impact\nsociety, especially in countries like Ethiopia, where it can trigger conflicts\namong diverse ethnic and religious groups. While hate speech detection in\nresource rich languages are progressing, for low resource languages such as\nAmharic are lacking. To address this gap, we develop Amharic hate speech data\nand SBi-LSTM deep learning model that can detect and classify text into four\ncategories of hate speech: racial, religious, gender, and non-hate speech. We\nhave annotated 5k Amharic social media post and comment data into four\ncategories. The data is annotated using a custom annotation tool by a total of\n100 native Amharic speakers. The model achieves a 94.8 F1-score performance.\nFuture improvements will include expanding the dataset and develop state-of-the\nart models.\n  Keywords: Amharic hate speech detection, classification, Amharic dataset,\nDeep Learning, SBi-LSTM", "arxiv_id": "2408.03849v1", "pdf_url": "http://arxiv.org/pdf/2408.03849v1", "abstract_url": "http://arxiv.org/abs/2408.03849v1", "primary_category": "cs.CL", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Hate Speech Detection and Classification in Amharic Text with Deep Learning", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:42.792617"}
{"title": "Bi-Level Spatial and Channel-aware Transformer for Learned Image Compression", "authors": "Hamidreza Soltani, Erfan Ghasemi", "abstract": "Recent advancements in learned image compression (LIC) methods have\ndemonstrated superior performance over traditional hand-crafted codecs. These\nlearning-based methods often employ convolutional neural networks (CNNs) or\nTransformer-based architectures. However, these nonlinear approaches frequently\noverlook the frequency characteristics of images, which limits their\ncompression efficiency. To address this issue, we propose a novel\nTransformer-based image compression method that enhances the transformation\nstage by considering frequency components within the feature map. Our method\nintegrates a novel Hybrid Spatial-Channel Attention Transformer Block (HSCATB),\nwhere a spatial-based branch independently handles high and low frequencies at\nthe attention layer, and a Channel-aware Self-Attention (CaSA) module captures\ninformation across channels, significantly improving compression performance.\nAdditionally, we introduce a Mixed Local-Global Feed Forward Network (MLGFFN)\nwithin the Transformer block to enhance the extraction of diverse and rich\ninformation, which is crucial for effective compression. These innovations\ncollectively improve the transformation's ability to project data into a more\ndecorrelated latent space, thereby boosting overall compression efficiency.\nExperimental results demonstrate that our framework surpasses state-of-the-art\nLIC methods in rate-distortion performance.", "arxiv_id": "2408.03842v1", "pdf_url": "http://arxiv.org/pdf/2408.03842v1", "abstract_url": "http://arxiv.org/abs/2408.03842v1", "primary_category": "cs.CV", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Bi-Level Spatial and Channel-aware Transformer for Learned Image Compression", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:43.616522"}
{"title": "Leveraging Variation Theory in Counterfactual Data Augmentation for Optimized Active Learning", "authors": "Simret Araya Gebreegziabher, Kuangshi Ai, Zheng Zhang, Elena L. Glassman, Toby Jia-Jun Li", "abstract": "Active Learning (AL) allows models to learn interactively from user feedback.\nThis paper introduces a counterfactual data augmentation approach to AL,\nparticularly addressing the selection of datapoints for user querying, a\npivotal concern in enhancing data efficiency. Our approach is inspired by\nVariation Theory, a theory of human concept learning that emphasizes the\nessential features of a concept by focusing on what stays the same and what\nchanges. Instead of just querying with existing datapoints, our approach\nsynthesizes artificial datapoints that highlight potential key similarities and\ndifferences among labels using a neuro-symbolic pipeline combining large\nlanguage models (LLMs) and rule-based models. Through an experiment in the\nexample domain of text classification, we show that our approach achieves\nsignificantly higher performance when there are fewer annotated data. As the\nannotated training data gets larger the impact of the generated data starts to\ndiminish showing its capability to address the cold start problem in AL. This\nresearch sheds light on integrating theories of human learning into the\noptimization of AL.", "arxiv_id": "2408.03819v1", "pdf_url": "http://arxiv.org/pdf/2408.03819v1", "abstract_url": "http://arxiv.org/abs/2408.03819v1", "primary_category": "cs.LG", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Leveraging Variation Theory in Counterfactual Data Augmentation for Optimized Active Learning", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:44.744716"}
{"title": "Early Prediction of Causes (not Effects) in Healthcare by Long-Term Clinical Time Series Forecasting", "authors": "Michael Staniek, Marius Fracarolli, Michael Hagmann, Stefan Riezler", "abstract": "Machine learning for early syndrome diagnosis aims to solve the intricate\ntask of predicting a ground truth label that most often is the outcome (effect)\nof a medical consensus definition applied to observed clinical measurements\n(causes), given clinical measurements observed several hours before. Instead of\nfocusing on the prediction of the future effect, we propose to directly predict\nthe causes via time series forecasting (TSF) of clinical variables and\ndetermine the effect by applying the gold standard consensus definition to the\nforecasted values. This method has the invaluable advantage of being\nstraightforwardly interpretable to clinical practitioners, and because model\ntraining does not rely on a particular label anymore, the forecasted data can\nbe used to predict any consensus-based label. We exemplify our method by means\nof long-term TSF with Transformer models, with a focus on accurate prediction\nof sparse clinical variables involved in the SOFA-based Sepsis-3 definition and\nthe new Simplified Acute Physiology Score (SAPS-II) definition. Our experiments\nare conducted on two datasets and show that contrary to recent proposals which\nadvocate set function encoders for time series and direct multi-step decoders,\nbest results are achieved by a combination of standard dense encoders with\niterative multi-step decoders. The key for success of iterative multi-step\ndecoding can be attributed to its ability to capture cross-variate dependencies\nand to a student forcing training strategy that teaches the model to rely on\nits own previous time step predictions for the next time step prediction.", "arxiv_id": "2408.03816v1", "pdf_url": "http://arxiv.org/pdf/2408.03816v1", "abstract_url": "http://arxiv.org/abs/2408.03816v1", "primary_category": "cs.LG", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Early Prediction of Causes (not Effects) in Healthcare by Long-Term Clinical Time Series Forecasting", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:45.726773"}
{"title": "Trustworthy Image Semantic Communication with GenAI: Explainablity, Controllability, and Efficiency", "authors": "Xijun Wang, Dongshan Ye, Chenyuan Feng, Howard H. Yang, Xiang Chen, Tony Q. S. Quek", "abstract": "Image semantic communication (ISC) has garnered significant attention for its\npotential to achieve high efficiency in visual content transmission. However,\nexisting ISC systems based on joint source-channel coding face challenges in\ninterpretability, operability, and compatibility. To address these limitations,\nwe propose a novel trustworthy ISC framework. This approach leverages text\nextraction and segmentation mapping techniques to convert images into\nexplainable semantics, while employing Generative Artificial Intelligence\n(GenAI) for multiple downstream inference tasks. We also introduce a multi-rate\nISC transmission protocol that dynamically adapts to both the received\nexplainable semantic content and specific task requirements at the receiver.\nSimulation results demonstrate that our framework achieves explainable\nlearning, decoupled training, and compatible transmission in various\napplication scenarios. Finally, some intriguing research directions and\napplication scenarios are identified.", "arxiv_id": "2408.03806v1", "pdf_url": "http://arxiv.org/pdf/2408.03806v1", "abstract_url": "http://arxiv.org/abs/2408.03806v1", "primary_category": "cs.IT", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Trustworthy Image Semantic Communication with GenAI: Explainablity, Controllability, and Efficiency", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:46.442875"}
{"title": "Learning from Noisy Labels for Long-tailed Data via Optimal Transport", "authors": "Mengting Li, Chuang Zhu", "abstract": "Noisy labels, which are common in real-world datasets, can significantly\nimpair the training of deep learning models. However, recent adversarial\nnoise-combating methods overlook the long-tailed distribution of real data,\nwhich can significantly harm the effect of denoising strategies. Meanwhile, the\nmismanagement of noisy labels further compromises the model's ability to handle\nlong-tailed data. To tackle this issue, we propose a novel approach to manage\ndata characterized by both long-tailed distributions and noisy labels. First,\nwe introduce a loss-distance cross-selection module, which integrates class\npredictions and feature distributions to filter clean samples, effectively\naddressing uncertainties introduced by noisy labels and long-tailed\ndistributions. Subsequently, we employ optimal transport strategies to generate\npseudo-labels for the noise set in a semi-supervised training manner, enhancing\npseudo-label quality while mitigating the effects of sample scarcity caused by\nthe long-tailed distribution. We conduct experiments on both synthetic and\nreal-world datasets, and the comprehensive experimental results demonstrate\nthat our method surpasses current state-of-the-art methods. Our code will be\navailable in the future.", "arxiv_id": "2408.03977v1", "pdf_url": "http://arxiv.org/pdf/2408.03977v1", "abstract_url": "http://arxiv.org/abs/2408.03977v1", "primary_category": "cs.LG", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Learning from Noisy Labels for Long-tailed Data via Optimal Transport", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:47.488500"}
{"title": "Anatomical Foundation Models for Brain MRIs", "authors": "Carlo Alberto Barbano, Matteo Brunello, Benoit Dufumier, Marco Grangetto", "abstract": "Deep Learning (DL) in neuroimaging has become increasingly relevant for\ndetecting neurological conditions and neurodegenerative disorders. One of the\nmost predominant biomarkers in neuroimaging is represented by brain age, which\nhas been shown to be a good indicator for different conditions, such as\nAlzheimer's Disease. Using brain age for pretraining DL models in transfer\nlearning settings has also recently shown promising results, especially when\ndealing with data scarcity of different conditions. On the other hand,\nanatomical information of brain MRIs (e.g. cortical thickness) can provide\nimportant information for learning good representations that can be transferred\nto many downstream tasks. In this work, we propose AnatCL, an anatomical\nfoundation model for brain MRIs that i.) leverages anatomical information with\na weakly contrastive learning approach and ii.) achieves state-of-the-art\nperformances in many different downstream tasks. To validate our approach we\nconsider 12 different downstream tasks for diagnosis classification, and\nprediction of 10 different clinical assessment scores.", "arxiv_id": "2408.07079v1", "pdf_url": "http://arxiv.org/pdf/2408.07079v1", "abstract_url": "http://arxiv.org/abs/2408.07079v1", "primary_category": "eess.IV", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Anatomical Foundation Models for Brain MRIs", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:49.326028"}
{"title": "Reliable Node Similarity Matrix Guided Contrastive Graph Clustering", "authors": "Yunhui Liu, Xinyi Gao, Tieke He, Tao Zheng, Jianhua Zhao, Hongzhi Yin", "abstract": "Graph clustering, which involves the partitioning of nodes within a graph\ninto disjoint clusters, holds significant importance for numerous subsequent\napplications. Recently, contrastive learning, known for utilizing supervisory\ninformation, has demonstrated encouraging results in deep graph clustering.\nThis methodology facilitates the learning of favorable node representations for\nclustering by attracting positively correlated node pairs and distancing\nnegatively correlated pairs within the representation space. Nevertheless, a\nsignificant limitation of existing methods is their inadequacy in thoroughly\nexploring node-wise similarity. For instance, some hypothesize that the node\nsimilarity matrix within the representation space is identical, ignoring the\ninherent semantic relationships among nodes. Given the fundamental role of\ninstance similarity in clustering, our research investigates contrastive graph\nclustering from the perspective of the node similarity matrix. We argue that an\nideal node similarity matrix within the representation space should accurately\nreflect the inherent semantic relationships among nodes, ensuring the\npreservation of semantic similarities in the learned representations. In\nresponse to this, we introduce a new framework, Reliable Node Similarity Matrix\nGuided Contrastive Graph Clustering (NS4GC), which estimates an approximately\nideal node similarity matrix within the representation space to guide\nrepresentation learning. Our method introduces node-neighbor alignment and\nsemantic-aware sparsification, ensuring the node similarity matrix is both\naccurate and efficiently sparse. Comprehensive experiments conducted on $8$\nreal-world datasets affirm the efficacy of learning the node similarity matrix\nand the superior performance of NS4GC.", "arxiv_id": "2408.03765v1", "pdf_url": "http://arxiv.org/pdf/2408.03765v1", "abstract_url": "http://arxiv.org/abs/2408.03765v1", "primary_category": "cs.LG", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Reliable Node Similarity Matrix Guided Contrastive Graph Clustering", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:50.371966"}
{"title": "A Guide to Similarity Measures", "authors": "Avivit Levy, B. Riva Shalom, Michal Chalamish", "abstract": "Similarity measures play a central role in various data science application\ndomains for a wide assortment of tasks. This guide describes a comprehensive\nset of prevalent similarity measures to serve both non-experts and\nprofessional. Non-experts that wish to understand the motivation for a measure\nas well as how to use it may find a friendly and detailed exposition of the\nformulas of the measures, whereas experts may find a glance to the principles\nof designing similarity measures and ideas for a better way to measure\nsimilarity for their desired task in a given application domain.", "arxiv_id": "2408.07706v1", "pdf_url": "http://arxiv.org/pdf/2408.07706v1", "abstract_url": "http://arxiv.org/abs/2408.07706v1", "primary_category": "cs.IR", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "A Guide to Similarity Measures", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:51.145579"}
{"title": "Online Model-based Anomaly Detection in Multivariate Time Series: Taxonomy, Survey, Research Challenges and Future Directions", "authors": "Lucas Correia, Jan-Christoph Goos, Philipp Klein, Thomas B\u00e4ck, Anna V. Kononova", "abstract": "Time-series anomaly detection plays an important role in engineering\nprocesses, like development, manufacturing and other operations involving\ndynamic systems. These processes can greatly benefit from advances in the\nfield, as state-of-the-art approaches may aid in cases involving, for example,\nhighly dimensional data. To provide the reader with understanding of the\nterminology, this survey introduces a novel taxonomy where a distinction\nbetween online and offline, and training and inference is made. Additionally,\nit presents the most popular data sets and evaluation metrics used in the\nliterature, as well as a detailed analysis. Furthermore, this survey provides\nan extensive overview of the state-of-the-art model-based online semi- and\nunsupervised anomaly detection approaches for multivariate time-series data,\ncategorising them into different model families and other properties. The\nbiggest research challenge revolves around benchmarking, as currently there is\nno reliable way to compare different approaches against one another. This\nproblem is two-fold: on the one hand, public data sets suffers from at least\none fundamental flaw, while on the other hand, there is a lack of intuitive and\nrepresentative evaluation metrics in the field. Moreover, the way most\npublications choose a detection threshold disregards real-world conditions,\nwhich hinders the application in the real world. To allow for tangible advances\nin the field, these issues must be addressed in future work.", "arxiv_id": "2408.03747v2", "pdf_url": "http://arxiv.org/pdf/2408.03747v2", "abstract_url": "http://arxiv.org/abs/2408.03747v2", "primary_category": "cs.LG", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Online Model-based Anomaly Detection in Multivariate Time Series: Taxonomy, Survey, Research Challenges and Future Directions", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:52.067423"}
{"title": "Flexible Bayesian Last Layer Models Using Implicit Priors and Diffusion Posterior Sampling", "authors": "Jian Xu, Zhiqi Lin, Shigui Li, Min Chen, Junmei Yang, Delu Zeng, John Paisley", "abstract": "Bayesian Last Layer (BLL) models focus solely on uncertainty in the output\nlayer of neural networks, demonstrating comparable performance to more complex\nBayesian models. However, the use of Gaussian priors for last layer weights in\nBayesian Last Layer (BLL) models limits their expressive capacity when faced\nwith non-Gaussian, outlier-rich, or high-dimensional datasets. To address this\nshortfall, we introduce a novel approach that combines diffusion techniques and\nimplicit priors for variational learning of Bayesian last layer weights. This\nmethod leverages implicit distributions for modeling weight priors in BLL,\ncoupled with diffusion samplers for approximating true posterior predictions,\nthereby establishing a comprehensive Bayesian prior and posterior estimation\nstrategy. By delivering an explicit and computationally efficient variational\nlower bound, our method aims to augment the expressive abilities of BLL models,\nenhancing model accuracy, calibration, and out-of-distribution detection\nproficiency. Through detailed exploration and experimental validation, We\nshowcase the method's potential for improving predictive accuracy and\nuncertainty quantification while ensuring computational efficiency.", "arxiv_id": "2408.03746v1", "pdf_url": "http://arxiv.org/pdf/2408.03746v1", "abstract_url": "http://arxiv.org/abs/2408.03746v1", "primary_category": "cs.LG", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Flexible Bayesian Last Layer Models Using Implicit Priors and Diffusion Posterior Sampling", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:52.819672"}
{"title": "Advancing Multimodal Large Language Models with Quantization-Aware Scale Learning for Efficient Adaptation", "authors": "Jingjing Xie, Yuxin Zhang, Mingbao Lin, Liujuan Cao, Rongrong Ji", "abstract": "This paper presents the first study to explore the potential of parameter\nquantization for multimodal large language models to alleviate the significant\nresource constraint encountered during vision-language instruction tuning. We\nintroduce a Quantization-aware Scale LeArning method based on multimodal\nWarmup, termed QSLAW. This method is grounded in two key innovations: (1) The\nlearning of group-wise scale factors for quantized LLM weights to mitigate the\nquantization error arising from activation outliers and achieve more effective\nvision-language instruction tuning; (2) The implementation of a multimodal\nwarmup that progressively integrates linguistic and multimodal training\nsamples, thereby preventing overfitting of the quantized model to multimodal\ndata while ensuring stable adaptation of multimodal large language models to\ndownstream vision-language tasks. Extensive experiments demonstrate that models\nquantized by QSLAW perform on par with, or even surpass, their full-precision\ncounterparts, while facilitating up to 1.4 times reduction in VL tuning time\nand GPU consumption. Our code is released at https://github.com/xjjxmu/QSLAW.", "arxiv_id": "2408.03735v1", "pdf_url": "http://arxiv.org/pdf/2408.03735v1", "abstract_url": "http://arxiv.org/abs/2408.03735v1", "primary_category": "cs.CV", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Advancing Multimodal Large Language Models with Quantization-Aware Scale Learning for Efficient Adaptation", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:53.608207"}
{"title": "Bayes-optimal learning of an extensive-width neural network from quadratically many samples", "authors": "Antoine Maillard, Emanuele Troiani, Simon Martin, Florent Krzakala, Lenka Zdeborov\u00e1", "abstract": "We consider the problem of learning a target function corresponding to a\nsingle hidden layer neural network, with a quadratic activation function after\nthe first layer, and random weights. We consider the asymptotic limit where the\ninput dimension and the network width are proportionally large. Recent work\n[Cui & al '23] established that linear regression provides Bayes-optimal test\nerror to learn such a function when the number of available samples is only\nlinear in the dimension. That work stressed the open challenge of theoretically\nanalyzing the optimal test error in the more interesting regime where the\nnumber of samples is quadratic in the dimension. In this paper, we solve this\nchallenge for quadratic activations and derive a closed-form expression for the\nBayes-optimal test error. We also provide an algorithm, that we call GAMP-RIE,\nwhich combines approximate message passing with rotationally invariant matrix\ndenoising, and that asymptotically achieves the optimal performance.\nTechnically, our result is enabled by establishing a link with recent works on\noptimal denoising of extensive-rank matrices and on the ellipsoid fitting\nproblem. We further show empirically that, in the absence of noise,\nrandomly-initialized gradient descent seems to sample the space of weights,\nleading to zero training loss, and averaging over initialization leads to a\ntest error equal to the Bayes-optimal one.", "arxiv_id": "2408.03733v1", "pdf_url": "http://arxiv.org/pdf/2408.03733v1", "abstract_url": "http://arxiv.org/abs/2408.03733v1", "primary_category": "stat.ML", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Bayes-optimal learning of an extensive-width neural network from quadratically many samples", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:54.327386"}
{"title": "Question Rephrasing for Quantifying Uncertainty in Large Language Models: Applications in Molecular Chemistry Tasks", "authors": "Zizhang Chen, Pengyu Hong, Sandeep Madireddy", "abstract": "Uncertainty quantification enables users to assess the reliability of\nresponses generated by large language models (LLMs). We present a novel\nQuestion Rephrasing technique to evaluate the input uncertainty of LLMs, which\nrefers to the uncertainty arising from equivalent variations of the inputs\nprovided to LLMs. This technique is integrated with sampling methods that\nmeasure the output uncertainty of LLMs, thereby offering a more comprehensive\nuncertainty assessment. We validated our approach on property prediction and\nreaction prediction for molecular chemistry tasks.", "arxiv_id": "2408.03732v1", "pdf_url": "http://arxiv.org/pdf/2408.03732v1", "abstract_url": "http://arxiv.org/abs/2408.03732v1", "primary_category": "cs.CL", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Question Rephrasing for Quantifying Uncertainty in Large Language Models: Applications in Molecular Chemistry Tasks", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:55.294266"}
{"title": "A Convex-optimization-based Layer-wise Post-training Pruner for Large Language Models", "authors": "Pengxiang Zhao, Hanyu Hu, Ping Li, Yi Zheng, Zhefeng Wang, Xiaoming Yuan", "abstract": "Pruning is a critical strategy for compressing trained large language models\n(LLMs), aiming at substantial memory conservation and computational\nacceleration without compromising performance. However, existing pruning\nmethods often necessitate inefficient retraining for billion-scale LLMs or rely\non heuristic methods such as the optimal brain surgeon framework, which degrade\nperformance. In this paper, we introduce FISTAPruner, the first post-training\npruner based on convex optimization models and algorithms. Specifically, we\npropose a convex optimization model incorporating $\\ell_1$ norm to induce\nsparsity and utilize the FISTA solver for optimization. FISTAPruner\nincorporates an intra-layer cumulative error correction mechanism and supports\nparallel pruning. We comprehensively evaluate FISTAPruner on models such as\nOPT, LLaMA, LLaMA-2, and LLaMA-3 with 125M to 70B parameters under unstructured\nand 2:4 semi-structured sparsity, demonstrating superior performance over\nexisting state-of-the-art methods across various language benchmarks.", "arxiv_id": "2408.03728v1", "pdf_url": "http://arxiv.org/pdf/2408.03728v1", "abstract_url": "http://arxiv.org/abs/2408.03728v1", "primary_category": "cs.LG", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "A Convex-optimization-based Layer-wise Post-training Pruner for Large Language Models", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:56.164991"}
{"title": "Local Topology Measures of Contextual Language Model Latent Spaces With Applications to Dialogue Term Extraction", "authors": "Benjamin Matthias Ruppik, Michael Heck, Carel van Niekerk, Renato Vukovic, Hsien-chin Lin, Shutong Feng, Marcus Zibrowius, Milica Ga\u0161i\u0107", "abstract": "A common approach for sequence tagging tasks based on contextual word\nrepresentations is to train a machine learning classifier directly on these\nembedding vectors. This approach has two shortcomings. First, such methods\nconsider single input sequences in isolation and are unable to put an\nindividual embedding vector in relation to vectors outside the current local\ncontext of use. Second, the high performance of these models relies on\nfine-tuning the embedding model in conjunction with the classifier, which may\nnot always be feasible due to the size or inaccessibility of the underlying\nfeature-generation model. It is thus desirable, given a collection of embedding\nvectors of a corpus, i.e., a datastore, to find features of each vector that\ndescribe its relation to other, similar vectors in the datastore. With this in\nmind, we introduce complexity measures of the local topology of the latent\nspace of a contextual language model with respect to a given datastore. The\neffectiveness of our features is demonstrated through their application to\ndialogue term extraction. Our work continues a line of research that explores\nthe manifold hypothesis for word embeddings, demonstrating that local structure\nin the space carved out by word embeddings can be exploited to infer semantic\nproperties.", "arxiv_id": "2408.03706v1", "pdf_url": "http://arxiv.org/pdf/2408.03706v1", "abstract_url": "http://arxiv.org/abs/2408.03706v1", "primary_category": "cs.CL", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Local Topology Measures of Contextual Language Model Latent Spaces With Applications to Dialogue Term Extraction", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:56.931210"}
{"title": "A Blockchain-based Reliable Federated Meta-learning for Metaverse: A Dual Game Framework", "authors": "Emna Baccour, Aiman Erbad, Amr Mohamed, Mounir Hamdi, Mohsen Guizani", "abstract": "The metaverse, envisioned as the next digital frontier for avatar-based\nvirtual interaction, involves high-performance models. In this dynamic\nenvironment, users' tasks frequently shift, requiring fast model\npersonalization despite limited data. This evolution consumes extensive\nresources and requires vast data volumes. To address this, meta-learning\nemerges as an invaluable tool for metaverse users, with federated meta-learning\n(FML), offering even more tailored solutions owing to its adaptive\ncapabilities. However, the metaverse is characterized by users heterogeneity\nwith diverse data structures, varied tasks, and uneven sample sizes,\npotentially undermining global training outcomes due to statistical difference.\nGiven this, an urgent need arises for smart coalition formation that accounts\nfor these disparities. This paper introduces a dual game-theoretic framework\nfor metaverse services involving meta-learners as workers to manage FML. A\nblockchain-based cooperative coalition formation game is crafted, grounded on a\nreputation metric, user similarity, and incentives. We also introduce a novel\nreputation system based on users' historical contributions and potential\ncontributions to present tasks, leveraging correlations between past and new\ntasks. Finally, a Stackelberg game-based incentive mechanism is presented to\nattract reliable workers to participate in meta-learning, minimizing users'\nenergy costs, increasing payoffs, boosting FML efficacy, and improving\nmetaverse utility. Results show that our dual game framework outperforms\nbest-effort, random, and non-uniform clustering schemes - improving training\nperformance by up to 10%, cutting completion times by as much as 30%, enhancing\nmetaverse utility by more than 25%, and offering up to 5% boost in training\nefficiency over non-blockchain systems, effectively countering misbehaving\nusers.", "arxiv_id": "2408.03694v1", "pdf_url": "http://arxiv.org/pdf/2408.03694v1", "abstract_url": "http://arxiv.org/abs/2408.03694v1", "primary_category": "cs.DC", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "A Blockchain-based Reliable Federated Meta-learning for Metaverse: A Dual Game Framework", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:57.808073"}
{"title": "Generative Design of Periodic Orbits in the Restricted Three-Body Problem", "authors": "Alvaro Francisco Gil, Walther Litteri, Victor Rodriguez-Fernandez, David Camacho, Massimiliano Vasile", "abstract": "The Three-Body Problem has fascinated scientists for centuries and it has\nbeen crucial in the design of modern space missions. Recent developments in\nGenerative Artificial Intelligence hold transformative promise for addressing\nthis longstanding problem. This work investigates the use of Variational\nAutoencoder (VAE) and its internal representation to generate periodic orbits.\nWe utilize a comprehensive dataset of periodic orbits in the Circular\nRestricted Three-Body Problem (CR3BP) to train deep-learning architectures that\ncapture key orbital characteristics, and we set up physical evaluation metrics\nfor the generated trajectories. Through this investigation, we seek to enhance\nthe understanding of how Generative AI can improve space mission planning and\nastrodynamics research, leading to novel, data-driven approaches in the field.", "arxiv_id": "2408.03691v1", "pdf_url": "http://arxiv.org/pdf/2408.03691v1", "abstract_url": "http://arxiv.org/abs/2408.03691v1", "primary_category": "cs.LG", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Generative Design of Periodic Orbits in the Restricted Three-Body Problem", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:58.782512"}
{"title": "RL-ADN: A High-Performance Deep Reinforcement Learning Environment for Optimal Energy Storage Systems Dispatch in Active Distribution Networks", "authors": "Shengren Hou, Shuyi Gao, Weijie Xia, Edgar Mauricio Salazar Duque, Peter Palensky, Pedro P. Vergara", "abstract": "Deep Reinforcement Learning (DRL) presents a promising avenue for optimizing\nEnergy Storage Systems (ESSs) dispatch in distribution networks. This paper\nintroduces RL-ADN, an innovative open-source library specifically designed for\nsolving the optimal ESSs dispatch in active distribution networks. RL-ADN\noffers unparalleled flexibility in modeling distribution networks, and ESSs,\naccommodating a wide range of research goals. A standout feature of RL-ADN is\nits data augmentation module, based on Gaussian Mixture Model and Copula (GMC)\nfunctions, which elevates the performance ceiling of DRL agents. Additionally,\nRL-ADN incorporates the Laurent power flow solver, significantly reducing the\ncomputational burden of power flow calculations during training without\nsacrificing accuracy. The effectiveness of RL-ADN is demonstrated using in\ndifferent sizes of distribution networks, showing marked performance\nimprovements in the adaptability of DRL algorithms for ESS dispatch tasks. This\nenhancement is particularly beneficial from the increased diversity of training\nscenarios. Furthermore, RL-ADN achieves a tenfold increase in computational\nefficiency during training, making it highly suitable for large-scale network\napplications. The library sets a new benchmark in DRL-based ESSs dispatch in\ndistribution networks and it is poised to advance DRL applications in\ndistribution network operations significantly. RL-ADN is available at:\nhttps://github.com/ShengrenHou/RL-ADN and\nhttps://github.com/distributionnetworksTUDelft/RL-ADN.", "arxiv_id": "2408.03685v2", "pdf_url": "http://arxiv.org/pdf/2408.03685v2", "abstract_url": "http://arxiv.org/abs/2408.03685v2", "primary_category": "cs.LG", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "RL-ADN: A High-Performance Deep Reinforcement Learning Environment for Optimal Energy Storage Systems Dispatch in Active Distribution Networks", "response": "RELEVANT", "timestamp": "2024-08-19T13:42:59.548790"}
{"title": "Beyond Over-smoothing: Uncovering the Trainability Challenges in Deep Graph Neural Networks", "authors": "Jie Peng, Runlin Lei, Zhewei Wei", "abstract": "The drastic performance degradation of Graph Neural Networks (GNNs) as the\ndepth of the graph propagation layers exceeds 8-10 is widely attributed to a\nphenomenon of Over-smoothing. Although recent research suggests that\nOver-smoothing may not be the dominant reason for such a performance\ndegradation, they have not provided rigorous analysis from a theoretical view,\nwhich warrants further investigation. In this paper, we systematically analyze\nthe real dominant problem in deep GNNs and identify the issues that these GNNs\ntowards addressing Over-smoothing essentially work on via empirical experiments\nand theoretical gradient analysis. We theoretically prove that the difficult\ntraining problem of deep MLPs is actually the main challenge, and various\nexisting methods that supposedly tackle Over-smoothing actually improve the\ntrainability of MLPs, which is the main reason for their performance gains. Our\nfurther investigation into trainability issues reveals that properly\nconstrained smaller upper bounds of gradient flow notably enhance the\ntrainability of GNNs. Experimental results on diverse datasets demonstrate\nconsistency between our theoretical findings and empirical evidence. Our\nanalysis provides new insights in constructing deep graph models.", "arxiv_id": "2408.03669v1", "pdf_url": "http://arxiv.org/pdf/2408.03669v1", "abstract_url": "http://arxiv.org/abs/2408.03669v1", "primary_category": "cs.LG", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Beyond Over-smoothing: Uncovering the Trainability Challenges in Deep Graph Neural Networks", "response": "RELEVANT", "timestamp": "2024-08-19T13:43:00.876513"}
{"title": "AI-Driven approach for sustainable extraction of earth's subsurface renewable energy while minimizing seismic activity", "authors": "Diego Gutierrez-Oribio, Alexandros Stathas, Ioannis Stefanou", "abstract": "Deep Geothermal Energy, Carbon Capture and Storage, and Hydrogen Storage hold\nconsiderable promise for meeting the energy sector's large-scale requirements\nand reducing CO$_2$ emissions. However, the injection of fluids into the\nEarth's crust, essential for these activities, can induce or trigger\nearthquakes. In this paper, we highlight a new approach based on Reinforcement\nLearning for the control of human-induced seismicity in the highly complex\nenvironment of an underground reservoir. This complex system poses significant\nchallenges in the control design due to parameter uncertainties and unmodeled\ndynamics. We show that the reinforcement learning algorithm can interact\nefficiently with a robust controller, by choosing the controller parameters in\nreal-time, reducing human-induced seismicity and allowing the consideration of\nfurther production objectives, \\textit{e.g.}, minimal control power.\nSimulations are presented for a simplified underground reservoir under various\nenergy demand scenarios, demonstrating the reliability and effectiveness of the\nproposed control-reinforcement learning approach.", "arxiv_id": "2408.03664v1", "pdf_url": "http://arxiv.org/pdf/2408.03664v1", "abstract_url": "http://arxiv.org/abs/2408.03664v1", "primary_category": "cs.LG", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "AI-Driven approach for sustainable extraction of earth's subsurface renewable energy while minimizing seismic activity", "response": "RELEVANT", "timestamp": "2024-08-19T13:43:01.661671"}
{"title": "Consumer Transactions Simulation through Generative Adversarial Networks", "authors": "Sergiy Tkachuk, Szymon \u0141ukasik, Anna Wr\u00f3blewska", "abstract": "In the rapidly evolving domain of large-scale retail data systems,\nenvisioning and simulating future consumer transactions has become a crucial\narea of interest. It offers significant potential to fortify demand forecasting\nand fine-tune inventory management. This paper presents an innovative\napplication of Generative Adversarial Networks (GANs) to generate synthetic\nretail transaction data, specifically focusing on a novel system architecture\nthat combines consumer behavior modeling with stock-keeping unit (SKU)\navailability constraints to address real-world assortment optimization\nchallenges. We diverge from conventional methodologies by integrating SKU data\ninto our GAN architecture and using more sophisticated embedding methods (e.g.,\nhyper-graphs). This design choice enables our system to generate not only\nsimulated consumer purchase behaviors but also reflects the dynamic interplay\nbetween consumer behavior and SKU availability -- an aspect often overlooked,\namong others, because of data scarcity in legacy retail simulation models. Our\nGAN model generates transactions under stock constraints, pioneering a\nresourceful experimental system with practical implications for real-world\nretail operation and strategy. Preliminary results demonstrate enhanced realism\nin simulated transactions measured by comparing generated items with real ones\nusing methods employed earlier in related studies. This underscores the\npotential for more accurate predictive modeling.", "arxiv_id": "2408.03655v1", "pdf_url": "http://arxiv.org/pdf/2408.03655v1", "abstract_url": "http://arxiv.org/abs/2408.03655v1", "primary_category": "cs.LG", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Consumer Transactions Simulation through Generative Adversarial Networks", "response": "RELEVANT", "timestamp": "2024-08-19T13:43:02.562771"}
{"title": "mucAI at WojoodNER 2024: Arabic Named Entity Recognition with Nearest Neighbor Search", "authors": "Ahmed Abdou, Tasneem Mohsen", "abstract": "Named Entity Recognition (NER) is a task in Natural Language Processing (NLP)\nthat aims to identify and classify entities in text into predefined categories.\nHowever, when applied to Arabic data, NER encounters unique challenges stemming\nfrom the language's rich morphological inflections, absence of capitalization\ncues, and spelling variants, where a single word can comprise multiple\nmorphemes. In this paper, we introduce Arabic KNN-NER, our submission to the\nWojood NER Shared Task 2024 (ArabicNLP 2024). We have participated in the\nshared sub-task 1 Flat NER. In this shared sub-task, we tackle fine-grained\nflat-entity recognition for Arabic text, where we identify a single main entity\nand possibly zero or multiple sub-entities for each word. Arabic KNN-NER\naugments the probability distribution of a fine-tuned model with another label\nprobability distribution derived from performing a KNN search over the cached\ntraining data. Our submission achieved 91% on the test set on the WojoodFine\ndataset, placing Arabic KNN-NER on top of the leaderboard for the shared task.", "arxiv_id": "2408.03652v1", "pdf_url": "http://arxiv.org/pdf/2408.03652v1", "abstract_url": "http://arxiv.org/abs/2408.03652v1", "primary_category": "cs.CL", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "mucAI at WojoodNER 2024: Arabic Named Entity Recognition with Nearest Neighbor Search", "response": "RELEVANT", "timestamp": "2024-08-19T13:43:03.217917"}
{"title": "Time is Not Enough: Time-Frequency based Explanation for Time-Series Black-Box Models", "authors": "Hyunseung Chung, Sumin Jo, Yeonsu Kwon, Edward Choi", "abstract": "Despite the massive attention given to time-series explanations due to their\nextensive applications, a notable limitation in existing approaches is their\nprimary reliance on the time-domain. This overlooks the inherent characteristic\nof time-series data containing both time and frequency features. In this work,\nwe present Spectral eXplanation (SpectralX), an XAI framework that provides\ntime-frequency explanations for time-series black-box classifiers. This easily\nadaptable framework enables users to \"plug-in\" various perturbation-based XAI\nmethods for any pre-trained time-series classification models to assess their\nimpact on the explanation quality without having to modify the framework\narchitecture. Additionally, we introduce Feature Importance Approximations\n(FIA), a new perturbation-based XAI method. These methods consist of feature\ninsertion, deletion, and combination techniques to enhance computational\nefficiency and class-specific explanations in time-series classification tasks.\nWe conduct extensive experiments in the generated synthetic dataset and various\nUCR Time-Series datasets to first compare the explanation performance of FIA\nand other existing perturbation-based XAI methods in both time-domain and\ntime-frequency domain, and then show the superiority of our FIA in the\ntime-frequency domain with the SpectralX framework. Finally, we conduct a user\nstudy to confirm the practicality of our FIA in SpectralX framework for\nclass-specific time-frequency based time-series explanations. The source code\nis available in https://github.com/gustmd0121/Time_is_not_Enough", "arxiv_id": "2408.03636v2", "pdf_url": "http://arxiv.org/pdf/2408.03636v2", "abstract_url": "http://arxiv.org/abs/2408.03636v2", "primary_category": "cs.LG", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Time is Not Enough: Time-Frequency based Explanation for Time-Series Black-Box Models", "response": "RELEVANT", "timestamp": "2024-08-19T13:43:04.532552"}
{"title": "On the choice of the non-trainable internal weights in random feature maps", "authors": "Pinak Mandal, Georg A. Gottwald", "abstract": "The computationally cheap machine learning architecture of random feature\nmaps can be viewed as a single-layer feedforward network in which the weights\nof the hidden layer are random but fixed and only the outer weights are learned\nvia linear regression. The internal weights are typically chosen from a\nprescribed distribution. The choice of the internal weights significantly\nimpacts the accuracy of random feature maps. We address here the task of how to\nbest select the internal weights. In particular, we consider the forecasting\nproblem whereby random feature maps are used to learn a one-step propagator map\nfor a dynamical system. We provide a computationally cheap hit-and-run\nalgorithm to select good internal weights which lead to good forecasting skill.\nWe show that the number of good features is the main factor controlling the\nforecasting skill of random feature maps and acts as an effective feature\ndimension. Lastly, we compare random feature maps with single-layer feedforward\nneural networks in which the internal weights are now learned using gradient\ndescent. We find that random feature maps have superior forecasting\ncapabilities whilst having several orders of magnitude lower computational\ncost.", "arxiv_id": "2408.03626v1", "pdf_url": "http://arxiv.org/pdf/2408.03626v1", "abstract_url": "http://arxiv.org/abs/2408.03626v1", "primary_category": "cs.LG", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "On the choice of the non-trainable internal weights in random feature maps", "response": "RELEVANT", "timestamp": "2024-08-19T13:43:05.292280"}
{"title": "Making Robust Generalizers Less Rigid with Soft Ascent-Descent", "authors": "Matthew J. Holland, Toma Hamada", "abstract": "While the traditional formulation of machine learning tasks is in terms of\nperformance on average, in practice we are often interested in how well a\ntrained model performs on rare or difficult data points at test time. To\nachieve more robust and balanced generalization, methods applying\nsharpness-aware minimization to a subset of worst-case examples have proven\nsuccessful for image classification tasks, but only using deep neural networks\nin a scenario where the most difficult points are also the least common. In\nthis work, we show how such a strategy can dramatically break down under more\ndiverse models, and as a more robust alternative, instead of typical sharpness\nwe propose and evaluate a training criterion which penalizes poor loss\nconcentration, which can be easily combined with loss transformations such as\nCVaR or DRO that control tail emphasis.", "arxiv_id": "2408.03619v1", "pdf_url": "http://arxiv.org/pdf/2408.03619v1", "abstract_url": "http://arxiv.org/abs/2408.03619v1", "primary_category": "cs.LG", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Making Robust Generalizers Less Rigid with Soft Ascent-Descent", "response": "RELEVANT", "timestamp": "2024-08-19T13:43:06.121235"}
{"title": "A Logical Fallacy-Informed Framework for Argument Generation", "authors": "Luca Mouchel, Debjit Paul, Shaobo Cui, Robert West, Antoine Bosselut, Boi Faltings", "abstract": "Despite the remarkable performance of Large Language Models (LLMs), they\nstill struggle with generating logically sound arguments, resulting in\npotential risks such as spreading misinformation. An important factor\ncontributing to LLMs' suboptimal performance in generating coherent arguments\nis their oversight of logical fallacies. To address this issue, we introduce\nFIPO, a fallacy-informed framework that leverages preference optimization\nmethods to steer LLMs toward logically sound arguments. FIPO includes a\nclassification loss, to capture the fine-grained information on fallacy\ncategories. Our results on argumentation datasets show that our method reduces\nthe fallacy errors by up to 17.5%. Furthermore, our human evaluation results\nindicate that the quality of the generated arguments by our method\nsignificantly outperforms the fine-tuned baselines, as well as prior preference\noptimization methods, such as DPO. These findings highlight the importance of\nensuring models are aware of logical fallacies for effective argument\ngeneration.", "arxiv_id": "2408.03618v1", "pdf_url": "http://arxiv.org/pdf/2408.03618v1", "abstract_url": "http://arxiv.org/abs/2408.03618v1", "primary_category": "cs.CL", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "A Logical Fallacy-Informed Framework for Argument Generation", "response": "RELEVANT", "timestamp": "2024-08-19T13:43:06.858653"}
{"title": "Is Child-Directed Speech Effective Training Data for Language Models?", "authors": "Steven Y. Feng, Noah D. Goodman, Michael C. Frank", "abstract": "While high-performing language models are typically trained on hundreds of\nbillions of words, human children become fluent language users with a much\nsmaller amount of data. What are the features of the data they receive, and how\ndo these features support language modeling objectives? To investigate this\nquestion, we train GPT-2 models on 29M words of English-language child-directed\nspeech and a new matched, synthetic dataset (TinyDialogues), comparing to a\nheterogeneous blend of datasets from the BabyLM challenge. We evaluate both the\nsyntactic and semantic knowledge of these models using developmentally-inspired\nevaluations. Through pretraining experiments, we test whether the global\ndevelopmental ordering or the local discourse ordering of children's training\ndata support high performance relative to other datasets. The local properties\nof the data affect model results, but somewhat surprisingly, global properties\ndo not. Further, child language input is not uniquely valuable for training\nlanguage models. These findings support the hypothesis that, rather than\nproceeding from better data, children's learning is instead substantially more\nefficient than current language modeling techniques.", "arxiv_id": "2408.03617v1", "pdf_url": "http://arxiv.org/pdf/2408.03617v1", "abstract_url": "http://arxiv.org/abs/2408.03617v1", "primary_category": "cs.CL", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Is Child-Directed Speech Effective Training Data for Language Models?", "response": "RELEVANT", "timestamp": "2024-08-19T13:43:07.797515"}
{"title": "JARViS: Detecting Actions in Video Using Unified Actor-Scene Context Relation Modeling", "authors": "Seok Hwan Lee, Taein Son, Soo Won Seo, Jisong Kim, Jun Won Choi", "abstract": "Video action detection (VAD) is a formidable vision task that involves the\nlocalization and classification of actions within the spatial and temporal\ndimensions of a video clip. Among the myriad VAD architectures, two-stage VAD\nmethods utilize a pre-trained person detector to extract the region of interest\nfeatures, subsequently employing these features for action detection. However,\nthe performance of two-stage VAD methods has been limited as they depend solely\non localized actor features to infer action semantics. In this study, we\npropose a new two-stage VAD framework called Joint Actor-scene context Relation\nmodeling based on Visual Semantics (JARViS), which effectively consolidates\ncross-modal action semantics distributed globally across spatial and temporal\ndimensions using Transformer attention. JARViS employs a person detector to\nproduce densely sampled actor features from a keyframe. Concurrently, it uses a\nvideo backbone to create spatio-temporal scene features from a video clip.\nFinally, the fine-grained interactions between actors and scenes are modeled\nthrough a Unified Action-Scene Context Transformer to directly output the final\nset of actions in parallel. Our experimental results demonstrate that JARViS\noutperforms existing methods by significant margins and achieves\nstate-of-the-art performance on three popular VAD datasets, including AVA,\nUCF101-24, and JHMDB51-21.", "arxiv_id": "2408.03612v1", "pdf_url": "http://arxiv.org/pdf/2408.03612v1", "abstract_url": "http://arxiv.org/abs/2408.03612v1", "primary_category": "cs.CV", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "JARViS: Detecting Actions in Video Using Unified Actor-Scene Context Relation Modeling", "response": "RELEVANT", "timestamp": "2024-08-19T13:43:09.262499"}
{"title": "InPer: Whole-Process Domain Generalization via Causal Intervention and Perturbation", "authors": "Luyao Tang, Yuxuan Yuan, Chaoqi Chen, Xinghao Ding, Yue Huang", "abstract": "Despite the considerable advancements achieved by deep neural networks, their\nperformance tends to degenerate when the test environment diverges from the\ntraining ones. Domain generalization (DG) solves this issue by learning\nrepresentations independent of domain-related information, thus facilitating\nextrapolation to unseen environments. Existing approaches typically focus on\nformulating tailored training objectives to extract shared features from the\nsource data. However, the disjointed training and testing procedures may\ncompromise robustness, particularly in the face of unforeseen variations during\ndeployment. In this paper, we propose a novel and holistic framework based on\ncausality, named InPer, designed to enhance model generalization by\nincorporating causal intervention during training and causal perturbation\nduring testing. Specifically, during the training phase, we employ\nentropy-based causal intervention (EnIn) to refine the selection of causal\nvariables. To identify samples with anti-interference causal variables from the\ntarget domain, we propose a novel metric, homeostatic score, through causal\nperturbation (HoPer) to construct a prototype classifier in test time.\nExperimental results across multiple cross-domain tasks confirm the efficacy of\nInPer.", "arxiv_id": "2408.03608v1", "pdf_url": "http://arxiv.org/pdf/2408.03608v1", "abstract_url": "http://arxiv.org/abs/2408.03608v1", "primary_category": "cs.LG", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "InPer: Whole-Process Domain Generalization via Causal Intervention and Perturbation", "response": "RELEVANT", "timestamp": "2024-08-19T13:43:10.037761"}
{"title": "EnJa: Ensemble Jailbreak on Large Language Models", "authors": "Jiahao Zhang, Zilong Wang, Ruofan Wang, Xingjun Ma, Yu-Gang Jiang", "abstract": "As Large Language Models (LLMs) are increasingly being deployed in\nsafety-critical applications, their vulnerability to potential jailbreaks --\nmalicious prompts that can disable the safety mechanism of LLMs -- has\nattracted growing research attention. While alignment methods have been\nproposed to protect LLMs from jailbreaks, many have found that aligned LLMs can\nstill be jailbroken by carefully crafted malicious prompts, producing content\nthat violates policy regulations. Existing jailbreak attacks on LLMs can be\ncategorized into prompt-level methods which make up stories/logic to circumvent\nsafety alignment and token-level attack methods which leverage gradient methods\nto find adversarial tokens. In this work, we introduce the concept of Ensemble\nJailbreak and explore methods that can integrate prompt-level and token-level\njailbreak into a more powerful hybrid jailbreak attack. Specifically, we\npropose a novel EnJa attack to hide harmful instructions using prompt-level\njailbreak, boost the attack success rate using a gradient-based attack, and\nconnect the two types of jailbreak attacks via a template-based connector. We\nevaluate the effectiveness of EnJa on several aligned models and show that it\nachieves a state-of-the-art attack success rate with fewer queries and is much\nstronger than any individual jailbreak.", "arxiv_id": "2408.03603v1", "pdf_url": "http://arxiv.org/pdf/2408.03603v1", "abstract_url": "http://arxiv.org/abs/2408.03603v1", "primary_category": "cs.CR", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "EnJa: Ensemble Jailbreak on Large Language Models", "response": "RELEVANT", "timestamp": "2024-08-19T13:43:11.100112"}
{"title": "Activations Through Extensions: A Framework To Boost Performance Of Neural Networks", "authors": "Chandramouli Kamanchi, Sumanta Mukherjee, Kameshwaran Sampath, Pankaj Dayama, Arindam Jati, Vijay Ekambaram, Dzung Phan", "abstract": "Activation functions are non-linearities in neural networks that allow them\nto learn complex mapping between inputs and outputs. Typical choices for\nactivation functions are ReLU, Tanh, Sigmoid etc., where the choice generally\ndepends on the application domain. In this work, we propose a\nframework/strategy that unifies several works on activation functions and\ntheoretically explains the performance benefits of these works. We also propose\nnovel techniques that originate from the framework and allow us to obtain\n``extensions'' (i.e. special generalizations of a given neural network) of\nneural networks through operations on activation functions. We theoretically\nand empirically show that ``extensions'' of neural networks have performance\nbenefits compared to vanilla neural networks with insignificant space and time\ncomplexity costs on standard test functions. We also show the benefits of\nneural network ``extensions'' in the time-series domain on real-world datasets.", "arxiv_id": "2408.03599v2", "pdf_url": "http://arxiv.org/pdf/2408.03599v2", "abstract_url": "http://arxiv.org/abs/2408.03599v2", "primary_category": "cs.LG", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Activations Through Extensions: A Framework To Boost Performance Of Neural Networks", "response": "RELEVANT", "timestamp": "2024-08-19T13:43:11.931808"}
{"title": "Focal Depth Estimation: A Calibration-Free, Subject- and Daytime Invariant Approach", "authors": "Benedikt W. Hosp, Bj\u00f6rn Severitt, Rajat Agarwala, Evgenia Rusak, Yannick Sauer, Siegfried Wahl", "abstract": "In an era where personalized technology is increasingly intertwined with\ndaily life, traditional eye-tracking systems and autofocal glasses face a\nsignificant challenge: the need for frequent, user-specific calibration, which\nimpedes their practicality. This study introduces a groundbreaking\ncalibration-free method for estimating focal depth, leveraging machine learning\ntechniques to analyze eye movement features within short sequences. Our\napproach, distinguished by its innovative use of LSTM networks and\ndomain-specific feature engineering, achieves a mean absolute error (MAE) of\nless than 10 cm, setting a new focal depth estimation accuracy standard. This\nadvancement promises to enhance the usability of autofocal glasses and pave the\nway for their seamless integration into extended reality environments, marking\na significant leap forward in personalized visual technology.", "arxiv_id": "2408.03591v1", "pdf_url": "http://arxiv.org/pdf/2408.03591v1", "abstract_url": "http://arxiv.org/abs/2408.03591v1", "primary_category": "cs.CV", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Focal Depth Estimation: A Calibration-Free, Subject- and Daytime Invariant Approach", "response": "RELEVANT", "timestamp": "2024-08-19T13:43:12.810062"}
{"title": "Sensitivity analysis using the Metamodel of Optimal Prognosis", "authors": "Thomas Most, Johannes Will", "abstract": "In real case applications within the virtual prototyping process, it is not\nalways possible to reduce the complexity of the physical models and to obtain\nnumerical models which can be solved quickly. Usually, every single numerical\nsimulation takes hours or even days. Although the progresses in numerical\nmethods and high performance computing, in such cases, it is not possible to\nexplore various model configurations, hence efficient surrogate models are\nrequired. Generally the available meta-model techniques show several advantages\nand disadvantages depending on the investigated problem. In this paper we\npresent an automatic approach for the selection of the optimal suitable\nmeta-model for the actual problem. Together with an automatic reduction of the\nvariable space using advanced filter techniques an efficient approximation is\nenabled also for high dimensional problems. This filter techniques enable a\nreduction of the high dimensional variable space to a much smaller subspace\nwhere meta-model-based sensitivity analyses are carried out to assess the\ninfluence of important variables and to identify the optimal subspace with\ncorresponding surrogate model which enables the most accurate probabilistic\nanalysis. For this purpose we investigate variance-based and moment-free\nsensitivity measures in combination with advanced meta-models as moving least\nsquares and kriging.", "arxiv_id": "2408.03590v1", "pdf_url": "http://arxiv.org/pdf/2408.03590v1", "abstract_url": "http://arxiv.org/abs/2408.03590v1", "primary_category": "stat.ME", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Sensitivity analysis using the Metamodel of Optimal Prognosis", "response": "RELEVANT", "timestamp": "2024-08-19T13:43:13.645288"}
{"title": "Enhancing Output Diversity Improves Conjugate Gradient-based Adversarial Attacks", "authors": "Keiichiro Yamamura, Issa Oe, Hiroki Ishikura, Katsuki Fujisawa", "abstract": "Deep neural networks are vulnerable to adversarial examples, and adversarial\nattacks that generate adversarial examples have been studied in this context.\nExisting studies imply that increasing the diversity of model outputs\ncontributes to improving the attack performance. This study focuses on the Auto\nConjugate Gradient (ACG) attack, which is inspired by the conjugate gradient\nmethod and has a high diversification performance. We hypothesized that\nincreasing the distance between two consecutive search points would enhance the\noutput diversity. To test our hypothesis, we propose Rescaling-ACG (ReACG),\nwhich automatically modifies the two components that significantly affect the\ndistance between two consecutive search points, including the search direction\nand step size. ReACG showed higher attack performance than that of ACG, and is\nparticularly effective for ImageNet models with several classification classes.\nExperimental results show that the distance between two consecutive search\npoints enhances the output diversity and may help develop new potent attacks.\nThe code is available at \\url{https://github.com/yamamura-k/ReACG}", "arxiv_id": "2408.03972v1", "pdf_url": "http://arxiv.org/pdf/2408.03972v1", "abstract_url": "http://arxiv.org/abs/2408.03972v1", "primary_category": "cs.LG", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Enhancing Output Diversity Improves Conjugate Gradient-based Adversarial Attacks", "response": "RELEVANT", "timestamp": "2024-08-19T13:43:14.556527"}
{"title": "Facing the Music: Tackling Singing Voice Separation in Cinematic Audio Source Separation", "authors": "Karn N. Watcharasupat, Chih-Wei Wu, Iroro Orife", "abstract": "Cinematic audio source separation (CASS) is a fairly new subtask of audio\nsource separation. A typical setup of CASS is a three-stem problem, with the\naim of separating the mixture into the dialogue stem (DX), music stem (MX), and\neffects stem (FX). In practice, however, several edge cases exist as some sound\nsources do not fit neatly in either of these three stems, necessitating the use\nof additional auxiliary stems in production. One very common edge case is the\nsinging voice in film audio, which may belong in either the DX or MX, depending\nheavily on the cinematic context. In this work, we demonstrate a very\nstraightforward extension of the dedicated-decoder Bandit and query-based\nsingle-decoder Banquet models to a four-stem problem, treating non-musical\ndialogue, instrumental music, singing voice, and effects as separate stems.\nInterestingly, the query-based Banquet model outperformed the dedicated-decoder\nBandit model. We hypothesized that this is due to a better feature alignment at\nthe bottleneck as enforced by the band-agnostic FiLM layer. Dataset and model\nimplementation will be made available at\nhttps://github.com/kwatcharasupat/source-separation-landing.", "arxiv_id": "2408.03588v1", "pdf_url": "http://arxiv.org/pdf/2408.03588v1", "abstract_url": "http://arxiv.org/abs/2408.03588v1", "primary_category": "eess.AS", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Facing the Music: Tackling Singing Voice Separation in Cinematic Audio Source Separation", "response": "RELEVANT", "timestamp": "2024-08-19T13:43:15.317487"}
{"title": "Hierarchical Neural Constructive Solver for Real-world TSP Scenarios", "authors": "Yong Liang Goh, Zhiguang Cao, Yining Ma, Yanfei Dong, Mohammed Haroon Dupty, Wee Sun Lee", "abstract": "Existing neural constructive solvers for routing problems have predominantly\nemployed transformer architectures, conceptualizing the route construction as a\nset-to-sequence learning task. However, their efficacy has primarily been\ndemonstrated on entirely random problem instances that inadequately capture\nreal-world scenarios. In this paper, we introduce realistic Traveling Salesman\nProblem (TSP) scenarios relevant to industrial settings and derive the\nfollowing insights: (1) The optimal next node (or city) to visit often lies\nwithin proximity to the current node, suggesting the potential benefits of\nbiasing choices based on current locations. (2) Effectively solving the TSP\nrequires robust tracking of unvisited nodes and warrants succinct grouping\nstrategies. Building upon these insights, we propose integrating a learnable\nchoice layer inspired by Hypernetworks to prioritize choices based on the\ncurrent location, and a learnable approximate clustering algorithm inspired by\nthe Expectation-Maximization algorithm to facilitate grouping the unvisited\ncities. Together, these two contributions form a hierarchical approach towards\nsolving the realistic TSP by considering both immediate local neighbourhoods\nand learning an intermediate set of node representations. Our hierarchical\napproach yields superior performance compared to both classical and recent\ntransformer models, showcasing the efficacy of the key designs.", "arxiv_id": "2408.03585v1", "pdf_url": "http://arxiv.org/pdf/2408.03585v1", "abstract_url": "http://arxiv.org/abs/2408.03585v1", "primary_category": "cs.LG", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Hierarchical Neural Constructive Solver for Real-world TSP Scenarios", "response": "RELEVANT", "timestamp": "2024-08-19T13:43:16.084645"}
{"title": "Teach CLIP to Develop a Number Sense for Ordinal Regression", "authors": "Yao Du, Qiang Zhai, Weihang Dai, Xiaomeng Li", "abstract": "Ordinal regression is a fundamental problem within the field of computer\nvision, with customised well-trained models on specific tasks. While\npre-trained vision-language models (VLMs) have exhibited impressive performance\non various vision tasks, their potential for ordinal regression has received\nless exploration. In this study, we first investigate CLIP's potential for\nordinal regression, from which we expect the model could generalise to\ndifferent ordinal regression tasks and scenarios. Unfortunately, vanilla CLIP\nfails on this task, since current VLMs have a well-documented limitation of\nencapsulating compositional concepts such as number sense. We propose a simple\nyet effective method called NumCLIP to improve the quantitative understanding\nof VLMs. We disassemble the exact image to number-specific text matching\nproblem into coarse classification and fine prediction stages. We discretize\nand phrase each numerical bin with common language concept to better leverage\nthe available pre-trained alignment in CLIP. To consider the inherent\ncontinuous property of ordinal regression, we propose a novel fine-grained\ncross-modal ranking-based regularisation loss specifically designed to keep\nboth semantic and ordinal alignment in CLIP's feature space. Experimental\nresults on three general ordinal regression tasks demonstrate the effectiveness\nof NumCLIP, with 10% and 3.83% accuracy improvement on historical image dating\nand image aesthetics assessment task, respectively. Code is publicly available\nat https://github.com/xmed-lab/NumCLIP.", "arxiv_id": "2408.03574v1", "pdf_url": "http://arxiv.org/pdf/2408.03574v1", "abstract_url": "http://arxiv.org/abs/2408.03574v1", "primary_category": "cs.CV", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Teach CLIP to Develop a Number Sense for Ordinal Regression", "response": "RELEVANT", "timestamp": "2024-08-19T13:43:17.210510"}
{"title": "2D-OOB: Attributing Data Contribution through Joint Valuation Framework", "authors": "Yifan Sun, Jingyan Shen, Yongchan Kwon", "abstract": "Data valuation has emerged as a powerful framework to quantify the\ncontribution of each datum to the training of a particular machine learning\nmodel. However, it is crucial to recognize that the quality of various cells\nwithin a single data point can vary greatly in practice. For example, even in\nthe case of an abnormal data point, not all cells are necessarily noisy. The\nsingle scalar valuation assigned by existing methods blurs the distinction\nbetween noisy and clean cells of a data point, thereby compromising the\ninterpretability of the valuation. In this paper, we propose 2D-OOB, an\nout-of-bag estimation framework for jointly determining helpful (or\ndetrimental) samples, as well as the particular cells that drive them. Our\ncomprehensive experiments demonstrate that 2D-OOB achieves state-of-the-art\nperformance across multiple use cases, while being exponentially faster. 2D-OOB\nexcels in detecting and rectifying fine-grained outliers at the cell level, as\nwell as localizing backdoor triggers in data poisoning attacks.", "arxiv_id": "2408.03572v1", "pdf_url": "http://arxiv.org/pdf/2408.03572v1", "abstract_url": "http://arxiv.org/abs/2408.03572v1", "primary_category": "cs.LG", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "2D-OOB: Attributing Data Contribution through Joint Valuation Framework", "response": "RELEVANT", "timestamp": "2024-08-19T13:43:29.423863"}
{"title": "Maximum a Posteriori Estimation for Linear Structural Dynamics Models Using Bayesian Optimization with Rational Polynomial Chaos Expansions", "authors": "Felix Schneider, Iason Papaioannou, Bruno Sudret, Gerhard M\u00fcller", "abstract": "Bayesian analysis enables combining prior knowledge with measurement data to\nlearn model parameters. Commonly, one resorts to computing the maximum a\nposteriori (MAP) estimate, when only a point estimate of the parameters is of\ninterest. We apply MAP estimation in the context of structural dynamic models,\nwhere the system response can be described by the frequency response function.\nTo alleviate high computational demands from repeated expensive model calls, we\nutilize a rational polynomial chaos expansion (RPCE) surrogate model that\nexpresses the system frequency response as a rational of two polynomials with\ncomplex coefficients. We propose an extension to an existing sparse Bayesian\nlearning approach for RPCE based on Laplace's approximation for the posterior\ndistribution of the denominator coefficients. Furthermore, we introduce a\nBayesian optimization approach, which allows to adaptively enrich the\nexperimental design throughout the optimization process of MAP estimation.\nThereby, we utilize the expected improvement acquisition function as a means to\nidentify sample points in the input space that are possibly associated with\nlarge objective function values. The acquisition function is estimated through\nMonte Carlo sampling based on the posterior distribution of the expansion\ncoefficients identified in the sparse Bayesian learning process. By combining\nthe sparsity-inducing learning procedure with the sequential experimental\ndesign, we effectively reduce the number of model evaluations in the MAP\nestimation problem. We demonstrate the applicability of the presented methods\non the parameter updating problem of an algebraic two-degree-of-freedom system\nand the finite element model of a cross-laminated timber plate.", "arxiv_id": "2408.03569v1", "pdf_url": "http://arxiv.org/pdf/2408.03569v1", "abstract_url": "http://arxiv.org/abs/2408.03569v1", "primary_category": "stat.ML", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Maximum a Posteriori Estimation for Linear Structural Dynamics Models Using Bayesian Optimization with Rational Polynomial Chaos Expansions", "response": "RELEVANT", "timestamp": "2024-08-19T13:43:30.403034"}
{"title": "A comparative study of generative adversarial networks for image recognition algorithms based on deep learning and traditional methods", "authors": "Yihao Zhong, Yijing Wei, Yingbin Liang, Xiqing Liu, Rongwei Ji, Yiru Cang", "abstract": "In this paper, an image recognition algorithm based on the combination of\ndeep learning and generative adversarial network (GAN) is studied, and compared\nwith traditional image recognition methods. The purpose of this study is to\nevaluate the advantages and application prospects of deep learning technology,\nespecially GAN, in the field of image recognition. Firstly, this paper reviews\nthe basic principles and techniques of traditional image recognition methods,\nincluding the classical algorithms based on feature extraction such as SIFT,\nHOG and their combination with support vector machine (SVM), random forest, and\nother classifiers. Then, the working principle, network structure, and unique\nadvantages of GAN in image generation and recognition are introduced. In order\nto verify the effectiveness of GAN in image recognition, a series of\nexperiments are designed and carried out using multiple public image data sets\nfor training and testing. The experimental results show that compared with\ntraditional methods, GAN has excellent performance in processing complex\nimages, recognition accuracy, and anti-noise ability. Specifically, Gans are\nbetter able to capture high-dimensional features and details of images,\nsignificantly improving recognition performance. In addition, Gans shows unique\nadvantages in dealing with image noise, partial missing information, and\ngenerating high-quality images.", "arxiv_id": "2408.03568v1", "pdf_url": "http://arxiv.org/pdf/2408.03568v1", "abstract_url": "http://arxiv.org/abs/2408.03568v1", "primary_category": "cs.CV", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "A comparative study of generative adversarial networks for image recognition algorithms based on deep learning and traditional methods", "response": "RELEVANT", "timestamp": "2024-08-19T13:43:31.049346"}
{"title": "MPC-Minimized Secure LLM Inference", "authors": "Deevashwer Rathee, Dacheng Li, Ion Stoica, Hao Zhang, Raluca Popa", "abstract": "Many inference services based on large language models (LLMs) pose a privacy\nconcern, either revealing user prompts to the service or the proprietary\nweights to the user. Secure inference offers a solution to this problem through\nsecure multi-party computation (MPC), however, it is still impractical for\nmodern LLM workload due to the large overhead imposed by MPC. To address this\noverhead, we propose Marill, a framework that adapts LLM fine-tuning to\nminimize MPC usage during secure inference. Marill introduces high-level\narchitectural changes during fine-tuning that significantly reduce the number\nof expensive operations needed within MPC during inference, by removing some\nand relocating others outside MPC without compromising security. As a result,\nMarill-generated models are more efficient across all secure inference\nprotocols and our approach complements MPC-friendly approximations for such\noperations. Compared to standard fine-tuning, Marill results in 3.6-11.3x\nbetter runtime and 2.4-6.9x better communication during secure inference across\nvarious MPC settings, while typically preserving over 90% performance across\ndownstream tasks.", "arxiv_id": "2408.03561v1", "pdf_url": "http://arxiv.org/pdf/2408.03561v1", "abstract_url": "http://arxiv.org/abs/2408.03561v1", "primary_category": "cs.CR", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "MPC-Minimized Secure LLM Inference", "response": "RELEVANT", "timestamp": "2024-08-19T13:43:32.144679"}
{"title": "In2Core: Leveraging Influence Functions for Coreset Selection in Instruction Finetuning of Large Language Models", "authors": "Ayrton San Joaquin, Bin Wang, Zhengyuan Liu, Nicholas Asher, Brian Lim, Philippe Muller, Nancy Chen", "abstract": "Despite advancements, fine-tuning Large Language Models (LLMs) remains costly\ndue to the extensive parameter count and substantial data requirements for\nmodel generalization. Accessibility to computing resources remains a barrier\nfor the open-source community. To address this challenge, we propose the\nIn2Core algorithm, which selects a coreset by analyzing the correlation between\ntraining and evaluation samples with a trained model. Notably, we assess the\nmodel's internal gradients to estimate this relationship, aiming to rank the\ncontribution of each training point. To enhance efficiency, we propose an\noptimization to compute influence functions with a reduced number of layers\nwhile achieving similar accuracy. By applying our algorithm to instruction\nfine-tuning data of LLMs, we can achieve similar performance with just 50% of\nthe training data. Meantime, using influence functions to analyze model\ncoverage to certain testing samples could provide a reliable and interpretable\nsignal on the training set's coverage of those test points.", "arxiv_id": "2408.03560v1", "pdf_url": "http://arxiv.org/pdf/2408.03560v1", "abstract_url": "http://arxiv.org/abs/2408.03560v1", "primary_category": "cs.LG", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "In2Core: Leveraging Influence Functions for Coreset Selection in Instruction Finetuning of Large Language Models", "response": "RELEVANT", "timestamp": "2024-08-19T13:43:32.974700"}
{"title": "Empirical Analysis of Large Vision-Language Models against Goal Hijacking via Visual Prompt Injection", "authors": "Subaru Kimura, Ryota Tanaka, Shumpei Miyawaki, Jun Suzuki, Keisuke Sakaguchi", "abstract": "We explore visual prompt injection (VPI) that maliciously exploits the\nability of large vision-language models (LVLMs) to follow instructions drawn\nonto the input image. We propose a new VPI method, \"goal hijacking via visual\nprompt injection\" (GHVPI), that swaps the execution task of LVLMs from an\noriginal task to an alternative task designated by an attacker. The\nquantitative analysis indicates that GPT-4V is vulnerable to the GHVPI and\ndemonstrates a notable attack success rate of 15.8%, which is an unignorable\nsecurity risk. Our analysis also shows that successful GHVPI requires high\ncharacter recognition capability and instruction-following ability in LVLMs.", "arxiv_id": "2408.03554v1", "pdf_url": "http://arxiv.org/pdf/2408.03554v1", "abstract_url": "http://arxiv.org/abs/2408.03554v1", "primary_category": "cs.CL", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Empirical Analysis of Large Vision-Language Models against Goal Hijacking via Visual Prompt Injection", "response": "RELEVANT", "timestamp": "2024-08-19T13:43:33.714490"}
{"title": "Deep Reinforcement Learning for Robotics: A Survey of Real-World Successes", "authors": "Chen Tang, Ben Abbatematteo, Jiaheng Hu, Rohan Chandra, Roberto Mart\u00edn-Mart\u00edn, Peter Stone", "abstract": "Reinforcement learning (RL), particularly its combination with deep neural\nnetworks referred to as deep RL (DRL), has shown tremendous promise across a\nwide range of applications, suggesting its potential for enabling the\ndevelopment of sophisticated robotic behaviors. Robotics problems, however,\npose fundamental difficulties for the application of RL, stemming from the\ncomplexity and cost of interacting with the physical world. This article\nprovides a modern survey of DRL for robotics, with a particular focus on\nevaluating the real-world successes achieved with DRL in realizing several key\nrobotic competencies. Our analysis aims to identify the key factors underlying\nthose exciting successes, reveal underexplored areas, and provide an overall\ncharacterization of the status of DRL in robotics. We highlight several\nimportant avenues for future work, emphasizing the need for stable and\nsample-efficient real-world RL paradigms, holistic approaches for discovering\nand integrating various competencies to tackle complex long-horizon, open-world\ntasks, and principled development and evaluation procedures. This survey is\ndesigned to offer insights for both RL practitioners and roboticists toward\nharnessing RL's power to create generally capable real-world robotic systems.", "arxiv_id": "2408.03539v2", "pdf_url": "http://arxiv.org/pdf/2408.03539v2", "abstract_url": "http://arxiv.org/abs/2408.03539v2", "primary_category": "cs.RO", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Deep Reinforcement Learning for Robotics: A Survey of Real-World Successes", "response": "RELEVANT", "timestamp": "2024-08-19T13:43:34.547416"}
{"title": "Minimum Enclosing Ball Synthetic Minority Oversampling Technique from a Geometric Perspective", "authors": "Yi-Yang Shangguan, Shi-Shun Chen, Xiao-Yang Li", "abstract": "Class imbalance refers to the significant difference in the number of samples\nfrom different classes within a dataset, making it challenging to identify\nminority class samples correctly. This issue is prevalent in real-world\nclassification tasks, such as software defect prediction, medical diagnosis,\nand fraud detection. The synthetic minority oversampling technique (SMOTE) is\nwidely used to address class imbalance issue, which is based on interpolation\nbetween randomly selected minority class samples and their neighbors. However,\ntraditional SMOTE and most of its variants only interpolate between existing\nsamples, which may be affected by noise samples in some cases and synthesize\nsamples that lack diversity. To overcome these shortcomings, this paper\nproposes the Minimum Enclosing Ball SMOTE (MEB-SMOTE) method from a geometry\nperspective. Specifically, MEB is innovatively introduced into the oversampling\nmethod to construct a representative point. Then, high-quality samples are\nsynthesized by interpolation between this representative point and the existing\nsamples. The rationale behind constructing a representative point is discussed,\ndemonstrating that the center of MEB is more suitable as the representative\npoint. To exhibit the superiority of MEB-SMOTE, experiments are conducted on 15\nreal-world imbalanced datasets. The results indicate that MEB-SMOTE can\neffectively improve the classification performance on imbalanced datasets.", "arxiv_id": "2408.03526v1", "pdf_url": "http://arxiv.org/pdf/2408.03526v1", "abstract_url": "http://arxiv.org/abs/2408.03526v1", "primary_category": "cs.LG", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Minimum Enclosing Ball Synthetic Minority Oversampling Technique from a Geometric Perspective", "response": "RELEVANT", "timestamp": "2024-08-19T13:43:35.224860"}
{"title": "Leveraging LLMs for Enhanced Open-Vocabulary 3D Scene Understanding in Autonomous Driving", "authors": "Amirhosein Chahe, Lifeng Zhou", "abstract": "This paper introduces a novel method for open-vocabulary 3D scene\nunderstanding in autonomous driving by combining Language Embedded 3D Gaussians\nwith Large Language Models (LLMs) for enhanced inference. We propose utilizing\nLLMs to generate contextually relevant canonical phrases for segmentation and\nscene interpretation. Our method leverages the contextual and semantic\ncapabilities of LLMs to produce a set of canonical phrases, which are then\ncompared with the language features embedded in the 3D Gaussians. This\nLLM-guided approach significantly improves zero-shot scene understanding and\ndetection of objects of interest, even in the most challenging or unfamiliar\nenvironments. Experimental results on the WayveScenes101 dataset demonstrate\nthat our approach surpasses state-of-the-art methods in terms of accuracy and\nflexibility for open-vocabulary object detection and segmentation. This work\nrepresents a significant advancement towards more intelligent, context-aware\nautonomous driving systems, effectively bridging 3D scene representation with\nhigh-level semantic understanding.", "arxiv_id": "2408.03516v1", "pdf_url": "http://arxiv.org/pdf/2408.03516v1", "abstract_url": "http://arxiv.org/abs/2408.03516v1", "primary_category": "cs.CV", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Leveraging LLMs for Enhanced Open-Vocabulary 3D Scene Understanding in Autonomous Driving", "response": "RELEVANT", "timestamp": "2024-08-19T13:43:36.190780"}
{"title": "Autonomous, Self-driving Multi-Step Growth of Semiconductor Heterostructures Guided by Machine Learning", "authors": "Chao Shen, Wenkang Zhan, Hongyu Sun, Kaiyao Xin, Bo Xu, Zhanguo Wang, Chao Zhao", "abstract": "The semiconductor industry has prioritized automating repetitive tasks by\nclosed-loop, autonomous experimentation which enables accelerated optimization\nof complex multi-step processes. The emergence of machine learning (ML) has\nushered in automated process with minimal human intervention. In this work, we\ndevelop SemiEpi, a self-driving automation platform capable of executing\nmolecular beam epitaxy (MBE) growth with multi-steps, continuous in-situ\nmonitoring, and on-the-fly feedback control. By integrating standard hardware,\nhomemade software, curve fitting, and multiple ML models, SemiEpi operates\nautonomously, eliminating the need for extensive expertise in MBE processes to\nachieve optimal outcomes. The platform actively learns from previous\nexperimental results, identifying favorable conditions and proposing new\nexperiments to achieve the desired results. We standardize and optimize growth\nfor InAs/GaAs quantum dots (QDs) heterostructures to showcase the power of\nML-guided multi-step growth. A temperature calibration was implemented to get\nthe initial growth condition, and fine control of the process was executed\nusing ML. Leveraging RHEED movies acquired during the growth, SemiEpi\nsuccessfully identified and optimized a novel route for multi-step\nheterostructure growth. This work demonstrates the capabilities of closed-loop,\nML-guided systems in addressing challenges in multi-step growth for any device.\nOur method is critical to achieve repeatable materials growth using\ncommercially scalable tools. Our strategy facilitates the development of a\nhardware-independent process and enhancing process repeatability and stability,\neven without exhaustive knowledge of growth parameters.", "arxiv_id": "2408.03508v2", "pdf_url": "http://arxiv.org/pdf/2408.03508v2", "abstract_url": "http://arxiv.org/abs/2408.03508v2", "primary_category": "cond-mat.mtrl-sci", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Autonomous, Self-driving Multi-Step Growth of Semiconductor Heterostructures Guided by Machine Learning", "response": "RELEVANT", "timestamp": "2024-08-19T13:43:37.105948"}
{"title": "Advanced User Credit Risk Prediction Model using LightGBM, XGBoost and Tabnet with SMOTEENN", "authors": "Chang Yu, Yixin Jin, Qianwen Xing, Ye Zhang, Shaobo Guo, Shuchen Meng", "abstract": "Bank credit risk is a significant challenge in modern financial transactions,\nand the ability to identify qualified credit card holders among a large number\nof applicants is crucial for the profitability of a bank'sbank's credit card\nbusiness. In the past, screening applicants'applicants' conditions often\nrequired a significant amount of manual labor, which was time-consuming and\nlabor-intensive. Although the accuracy and reliability of previously used ML\nmodels have been continuously improving, the pursuit of more reliable and\npowerful AI intelligent models is undoubtedly the unremitting pursuit by major\nbanks in the financial industry. In this study, we used a dataset of over\n40,000 records provided by a commercial bank as the research object. We\ncompared various dimensionality reduction techniques such as PCA and T-SNE for\npreprocessing high-dimensional datasets and performed in-depth adaptation and\ntuning of distributed models such as LightGBM and XGBoost, as well as deep\nmodels like Tabnet. After a series of research and processing, we obtained\nexcellent research results by combining SMOTEENN with these techniques. The\nexperiments demonstrated that LightGBM combined with PCA and SMOTEENN\ntechniques can assist banks in accurately predicting potential high-quality\ncustomers, showing relatively outstanding performance compared to other models.", "arxiv_id": "2408.03497v1", "pdf_url": "http://arxiv.org/pdf/2408.03497v1", "abstract_url": "http://arxiv.org/abs/2408.03497v1", "primary_category": "cs.LG", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Advanced User Credit Risk Prediction Model using LightGBM, XGBoost and Tabnet with SMOTEENN", "response": "RELEVANT", "timestamp": "2024-08-19T13:43:38.095722"}
{"title": "Simultaneous and Meshfree Topology Optimization with Physics-informed Gaussian Processes", "authors": "Amin Yousefpour, Shirin Hosseinmardi, Carlos Mora, Ramin Bostanabad", "abstract": "Topology optimization (TO) provides a principled mathematical approach for\noptimizing the performance of a structure by designing its material spatial\ndistribution in a pre-defined domain and subject to a set of constraints. The\nmajority of existing TO approaches leverage numerical solvers for design\nevaluations during the optimization and hence have a nested nature and rely on\ndiscretizing the design variables. Contrary to these approaches, herein we\ndevelop a new class of TO methods based on the framework of Gaussian processes\n(GPs) whose mean functions are parameterized via deep neural networks.\nSpecifically, we place GP priors on all design and state variables to represent\nthem via parameterized continuous functions. These GPs share a deep neural\nnetwork as their mean function but have as many independent kernels as there\nare state and design variables. We estimate all the parameters of our model in\na single for loop that optimizes a penalized version of the performance metric\nwhere the penalty terms correspond to the state equations and design\nconstraints. Attractive features of our approach include $(1)$ having a\nbuilt-in continuation nature since the performance metric is optimized at the\nsame time that the state equations are solved, and $(2)$ being\ndiscretization-invariant and accommodating complex domains and topologies. To\ntest our method against conventional TO approaches implemented in commercial\nsoftware, we evaluate it on four problems involving the minimization of\ndissipated power in Stokes flow. The results indicate that our approach does\nnot need filtering techniques, has consistent computational costs, and is\nhighly robust against random initializations and problem setup.", "arxiv_id": "2408.03490v1", "pdf_url": "http://arxiv.org/pdf/2408.03490v1", "abstract_url": "http://arxiv.org/abs/2408.03490v1", "primary_category": "cs.LG", "published_date": "2024-08-07", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Simultaneous and Meshfree Topology Optimization with Physics-informed Gaussian Processes", "response": "RELEVANT", "timestamp": "2024-08-19T13:43:38.794570"}
{"title": "Advancing EEG-Based Gaze Prediction Using Depthwise Separable Convolution and Enhanced Pre-Processing", "authors": "Matthew L Key, Tural Mehtiyev, Xiaodong Qu", "abstract": "In the field of EEG-based gaze prediction, the application of deep learning\nto interpret complex neural data poses significant challenges. This study\nevaluates the effectiveness of pre-processing techniques and the effect of\nadditional depthwise separable convolution on EEG vision transformers (ViTs) in\na pretrained model architecture. We introduce a novel method, the EEG Deeper\nClustered Vision Transformer (EEG-DCViT), which combines depthwise separable\nconvolutional neural networks (CNNs) with vision transformers, enriched by a\npre-processing strategy involving data clustering. The new approach\ndemonstrates superior performance, establishing a new benchmark with a Root\nMean Square Error (RMSE) of 51.6 mm. This achievement underscores the impact of\npre-processing and model refinement in enhancing EEG-based applications.", "arxiv_id": "2408.03480v1", "pdf_url": "http://arxiv.org/pdf/2408.03480v1", "abstract_url": "http://arxiv.org/abs/2408.03480v1", "primary_category": "cs.LG", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Advancing EEG-Based Gaze Prediction Using Depthwise Separable Convolution and Enhanced Pre-Processing", "response": "RELEVANT", "timestamp": "2024-08-19T13:43:39.672414"}
{"title": "Effect of Kernel Size on CNN-Vision-Transformer-Based Gaze Prediction Using Electroencephalography Data", "authors": "Chuhui Qiu, Bugao Liang, Matthew L Key", "abstract": "In this paper, we present an algorithm of gaze prediction from\nElectroencephalography (EEG) data. EEG-based gaze prediction is a new research\ntopic that can serve as an alternative to traditional video-based eye-tracking.\nCompared to the existing state-of-the-art (SOTA) method, we improved the root\nmean-squared-error of EEG-based gaze prediction to 53.06 millimeters, while\nreducing the training time to less than 33% of its original duration. Our\nsource code can be found at https://github.com/AmCh-Q/CSCI6907Project", "arxiv_id": "2408.03478v1", "pdf_url": "http://arxiv.org/pdf/2408.03478v1", "abstract_url": "http://arxiv.org/abs/2408.03478v1", "primary_category": "cs.LG", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "NOT_ENOUGH_RELATED"}
{"title": "Effect of Kernel Size on CNN-Vision-Transformer-Based Gaze Prediction Using Electroencephalography Data", "response": "NOT_ENOUGH_RELATED", "timestamp": "2024-08-19T13:43:40.720203"}
{"title": "Can LLMs Serve As Time Series Anomaly Detectors?", "authors": "Manqing Dong, Hao Huang, Longbing Cao", "abstract": "An emerging topic in large language models (LLMs) is their application to\ntime series forecasting, characterizing mainstream and patternable\ncharacteristics of time series. A relevant but rarely explored and more\nchallenging question is whether LLMs can detect and explain time series\nanomalies, a critical task across various real-world applications. In this\npaper, we investigate the capabilities of LLMs, specifically GPT-4 and LLaMA3,\nin detecting and explaining anomalies in time series. Our studies reveal that:\n1) LLMs cannot be directly used for time series anomaly detection. 2) By\ndesigning prompt strategies such as in-context learning and chain-of-thought\nprompting, GPT-4 can detect time series anomalies with results competitive to\nbaseline methods. 3) We propose a synthesized dataset to automatically generate\ntime series anomalies with corresponding explanations. By applying instruction\nfine-tuning on this dataset, LLaMA3 demonstrates improved performance in time\nseries anomaly detection tasks. In summary, our exploration shows the promising\npotential of LLMs as time series anomaly detectors.", "arxiv_id": "2408.03475v1", "pdf_url": "http://arxiv.org/pdf/2408.03475v1", "abstract_url": "http://arxiv.org/abs/2408.03475v1", "primary_category": "cs.LG", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Can LLMs Serve As Time Series Anomaly Detectors?", "response": "RELEVANT", "timestamp": "2024-08-19T13:43:41.772001"}
{"title": "Integrating HCI Datasets in Project-Based Machine Learning Courses: A College-Level Review and Case Study", "authors": "Xiaodong Qu, Matthew Key, Eric Luo, Chuhui Qiu", "abstract": "This study explores the integration of real-world machine learning (ML)\nprojects using human-computer interfaces (HCI) datasets in college-level\ncourses to enhance both teaching and learning experiences. Employing a\ncomprehensive literature review, course websites analysis, and a detailed case\nstudy, the research identifies best practices for incorporating HCI datasets\ninto project-based ML education. Key f indings demonstrate increased student\nengagement, motivation, and skill development through hands-on projects, while\ninstructors benefit from effective tools for teaching complex concepts. The\nstudy also addresses challenges such as data complexity and resource\nallocation, offering recommendations for future improvements. These insights\nprovide a valuable framework for educators aiming to bridge the gap between", "arxiv_id": "2408.03472v1", "pdf_url": "http://arxiv.org/pdf/2408.03472v1", "abstract_url": "http://arxiv.org/abs/2408.03472v1", "primary_category": "cs.LG", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Integrating HCI Datasets in Project-Based Machine Learning Courses: A College-Level Review and Case Study", "response": "RELEVANT", "timestamp": "2024-08-19T13:43:42.472169"}
{"title": "AI Foundation Models in Remote Sensing: A Survey", "authors": "Siqi Lu, Junlin Guo, James R Zimmer-Dauphinee, Jordan M Nieusma, Xiao Wang, Parker VanValkenburgh, Steven A Wernke, Yuankai Huo", "abstract": "Artificial Intelligence (AI) technologies have profoundly transformed the\nfield of remote sensing, revolutionizing data collection, processing, and\nanalysis. Traditionally reliant on manual interpretation and task-specific\nmodels, remote sensing has been significantly enhanced by the advent of\nfoundation models--large-scale, pre-trained AI models capable of performing a\nwide array of tasks with unprecedented accuracy and efficiency. This paper\nprovides a comprehensive survey of foundation models in the remote sensing\ndomain, covering models released between June 2021 and June 2024. We categorize\nthese models based on their applications in computer vision and domain-specific\ntasks, offering insights into their architectures, pre-training datasets, and\nmethodologies. Through detailed performance comparisons, we highlight emerging\ntrends and the significant advancements achieved by these foundation models.\nAdditionally, we discuss the technical challenges, practical implications, and\nfuture research directions, addressing the need for high-quality data,\ncomputational resources, and improved model generalization. Our research also\nfinds that pre-training methods, particularly self-supervised learning\ntechniques like contrastive learning and masked autoencoders, significantly\nenhance the performance and robustness of foundation models in remote sensing\ntasks such as scene classification, object detection, and other applications.\nThis survey aims to serve as a resource for researchers and practitioners by\nproviding a panorama of advances and promising pathways for continued\ndevelopment and application of foundation models in remote sensing.", "arxiv_id": "2408.03464v1", "pdf_url": "http://arxiv.org/pdf/2408.03464v1", "abstract_url": "http://arxiv.org/abs/2408.03464v1", "primary_category": "cs.CV", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "AI Foundation Models in Remote Sensing: A Survey", "response": "RELEVANT", "timestamp": "2024-08-19T13:43:43.418906"}
{"title": "FLASH: Federated Learning-Based LLMs for Advanced Query Processing in Social Networks through RAG", "authors": "Sai Puppala, Ismail Hossain, Md Jahangir Alam, Sajedul Talukder", "abstract": "Our paper introduces a novel approach to social network information retrieval\nand user engagement through a personalized chatbot system empowered by\nFederated Learning GPT. The system is designed to seamlessly aggregate and\ncurate diverse social media data sources, including user posts, multimedia\ncontent, and trending news. Leveraging Federated Learning techniques, the GPT\nmodel is trained on decentralized data sources to ensure privacy and security\nwhile providing personalized insights and recommendations. Users interact with\nthe chatbot through an intuitive interface, accessing tailored information and\nreal-time updates on social media trends and user-generated content. The\nsystem's innovative architecture enables efficient processing of input files,\nparsing and enriching text data with metadata, and generating relevant\nquestions and answers using advanced language models. By facilitating\ninteractive access to a wealth of social network information, this personalized\nchatbot system represents a significant advancement in social media\ncommunication and knowledge dissemination.", "arxiv_id": "2408.05242v1", "pdf_url": "http://arxiv.org/pdf/2408.05242v1", "abstract_url": "http://arxiv.org/abs/2408.05242v1", "primary_category": "cs.LG", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "FLASH: Federated Learning-Based LLMs for Advanced Query Processing in Social Networks through RAG", "response": "RELEVANT", "timestamp": "2024-08-19T13:43:44.267397"}
{"title": "When does the mean network capture the topology of a sample of networks?", "authors": "Fran\u00e7ois G Meyer", "abstract": "The notion of Fr\\'echet mean (also known as \"barycenter\") network is the\nworkhorse of most machine learning algorithms that require the estimation of a\n\"location\" parameter to analyse network-valued data. In this context, it is\ncritical that the network barycenter inherits the topological structure of the\nnetworks in the training dataset. The metric - which measures the proximity\nbetween networks - controls the structural properties of the barycenter. This\nwork is significant because it provides for the first time analytical estimates\nof the sample Fr\\'echet mean for the stochastic blockmodel, which is at the\ncutting edge of rigorous probabilistic analysis of random networks. We show\nthat the mean network computed with the Hamming distance is unable to capture\nthe topology of the networks in the training sample, whereas the mean network\ncomputed using the effective resistance distance recovers the correct\npartitions and associated edge density. From a practical standpoint, our work\ninforms the choice of metrics in the context where the sample Fr\\'echet mean\nnetwork is used to characterise the topology of networks for network-valued\nmachine learning", "arxiv_id": "2408.03461v1", "pdf_url": "http://arxiv.org/pdf/2408.03461v1", "abstract_url": "http://arxiv.org/abs/2408.03461v1", "primary_category": "stat.ML", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "When does the mean network capture the topology of a sample of networks?", "response": "RELEVANT", "timestamp": "2024-08-19T13:43:45.050481"}
{"title": "On the Generalization of Preference Learning with DPO", "authors": "Shawn Im, Yixuan Li", "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities but\noften struggle to align with human preferences, leading to harmful or\nundesirable outputs. Preference learning, which trains models to distinguish\nbetween preferred and non-preferred responses based on human feedback, has\nbecome a crucial component for ensuring that LLMs align with human values.\nDespite the widespread adoption in real-world systems, a thorough theoretical\nunderstanding of the generalization guarantees for these models remain lacking.\nThis paper bridges that gap by introducing a new theoretical framework to\nanalyze the generalization guarantees of models trained with direct preference\noptimization (DPO). While existing generalization theory often focuses on\noverparameterized models achieving near-optimal loss or models independent of\nthe training process, our framework rigorously assesses how well models\ngeneralize after a finite number of gradient steps, reflecting real-world LLM\ntraining practices. By analyzing the reward margin associated with each sample\nand its trajectory throughout training, we can effectively bound the\ngeneralization error. We derive learning guarantees showing that, under\nspecific conditions, models trained with DPO can correctly discern preferred\nresponses on unseen data with high probability. These insights are empirically\nvalidated on contemporary LLMs, underscoring the practical relevance of our\ntheoretical findings.", "arxiv_id": "2408.03459v2", "pdf_url": "http://arxiv.org/pdf/2408.03459v2", "abstract_url": "http://arxiv.org/abs/2408.03459v2", "primary_category": "cs.LG", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "On the Generalization of Preference Learning with DPO", "response": "RELEVANT", "timestamp": "2024-08-19T13:43:45.875294"}
{"title": "Probabilistic Surrogate Model for Accelerating the Design of Electric Vehicle Battery Enclosures for Crash Performance", "authors": "Shadab Anwar Shaikh, Harish Cherukuri, Kranthi Balusu, Ram Devanathan, Ayoub Soulami", "abstract": "This paper presents a probabilistic surrogate model for the accelerated\ndesign of electric vehicle battery enclosures with a focus on crash\nperformance. The study integrates high-throughput finite element simulations\nand Gaussian Process Regression to develop a surrogate model that predicts\ncrash parameters with high accuracy while providing uncertainty estimates. The\nmodel was trained using data generated from thermoforming and crash simulations\nover a range of material and process parameters. Validation against new\nsimulation data demonstrated the model's predictive accuracy with mean absolute\npercentage errors within 8.08% for all output variables. Additionally, a Monte\nCarlo uncertainty propagation study revealed the impact of input variability on\noutputs. The results highlight the efficacy of the Gaussian Process Regression\nmodel in capturing complex relationships within the dataset, offering a robust\nand efficient tool for the design optimization of composite battery enclosures.", "arxiv_id": "2408.03450v1", "pdf_url": "http://arxiv.org/pdf/2408.03450v1", "abstract_url": "http://arxiv.org/abs/2408.03450v1", "primary_category": "cs.LG", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Probabilistic Surrogate Model for Accelerating the Design of Electric Vehicle Battery Enclosures for Crash Performance", "response": "RELEVANT", "timestamp": "2024-08-19T13:43:47.104861"}
{"title": "EEGMobile: Enhancing Speed and Accuracy in EEG-Based Gaze Prediction with Advanced Mobile Architectures", "authors": "Teng Liang, Andrews Damoah", "abstract": "Electroencephalography (EEG) analysis is an important domain in the realm of\nBrain-Computer Interface (BCI) research. To ensure BCI devices are capable of\nproviding practical applications in the real world, brain signal processing\ntechniques must be fast, accurate, and resource-conscious to deliver\nlow-latency neural analytics. This study presents a model that leverages a\npre-trained MobileViT alongside Knowledge Distillation (KD) for EEG regression\ntasks. Our results showcase that this model is capable of performing at a level\ncomparable (only 3% lower) to the previous State-Of-The-Art (SOTA) on the\nEEGEyeNet Absolute Position Task while being 33% faster and 60% smaller. Our\nresearch presents a cost-effective model applicable to resource-constrained\ndevices and contributes to expanding future research on lightweight,\nmobile-friendly models for EEG regression.", "arxiv_id": "2408.03449v1", "pdf_url": "http://arxiv.org/pdf/2408.03449v1", "abstract_url": "http://arxiv.org/abs/2408.03449v1", "primary_category": "eess.SP", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "EEGMobile: Enhancing Speed and Accuracy in EEG-Based Gaze Prediction with Advanced Mobile Architectures", "response": "RELEVANT", "timestamp": "2024-08-19T13:43:48.027297"}
{"title": "Spacecraft inertial parameters estimation using time series clustering and reinforcement learning", "authors": "Konstantinos Platanitis, Miguel Arana-Catania, Leonardo Capicchiano, Saurabh Upadhyay, Leonard Felicetti", "abstract": "This paper presents a machine learning approach to estimate the inertial\nparameters of a spacecraft in cases when those change during operations, e.g.\nmultiple deployments of payloads, unfolding of appendages and booms, propellant\nconsumption as well as during in-orbit servicing and active debris removal\noperations. The machine learning approach uses time series clustering together\nwith an optimised actuation sequence generated by reinforcement learning to\nfacilitate distinguishing among different inertial parameter sets. The\nperformance of the proposed strategy is assessed against the case of a\nmulti-satellite deployment system showing that the algorithm is resilient\ntowards common disturbances in such kinds of operations.", "arxiv_id": "2408.03445v1", "pdf_url": "http://arxiv.org/pdf/2408.03445v1", "abstract_url": "http://arxiv.org/abs/2408.03445v1", "primary_category": "astro-ph.IM", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Spacecraft inertial parameters estimation using time series clustering and reinforcement learning", "response": "RELEVANT", "timestamp": "2024-08-19T13:43:48.743269"}
{"title": "Simple Perturbations Subvert Ethereum Phishing Transactions Detection: An Empirical Analysis", "authors": "Ahod Alghureid, David Mohaisen", "abstract": "This paper explores the vulnerability of machine learning models,\nspecifically Random Forest, Decision Tree, and K-Nearest Neighbors, to very\nsimple single-feature adversarial attacks in the context of Ethereum fraudulent\ntransaction detection. Through comprehensive experimentation, we investigate\nthe impact of various adversarial attack strategies on model performance\nmetrics, such as accuracy, precision, recall, and F1-score. Our findings,\nhighlighting how prone those techniques are to simple attacks, are alarming,\nand the inconsistency in the attacks' effect on different algorithms promises\nways for attack mitigation. We examine the effectiveness of different\nmitigation strategies, including adversarial training and enhanced feature\nselection, in enhancing model robustness.", "arxiv_id": "2408.03441v1", "pdf_url": "http://arxiv.org/pdf/2408.03441v1", "abstract_url": "http://arxiv.org/abs/2408.03441v1", "primary_category": "cs.CR", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Simple Perturbations Subvert Ethereum Phishing Transactions Detection: An Empirical Analysis", "response": "RELEVANT", "timestamp": "2024-08-19T13:43:49.577601"}
{"title": "Hybrid diffusion models: combining supervised and generative pretraining for label-efficient fine-tuning of segmentation models", "authors": "Bruno Sauvalle, Mathieu Salzmann", "abstract": "We are considering in this paper the task of label-efficient fine-tuning of\nsegmentation models: We assume that a large labeled dataset is available and\nallows to train an accurate segmentation model in one domain, and that we have\nto adapt this model on a related domain where only a few samples are available.\nWe observe that this adaptation can be done using two distinct methods: The\nfirst method, supervised pretraining, is simply to take the model trained on\nthe first domain using classical supervised learning, and fine-tune it on the\nsecond domain with the available labeled samples. The second method is to\nperform self-supervised pretraining on the first domain using a generic pretext\ntask in order to get high-quality representations which can then be used to\ntrain a model on the second domain in a label-efficient way. We propose in this\npaper to fuse these two approaches by introducing a new pretext task, which is\nto perform simultaneously image denoising and mask prediction on the first\ndomain. We motivate this choice by showing that in the same way that an image\ndenoiser conditioned on the noise level can be considered as a generative model\nfor the unlabeled image distribution using the theory of diffusion models, a\nmodel trained using this new pretext task can be considered as a generative\nmodel for the joint distribution of images and segmentation masks under the\nassumption that the mapping from images to segmentation masks is deterministic.\nWe then empirically show on several datasets that fine-tuning a model\npretrained using this approach leads to better results than fine-tuning a\nsimilar model trained using either supervised or unsupervised pretraining only.", "arxiv_id": "2408.03433v1", "pdf_url": "http://arxiv.org/pdf/2408.03433v1", "abstract_url": "http://arxiv.org/abs/2408.03433v1", "primary_category": "cs.CV", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Hybrid diffusion models: combining supervised and generative pretraining for label-efficient fine-tuning of segmentation models", "response": "RELEVANT", "timestamp": "2024-08-19T13:43:51.202088"}
{"title": "Sequential Conditional Transport on Probabilistic Graphs for Interpretable Counterfactual Fairness", "authors": "Agathe Fernandes Machado, Arthur Charpentier, Ewen Gallic", "abstract": "In this paper, we link two existing approaches to derive counterfactuals:\nadaptations based on a causal graph, as suggested in Ple\\v{c}ko and Meinshausen\n(2020) and optimal transport, as in De Lara et al. (2024). We extend \"Knothe's\nrearrangement\" Bonnotte (2013) and \"triangular transport\" Zech and Marzouk\n(2022a) to probabilistic graphical models, and use this counterfactual\napproach, referred to as sequential transport, to discuss individual fairness.\nAfter establishing the theoretical foundations of the proposed method, we\ndemonstrate its application through numerical experiments on both synthetic and\nreal datasets.", "arxiv_id": "2408.03425v1", "pdf_url": "http://arxiv.org/pdf/2408.03425v1", "abstract_url": "http://arxiv.org/abs/2408.03425v1", "primary_category": "cs.LG", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Sequential Conditional Transport on Probabilistic Graphs for Interpretable Counterfactual Fairness", "response": "RELEVANT", "timestamp": "2024-08-19T13:43:51.990930"}
{"title": "Probabilistic Scores of Classifiers, Calibration is not Enough", "authors": "Agathe Fernandes Machado, Arthur Charpentier, Emmanuel Flachaire, Ewen Gallic, Fran\u00e7ois Hu", "abstract": "In binary classification tasks, accurate representation of probabilistic\npredictions is essential for various real-world applications such as predicting\npayment defaults or assessing medical risks. The model must then be\nwell-calibrated to ensure alignment between predicted probabilities and actual\noutcomes. However, when score heterogeneity deviates from the underlying data\nprobability distribution, traditional calibration metrics lose reliability,\nfailing to align score distribution with actual probabilities. In this study,\nwe highlight approaches that prioritize optimizing the alignment between\npredicted scores and true probability distributions over minimizing traditional\nperformance or calibration metrics. When employing tree-based models such as\nRandom Forest and XGBoost, our analysis emphasizes the flexibility these models\noffer in tuning hyperparameters to minimize the Kullback-Leibler (KL)\ndivergence between predicted and true distributions. Through extensive\nempirical analysis across 10 UCI datasets and simulations, we demonstrate that\noptimizing tree-based models based on KL divergence yields superior alignment\nbetween predicted scores and actual probabilities without significant\nperformance loss. In real-world scenarios, the reference probability is\ndetermined a priori as a Beta distribution estimated through maximum\nlikelihood. Conversely, minimizing traditional calibration metrics may lead to\nsuboptimal results, characterized by notable performance declines and inferior\nKL values. Our findings reveal limitations in traditional calibration metrics,\nwhich could undermine the reliability of predictive models for critical\ndecision-making.", "arxiv_id": "2408.03421v1", "pdf_url": "http://arxiv.org/pdf/2408.03421v1", "abstract_url": "http://arxiv.org/abs/2408.03421v1", "primary_category": "cs.LG", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Probabilistic Scores of Classifiers, Calibration is not Enough", "response": "RELEVANT", "timestamp": "2024-08-19T13:43:52.941647"}
{"title": "Logistic Regression makes small LLMs strong and explainable \"tens-of-shot\" classifiers", "authors": "Marcus Buckmann, Edward Hill", "abstract": "For simple classification tasks, we show that users can benefit from the\nadvantages of using small, local, generative language models instead of large\ncommercial models without a trade-off in performance or introducing extra\nlabelling costs. These advantages, including those around privacy,\navailability, cost, and explainability, are important both in commercial\napplications and in the broader democratisation of AI. Through experiments on\n17 sentence classification tasks (2-4 classes), we show that penalised logistic\nregression on the embeddings from a small LLM equals (and usually betters) the\nperformance of a large LLM in the \"tens-of-shot\" regime. This requires no more\nlabelled instances than are needed to validate the performance of the large\nLLM. Finally, we extract stable and sensible explanations for classification\ndecisions.", "arxiv_id": "2408.03414v1", "pdf_url": "http://arxiv.org/pdf/2408.03414v1", "abstract_url": "http://arxiv.org/abs/2408.03414v1", "primary_category": "cs.CL", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Logistic Regression makes small LLMs strong and explainable \"tens-of-shot\" classifiers", "response": "RELEVANT", "timestamp": "2024-08-19T13:43:54.170206"}
{"title": "A TVD neural network closure and application to turbulent combustion", "authors": "Seung Won Suh, Jonathan F MacArt, Luke N Olson, Jonathan B Freund", "abstract": "Trained neural networks (NN) have attractive features for closing governing\nequations, but in the absence of additional constraints, they can stray from\nphysical reality. A NN formulation is introduced to preclude spurious\noscillations that violate solution boundedness or positivity. It is embedded in\nthe discretized equations as a machine learning closure and strictly\nconstrained, inspired by total variation diminishing (TVD) methods for\nhyperbolic conservation laws. The constraint is exactly enforced during\ngradient-descent training by rescaling the NN parameters, which maps them onto\nan explicit feasible set. Demonstrations show that the constrained NN closure\nmodel usefully recovers linear and nonlinear hyperbolic phenomena and\nanti-diffusion while enforcing the non-oscillatory property. Finally, the model\nis applied to subgrid-scale (SGS) modeling of a turbulent reacting flow, for\nwhich it suppresses spurious oscillations in scalar fields that otherwise\nviolate the solution boundedness. It outperforms a simple penalization of\noscillations in the loss function.", "arxiv_id": "2408.03413v1", "pdf_url": "http://arxiv.org/pdf/2408.03413v1", "abstract_url": "http://arxiv.org/abs/2408.03413v1", "primary_category": "cs.LG", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "A TVD neural network closure and application to turbulent combustion", "response": "RELEVANT", "timestamp": "2024-08-19T13:43:54.995401"}
{"title": "LLM-Aided Compilation for Tensor Accelerators", "authors": "Charles Hong, Sahil Bhatia, Altan Haan, Shengjun Kris Dong, Dima Nikiforov, Alvin Cheung, Yakun Sophia Shao", "abstract": "Hardware accelerators, in particular accelerators for tensor processing, have\nmany potential application domains. However, they currently lack the software\ninfrastructure to support the majority of domains outside of deep learning.\nFurthermore, a compiler that can easily be updated to reflect changes at both\napplication and hardware levels would enable more agile development and design\nspace exploration of accelerators, allowing hardware designers to realize\ncloser-to-optimal performance. In this work, we discuss how large language\nmodels (LLMs) could be leveraged to build such a compiler. Specifically, we\ndemonstrate the ability of GPT-4 to achieve high pass rates in translating code\nto the Gemmini accelerator, and prototype a technique for decomposing\ntranslation into smaller, more LLM-friendly steps. Additionally, we propose a\n2-phase workflow for utilizing LLMs to generate hardware-optimized code.", "arxiv_id": "2408.03408v1", "pdf_url": "http://arxiv.org/pdf/2408.03408v1", "abstract_url": "http://arxiv.org/abs/2408.03408v1", "primary_category": "cs.AR", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "LLM-Aided Compilation for Tensor Accelerators", "response": "RELEVANT", "timestamp": "2024-08-19T13:43:55.810132"}
{"title": "Deep Clustering via Distribution Learning", "authors": "Guanfang Dong, Zijie Tan, Chenqiu Zhao, Anup Basu", "abstract": "Distribution learning finds probability density functions from a set of data\nsamples, whereas clustering aims to group similar data points to form clusters.\nAlthough there are deep clustering methods that employ distribution learning\nmethods, past work still lacks theoretical analysis regarding the relationship\nbetween clustering and distribution learning. Thus, in this work, we provide a\ntheoretical analysis to guide the optimization of clustering via distribution\nlearning. To achieve better results, we embed deep clustering guided by a\ntheoretical analysis. Furthermore, the distribution learning method cannot\nalways be directly applied to data. To overcome this issue, we introduce a\nclustering-oriented distribution learning method called Monte-Carlo\nMarginalization for Clustering. We integrate Monte-Carlo Marginalization for\nClustering into Deep Clustering, resulting in Deep Clustering via Distribution\nLearning (DCDL). Eventually, the proposed DCDL achieves promising results\ncompared to state-of-the-art methods on popular datasets. Considering a\nclustering task, the new distribution learning method outperforms previous\nmethods as well.", "arxiv_id": "2408.03407v1", "pdf_url": "http://arxiv.org/pdf/2408.03407v1", "abstract_url": "http://arxiv.org/abs/2408.03407v1", "primary_category": "cs.LG", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Deep Clustering via Distribution Learning", "response": "RELEVANT", "timestamp": "2024-08-19T13:43:56.833866"}
{"title": "Combining Diverse Information for Coordinated Action: Stochastic Bandit Algorithms for Heterogeneous Agents", "authors": "Lucia Gordon, Esther Rolf, Milind Tambe", "abstract": "Stochastic multi-agent multi-armed bandits typically assume that the rewards\nfrom each arm follow a fixed distribution, regardless of which agent pulls the\narm. However, in many real-world settings, rewards can depend on the\nsensitivity of each agent to their environment. In medical screening, disease\ndetection rates can vary by test type; in preference matching, rewards can\ndepend on user preferences; and in environmental sensing, observation quality\ncan vary across sensors. Since past work does not specify how to allocate\nagents of heterogeneous but known sensitivity of these types in a stochastic\nbandit setting, we introduce a UCB-style algorithm, Min-Width, which aggregates\ninformation from diverse agents. In doing so, we address the joint challenges\nof (i) aggregating the rewards, which follow different distributions for each\nagent-arm pair, and (ii) coordinating the assignments of agents to arms.\nMin-Width facilitates efficient collaboration among heterogeneous agents,\nexploiting the known structure in the agents' reward functions to weight their\nrewards accordingly. We analyze the regret of Min-Width and conduct\npseudo-synthetic and fully synthetic experiments to study the performance of\ndifferent levels of information sharing. Our results confirm that the gains to\nmodeling agent heterogeneity tend to be greater when the sensitivities are more\nvaried across agents, while combining more information does not always improve\nperformance.", "arxiv_id": "2408.03405v1", "pdf_url": "http://arxiv.org/pdf/2408.03405v1", "abstract_url": "http://arxiv.org/abs/2408.03405v1", "primary_category": "cs.MA", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Combining Diverse Information for Coordinated Action: Stochastic Bandit Algorithms for Heterogeneous Agents", "response": "RELEVANT", "timestamp": "2024-08-19T13:43:58.164682"}
{"title": "Set2Seq Transformer: Learning Permutation Aware Set Representations of Artistic Sequences", "authors": "Athanasios Efthymiou, Stevan Rudinac, Monika Kackovic, Nachoem Wijnberg, Marcel Worring", "abstract": "We propose Set2Seq Transformer, a novel sequential multiple instance\narchitecture, that learns to rank permutation aware set representations of\nsequences. First, we illustrate that learning temporal position-aware\nrepresentations of discrete timesteps can greatly improve static visual\nmultiple instance learning methods that do not regard temporality and\nconcentrate almost exclusively on visual content analysis. We further\ndemonstrate the significant advantages of end-to-end sequential multiple\ninstance learning, integrating visual content and temporal information in a\nmultimodal manner. As application we focus on fine art analysis related tasks.\nTo that end, we show that our Set2Seq Transformer can leverage visual set and\ntemporal position-aware representations for modelling visual artists' oeuvres\nfor predicting artistic success. Finally, through extensive quantitative and\nqualitative evaluation using a novel dataset, WikiArt-Seq2Rank, and a visual\nlearning-to-rank downstream task, we show that our Set2Seq Transformer captures\nessential temporal information improving the performance of strong static and\nsequential multiple instance learning methods for predicting artistic success.", "arxiv_id": "2408.03404v1", "pdf_url": "http://arxiv.org/pdf/2408.03404v1", "abstract_url": "http://arxiv.org/abs/2408.03404v1", "primary_category": "cs.CV", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Set2Seq Transformer: Learning Permutation Aware Set Representations of Artistic Sequences", "response": "RELEVANT", "timestamp": "2024-08-19T13:43:58.981896"}
{"title": "Attacks and Defenses for Generative Diffusion Models: A Comprehensive Survey", "authors": "Vu Tuan Truong, Luan Ba Dang, Long Bao Le", "abstract": "Diffusion models (DMs) have achieved state-of-the-art performance on various\ngenerative tasks such as image synthesis, text-to-image, and text-guided\nimage-to-image generation. However, the more powerful the DMs, the more harmful\nthey potentially are. Recent studies have shown that DMs are prone to a wide\nrange of attacks, including adversarial attacks, membership inference, backdoor\ninjection, and various multi-modal threats. Since numerous pre-trained DMs are\npublished widely on the Internet, potential threats from these attacks are\nespecially detrimental to the society, making DM-related security a worth\ninvestigating topic. Therefore, in this paper, we conduct a comprehensive\nsurvey on the security aspect of DMs, focusing on various attack and defense\nmethods for DMs. First, we present crucial knowledge of DMs with five main\ntypes of DMs, including denoising diffusion probabilistic models, denoising\ndiffusion implicit models, noise conditioned score networks, stochastic\ndifferential equations, and multi-modal conditional DMs. We further survey a\nvariety of recent studies investigating different types of attacks that exploit\nthe vulnerabilities of DMs. Then, we thoroughly review potential\ncountermeasures to mitigate each of the presented threats. Finally, we discuss\nopen challenges of DM-related security and envision certain research directions\nfor this topic.", "arxiv_id": "2408.03400v1", "pdf_url": "http://arxiv.org/pdf/2408.03400v1", "abstract_url": "http://arxiv.org/abs/2408.03400v1", "primary_category": "cs.CR", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Attacks and Defenses for Generative Diffusion Models: A Comprehensive Survey", "response": "RELEVANT", "timestamp": "2024-08-19T13:44:00.010249"}
{"title": "RHiOTS: A Framework for Evaluating Hierarchical Time Series Forecasting Algorithms", "authors": "Luis Roque, Carlos Soares, Lu\u00eds Torgo", "abstract": "We introduce the Robustness of Hierarchically Organized Time Series (RHiOTS)\nframework, designed to assess the robustness of hierarchical time series\nforecasting models and algorithms on real-world datasets. Hierarchical time\nseries, where lower-level forecasts must sum to upper-level ones, are prevalent\nin various contexts, such as retail sales across countries. Current empirical\nevaluations of forecasting methods are often limited to a small set of\nbenchmark datasets, offering a narrow view of algorithm behavior. RHiOTS\naddresses this gap by systematically altering existing datasets and modifying\nthe characteristics of individual series and their interrelations. It uses a\nset of parameterizable transformations to simulate those changes in the data\ndistribution. Additionally, RHiOTS incorporates an innovative visualization\ncomponent, turning complex, multidimensional robustness evaluation results into\nintuitive, easily interpretable visuals. This approach allows an in-depth\nanalysis of algorithm and model behavior under diverse conditions. We\nillustrate the use of RHiOTS by analyzing the predictive performance of several\nalgorithms. Our findings show that traditional statistical methods are more\nrobust than state-of-the-art deep learning algorithms, except when the\ntransformation effect is highly disruptive. Furthermore, we found no\nsignificant differences in the robustness of the algorithms when applying\nspecific reconciliation methods, such as MinT. RHiOTS provides researchers with\na comprehensive tool for understanding the nuanced behavior of forecasting\nalgorithms, offering a more reliable basis for selecting the most appropriate\nmethod for a given problem.", "arxiv_id": "2408.03399v1", "pdf_url": "http://arxiv.org/pdf/2408.03399v1", "abstract_url": "http://arxiv.org/abs/2408.03399v1", "primary_category": "cs.LG", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "RHiOTS: A Framework for Evaluating Hierarchical Time Series Forecasting Algorithms", "response": "RELEVANT", "timestamp": "2024-08-19T13:44:12.053585"}
{"title": "HeTraX: Energy Efficient 3D Heterogeneous Manycore Architecture for Transformer Acceleration", "authors": "Pratyush Dhingra, Janardhan Rao Doppa, Partha Pratim Pande", "abstract": "Transformers have revolutionized deep learning and generative modeling to\nenable unprecedented advancements in natural language processing tasks and\nbeyond. However, designing hardware accelerators for executing transformer\nmodels is challenging due to the wide variety of computing kernels involved in\nthe transformer architecture. Existing accelerators are either inadequate to\naccelerate end-to-end transformer models or suffer notable thermal limitations.\nIn this paper, we propose the design of a three-dimensional heterogeneous\narchitecture referred to as HeTraX specifically optimized to accelerate\nend-to-end transformer models. HeTraX employs hardware resources aligned with\nthe computational kernels of transformers and optimizes both performance and\nenergy. Experimental results show that HeTraX outperforms existing\nstate-of-the-art by up to 5.6x in speedup and improves EDP by 14.5x while\nensuring thermally feasibility.", "arxiv_id": "2408.03397v1", "pdf_url": "http://arxiv.org/pdf/2408.03397v1", "abstract_url": "http://arxiv.org/abs/2408.03397v1", "primary_category": "cs.AR", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "HeTraX: Energy Efficient 3D Heterogeneous Manycore Architecture for Transformer Acceleration", "response": "RELEVANT", "timestamp": "2024-08-19T13:44:12.910892"}
{"title": "A Non-negative VAE:the Generalized Gamma Belief Network", "authors": "Zhibin Duan, Tiansheng Wen, Muyao Wang, Bo Chen, Mingyuan Zhou", "abstract": "The gamma belief network (GBN), often regarded as a deep topic model, has\ndemonstrated its potential for uncovering multi-layer interpretable latent\nrepresentations in text data. Its notable capability to acquire interpretable\nlatent factors is partially attributed to sparse and non-negative\ngamma-distributed latent variables. However, the existing GBN and its\nvariations are constrained by the linear generative model, thereby limiting\ntheir expressiveness and applicability. To address this limitation, we\nintroduce the generalized gamma belief network (Generalized GBN) in this paper,\nwhich extends the original linear generative model to a more expressive\nnon-linear generative model. Since the parameters of the Generalized GBN no\nlonger possess an analytic conditional posterior, we further propose an\nupward-downward Weibull inference network to approximate the posterior\ndistribution of the latent variables. The parameters of both the generative\nmodel and the inference network are jointly trained within the variational\ninference framework. Finally, we conduct comprehensive experiments on both\nexpressivity and disentangled representation learning tasks to evaluate the\nperformance of the Generalized GBN against state-of-the-art Gaussian\nvariational autoencoders serving as baselines.", "arxiv_id": "2408.03388v2", "pdf_url": "http://arxiv.org/pdf/2408.03388v2", "abstract_url": "http://arxiv.org/abs/2408.03388v2", "primary_category": "cs.LG", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "A Non-negative VAE:the Generalized Gamma Belief Network", "response": "RELEVANT", "timestamp": "2024-08-19T13:44:13.831707"}
{"title": "ClassiFIM: An Unsupervised Method To Detect Phase Transitions", "authors": "Victor Kasatkin, Evgeny Mozgunov, Nicholas Ezzell, Utkarsh Mishra, Itay Hen, Daniel Lidar", "abstract": "Estimation of the Fisher Information Metric (FIM-estimation) is an important\ntask that arises in unsupervised learning of phase transitions, a problem\nproposed by physicists. This work completes the definition of the task by\ndefining rigorous evaluation metrics distMSE, distMSEPS, and distRE and\nintroduces ClassiFIM, a novel machine learning method designed to solve the\nFIM-estimation task. Unlike existing methods for unsupervised learning of phase\ntransitions, ClassiFIM directly estimates a well-defined quantity (the FIM),\nallowing it to be rigorously compared to any present and future other methods\nthat estimate the same. ClassiFIM transforms a dataset for the FIM-estimation\ntask into a dataset for an auxiliary binary classification task and involves\nselecting and training a model for the latter. We prove that the output of\nClassiFIM approaches the exact FIM in the limit of infinite dataset size and\nunder certain regularity conditions. We implement ClassiFIM on multiple\ndatasets, including datasets describing classical and quantum phase\ntransitions, and find that it achieves a good ground truth approximation with\nmodest computational resources. Furthermore, we independently implement two\nalternative state-of-the-art methods for unsupervised estimation of phase\ntransition locations on the same datasets and find that ClassiFIM predicts such\nlocations at least as well as these other methods. To emphasize the generality\nof our method, we also propose and generate the MNIST-CNN dataset, which\nconsists of the output of CNNs trained on MNIST for different hyperparameter\nchoices. Using ClassiFIM on this dataset suggests there is a phase transition\nin the distribution of image-prediction pairs for CNNs trained on MNIST,\ndemonstrating the broad scope of FIM-estimation beyond physics.", "arxiv_id": "2408.03323v1", "pdf_url": "http://arxiv.org/pdf/2408.03323v1", "abstract_url": "http://arxiv.org/abs/2408.03323v1", "primary_category": "cs.LG", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "ClassiFIM: An Unsupervised Method To Detect Phase Transitions", "response": "RELEVANT", "timestamp": "2024-08-19T13:44:14.537206"}
{"title": "Hedge Fund Portfolio Construction Using PolyModel Theory and iTransformer", "authors": "Siqiao Zhao, Zhikang Dong, Zeyu Cao, Raphael Douady", "abstract": "When constructing portfolios, a key problem is that a lot of financial time\nseries data are sparse, making it challenging to apply machine learning\nmethods. Polymodel theory can solve this issue and demonstrate superiority in\nportfolio construction from various aspects. To implement the PolyModel theory\nfor constructing a hedge fund portfolio, we begin by identifying an asset pool,\nutilizing over 10,000 hedge funds for the past 29 years' data. PolyModel theory\nalso involves choosing a wide-ranging set of risk factors, which includes\nvarious financial indices, currencies, and commodity prices. This comprehensive\nselection mirrors the complexities of the real-world environment. Leveraging on\nthe PolyModel theory, we create quantitative measures such as Long-term Alpha,\nLong-term Ratio, and SVaR. We also use more classical measures like the Sharpe\nratio or Morningstar's MRAR. To enhance the performance of the constructed\nportfolio, we also employ the latest deep learning techniques (iTransformer) to\ncapture the upward trend, while efficiently controlling the downside, using all\nthe features. The iTransformer model is specifically designed to address the\nchallenges in high-dimensional time series forecasting and could largely\nimprove our strategies. More precisely, our strategies achieve better Sharpe\nratio and annualized return. The above process enables us to create multiple\nportfolio strategies aiming for high returns and low risks when compared to\nvarious benchmarks.", "arxiv_id": "2408.03320v2", "pdf_url": "http://arxiv.org/pdf/2408.03320v2", "abstract_url": "http://arxiv.org/abs/2408.03320v2", "primary_category": "q-fin.PM", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Hedge Fund Portfolio Construction Using PolyModel Theory and iTransformer", "response": "RELEVANT", "timestamp": "2024-08-19T13:44:15.308470"}
{"title": "Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters", "authors": "Charlie Snell, Jaehoon Lee, Kelvin Xu, Aviral Kumar", "abstract": "Enabling LLMs to improve their outputs by using more test-time computation is\na critical step towards building generally self-improving agents that can\noperate on open-ended natural language. In this paper, we study the scaling of\ninference-time computation in LLMs, with a focus on answering the question: if\nan LLM is allowed to use a fixed but non-trivial amount of inference-time\ncompute, how much can it improve its performance on a challenging prompt?\nAnswering this question has implications not only on the achievable performance\nof LLMs, but also on the future of LLM pretraining and how one should tradeoff\ninference-time and pre-training compute. Despite its importance, little\nresearch attempted to understand the scaling behaviors of various test-time\ninference methods. Moreover, current work largely provides negative results for\na number of these strategies. In this work, we analyze two primary mechanisms\nto scale test-time computation: (1) searching against dense, process-based\nverifier reward models; and (2) updating the model's distribution over a\nresponse adaptively, given the prompt at test time. We find that in both cases,\nthe effectiveness of different approaches to scaling test-time compute\ncritically varies depending on the difficulty of the prompt. This observation\nmotivates applying a \"compute-optimal\" scaling strategy, which acts to most\neffectively allocate test-time compute adaptively per prompt. Using this\ncompute-optimal strategy, we can improve the efficiency of test-time compute\nscaling by more than 4x compared to a best-of-N baseline. Additionally, in a\nFLOPs-matched evaluation, we find that on problems where a smaller base model\nattains somewhat non-trivial success rates, test-time compute can be used to\noutperform a 14x larger model.", "arxiv_id": "2408.03314v1", "pdf_url": "http://arxiv.org/pdf/2408.03314v1", "abstract_url": "http://arxiv.org/abs/2408.03314v1", "primary_category": "cs.LG", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters", "response": "RELEVANT", "timestamp": "2024-08-19T13:44:17.033892"}
{"title": "Pre-training and in-context learning IS Bayesian inference a la De Finetti", "authors": "Naimeng Ye, Hanming Yang, Andrew Siah, Hongseok Namkoong", "abstract": "Accurately gauging uncertainty on the underlying environment is a\nlongstanding goal of intelligent systems. We characterize which latent concepts\npre-trained sequence models are naturally able to reason with. We go back to De\nFinetti's predictive view of Bayesian reasoning: instead of modeling latent\nparameters through priors and likelihoods like topic models do, De Finetti has\nlong advocated for modeling exchangeable (permutation invariant) sequences of\nobservables. According to this view, pre-training autoregressive models\nformulates informed beliefs based on prior observations (\"empirical Bayes\"),\nand forward generation is a simulated instantiation of an environment\n(\"posterior inference\"). This connection allows extending in-context learning\n(ICL) beyond predictive settings, highlighting sequence models' ability to\nperform explicit statistical inference. In particular, we show the sequence\nprediction loss over exchangeable documents controls performance on downstream\ntasks where uncertainty quantification is key. Empirically, we propose and\ndemonstrate several approaches for encoding exchangeability in sequence model\narchitectures: data augmentation, regularization, and causal masking.", "arxiv_id": "2408.03307v1", "pdf_url": "http://arxiv.org/pdf/2408.03307v1", "abstract_url": "http://arxiv.org/abs/2408.03307v1", "primary_category": "stat.ML", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Pre-training and in-context learning IS Bayesian inference a la De Finetti", "response": "RELEVANT", "timestamp": "2024-08-19T13:44:17.941033"}
{"title": "Fusing Forces: Deep-Human-Guided Refinement of Segmentation Masks", "authors": "Rafael Sterzinger, Christian Stippel, Robert Sablatnig", "abstract": "Etruscan mirrors constitute a significant category in Etruscan art,\ncharacterized by elaborate figurative illustrations featured on their backside.\nA laborious and costly aspect of their analysis and documentation is the task\nof manually tracing these illustrations. In previous work, a methodology has\nbeen proposed to automate this process, involving photometric-stereo scanning\nin combination with deep neural networks. While achieving quantitative\nperformance akin to an expert annotator, some results still lack qualitative\nprecision and, thus, require annotators for inspection and potential\ncorrection, maintaining resource intensity. In response, we propose a deep\nneural network trained to interactively refine existing annotations based on\nhuman guidance. Our human-in-the-loop approach streamlines annotation,\nachieving equal quality with up to 75% less manual input required. Moreover,\nduring the refinement process, the relative improvement of our methodology over\npure manual labeling reaches peak values of up to 26%, attaining drastically\nbetter quality quicker. By being tailored to the complex task of segmenting\nintricate lines, specifically distinguishing it from previous methods, our\napproach offers drastic improvements in efficacy, transferable to a broad\nspectrum of applications beyond Etruscan mirrors.", "arxiv_id": "2408.03304v1", "pdf_url": "http://arxiv.org/pdf/2408.03304v1", "abstract_url": "http://arxiv.org/abs/2408.03304v1", "primary_category": "cs.CV", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Fusing Forces: Deep-Human-Guided Refinement of Segmentation Masks", "response": "RELEVANT", "timestamp": "2024-08-19T13:44:18.574662"}
{"title": "Prioritize Alignment in Dataset Distillation", "authors": "Zekai Li, Ziyao Guo, Wangbo Zhao, Tianle Zhang, Zhi-Qi Cheng, Samir Khaki, Kaipeng Zhang, Ahmad Sajedi, Konstantinos N Plataniotis, Kai Wang, Yang You", "abstract": "Dataset Distillation aims to compress a large dataset into a significantly\nmore compact, synthetic one without compromising the performance of the trained\nmodels. To achieve this, existing methods use the agent model to extract\ninformation from the target dataset and embed it into the distilled dataset.\nConsequently, the quality of extracted and embedded information determines the\nquality of the distilled dataset. In this work, we find that existing methods\nintroduce misaligned information in both information extraction and embedding\nstages. To alleviate this, we propose Prioritize Alignment in Dataset\nDistillation (PAD), which aligns information from the following two\nperspectives. 1) We prune the target dataset according to the compressing ratio\nto filter the information that can be extracted by the agent model. 2) We use\nonly deep layers of the agent model to perform the distillation to avoid\nexcessively introducing low-level information. This simple strategy effectively\nfilters out misaligned information and brings non-trivial improvement for\nmainstream matching-based distillation algorithms. Furthermore, built on\ntrajectory matching, \\textbf{PAD} achieves remarkable improvements on various\nbenchmarks, achieving state-of-the-art performance.", "arxiv_id": "2408.03360v2", "pdf_url": "http://arxiv.org/pdf/2408.03360v2", "abstract_url": "http://arxiv.org/abs/2408.03360v2", "primary_category": "cs.LG", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Prioritize Alignment in Dataset Distillation", "response": "RELEVANT", "timestamp": "2024-08-19T13:44:19.351144"}
{"title": "LLM Stability: A detailed analysis with some surprises", "authors": "Berk Atil, Alexa Chittams, Liseng Fu, Ferhan Ture, Lixinyu Xu, Breck Baldwin", "abstract": "A concerning property of our nearly magical LLMs involves the variation of\nresults given the exact same input and deterministic hyper-parameters. While AI\nhas always had a certain level of noisiness from inputs outside of training\ndata, we have generally had deterministic results for any particular input;\nthat is no longer true. While most LLM practitioners are \"in the know\", we are\nunaware of any work that attempts to quantify current LLM stability. We suspect\nno one has taken the trouble because it is just too boring a paper to execute\nand write. But we have done it and there are some surprises.\n  What kinds of surprises?\n  The evaluated LLMs are rarely deterministic at the raw output level; they are\nmuch more deterministic at the parsed output/answer level but still rarely 100%\nstable across 5 re-runs with same data input.\n  LLM accuracy variation is not normally distributed.\n  Stability varies based on task.", "arxiv_id": "2408.04667v1", "pdf_url": "http://arxiv.org/pdf/2408.04667v1", "abstract_url": "http://arxiv.org/abs/2408.04667v1", "primary_category": "cs.CL", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "LLM Stability: A detailed analysis with some surprises", "response": "RELEVANT", "timestamp": "2024-08-19T13:44:20.180927"}
{"title": "SARA: Singular-Value Based Adaptive Low-Rank Adaption", "authors": "Jihao Gu, Shuai Chen, Zelin Wang, Yibo Zhang, Ping Gong", "abstract": "With the increasing number of parameters in large pre-trained models, LoRA as\na parameter-efficient fine-tuning(PEFT) method is widely used for not adding\ninference overhead. The LoRA method assumes that weight changes during\nfine-tuning can be approximated by low-rank matrices. However, the rank values\nneed to be manually verified to match different downstream tasks, and they\ncannot accommodate the varying importance of different layers in the model. In\nthis work, we first analyze the relationship between the performance of\ndifferent layers and their ranks using SVD. Based on this, we design the\nSingular-Value Based Adaptive Low-Rank Adaption(SARA), which adaptively finds\nthe rank during initialization by performing SVD on the pre-trained weights.\nAdditionally, we explore the Mixture-of-SARA(Mo-SARA), which significantly\nreduces the number of parameters by fine-tuning only multiple parallel sets of\nsingular values controlled by a router. Extensive experiments on various\ncomplex tasks demonstrate the simplicity and parameter efficiency of our\nmethods. They can effectively and adaptively find the most suitable rank for\neach layer of each model.", "arxiv_id": "2408.03290v1", "pdf_url": "http://arxiv.org/pdf/2408.03290v1", "abstract_url": "http://arxiv.org/abs/2408.03290v1", "primary_category": "cs.LG", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "SARA: Singular-Value Based Adaptive Low-Rank Adaption", "response": "RELEVANT", "timestamp": "2024-08-19T13:44:21.102407"}
{"title": "Malicious Internet Entity Detection Using Local Graph Inference", "authors": "Simon Mandlik, Tomas Pevny, Vaclav Smidl, Lukas Bajer", "abstract": "Detection of malicious behavior in a large network is a challenging problem\nfor machine learning in computer security, since it requires a model with high\nexpressive power and scalable inference. Existing solutions struggle to achieve\nthis feat -- current cybersec-tailored approaches are still limited in\nexpressivity, and methods successful in other domains do not scale well for\nlarge volumes of data, rendering frequent retraining impossible. This work\nproposes a new perspective for learning from graph data that is modeling\nnetwork entity interactions as a large heterogeneous graph. High expressivity\nof the method is achieved with neural network architecture HMILnet that\nnaturally models this type of data and provides theoretical guarantees. The\nscalability is achieved by pursuing local graph inference, i.e., classifying\nindividual vertices and their neighborhood as independent samples. Our\nexperiments exhibit improvement over the state-of-the-art Probabilistic Threat\nPropagation (PTP) algorithm, show a further threefold accuracy improvement when\nadditional data is used, which is not possible with the PTP algorithm, and\ndemonstrate the generalization capabilities of the method to new, previously\nunseen entities.", "arxiv_id": "2408.03287v2", "pdf_url": "http://arxiv.org/pdf/2408.03287v2", "abstract_url": "http://arxiv.org/abs/2408.03287v2", "primary_category": "cs.LG", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Malicious Internet Entity Detection Using Local Graph Inference", "response": "RELEVANT", "timestamp": "2024-08-19T13:44:22.274844"}
{"title": "StructEval: Deepen and Broaden Large Language Model Assessment via Structured Evaluation", "authors": "Boxi Cao, Mengjie Ren, Hongyu Lin, Xianpei Han, Feng Zhang, Junfeng Zhan, Le Sun", "abstract": "Evaluation is the baton for the development of large language models. Current\nevaluations typically employ a single-item assessment paradigm for each atomic\ntest objective, which struggles to discern whether a model genuinely possesses\nthe required capabilities or merely memorizes/guesses the answers to specific\nquestions. To this end, we propose a novel evaluation framework referred to as\nStructEval. Starting from an atomic test objective, StructEval deepens and\nbroadens the evaluation by conducting a structured assessment across multiple\ncognitive levels and critical concepts, and therefore offers a comprehensive,\nrobust and consistent evaluation for LLMs. Experiments on three widely-used\nbenchmarks demonstrate that StructEval serves as a reliable tool for resisting\nthe risk of data contamination and reducing the interference of potential\nbiases, thereby providing more reliable and consistent conclusions regarding\nmodel capabilities. Our framework also sheds light on the design of future\nprincipled and trustworthy LLM evaluation protocols.", "arxiv_id": "2408.03281v2", "pdf_url": "http://arxiv.org/pdf/2408.03281v2", "abstract_url": "http://arxiv.org/abs/2408.03281v2", "primary_category": "cs.CL", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "StructEval: Deepen and Broaden Large Language Model Assessment via Structured Evaluation", "response": "RELEVANT", "timestamp": "2024-08-19T13:44:23.154863"}
{"title": "Compress and Compare: Interactively Evaluating Efficiency and Behavior Across ML Model Compression Experiments", "authors": "Angie Boggust, Venkatesh Sivaraman, Yannick Assogba, Donghao Ren, Dominik Moritz, Fred Hohman", "abstract": "To deploy machine learning models on-device, practitioners use compression\nalgorithms to shrink and speed up models while maintaining their high-quality\noutput. A critical aspect of compression in practice is model comparison,\nincluding tracking many compression experiments, identifying subtle changes in\nmodel behavior, and negotiating complex accuracy-efficiency trade-offs.\nHowever, existing compression tools poorly support comparison, leading to\ntedious and, sometimes, incomplete analyses spread across disjoint tools. To\nsupport real-world comparative workflows, we develop an interactive visual\nsystem called Compress and Compare. Within a single interface, Compress and\nCompare surfaces promising compression strategies by visualizing provenance\nrelationships between compressed models and reveals compression-induced\nbehavior changes by comparing models' predictions, weights, and activations. We\ndemonstrate how Compress and Compare supports common compression analysis tasks\nthrough two case studies, debugging failed compression on generative language\nmodels and identifying compression artifacts in image classification models. We\nfurther evaluate Compress and Compare in a user study with eight compression\nexperts, illustrating its potential to provide structure to compression\nworkflows, help practitioners build intuition about compression, and encourage\nthorough analysis of compression's effect on model behavior. Through these\nevaluations, we identify compression-specific challenges that future visual\nanalytics tools should consider and Compress and Compare visualizations that\nmay generalize to broader model comparison tasks.", "arxiv_id": "2408.03274v1", "pdf_url": "http://arxiv.org/pdf/2408.03274v1", "abstract_url": "http://arxiv.org/abs/2408.03274v1", "primary_category": "cs.HC", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Compress and Compare: Interactively Evaluating Efficiency and Behavior Across ML Model Compression Experiments", "response": "RELEVANT", "timestamp": "2024-08-19T13:44:24.278932"}
{"title": "LAMPO: Large Language Models as Preference Machines for Few-shot Ordinal Classification", "authors": "Zhen Qin, Junru Wu, Jiaming Shen, Tianqi Liu, Xuanhui Wang", "abstract": "We introduce LAMPO, a novel paradigm that leverages Large Language Models\n(LLMs) for solving few-shot multi-class ordinal classification tasks. Unlike\nconventional methods, which concatenate all demonstration examples with the\ntest instance and prompt LLMs to produce the pointwise prediction, our\nframework uses the LLM as a preference machine that makes a relative\ncomparative decision between the test instance and each demonstration. A\nself-supervised method is then introduced to aggregate these binary comparisons\ninto the final ordinal decision. LAMPO addresses several limitations inherent\nin previous methods, including context length constraints, ordering biases, and\nchallenges associated with absolute point-wise estimation. Extensive\nexperiments on seven public datasets demonstrate LAMPO's remarkably competitive\nperformance across a diverse spectrum of applications (e.g., movie review\nanalysis and hate speech detection). Notably, in certain applications, the\nimprovement can be substantial, exceeding 20% in an absolute term. Moreover, we\nbelieve LAMPO represents an interesting addition to the non-parametric\napplication layered on top of LLMs, as it supports black-box LLMs without\nnecessitating the outputting of LLM's internal states (e.g., embeddings), as\nseen in previous approaches.", "arxiv_id": "2408.03359v1", "pdf_url": "http://arxiv.org/pdf/2408.03359v1", "abstract_url": "http://arxiv.org/abs/2408.03359v1", "primary_category": "cs.LG", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "LAMPO: Large Language Models as Preference Machines for Few-shot Ordinal Classification", "response": "RELEVANT", "timestamp": "2024-08-19T13:44:25.096623"}
{"title": "Analysis of Partially-Calibrated Sparse Subarrays for Direction Finding with Extended Degrees of Freedom", "authors": "W. S. Leite, R. C. de Lamare", "abstract": "This paper investigates the problem of direction-of-arrival (DOA) estimation\nusing multiple partially-calibrated sparse subarrays. In particular, we present\nthe Generalized Coarray Multiple Signal Classification (GCA-MUSIC) DOA\nestimation algorithm to scenarios with partially-calibrated sparse subarrays.\nThe proposed GCA-MUSIC algorithm exploits the difference coarray for each\nsubarray, followed by a specific pseudo-spectrum merging rule that is based on\nthe intersection of the signal subspaces associated to each subarray. This rule\nassumes that there is no a priori knowledge about the cross-covariance between\nsubarrays. In that way, only the second-order statistics of each subarray are\nused to estimate the directions with increased degrees of freedom, i.e., the\nestimation procedure preserves the coarray Multiple Signal Classification and\nsparse arrays properties to estimate more sources than the number of physical\nsensors in each subarray. Numerical simulations show that the proposed\nGCA-MUSIC has better performance than other similar strategies.", "arxiv_id": "2408.03236v1", "pdf_url": "http://arxiv.org/pdf/2408.03236v1", "abstract_url": "http://arxiv.org/abs/2408.03236v1", "primary_category": "cs.LG", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Analysis of Partially-Calibrated Sparse Subarrays for Direction Finding with Extended Degrees of Freedom", "response": "RELEVANT", "timestamp": "2024-08-19T13:44:26.257313"}
{"title": "Don't Think It Twice: Exploit Shift Invariance for Efficient Online Streaming Inference of CNNs", "authors": "Christodoulos Kechris, Jonathan Dan, Jose Miranda, David Atienza", "abstract": "Deep learning time-series processing often relies on convolutional neural\nnetworks with overlapping windows. This overlap allows the network to produce\nan output faster than the window length. However, it introduces additional\ncomputations. This work explores the potential to optimize computational\nefficiency during inference by exploiting convolution's shift-invariance\nproperties to skip the calculation of layer activations between successive\noverlapping windows. Although convolutions are shift-invariant, zero-padding\nand pooling operations, widely used in such networks, are not efficient and\ncomplicate efficient streaming inference. We introduce StreamiNNC, a strategy\nto deploy Convolutional Neural Networks for online streaming inference. We\nexplore the adverse effects of zero padding and pooling on the accuracy of\nstreaming inference, deriving theoretical error upper bounds for pooling during\nstreaming. We address these limitations by proposing signal padding and pooling\nalignment and provide guidelines for designing and deploying models for\nStreamiNNC. We validate our method in simulated data and on three real-world\nbiomedical signal processing applications. StreamiNNC achieves a low deviation\nbetween streaming output and normal inference for all three networks (2.03 -\n3.55% NRMSE). This work demonstrates that it is possible to linearly speed up\nthe inference of streaming CNNs processing overlapping windows, negating the\nadditional computation typically incurred by overlapping windows.", "arxiv_id": "2408.03223v1", "pdf_url": "http://arxiv.org/pdf/2408.03223v1", "abstract_url": "http://arxiv.org/abs/2408.03223v1", "primary_category": "cs.LG", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Don't Think It Twice: Exploit Shift Invariance for Efficient Online Streaming Inference of CNNs", "response": "RELEVANT", "timestamp": "2024-08-19T13:44:26.939965"}
{"title": "Masked Random Noise for Communication Efficient Federaetd Learning", "authors": "Shiwei Li, Yingyi Cheng, Haozhao Wang, Xing Tang, Shijie Xu, Weihong Luo, Yuhua Li, Dugang Liu, Xiuqiang He, and Ruixuan Li", "abstract": "Federated learning is a promising distributed training paradigm that\neffectively safeguards data privacy. However, it may involve significant\ncommunication costs, which hinders training efficiency. In this paper, we aim\nto enhance communication efficiency from a new perspective. Specifically, we\nrequest the distributed clients to find optimal model updates relative to\nglobal model parameters within predefined random noise. For this purpose, we\npropose Federated Masked Random Noise (FedMRN), a novel framework that enables\nclients to learn a 1-bit mask for each model parameter and apply masked random\nnoise (i.e., the Hadamard product of random noise and masks) to represent model\nupdates. To make FedMRN feasible, we propose an advanced mask training\nstrategy, called progressive stochastic masking (PSM). After local training,\neach client only need to transmit local masks and a random seed to the server.\nAdditionally, we provide theoretical guarantees for the convergence of FedMRN\nunder both strongly convex and non-convex assumptions. Extensive experiments\nare conducted on four popular datasets. The results show that FedMRN exhibits\nsuperior convergence speed and test accuracy compared to relevant baselines,\nwhile attaining a similar level of accuracy as FedAvg.", "arxiv_id": "2408.03220v1", "pdf_url": "http://arxiv.org/pdf/2408.03220v1", "abstract_url": "http://arxiv.org/abs/2408.03220v1", "primary_category": "cs.LG", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Masked Random Noise for Communication Efficient Federaetd Learning", "response": "RELEVANT", "timestamp": "2024-08-19T13:44:27.759518"}
{"title": "Learning to Learn without Forgetting using Attention", "authors": "Anna Vettoruzzo, Joaquin Vanschoren, Mohamed-Rafik Bouguelia, Thorsteinn R\u00f6gnvaldsson", "abstract": "Continual learning (CL) refers to the ability to continually learn over time\nby accommodating new knowledge while retaining previously learned experience.\nWhile this concept is inherent in human learning, current machine learning\nmethods are highly prone to overwrite previously learned patterns and thus\nforget past experience. Instead, model parameters should be updated selectively\nand carefully, avoiding unnecessary forgetting while optimally leveraging\npreviously learned patterns to accelerate future learning. Since hand-crafting\neffective update mechanisms is difficult, we propose meta-learning a\ntransformer-based optimizer to enhance CL. This meta-learned optimizer uses\nattention to learn the complex relationships between model parameters across a\nstream of tasks, and is designed to generate effective weight updates for the\ncurrent task while preventing catastrophic forgetting on previously encountered\ntasks. Evaluations on benchmark datasets like SplitMNIST, RotatedMNIST, and\nSplitCIFAR-100 affirm the efficacy of the proposed approach in terms of both\nforward and backward transfer, even on small sets of labeled data, highlighting\nthe advantages of integrating a meta-learned optimizer within the continual\nlearning framework.", "arxiv_id": "2408.03219v2", "pdf_url": "http://arxiv.org/pdf/2408.03219v2", "abstract_url": "http://arxiv.org/abs/2408.03219v2", "primary_category": "cs.LG", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Learning to Learn without Forgetting using Attention", "response": "RELEVANT", "timestamp": "2024-08-19T13:44:28.564385"}
{"title": "FedBAT: Communication-Efficient Federated Learning via Learnable Binarization", "authors": "Shiwei Li, Wenchao Xu, Haozhao Wang, Xing Tang, Yining Qi, Shijie Xu, Weihong Luo, Yuhua Li, Xiuqiang He, Ruixuan Li", "abstract": "Federated learning is a promising distributed machine learning paradigm that\ncan effectively exploit large-scale data without exposing users' privacy.\nHowever, it may incur significant communication overhead, thereby potentially\nimpairing the training efficiency. To address this challenge, numerous studies\nsuggest binarizing the model updates. Nonetheless, traditional methods usually\nbinarize model updates in a post-training manner, resulting in significant\napproximation errors and consequent degradation in model accuracy. To this end,\nwe propose Federated Binarization-Aware Training (FedBAT), a novel framework\nthat directly learns binary model updates during the local training process,\nthus inherently reducing the approximation errors. FedBAT incorporates an\ninnovative binarization operator, along with meticulously designed derivatives\nto facilitate efficient learning. In addition, we establish theoretical\nguarantees regarding the convergence of FedBAT. Extensive experiments are\nconducted on four popular datasets. The results show that FedBAT significantly\naccelerates the convergence and exceeds the accuracy of baselines by up to 9\\%,\neven surpassing that of FedAvg in some cases.", "arxiv_id": "2408.03215v1", "pdf_url": "http://arxiv.org/pdf/2408.03215v1", "abstract_url": "http://arxiv.org/abs/2408.03215v1", "primary_category": "cs.LG", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "FedBAT: Communication-Efficient Federated Learning via Learnable Binarization", "response": "RELEVANT", "timestamp": "2024-08-19T13:44:29.325373"}
{"title": "MLC-GCN: Multi-Level Generated Connectome Based GCN for AD Analysis", "authors": "Wenqi Zhu, Yinghua Fu, Ze Wang", "abstract": "Alzheimer's Disease (AD) is a currently incurable neurodegeneartive disease.\nAccurately detecting AD, especially in the early stage, represents a high\nresearch priority. AD is characterized by progressive cognitive impairments\nthat are related to alterations in brain functional connectivity (FC). Based on\nthis association, many studies have been published over the decades using FC\nand machine learning to differentiate AD from healthy aging. The most recent\ndevelopment in this detection method highlights the use of graph neural network\n(GNN) as the brain functionality analysis. In this paper, we proposed a stack\nof spatio-temporal feature extraction and graph generation based AD\nclassification model using resting state fMRI. The proposed multi-level\ngenerated connectome (MLC) based graph convolutional network (GCN) (MLC-GCN)\ncontains a multi-graph generation block and a GCN prediction block. The\nmulti-graph generation block consists of a hierarchy of spatio-temporal feature\nextraction layers for extracting spatio-temporal rsfMRI features at different\ndepths and building the corresponding connectomes. The GCN prediction block\ntakes the learned multi-level connectomes to build and optimize GCNs at each\nlevel and concatenates the learned graphical features as the final predicting\nfeatures for AD classification. Through independent cohort validations, MLC-GCN\nshows better performance for differentiating MCI, AD, and normal aging than\nstate-of-art GCN and rsfMRI based AD classifiers. The proposed MLC-GCN also\nshowed high explainability in terms of learning clinically reasonable\nconnectome node and connectivity features from two independent datasets. While\nwe only tested MLC-GCN on AD, the basic rsfMRI-based multi-level learned GCN\nbased outcome prediction strategy is valid for other diseases or clinical\noutcomes.", "arxiv_id": "2408.03358v1", "pdf_url": "http://arxiv.org/pdf/2408.03358v1", "abstract_url": "http://arxiv.org/abs/2408.03358v1", "primary_category": "cs.LG", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "MLC-GCN: Multi-Level Generated Connectome Based GCN for AD Analysis", "response": "RELEVANT", "timestamp": "2024-08-19T13:44:30.116994"}
{"title": "Convergence Conditions for Stochastic Line Search Based Optimization of Over-parametrized Models", "authors": "Matteo Lapucci, Davide Pucci", "abstract": "In this paper, we deal with algorithms to solve the finite-sum problems\nrelated to fitting over-parametrized models, that typically satisfy the\ninterpolation condition. In particular, we focus on approaches based on\nstochastic line searches and employing general search directions. We define\nconditions on the sequence of search directions that guarantee finite\ntermination and bounds for the backtracking procedure. Moreover, we shed light\non the additional property of directions needed to prove fast (linear)\nconvergence of the general class of algorithms when applied to PL functions in\nthe interpolation regime. From the point of view of algorithms design, the\nproposed analysis identifies safeguarding conditions that could be employed in\nrelevant algorithmic framework. In particular, it could be of interest to\nintegrate stochastic line searches within momentum, conjugate gradient or\nadaptive preconditioning methods.", "arxiv_id": "2408.03199v1", "pdf_url": "http://arxiv.org/pdf/2408.03199v1", "abstract_url": "http://arxiv.org/abs/2408.03199v1", "primary_category": "math.OC", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Convergence Conditions for Stochastic Line Search Based Optimization of Over-parametrized Models", "response": "RELEVANT", "timestamp": "2024-08-19T13:44:30.942188"}
{"title": "RELIEF: Reinforcement Learning Empowered Graph Feature Prompt Tuning", "authors": "Jiapeng Zhu, Zichen Ding, Jianxiang Yu, Jiaqi Tan, Xiang Li, Weining Qian", "abstract": "The advent of the \"pre-train, prompt\" paradigm has recently extended its\ngeneralization ability and data efficiency to graph representation learning,\nfollowing its achievements in Natural Language Processing (NLP). Initial graph\nprompt tuning approaches tailored specialized prompting functions for Graph\nNeural Network (GNN) models pre-trained with specific strategies, such as edge\nprediction, thus limiting their applicability. In contrast, another pioneering\nline of research has explored universal prompting via adding prompts to the\ninput graph's feature space, thereby removing the reliance on specific\npre-training strategies. However, the necessity to add feature prompts to all\nnodes remains an open question. Motivated by findings from prompt tuning\nresearch in the NLP domain, which suggest that highly capable pre-trained\nmodels need less conditioning signal to achieve desired behaviors, we advocate\nfor strategically incorporating necessary and lightweight feature prompts to\ncertain graph nodes to enhance downstream task performance. This introduces a\ncombinatorial optimization problem, requiring a policy to decide 1) which nodes\nto prompt and 2) what specific feature prompts to attach. We then address the\nproblem by framing the prompt incorporation process as a sequential\ndecision-making problem and propose our method, RELIEF, which employs\nReinforcement Learning (RL) to optimize it. At each step, the RL agent selects\na node (discrete action) and determines the prompt content (continuous action),\naiming to maximize cumulative performance gain. Extensive experiments on graph\nand node-level tasks with various pre-training strategies in few-shot scenarios\ndemonstrate that our RELIEF outperforms fine-tuning and other prompt-based\napproaches in classification performance and data efficiency.", "arxiv_id": "2408.03195v1", "pdf_url": "http://arxiv.org/pdf/2408.03195v1", "abstract_url": "http://arxiv.org/abs/2408.03195v1", "primary_category": "cs.LG", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "RELIEF: Reinforcement Learning Empowered Graph Feature Prompt Tuning", "response": "RELEVANT", "timestamp": "2024-08-19T13:44:31.752006"}
{"title": "An Object is Worth 64x64 Pixels: Generating 3D Object via Image Diffusion", "authors": "Xingguang Yan, Han-Hung Lee, Ziyu Wan, Angel X. Chang", "abstract": "We introduce a new approach for generating realistic 3D models with UV maps\nthrough a representation termed \"Object Images.\" This approach encapsulates\nsurface geometry, appearance, and patch structures within a 64x64 pixel image,\neffectively converting complex 3D shapes into a more manageable 2D format. By\ndoing so, we address the challenges of both geometric and semantic irregularity\ninherent in polygonal meshes. This method allows us to use image generation\nmodels, such as Diffusion Transformers, directly for 3D shape generation.\nEvaluated on the ABO dataset, our generated shapes with patch structures\nachieve point cloud FID comparable to recent 3D generative models, while\nnaturally supporting PBR material generation.", "arxiv_id": "2408.03178v1", "pdf_url": "http://arxiv.org/pdf/2408.03178v1", "abstract_url": "http://arxiv.org/abs/2408.03178v1", "primary_category": "cs.CV", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "An Object is Worth 64x64 Pixels: Generating 3D Object via Image Diffusion", "response": "RELEVANT", "timestamp": "2024-08-19T13:44:32.455054"}
{"title": "Leveraging Parameter Efficient Training Methods for Low Resource Text Classification: A Case Study in Marathi", "authors": "Pranita Deshmukh, Nikita Kulkarni, Sanhita Kulkarni, Kareena Manghani, Raviraj Joshi", "abstract": "With the surge in digital content in low-resource languages, there is an\nescalating demand for advanced Natural Language Processing (NLP) techniques\ntailored to these languages. BERT (Bidirectional Encoder Representations from\nTransformers), serving as the foundational framework for numerous NLP\narchitectures and language models, is increasingly employed for the development\nof low-resource NLP models. Parameter Efficient Fine-Tuning (PEFT) is a method\nfor fine-tuning Large Language Models (LLMs) and reducing the training\nparameters to some extent to decrease the computational costs needed for\ntraining the model and achieve results comparable to a fully fine-tuned model.\nIn this work, we present a study of PEFT methods for the Indic low-resource\nlanguage Marathi. We conduct a comprehensive analysis of PEFT methods applied\nto various monolingual and multilingual Marathi BERT models. These approaches\nare evaluated on prominent text classification datasets like MahaSent,\nMahaHate, and MahaNews. The incorporation of PEFT techniques is demonstrated to\nsignificantly expedite the training speed of the models, addressing a critical\naspect of model development and deployment. In this study, we explore Low-Rank\nAdaptation of Large Language Models (LoRA) and adapter methods for low-resource\ntext classification. We show that these methods are competitive with full\nfine-tuning and can be used without loss in accuracy. This study contributes\nvaluable insights into the effectiveness of Marathi BERT models, offering a\nfoundation for the continued advancement of NLP capabilities in Marathi and\nsimilar Indic languages.", "arxiv_id": "2408.03172v1", "pdf_url": "http://arxiv.org/pdf/2408.03172v1", "abstract_url": "http://arxiv.org/abs/2408.03172v1", "primary_category": "cs.CL", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Leveraging Parameter Efficient Training Methods for Low Resource Text Classification: A Case Study in Marathi", "response": "RELEVANT", "timestamp": "2024-08-19T13:44:33.288486"}
{"title": "Iterative CT Reconstruction via Latent Variable Optimization of Shallow Diffusion Models", "authors": "Sho Ozaki, Shizuo Kaji, Toshikazu Imae, Kanabu Nawa, Hideomi Yamashita, Keiichi Nakagawa", "abstract": "Image generative AI has garnered significant attention in recent years. In\nparticular, the diffusion model, a core component of recent generative AI,\nproduces high-quality images with rich diversity. In this study, we propose a\nnovel CT reconstruction method by combining the denoising diffusion\nprobabilistic model with iterative CT reconstruction. In sharp contrast to\nprevious studies, we optimize the fidelity loss of CT reconstruction with\nrespect to the latent variable of the diffusion model, instead of the image and\nmodel parameters. To suppress anatomical structure changes produced by the\ndiffusion model, we shallow the diffusion and reverse processes, and fix a set\nof added noises in the reverse process to make it deterministic during\ninference. We demonstrate the effectiveness of the proposed method through\nsparse view CT reconstruction of 1/10 view projection data. Despite the\nsimplicity of the implementation, the proposed method shows the capability of\nreconstructing high-quality images while preserving the patient's anatomical\nstructure, and outperforms existing methods including iterative reconstruction,\niterative reconstruction with total variation, and the diffusion model alone in\nterms of quantitative indices such as SSIM and PSNR. We also explore further\nsparse view CT using 1/20 view projection data with the same trained diffusion\nmodel. As the number of iterations increases, image quality improvement\ncomparable to that of 1/10 sparse view CT reconstruction is achieved. In\nprinciple, the proposed method can be widely applied not only to CT but also to\nother imaging modalities such as MRI, PET, and SPECT.", "arxiv_id": "2408.03156v1", "pdf_url": "http://arxiv.org/pdf/2408.03156v1", "abstract_url": "http://arxiv.org/abs/2408.03156v1", "primary_category": "cs.CV", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Iterative CT Reconstruction via Latent Variable Optimization of Shallow Diffusion Models", "response": "RELEVANT", "timestamp": "2024-08-19T13:44:34.274219"}
{"title": "TSC: A Simple Two-Sided Constraint against Over-Smoothing", "authors": "Furong Peng, Kang Liu, Xuan Lu, Yuhua Qian, Hongren Yan, Chao Ma", "abstract": "Graph Convolutional Neural Network (GCN), a widely adopted method for\nanalyzing relational data, enhances node discriminability through the\naggregation of neighboring information. Usually, stacking multiple layers can\nimprove the performance of GCN by leveraging information from high-order\nneighbors. However, the increase of the network depth will induce the\nover-smoothing problem, which can be attributed to the quality and quantity of\nneighbors changing: (a) neighbor quality, node's neighbors become overlapping\nin high order, leading to aggregated information becoming indistinguishable,\n(b) neighbor quantity, the exponentially growing aggregated neighbors submerges\nthe node's initial feature by recursively aggregating operations. Current\nsolutions mainly focus on one of the above causes and seldom consider both at\nonce.\n  Aiming at tackling both causes of over-smoothing in one shot, we introduce a\nsimple Two-Sided Constraint (TSC) for GCNs, comprising two straightforward yet\npotent techniques: random masking and contrastive constraint. The random\nmasking acts on the representation matrix's columns to regulate the degree of\ninformation aggregation from neighbors, thus preventing the convergence of node\nrepresentations. Meanwhile, the contrastive constraint, applied to the\nrepresentation matrix's rows, enhances the discriminability of the nodes.\nDesigned as a plug-in module, TSC can be easily coupled with GCN or SGC\narchitectures. Experimental analyses on diverse real-world graph datasets\nverify that our approach markedly reduces the convergence of node's\nrepresentation and the performance degradation in deeper GCN.", "arxiv_id": "2408.03152v1", "pdf_url": "http://arxiv.org/pdf/2408.03152v1", "abstract_url": "http://arxiv.org/abs/2408.03152v1", "primary_category": "cs.LG", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "TSC: A Simple Two-Sided Constraint against Over-Smoothing", "response": "RELEVANT", "timestamp": "2024-08-19T13:44:35.235539"}
{"title": "Conditioning LLMs with Emotion in Neural Machine Translation", "authors": "Charles Brazier, Jean-Luc Rouas", "abstract": "Large Language Models (LLMs) have shown remarkable performance in Natural\nLanguage Processing tasks, including Machine Translation (MT). In this work, we\npropose a novel MT pipeline that integrates emotion information extracted from\na Speech Emotion Recognition (SER) model into LLMs to enhance translation\nquality. We first fine-tune five existing LLMs on the Libri-trans dataset and\nselect the most performant model. Subsequently, we augment LLM prompts with\ndifferent dimensional emotions and train the selected LLM under these different\nconfigurations. Our experiments reveal that integrating emotion information,\nespecially arousal, into LLM prompts leads to notable improvements in\ntranslation quality.", "arxiv_id": "2408.03150v1", "pdf_url": "http://arxiv.org/pdf/2408.03150v1", "abstract_url": "http://arxiv.org/abs/2408.03150v1", "primary_category": "cs.CL", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Conditioning LLMs with Emotion in Neural Machine Translation", "response": "RELEVANT", "timestamp": "2024-08-19T13:44:35.950243"}
{"title": "Active Learning for Level Set Estimation Using Randomized Straddle Algorithms", "authors": "Yu Inatsu, Shion Takeno, Kentaro Kutsukake, Ichiro Takeuchi", "abstract": "Level set estimation (LSE), the problem of identifying the set of input\npoints where a function takes value above (or below) a given threshold, is\nimportant in practical applications. When the function is expensive-to-evaluate\nand black-box, the \\textit{straddle} algorithm, which is a representative\nheuristic for LSE based on Gaussian process models, and its extensions having\ntheoretical guarantees have been developed. However, many of existing methods\ninclude a confidence parameter $\\beta^{1/2}_t$ that must be specified by the\nuser, and methods that choose $\\beta^{1/2}_t$ heuristically do not provide\ntheoretical guarantees. In contrast, theoretically guaranteed values of\n$\\beta^{1/2}_t$ need to be increased depending on the number of iterations and\ncandidate points, and are conservative and not good for practical performance.\nIn this study, we propose a novel method, the \\textit{randomized straddle}\nalgorithm, in which $\\beta_t$ in the straddle algorithm is replaced by a random\nsample from the chi-squared distribution with two degrees of freedom. The\nconfidence parameter in the proposed method has the advantages of not needing\nadjustment, not depending on the number of iterations and candidate points, and\nnot being conservative. Furthermore, we show that the proposed method has\ntheoretical guarantees that depend on the sample complexity and the number of\niterations. Finally, we confirm the usefulness of the proposed method through\nnumerical experiments using synthetic and real data.", "arxiv_id": "2408.03144v1", "pdf_url": "http://arxiv.org/pdf/2408.03144v1", "abstract_url": "http://arxiv.org/abs/2408.03144v1", "primary_category": "stat.ML", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Active Learning for Level Set Estimation Using Randomized Straddle Algorithms", "response": "RELEVANT", "timestamp": "2024-08-19T13:44:38.303473"}
{"title": "Huge Ensembles Part I: Design of Ensemble Weather Forecasts using Spherical Fourier Neural Operators", "authors": "Ankur Mahesh, William Collins, Boris Bonev, Noah Brenowitz, Yair Cohen, Joshua Elms, Peter Harrington, Karthik Kashinath, Thorsten Kurth, Joshua North, Travis OBrien, Michael Pritchard, David Pruitt, Mark Risser, Shashank Subramanian, Jared Willard", "abstract": "Studying low-likelihood high-impact extreme weather events in a warming world\nis a significant and challenging task for current ensemble forecasting systems.\nWhile these systems presently use up to 100 members, larger ensembles could\nenrich the sampling of internal variability. They may capture the long tails\nassociated with climate hazards better than traditional ensemble sizes. Due to\ncomputational constraints, it is infeasible to generate huge ensembles\n(comprised of 1,000-10,000 members) with traditional, physics-based numerical\nmodels. In this two-part paper, we replace traditional numerical simulations\nwith machine learning (ML) to generate hindcasts of huge ensembles. In Part I,\nwe construct an ensemble weather forecasting system based on Spherical Fourier\nNeural Operators (SFNO), and we discuss important design decisions for\nconstructing such an ensemble. The ensemble represents model uncertainty\nthrough perturbed-parameter techniques, and it represents initial condition\nuncertainty through bred vectors, which sample the fastest growing modes of the\nforecast. Using the European Centre for Medium-Range Weather Forecasts\nIntegrated Forecasting System (IFS) as a baseline, we develop an evaluation\npipeline composed of mean, spectral, and extreme diagnostics. Using\nlarge-scale, distributed SFNOs with 1.1 billion learned parameters, we achieve\ncalibrated probabilistic forecasts. As the trajectories of the individual\nmembers diverge, the ML ensemble mean spectra degrade with lead time,\nconsistent with physical expectations. However, the individual ensemble\nmembers' spectra stay constant with lead time. Therefore, these members\nsimulate realistic weather states, and the ML ensemble thus passes a crucial\nspectral test in the literature. The IFS and ML ensembles have similar Extreme\nForecast Indices, and we show that the ML extreme weather forecasts are\nreliable and discriminating.", "arxiv_id": "2408.03100v1", "pdf_url": "http://arxiv.org/pdf/2408.03100v1", "abstract_url": "http://arxiv.org/abs/2408.03100v1", "primary_category": "physics.ao-ph", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Huge Ensembles Part I: Design of Ensemble Weather Forecasts using Spherical Fourier Neural Operators", "response": "RELEVANT", "timestamp": "2024-08-19T13:44:39.021497"}
{"title": "Topic Modeling with Fine-tuning LLMs and Bag of Sentences", "authors": "Johannes Schneider", "abstract": "Large language models (LLM)'s are increasingly used for topic modeling\noutperforming classical topic models such as LDA. Commonly, pre-trained LLM\nencoders such as BERT are used out-of-the-box despite the fact that fine-tuning\nis known to improve LLMs considerably. The challenge lies in obtaining a\nsuitable (labeled) dataset for fine-tuning. In this paper, we use the recent\nidea to use bag of sentences as the elementary unit in computing topics. In\nturn, we derive an approach FT-Topic to perform unsupervised fine-tuning\nrelying primarily on two steps for constructing a training dataset in an\nautomatic fashion. First, a heuristic method to identifies pairs of sentence\ngroups that are either assumed to be of the same or different topics. Second,\nwe remove sentence pairs that are likely labeled incorrectly. The dataset is\nthen used to fine-tune an encoder LLM, which can be leveraged by any topic\nmodeling approach using embeddings. However, in this work, we demonstrate its\neffectiveness by deriving a novel state-of-the-art topic modeling method called\nSenClu, which achieves fast inference through an expectation-maximization\nalgorithm and hard assignments of sentence groups to a single topic, while\ngiving users the possibility to encode prior knowledge on the topic-document\ndistribution. Code is at \\url{https://github.com/JohnTailor/FT-Topic}", "arxiv_id": "2408.03099v1", "pdf_url": "http://arxiv.org/pdf/2408.03099v1", "abstract_url": "http://arxiv.org/abs/2408.03099v1", "primary_category": "cs.CL", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Topic Modeling with Fine-tuning LLMs and Bag of Sentences", "response": "RELEVANT", "timestamp": "2024-08-19T13:44:39.766360"}
{"title": "Learning Provably Robust Policies in Uncertain Parametric Environments", "authors": "Yannik Schnitzer, Alessandro Abate, David Parker", "abstract": "We present a data-driven approach for learning MDP policies that are robust\nacross stochastic environments whose transition probabilities are defined by\nparameters with an unknown distribution. We produce probably approximately\ncorrect (PAC) guarantees for the performance of these learned policies in a\nnew, unseen environment over the unknown distribution. Our approach is based on\nfinite samples of the MDP environments, for each of which we build an\napproximation of the model as an interval MDP, by exploring a set of generated\ntrajectories. We use the built approximations to synthesise a single policy\nthat performs well (meets given requirements) across the sampled environments,\nand furthermore bound its risk (of not meeting the given requirements) when\ndeployed in an unseen environment. Our procedure offers a trade-off between the\nguaranteed performance of the learned policy and the risk of not meeting the\nguarantee in an unseen environment. Our approach exploits knowledge of the\nenvironment's state space and graph structure, and we show how additional\nknowledge of its parametric structure can be leveraged to optimize learning and\nto obtain tighter guarantees from less samples. We evaluate our approach on a\ndiverse range of established benchmarks, demonstrating that we can generate\nhighly performing and robust policies, along with guarantees that tightly\nquantify their performance and the associated risk.", "arxiv_id": "2408.03093v1", "pdf_url": "http://arxiv.org/pdf/2408.03093v1", "abstract_url": "http://arxiv.org/abs/2408.03093v1", "primary_category": "cs.LG", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Learning Provably Robust Policies in Uncertain Parametric Environments", "response": "RELEVANT", "timestamp": "2024-08-19T13:44:40.670480"}
{"title": "QADQN: Quantum Attention Deep Q-Network for Financial Market Prediction", "authors": "Siddhant Dutta, Nouhaila Innan, Alberto Marchisio, Sadok Ben Yahia, Muhammad Shafique", "abstract": "Financial market prediction and optimal trading strategy development remain\nchallenging due to market complexity and volatility. Our research in quantum\nfinance and reinforcement learning for decision-making demonstrates the\napproach of quantum-classical hybrid algorithms to tackling real-world\nfinancial challenges. In this respect, we corroborate the concept with rigorous\nbacktesting and validate the framework's performance under realistic market\nconditions, by including fixed transaction cost per trade. This paper\nintroduces a Quantum Attention Deep Q-Network (QADQN) approach to address these\nchallenges through quantum-enhanced reinforcement learning. Our QADQN\narchitecture uses a variational quantum circuit inside a traditional deep\nQ-learning framework to take advantage of possible quantum advantages in\ndecision-making. We gauge the QADQN agent's performance on historical data from\nmajor market indices, including the S&P 500. We evaluate the agent's learning\nprocess by examining its reward accumulation and the effectiveness of its\nexperience replay mechanism. Our empirical results demonstrate the QADQN's\nsuperior performance, achieving better risk-adjusted returns with Sortino\nratios of 1.28 and 1.19 for non-overlapping and overlapping test periods\nrespectively, indicating effective downside risk management.", "arxiv_id": "2408.03088v1", "pdf_url": "http://arxiv.org/pdf/2408.03088v1", "abstract_url": "http://arxiv.org/abs/2408.03088v1", "primary_category": "quant-ph", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "QADQN: Quantum Attention Deep Q-Network for Financial Market Prediction", "response": "RELEVANT", "timestamp": "2024-08-19T13:44:41.378956"}
{"title": "Matrix Multiplication on Quantum Computer", "authors": "Jiaqi Yao, Ding Liu", "abstract": "This paper introduces an innovative and practical approach to universal\nquantum matrix multiplication. We designed optimized quantum adders and\nmultipliers based on Quantum Fourier Transform (QFT), which significantly\nreduced the number of gates used compared to classical adders and multipliers.\nSubsequently, we construct a basic universal quantum matrix multiplication and\nextend it to the Strassen algorithm. We conduct comparative experiments to\nanalyze the performance of the quantum matrix multiplication and evaluate the\nacceleration provided by the optimized quantum adder and multiplier.\nFurthermore, we investigate the advantages and disadvantages of the quantum\nStrassen algorithm compared to basic quantum matrix multiplication.", "arxiv_id": "2408.03085v1", "pdf_url": "http://arxiv.org/pdf/2408.03085v1", "abstract_url": "http://arxiv.org/abs/2408.03085v1", "primary_category": "quant-ph", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Matrix Multiplication on Quantum Computer", "response": "RELEVANT", "timestamp": "2024-08-19T13:44:42.094821"}
{"title": "Research on Autonomous Driving Decision-making Strategies based Deep Reinforcement Learning", "authors": "Zixiang Wang, Hao Yan, Changsong Wei, Junyu Wang, Shi Bo, Minheng Xiao", "abstract": "The behavior decision-making subsystem is a key component of the autonomous\ndriving system, which reflects the decision-making ability of the vehicle and\nthe driver, and is an important symbol of the high-level intelligence of the\nvehicle. However, the existing rule-based decision-making schemes are limited\nby the prior knowledge of designers, and it is difficult to cope with complex\nand changeable traffic scenarios. In this work, an advanced deep reinforcement\nlearning model is adopted, which can autonomously learn and optimize driving\nstrategies in a complex and changeable traffic environment by modeling the\ndriving decision-making process as a reinforcement learning problem.\nSpecifically, we used Deep Q-Network (DQN) and Proximal Policy Optimization\n(PPO) for comparative experiments. DQN guides the agent to choose the best\naction by approximating the state-action value function, while PPO improves the\ndecision-making quality by optimizing the policy function. We also introduce\nimprovements in the design of the reward function to promote the robustness and\nadaptability of the model in real-world driving situations. Experimental\nresults show that the decision-making strategy based on deep reinforcement\nlearning has better performance than the traditional rule-based method in a\nvariety of driving tasks.", "arxiv_id": "2408.03084v1", "pdf_url": "http://arxiv.org/pdf/2408.03084v1", "abstract_url": "http://arxiv.org/abs/2408.03084v1", "primary_category": "cs.LG", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Research on Autonomous Driving Decision-making Strategies based Deep Reinforcement Learning", "response": "RELEVANT", "timestamp": "2024-08-19T13:44:44.297494"}
{"title": "Adversarial Domain Adaptation for Cross-user Activity Recognition Using Diffusion-based Noise-centred Learning", "authors": "Xiaozhou Ye, Kevin I-Kai Wang", "abstract": "Human Activity Recognition (HAR) plays a crucial role in various applications\nsuch as human-computer interaction and healthcare monitoring. However,\nchallenges persist in HAR models due to the data distribution differences\nbetween training and real-world data distributions, particularly evident in\ncross-user scenarios. This paper introduces a novel framework, termed\nDiffusion-based Noise-centered Adversarial Learning Domain Adaptation\n(Diff-Noise-Adv-DA), designed to address these challenges by leveraging\ngenerative diffusion modeling and adversarial learning techniques. Traditional\nHAR models often struggle with the diversity of user behaviors and sensor data\ndistributions. Diff-Noise-Adv-DA innovatively integrates the inherent noise\nwithin diffusion models, harnessing its latent information to enhance domain\nadaptation. Specifically, the framework transforms noise into a critical\ncarrier of activity and domain class information, facilitating robust\nclassification across different user domains. Experimental evaluations\ndemonstrate the effectiveness of Diff-Noise-Adv-DA in improving HAR model\nperformance across different users, surpassing traditional domain adaptation\nmethods. The framework not only mitigates distribution mismatches but also\nenhances data quality through noise-based denoising techniques.", "arxiv_id": "2408.03353v1", "pdf_url": "http://arxiv.org/pdf/2408.03353v1", "abstract_url": "http://arxiv.org/abs/2408.03353v1", "primary_category": "cs.LG", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Adversarial Domain Adaptation for Cross-user Activity Recognition Using Diffusion-based Noise-centred Learning", "response": "RELEVANT", "timestamp": "2024-08-19T13:44:45.064843"}
{"title": "Highly Efficient Self-Adaptive Reward Shaping for Reinforcement Learning", "authors": "Haozhe Ma, Zhengding Luo, Thanh Vinh Vo, Kuankuan Sima, Tze-Yun Leong", "abstract": "Reward shaping addresses the challenge of sparse rewards in reinforcement\nlearning by constructing denser and more informative reward signals. To achieve\nself-adaptive and highly efficient reward shaping, we propose a novel method\nthat incorporates success rates derived from historical experiences into shaped\nrewards. Our approach utilizes success rates sampled from Beta distributions,\nwhich dynamically evolve from uncertain to reliable values as more data is\ncollected. Initially, the self-adaptive success rates exhibit more randomness\nto encourage exploration. Over time, they become more certain to enhance\nexploitation, thus achieving a better balance between exploration and\nexploitation. We employ Kernel Density Estimation (KDE) combined with Random\nFourier Features (RFF) to derive the Beta distributions, resulting in a\ncomputationally efficient implementation in high-dimensional continuous state\nspaces. This method provides a non-parametric and learning-free approach. The\nproposed method is evaluated on a wide range of continuous control tasks with\nsparse and delayed rewards, demonstrating significant improvements in sample\nefficiency and convergence stability compared to relevant baselines.", "arxiv_id": "2408.03029v2", "pdf_url": "http://arxiv.org/pdf/2408.03029v2", "abstract_url": "http://arxiv.org/abs/2408.03029v2", "primary_category": "cs.LG", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Highly Efficient Self-Adaptive Reward Shaping for Reinforcement Learning", "response": "RELEVANT", "timestamp": "2024-08-19T13:44:45.883794"}
{"title": "NeurDB: On the Design and Implementation of an AI-powered Autonomous Database", "authors": "Zhanhao Zhao, Shaofeng Cai, Haotian Gao, Hexiang Pan, Siqi Xiang, Naili Xing, Gang Chen, Beng Chin Ooi, Yanyan Shen, Yuncheng Wu, Meihui Zhang", "abstract": "Databases are increasingly embracing AI to provide autonomous system\noptimization and intelligent in-database analytics, aiming to relieve end-user\nburdens across various industry sectors. Nonetheless, most existing approaches\nfail to account for the dynamic nature of databases, which renders them\nineffective for real-world applications characterized by evolving data and\nworkloads. This paper introduces NeurDB, an AI-powered autonomous database that\ndeepens the fusion of AI and databases with adaptability to data and workload\ndrift. NeurDB establishes a new in-database AI ecosystem that seamlessly\nintegrates AI workflows within the database. This integration enables efficient\nand effective in-database AI analytics and fast-adaptive learned system\ncomponents. Empirical evaluations demonstrate that NeurDB substantially\noutperforms existing solutions in managing AI analytics tasks, with the\nproposed learned components more effectively handling environmental dynamism\nthan state-of-the-art approaches.", "arxiv_id": "2408.03013v1", "pdf_url": "http://arxiv.org/pdf/2408.03013v1", "abstract_url": "http://arxiv.org/abs/2408.03013v1", "primary_category": "cs.DB", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "NeurDB: On the Design and Implementation of an AI-powered Autonomous Database", "response": "RELEVANT", "timestamp": "2024-08-19T13:44:46.606885"}
{"title": "Federated Learning Architectures: A Performance Evaluation with Crop Yield Prediction Application", "authors": "Anwesha Mukherjee, Rajkumar Buyya", "abstract": "Federated learning has become an emerging technology for data analysis for\nIoT applications. This paper implements centralized and decentralized federated\nlearning frameworks for crop yield prediction based on Long Short-Term Memory\nNetwork. For centralized federated learning, multiple clients and one server is\nconsidered, where the clients exchange their model updates with the server that\nworks as the aggregator to build the global model. For the decentralized\nframework, a collaborative network is formed among the devices either using\nring topology or using mesh topology. In this network, each device receives\nmodel updates from the neighbour devices, and performs aggregation to build the\nupgraded model. The performance of the centralized and decentralized federated\nlearning frameworks are evaluated in terms of prediction accuracy, precision,\nrecall, F1-Score, and training time. The experimental results present that\n$\\geq$97% and $>$97.5% prediction accuracy are achieved using the centralized\nand decentralized federated learning-based frameworks respectively. The results\nalso show that the using centralized federated learning the response time can\nbe reduced by $\\sim$75% than the cloud-only framework. Finally, the future\nresearch directions of the use of federated learning in crop yield prediction\nare explored in this paper.", "arxiv_id": "2408.02998v1", "pdf_url": "http://arxiv.org/pdf/2408.02998v1", "abstract_url": "http://arxiv.org/abs/2408.02998v1", "primary_category": "cs.LG", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Federated Learning Architectures: A Performance Evaluation with Crop Yield Prediction Application", "response": "RELEVANT", "timestamp": "2024-08-19T13:44:47.699982"}
{"title": "A Differential Smoothness-based Compact-Dynamic Graph Convolutional Network for Spatiotemporal Signal Recovery", "authors": "Pengcheng Gao, Zicheng Gao, Ye Yuan", "abstract": "High quality spatiotemporal signal is vitally important for real application\nscenarios like energy management, traffic planning and cyber security. Due to\nthe uncontrollable factors like abrupt sensors breakdown or communication\nfault, the spatiotemporal signal collected by sensors is always incomplete. A\ndynamic graph convolutional network (DGCN) is effective for processing\nspatiotemporal signal recovery. However, it adopts a static GCN and a sequence\nneural network to explore the spatial and temporal patterns, separately. Such a\nseparated two-step processing is loose spatiotemporal, thereby failing to\ncapture the complex inner spatiotemporal correlation. To address this issue,\nthis paper proposes a Compact-Dynamic Graph Convolutional Network (CDGCN) for\nspatiotemporal signal recovery with the following two-fold ideas: a) leveraging\nthe tensor M-product to build a unified tensor graph convolution framework,\nwhich considers both spatial and temporal patterns simultaneously; and b)\nconstructing a differential smoothness-based objective function to reduce the\nnoise interference in spatiotemporal signal, thereby further improve the\nrecovery accuracy. Experiments on real-world spatiotemporal datasets\ndemonstrate that the proposed CDGCN significantly outperforms the\nstate-of-the-art models in terms of recovery accuracy.", "arxiv_id": "2408.02987v1", "pdf_url": "http://arxiv.org/pdf/2408.02987v1", "abstract_url": "http://arxiv.org/abs/2408.02987v1", "primary_category": "cs.LG", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "A Differential Smoothness-based Compact-Dynamic Graph Convolutional Network for Spatiotemporal Signal Recovery", "response": "RELEVANT", "timestamp": "2024-08-19T13:44:48.506527"}
{"title": "Wave Interpolation Neural Operator: Interpolated Prediction of Electric Fields Across Untrained Wavelengths", "authors": "Joonhyuk Seo, Chanik Kang, Dongjin Seo, Haejun Chung", "abstract": "Designing photonic structures requires electromagnetic simulations, which\noften require high computational costs. Researchers have developed surrogate\nsolvers for predicting electric fields to alleviate the computational issues.\nHowever, existing surrogate solvers are limited to performing inference at\nfixed simulation conditions and require retraining for different conditions. To\naddress this, we propose Wave Interpolation Neural Operator (WINO), a novel\nsurrogate solver enabling simulation condition interpolation across a\ncontinuous spectrum of broadband wavelengths. WINO introduces the Fourier Group\nConvolution Shuffling operator and a new conditioning method to efficiently\npredict electric fields from both trained and untrained wavelength data,\nachieving significant improvements in parameter efficiency and spectral\ninterpolation performance. Our model demonstrates approximately 100 times\nfaster performance than traditional finite-difference frequency-domain\nsimulations. Moreover, compared to the state-of-the-art model, we achieve a 74%\nreduction in parameters and 80.5% improvements in prediction accuracy for\nuntrained wavelengths, and 13.2% improvements for trained wavelengths.", "arxiv_id": "2408.02971v1", "pdf_url": "http://arxiv.org/pdf/2408.02971v1", "abstract_url": "http://arxiv.org/abs/2408.02971v1", "primary_category": "cs.LG", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Wave Interpolation Neural Operator: Interpolated Prediction of Electric Fields Across Untrained Wavelengths", "response": "RELEVANT", "timestamp": "2024-08-19T13:44:49.137824"}
{"title": "Data-Driven Stochastic Closure Modeling via Conditional Diffusion Model and Neural Operator", "authors": "Xinghao Dong, Chuanqi Chen, Jin-Long Wu", "abstract": "Closure models are widely used in simulating complex multiscale dynamical\nsystems such as turbulence and the earth system, for which direct numerical\nsimulation that resolves all scales is often too expensive. For those systems\nwithout a clear scale separation, deterministic and local closure models often\nlack enough generalization capability, which limits their performance in many\nreal-world applications. In this work, we propose a data-driven modeling\nframework for constructing stochastic and non-local closure models via\nconditional diffusion model and neural operator. Specifically, the Fourier\nneural operator is incorporated into a score-based diffusion model, which\nserves as a data-driven stochastic closure model for complex dynamical systems\ngoverned by partial differential equations (PDEs). We also demonstrate how\naccelerated sampling methods can improve the efficiency of the data-driven\nstochastic closure model. The results show that the proposed methodology\nprovides a systematic approach via generative machine learning techniques to\nconstruct data-driven stochastic closure models for multiscale dynamical\nsystems with continuous spatiotemporal fields.", "arxiv_id": "2408.02965v1", "pdf_url": "http://arxiv.org/pdf/2408.02965v1", "abstract_url": "http://arxiv.org/abs/2408.02965v1", "primary_category": "cs.LG", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Data-Driven Stochastic Closure Modeling via Conditional Diffusion Model and Neural Operator", "response": "RELEVANT", "timestamp": "2024-08-19T13:44:50.185026"}
{"title": "Synaptic Modulation using Interspike Intervals Increases Energy Efficiency of Spiking Neural Networks", "authors": "Dylan Adams, Magda Zajaczkowska, Ashiq Anjum, Andrea Soltoggio, Shirin Dora", "abstract": "Despite basic differences between Spiking Neural Networks (SNN) and\nArtificial Neural Networks (ANN), most research on SNNs involve adapting\nANN-based methods for SNNs. Pruning (dropping connections) and quantization\n(reducing precision) are often used to improve energy efficiency of SNNs. These\nmethods are very effective for ANNs whose energy needs are determined by\nsignals transmitted on synapses. However, the event-driven paradigm in SNNs\nimplies that energy is consumed by spikes. In this paper, we propose a new\nsynapse model whose weights are modulated by Interspike Intervals (ISI) i.e.\ntime difference between two spikes. SNNs composed of this synapse model, termed\nISI Modulated SNNs (IMSNN), can use gradient descent to estimate how the ISI of\na neuron changes after updating its synaptic parameters. A higher ISI implies\nfewer spikes and vice-versa. The learning algorithm for IMSNNs exploits this\ninformation to selectively propagate gradients such that learning is achieved\nby increasing the ISIs resulting in a network that generates fewer spikes. The\nperformance of IMSNNs with dense and convolutional layers have been evaluated\nin terms of classification accuracy and the number of spikes using the MNIST\nand FashionMNIST datasets. The performance comparison with conventional SNNs\nshows that IMSNNs exhibit upto 90% reduction in the number of spikes while\nmaintaining similar classification accuracy.", "arxiv_id": "2408.02961v1", "pdf_url": "http://arxiv.org/pdf/2408.02961v1", "abstract_url": "http://arxiv.org/abs/2408.02961v1", "primary_category": "cs.NE", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Synaptic Modulation using Interspike Intervals Increases Energy Efficiency of Spiking Neural Networks", "response": "RELEVANT", "timestamp": "2024-08-19T13:44:51.208642"}
{"title": "Kolmogorov-Arnold PointNet: Deep learning for prediction of fluid fields on irregular geometries", "authors": "Ali Kashefi", "abstract": "We present Kolmogorov-Arnold PointNet (KA-PointNet) as a novel supervised\ndeep learning framework for the prediction of incompressible steady-state fluid\nflow fields in irregular domains, where the predicted fields are a function of\nthe geometry of the domains. In KA-PointNet, we implement shared\nKolmogorov-Arnold Networks (KANs) in the segmentation branch of the PointNet\narchitecture. We utilize Jacobi polynomials to construct shared KANs. As a\nbenchmark test case, we consider incompressible laminar steady-state flow over\na cylinder, where the geometry of its cross-section varies over the data set.\nWe investigate the performance of Jacobi polynomials with different degrees as\nwell as special cases of Jacobi polynomials such as Legendre polynomials,\nChebyshev polynomials of the first and second kinds, and Gegenbauer\npolynomials, in terms of the computational cost of training and accuracy of\nprediction of the test set. Additionally, we compare the performance of\nPointNet with shared KANs (i.e., KA-PointNet) and PointNet with shared\nMultilayer Perceptrons (MLPs). It is observed that when the number of trainable\nparameters is approximately equal, PointNet with shared KANs (i.e.,\nKA-PointNet) outperforms PointNet with shared MLPs.", "arxiv_id": "2408.02950v1", "pdf_url": "http://arxiv.org/pdf/2408.02950v1", "abstract_url": "http://arxiv.org/abs/2408.02950v1", "primary_category": "cs.LG", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Kolmogorov-Arnold PointNet: Deep learning for prediction of fluid fields on irregular geometries", "response": "RELEVANT", "timestamp": "2024-08-19T13:44:52.027260"}
{"title": "Scaling Laws for Data Poisoning in LLMs", "authors": "Dillon Bowen, Brendan Murphy, Will Cai, David Khachaturov, Adam Gleave, Kellin Pelrine", "abstract": "Recent work shows that LLMs are vulnerable to data poisoning, in which they\nare trained on partially corrupted or harmful data. Poisoned data is hard to\ndetect, breaks guardrails, and leads to undesirable and harmful behavior. Given\nthe intense efforts by leading labs to train and deploy increasingly larger and\nmore capable LLMs, it is critical to ask if the risk of data poisoning will be\nnaturally mitigated by scale, or if it is an increasing threat. We consider\nthree threat models by which data poisoning can occur: malicious fine-tuning,\nimperfect data curation, and intentional data contamination. Our experiments\nevaluate the effects of data poisoning on 23 frontier LLMs ranging from 1.5-72\nbillion parameters on three datasets which speak to each of our threat models.\nWe find that larger LLMs are increasingly vulnerable, learning harmful behavior\n-- including sleeper agent behavior -- significantly more quickly than smaller\nLLMs with even minimal data poisoning. These results underscore the need for\nrobust safeguards against data poisoning in larger LLMs.", "arxiv_id": "2408.02946v1", "pdf_url": "http://arxiv.org/pdf/2408.02946v1", "abstract_url": "http://arxiv.org/abs/2408.02946v1", "primary_category": "cs.CR", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Scaling Laws for Data Poisoning in LLMs", "response": "RELEVANT", "timestamp": "2024-08-19T13:44:52.744358"}
{"title": "Achieving More with Less: A Tensor-Optimization-Powered Ensemble Method", "authors": "Jinghui Yuan, Weijin Jiang, Zhe Cao, Fangyuan Xie, Rong Wang, Feiping Nie, Yuan Yuan", "abstract": "Ensemble learning is a method that leverages weak learners to produce a\nstrong learner. However, obtaining a large number of base learners requires\nsubstantial time and computational resources. Therefore, it is meaningful to\nstudy how to achieve the performance typically obtained with many base learners\nusing only a few. We argue that to achieve this, it is essential to enhance\nboth classification performance and generalization ability during the ensemble\nprocess. To increase model accuracy, each weak base learner needs to be more\nefficiently integrated. It is observed that different base learners exhibit\nvarying levels of accuracy in predicting different classes. To capitalize on\nthis, we introduce confidence tensors $\\tilde{\\mathbf{\\Theta}}$ and\n$\\tilde{\\mathbf{\\Theta}}_{rst}$ signifies the degree of confidence that the\n$t$-th base classifier assigns the sample to class $r$ while it actually\nbelongs to class $s$. To the best of our knowledge, this is the first time an\nevaluation of the performance of base classifiers across different classes has\nbeen proposed. The proposed confidence tensor compensates for the strengths and\nweaknesses of each base classifier in different classes, enabling the method to\nachieve superior results with a smaller number of base learners. To enhance\ngeneralization performance, we design a smooth and convex objective function\nthat leverages the concept of margin, making the strong learner more\ndiscriminative. Furthermore, it is proved that in gradient matrix of the loss\nfunction, the sum of each column's elements is zero, allowing us to solve a\nconstrained optimization problem using gradient-based methods. We then compare\nour algorithm with random forests of ten times the size and other classical\nmethods across numerous datasets, demonstrating the superiority of our\napproach.", "arxiv_id": "2408.02936v2", "pdf_url": "http://arxiv.org/pdf/2408.02936v2", "abstract_url": "http://arxiv.org/abs/2408.02936v2", "primary_category": "cs.LG", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Achieving More with Less: A Tensor-Optimization-Powered Ensemble Method", "response": "RELEVANT", "timestamp": "2024-08-19T13:44:53.518293"}
{"title": "Doubly Stochastic Adaptive Neighbors Clustering via the Marcus Mapping", "authors": "Jinghui Yuan, Chusheng Zeng, Fangyuan Xie, Zhe Cao, Mulin Chen, Rong Wang, Feiping Nie, Yuan Yuan", "abstract": "Clustering is a fundamental task in machine learning and data science, and\nsimilarity graph-based clustering is an important approach within this domain.\nDoubly stochastic symmetric similarity graphs provide numerous benefits for\nclustering problems and downstream tasks, yet learning such graphs remains a\nsignificant challenge. Marcus theorem states that a strictly positive symmetric\nmatrix can be transformed into a doubly stochastic symmetric matrix by diagonal\nmatrices. However, in clustering, learning sparse matrices is crucial for\ncomputational efficiency. We extend Marcus theorem by proposing the Marcus\nmapping, which indicates that certain sparse matrices can also be transformed\ninto doubly stochastic symmetric matrices via diagonal matrices. Additionally,\nwe introduce rank constraints into the clustering problem and propose the\nDoubly Stochastic Adaptive Neighbors Clustering algorithm based on the Marcus\nMapping (ANCMM). This ensures that the learned graph naturally divides into the\ndesired number of clusters. We validate the effectiveness of our algorithm\nthrough extensive comparisons with state-of-the-art algorithms. Finally, we\nexplore the relationship between the Marcus mapping and optimal transport. We\nprove that the Marcus mapping solves a specific type of optimal transport\nproblem and demonstrate that solving this problem through Marcus mapping is\nmore efficient than directly applying optimal transport methods.", "arxiv_id": "2408.02932v2", "pdf_url": "http://arxiv.org/pdf/2408.02932v2", "abstract_url": "http://arxiv.org/abs/2408.02932v2", "primary_category": "cs.LG", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Doubly Stochastic Adaptive Neighbors Clustering via the Marcus Mapping", "response": "RELEVANT", "timestamp": "2024-08-19T13:44:54.370915"}
{"title": "The Need for a Big World Simulator: A Scientific Challenge for Continual Learning", "authors": "Saurabh Kumar, Hong Jun Jeon, Alex Lewandowski, Benjamin Van Roy", "abstract": "The \"small agent, big world\" frame offers a conceptual view that motivates\nthe need for continual learning. The idea is that a small agent operating in a\nmuch bigger world cannot store all information that the world has to offer. To\nperform well, the agent must be carefully designed to ingest, retain, and eject\nthe right information. To enable the development of performant continual\nlearning agents, a number of synthetic environments have been proposed.\nHowever, these benchmarks suffer from limitations, including unnatural\ndistribution shifts and a lack of fidelity to the \"small agent, big world\"\nframing. This paper aims to formalize two desiderata for the design of future\nsimulated environments. These two criteria aim to reflect the objectives and\ncomplexity of continual learning in practical settings while enabling rapid\nprototyping of algorithms on a smaller scale.", "arxiv_id": "2408.02930v1", "pdf_url": "http://arxiv.org/pdf/2408.02930v1", "abstract_url": "http://arxiv.org/abs/2408.02930v1", "primary_category": "cs.LG", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "The Need for a Big World Simulator: A Scientific Challenge for Continual Learning", "response": "RELEVANT", "timestamp": "2024-08-19T13:44:55.099749"}
{"title": "HARMONIC: Harnessing LLMs for Tabular Data Synthesis and Privacy Protection", "authors": "Yuxin Wang, Duanyu Feng, Yongfu Dai, Zhengyu Chen, Jimin Huang, Sophia Ananiadou, Qianqian Xie, Hao Wang", "abstract": "Data serves as the fundamental foundation for advancing deep learning,\nparticularly tabular data presented in a structured format, which is highly\nconducive to modeling. However, even in the era of LLM, obtaining tabular data\nfrom sensitive domains remains a challenge due to privacy or copyright\nconcerns. Hence, exploring how to effectively use models like LLMs to generate\nrealistic and privacy-preserving synthetic tabular data is urgent. In this\npaper, we take a step forward to explore LLMs for tabular data synthesis and\nprivacy protection, by introducing a new framework HARMONIC for tabular data\ngeneration and evaluation. In the tabular data generation of our framework,\nunlike previous small-scale LLM-based methods that rely on continued\npre-training, we explore the larger-scale LLMs with fine-tuning to generate\ntabular data and enhance privacy. Based on idea of the k-nearest neighbors\nalgorithm, an instruction fine-tuning dataset is constructed to inspire LLMs to\ndiscover inter-row relationships. Then, with fine-tuning, LLMs are trained to\nremember the format and connections of the data rather than the data itself,\nwhich reduces the risk of privacy leakage. In the evaluation part of our\nframework, we develop specific privacy risk metrics DLT for LLM synthetic data\ngeneration, as well as performance evaluation metrics LLE for downstream LLM\ntasks. Our experiments find that this tabular data generation framework\nachieves equivalent performance to existing methods with better privacy, which\nalso demonstrates our evaluation framework for the effectiveness of synthetic\ndata and privacy risks in LLM scenarios.", "arxiv_id": "2408.02927v1", "pdf_url": "http://arxiv.org/pdf/2408.02927v1", "abstract_url": "http://arxiv.org/abs/2408.02927v1", "primary_category": "cs.LG", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "HARMONIC: Harnessing LLMs for Tabular Data Synthesis and Privacy Protection", "response": "RELEVANT", "timestamp": "2024-08-19T13:44:55.920032"}
{"title": "A Metric Driven Approach to Mixed Precision Training", "authors": "Mitchelle Rasquinha, Gil Tabak", "abstract": "As deep learning methodologies have developed, it has been generally agreed\nthat increasing neural network size improves model quality. However, this is at\nthe expense of memory and compute requirements, which also need to be\nincreased. Various efficiency techniques have been proposed to rein in hardware\ncosts, one being the use of low precision numerics. Recent accelerators have\nintroduced several different 8-bit data types to help accommodate DNNs in terms\nof numerics. In this paper, we identify a metric driven methodology to aid in\nthe choice of numerics. We demonstrate how such a methodology can help scale\ntraining of a language representation model. The technique can be generalized\nto other model architectures.", "arxiv_id": "2408.02897v1", "pdf_url": "http://arxiv.org/pdf/2408.02897v1", "abstract_url": "http://arxiv.org/abs/2408.02897v1", "primary_category": "cs.LG", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "A Metric Driven Approach to Mixed Precision Training", "response": "RELEVANT", "timestamp": "2024-08-19T13:44:56.840750"}
{"title": "Compromising Embodied Agents with Contextual Backdoor Attacks", "authors": "Aishan Liu, Yuguang Zhou, Xianglong Liu, Tianyuan Zhang, Siyuan Liang, Jiakai Wang, Yanjun Pu, Tianlin Li, Junqi Zhang, Wenbo Zhou, Qing Guo, Dacheng Tao", "abstract": "Large language models (LLMs) have transformed the development of embodied\nintelligence. By providing a few contextual demonstrations, developers can\nutilize the extensive internal knowledge of LLMs to effortlessly translate\ncomplex tasks described in abstract language into sequences of code snippets,\nwhich will serve as the execution logic for embodied agents. However, this\npaper uncovers a significant backdoor security threat within this process and\nintroduces a novel method called \\method{}. By poisoning just a few contextual\ndemonstrations, attackers can covertly compromise the contextual environment of\na black-box LLM, prompting it to generate programs with context-dependent\ndefects. These programs appear logically sound but contain defects that can\nactivate and induce unintended behaviors when the operational agent encounters\nspecific triggers in its interactive environment. To compromise the LLM's\ncontextual environment, we employ adversarial in-context generation to optimize\npoisoned demonstrations, where an LLM judge evaluates these poisoned prompts,\nreporting to an additional LLM that iteratively optimizes the demonstration in\na two-player adversarial game using chain-of-thought reasoning. To enable\ncontext-dependent behaviors in downstream agents, we implement a dual-modality\nactivation strategy that controls both the generation and execution of program\ndefects through textual and visual triggers. We expand the scope of our attack\nby developing five program defect modes that compromise key aspects of\nconfidentiality, integrity, and availability in embodied agents. To validate\nthe effectiveness of our approach, we conducted extensive experiments across\nvarious tasks, including robot planning, robot manipulation, and compositional\nvisual reasoning. Additionally, we demonstrate the potential impact of our\napproach by successfully attacking real-world autonomous driving systems.", "arxiv_id": "2408.02882v1", "pdf_url": "http://arxiv.org/pdf/2408.02882v1", "abstract_url": "http://arxiv.org/abs/2408.02882v1", "primary_category": "cs.AI", "published_date": "2024-08-06", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Compromising Embodied Agents with Contextual Backdoor Attacks", "response": "RELEVANT", "timestamp": "2024-08-19T13:44:57.763310"}
{"title": "Back-Projection Diffusion: Solving the Wideband Inverse Scattering Problem with Diffusion Models", "authors": "Borong Zhang, Mart\u00edn Guerra, Qin Li, Leonardo Zepeda-N\u00fa\u00f1ez", "abstract": "We present Wideband back-projection diffusion, an end-to-end probabilistic\nframework for approximating the posterior distribution induced by the inverse\nscattering map from wideband scattering data. This framework leverages\nconditional diffusion models coupled with the underlying physics of\nwave-propagation and symmetries in the problem, to produce highly accurate\nreconstructions. The framework introduces a factorization of the score function\ninto a physics-based latent representation inspired by the filtered\nback-propagation formula and a conditional score function conditioned on this\nlatent representation. These two steps are also constrained to obey symmetries\nin the formulation while being amenable to compression by imposing the rank\nstructure found in the filtered back-projection formula. As a result,\nempirically, our framework is able to provide sharp reconstructions\neffortlessly, even recovering sub-Nyquist features in the multiple-scattering\nregime. It has low-sample and computational complexity, its number of\nparameters scales sub-linearly with the target resolution, and it has stable\ntraining dynamics.", "arxiv_id": "2408.02866v2", "pdf_url": "http://arxiv.org/pdf/2408.02866v2", "abstract_url": "http://arxiv.org/abs/2408.02866v2", "primary_category": "cs.LG", "published_date": "2024-08-05", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Back-Projection Diffusion: Solving the Wideband Inverse Scattering Problem with Diffusion Models", "response": "RELEVANT", "timestamp": "2024-08-19T13:44:58.593136"}
{"title": "A Framework for Fine-Tuning LLMs using Heterogeneous Feedback", "authors": "Ryan Aponte, Ryan A. Rossi, Shunan Guo, Franck Dernoncourt, Tong Yu, Xiang Chen, Subrata Mitra, Nedim Lipka", "abstract": "Large language models (LLMs) have been applied to a wide range of tasks,\nincluding text summarization, web navigation, and chatbots. They have\nbenefitted from supervised fine-tuning (SFT) and reinforcement learning from\nhuman feedback (RLHF) following an unsupervised pretraining. These datasets can\nbe difficult to collect, limited in scope, and vary in sample quality.\nAdditionally, datasets can vary extensively in supervision format, from\nnumerical to binary as well as multi-dimensional with many different values. We\npresent a framework for fine-tuning LLMs using heterogeneous feedback, which\nhas two main components. First, we combine the heterogeneous feedback data into\na single supervision format, compatible with methods like SFT and RLHF. Next,\ngiven this unified feedback dataset, we extract a high-quality and diverse\nsubset to obtain performance increases potentially exceeding the full dataset.\nWe conduct extensive experiments to understand the effectiveness of these\ntechniques for incorporating heterogeneous feedback, and demonstrate\nimprovements from using a high-quality and diverse subset of the data. We find\nthat our framework is able to improve models in multiple areas simultaneously,\nsuch as in instruction following and bias reduction.", "arxiv_id": "2408.02861v1", "pdf_url": "http://arxiv.org/pdf/2408.02861v1", "abstract_url": "http://arxiv.org/abs/2408.02861v1", "primary_category": "cs.CL", "published_date": "2024-08-05", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "A Framework for Fine-Tuning LLMs using Heterogeneous Feedback", "response": "RELEVANT", "timestamp": "2024-08-19T13:44:59.428056"}
{"title": "Active Learning for WBAN-based Health Monitoring", "authors": "Cho-Chun Chiu, Tuan Nguyen, Ting He, Shiqiang Wang, Beom-Su Kim, Ki-Il Kim", "abstract": "We consider a novel active learning problem motivated by the need of learning\nmachine learning models for health monitoring in wireless body area network\n(WBAN). Due to the limited resources at body sensors, collecting each unlabeled\nsample in WBAN incurs a nontrivial cost. Moreover, training health monitoring\nmodels typically requires labels indicating the patient's health state that\nneed to be generated by healthcare professionals, which cannot be obtained at\nthe same pace as data collection. These challenges make our problem\nfundamentally different from classical active learning, where unlabeled samples\nare free and labels can be queried in real time. To handle these challenges, we\npropose a two-phased active learning method, consisting of an online phase\nwhere a coreset construction algorithm is proposed to select a subset of\nunlabeled samples based on their noisy predictions, and an offline phase where\nthe selected samples are labeled to train the target model. The samples\nselected by our algorithm are proved to yield a guaranteed error in\napproximating the full dataset in evaluating the loss function. Our evaluation\nbased on real health monitoring data and our own experimentation demonstrates\nthat our solution can drastically save the data curation cost without\nsacrificing the quality of the target model.", "arxiv_id": "2408.02849v1", "pdf_url": "http://arxiv.org/pdf/2408.02849v1", "abstract_url": "http://arxiv.org/abs/2408.02849v1", "primary_category": "cs.LG", "published_date": "2024-08-05", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Active Learning for WBAN-based Health Monitoring", "response": "RELEVANT", "timestamp": "2024-08-19T13:45:00.322293"}
{"title": "Quantum Transfer Learning for MNIST Classification Using a Hybrid Quantum-Classical Approach", "authors": "Soumyadip Sarkar", "abstract": "In this research, we explore the integration of quantum computing with\nclassical machine learning for image classification tasks, specifically\nfocusing on the MNIST dataset. We propose a hybrid quantum-classical approach\nthat leverages the strengths of both paradigms. The process begins with\npreprocessing the MNIST dataset, normalizing the pixel values, and reshaping\nthe images into vectors. An autoencoder compresses these 784-dimensional\nvectors into a 64-dimensional latent space, effectively reducing the data's\ndimensionality while preserving essential features. These compressed features\nare then processed using a quantum circuit implemented on a 5-qubit system. The\nquantum circuit applies rotation gates based on the feature values, followed by\nHadamard and CNOT gates to entangle the qubits, and measurements are taken to\ngenerate quantum outcomes. These outcomes serve as input for a classical neural\nnetwork designed to classify the MNIST digits. The classical neural network\ncomprises multiple dense layers with batch normalization and dropout to enhance\ngeneralization and performance. We evaluate the performance of this hybrid\nmodel and compare it with a purely classical approach. The experimental results\nindicate that while the hybrid model demonstrates the feasibility of\nintegrating quantum computing with classical techniques, the accuracy of the\nfinal model, trained on quantum outcomes, is currently lower than the classical\nmodel trained on compressed features. This research highlights the potential of\nquantum computing in machine learning, though further optimization and advanced\nquantum algorithms are necessary to achieve superior performance.", "arxiv_id": "2408.03351v1", "pdf_url": "http://arxiv.org/pdf/2408.03351v1", "abstract_url": "http://arxiv.org/abs/2408.03351v1", "primary_category": "quant-ph", "published_date": "2024-08-05", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Quantum Transfer Learning for MNIST Classification Using a Hybrid Quantum-Classical Approach", "response": "RELEVANT", "timestamp": "2024-08-19T13:45:01.141578"}
{"title": "Heterogeneous graph attention network improves cancer multiomics integration", "authors": "Sina Tabakhi, Charlotte Vandermeulen, Ian Sudbery, Haiping Lu", "abstract": "The increase in high-dimensional multiomics data demands advanced integration\nmodels to capture the complexity of human diseases. Graph-based deep learning\nintegration models, despite their promise, struggle with small patient cohorts\nand high-dimensional features, often applying independent feature selection\nwithout modeling relationships among omics. Furthermore, conventional\ngraph-based omics models focus on homogeneous graphs, lacking multiple types of\nnodes and edges to capture diverse structures. We introduce a Heterogeneous\nGraph ATtention network for omics integration (HeteroGATomics) to improve\ncancer diagnosis. HeteroGATomics performs joint feature selection through a\nmulti-agent system, creating dedicated networks of feature and patient\nsimilarity for each omic modality. These networks are then combined into one\nheterogeneous graph for learning holistic omic-specific representations and\nintegrating predictions across modalities. Experiments on three cancer\nmultiomics datasets demonstrate HeteroGATomics' superior performance in cancer\ndiagnosis. Moreover, HeteroGATomics enhances interpretability by identifying\nimportant biomarkers contributing to the diagnosis outcomes.", "arxiv_id": "2408.02845v1", "pdf_url": "http://arxiv.org/pdf/2408.02845v1", "abstract_url": "http://arxiv.org/abs/2408.02845v1", "primary_category": "cs.LG", "published_date": "2024-08-05", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Heterogeneous graph attention network improves cancer multiomics integration", "response": "RELEVANT", "timestamp": "2024-08-19T13:45:02.021524"}
{"title": "Evaluating Posterior Probabilities: Decision Theory, Proper Scoring Rules, and Calibration", "authors": "Luciana Ferrer, Daniel Ramos", "abstract": "Most machine learning classifiers are designed to output posterior\nprobabilities for the classes given the input sample. These probabilities may\nbe used to make the categorical decision on the class of the sample; provided\nas input to a downstream system; or provided to a human for interpretation.\nEvaluating the quality of the posteriors generated by these system is an\nessential problem which was addressed decades ago with the invention of proper\nscoring rules (PSRs). Unfortunately, much of the recent machine learning\nliterature uses calibration metrics -- most commonly, the expected calibration\nerror (ECE) -- as a proxy to assess posterior performance. The problem with\nthis approach is that calibration metrics reflect only one aspect of the\nquality of the posteriors, ignoring the discrimination performance. For this\nreason, we argue that calibration metrics should play no role in the assessment\nof posterior quality. Expected PSRs should instead be used for this job,\npreferably normalized for ease of interpretation. In this work, we first give a\nbrief review of PSRs from a practical perspective, motivating their definition\nusing Bayes decision theory. We discuss why expected PSRs provide a principled\nmeasure of the quality of a system's posteriors and why calibration metrics are\nnot the right tool for this job. We argue that calibration metrics, while not\nuseful for performance assessment, may be used as diagnostic tools during\nsystem development. With this purpose in mind, we discuss a simple and\npractical calibration metric, called calibration loss, derived from a\ndecomposition of expected PSRs. We compare this metric with the ECE and with\nthe expected score divergence calibration metric from the PSR literature and\nargue, using theoretical and empirical evidence, that calibration loss is\nsuperior to these two metrics.", "arxiv_id": "2408.02841v1", "pdf_url": "http://arxiv.org/pdf/2408.02841v1", "abstract_url": "http://arxiv.org/abs/2408.02841v1", "primary_category": "stat.ML", "published_date": "2024-08-05", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Evaluating Posterior Probabilities: Decision Theory, Proper Scoring Rules, and Calibration", "response": "RELEVANT", "timestamp": "2024-08-19T13:45:02.885778"}
{"title": "Optimizing Cox Models with Stochastic Gradient Descent: Theoretical Foundations and Practical Guidances", "authors": "Lang Zeng, Weijing Tang, Zhao Ren, Ying Ding", "abstract": "Optimizing Cox regression and its neural network variants poses substantial\ncomputational challenges in large-scale studies. Stochastic gradient descent\n(SGD), known for its scalability in model optimization, has recently been\nadapted to optimize Cox models. Unlike its conventional application, which\ntypically targets a sum of independent individual loss, SGD for Cox models\nupdates parameters based on the partial likelihood of a subset of data. Despite\nits empirical success, the theoretical foundation for optimizing Cox partial\nlikelihood with SGD is largely underexplored. In this work, we demonstrate that\nthe SGD estimator targets an objective function that is batch-size-dependent.\nWe establish that the SGD estimator for the Cox neural network (Cox-NN) is\nconsistent and achieves the optimal minimax convergence rate up to a\npolylogarithmic factor. For Cox regression, we further prove the\n$\\sqrt{n}$-consistency and asymptotic normality of the SGD estimator, with\nvariance depending on the batch size. Furthermore, we quantify the impact of\nbatch size on Cox-NN training and its effect on the SGD estimator's asymptotic\nefficiency in Cox regression. These findings are validated by extensive\nnumerical experiments and provide guidance for selecting batch sizes in SGD\napplications. Finally, we demonstrate the effectiveness of SGD in a real-world\napplication where GD is unfeasible due to the large scale of data.", "arxiv_id": "2408.02839v1", "pdf_url": "http://arxiv.org/pdf/2408.02839v1", "abstract_url": "http://arxiv.org/abs/2408.02839v1", "primary_category": "stat.ML", "published_date": "2024-08-05", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Optimizing Cox Models with Stochastic Gradient Descent: Theoretical Foundations and Practical Guidances", "response": "RELEVANT", "timestamp": "2024-08-19T13:45:03.701380"}
{"title": "Interpretation of the Intent Detection Problem as Dynamics in a Low-dimensional Space", "authors": "Eduardo Sanchez-Karhunen, Jose F. Quesada-Moreno, Miguel A. Guti\u00e9rrez-Naranjo", "abstract": "Intent detection is a text classification task whose aim is to recognize and\nlabel the semantics behind a users query. It plays a critical role in various\nbusiness applications. The output of the intent detection module strongly\nconditions the behavior of the whole system. This sequence analysis task is\nmainly tackled using deep learning techniques. Despite the widespread use of\nthese techniques, the internal mechanisms used by networks to solve the problem\nare poorly understood. Recent lines of work have analyzed the computational\nmechanisms learned by RNNs from a dynamical systems perspective. In this work,\nwe investigate how different RNN architectures solve the SNIPS intent detection\nproblem. Sentences injected into trained networks can be interpreted as\ntrajectories traversing a hidden state space. This space is constrained to a\nlow-dimensional manifold whose dimensionality is related to the embedding and\nhidden layer sizes. To generate predictions, RNN steers the trajectories\ntowards concrete regions, spatially aligned with the output layer matrix rows\ndirections. Underlying the system dynamics, an unexpected fixed point topology\nhas been identified with a limited number of attractors. Our results provide\nnew insights into the inner workings of networks that solve the intent\ndetection task.", "arxiv_id": "2408.02838v1", "pdf_url": "http://arxiv.org/pdf/2408.02838v1", "abstract_url": "http://arxiv.org/abs/2408.02838v1", "primary_category": "cs.LG", "published_date": "2024-08-05", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Interpretation of the Intent Detection Problem as Dynamics in a Low-dimensional Space", "response": "RELEVANT", "timestamp": "2024-08-19T13:45:04.725666"}
{"title": "Training a multilayer dynamical spintronic network with standard machine learning tools to perform time series classification", "authors": "Erwan Plouet, D\u00e9dalo Sanz-Hern\u00e1ndez, Aymeric Vecchiola, Julie Grollier, Frank Mizrahi", "abstract": "The ability to process time-series at low energy cost is critical for many\napplications. Recurrent neural network, which can perform such tasks, are\ncomputationally expensive when implementing in software on conventional\ncomputers. Here we propose to implement a recurrent neural network in hardware\nusing spintronic oscillators as dynamical neurons. Using numerical simulations,\nwe build a multi-layer network and demonstrate that we can use backpropagation\nthrough time (BPTT) and standard machine learning tools to train this network.\nLeveraging the transient dynamics of the spintronic oscillators, we solve the\nsequential digits classification task with $89.83\\pm2.91~\\%$ accuracy, as good\nas the equivalent software network. We devise guidelines on how to choose the\ntime constant of the oscillators as well as hyper-parameters of the network to\nadapt to different input time scales.", "arxiv_id": "2408.02835v2", "pdf_url": "http://arxiv.org/pdf/2408.02835v2", "abstract_url": "http://arxiv.org/abs/2408.02835v2", "primary_category": "cond-mat.dis-nn", "published_date": "2024-08-05", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Training a multilayer dynamical spintronic network with standard machine learning tools to perform time series classification", "response": "RELEVANT", "timestamp": "2024-08-19T13:45:05.577820"}
{"title": "DaCapo: a modular deep learning framework for scalable 3D image segmentation", "authors": "William Patton, Jeff L. Rhoades, Marwan Zouinkhi, David G. Ackerman, Caroline Malin-Mayor, Diane Adjavon, Larissa Heinrich, Davis Bennett, Yurii Zubov, CellMap Project Team, Aubrey V. Weigel, Jan Funke", "abstract": "DaCapo is a specialized deep learning library tailored to expedite the\ntraining and application of existing machine learning approaches on large,\nnear-isotropic image data. In this correspondence, we introduce DaCapo's unique\nfeatures optimized for this specific domain, highlighting its modular\nstructure, efficient experiment management tools, and scalable deployment\ncapabilities. We discuss its potential to improve access to large-scale,\nisotropic image segmentation and invite the community to explore and contribute\nto this open-source initiative.", "arxiv_id": "2408.02834v1", "pdf_url": "http://arxiv.org/pdf/2408.02834v1", "abstract_url": "http://arxiv.org/abs/2408.02834v1", "primary_category": "cs.CV", "published_date": "2024-08-05", "votes": 0, "preferences": "LLM reasoning", "response": "NOT_ENOUGH_RELATED"}
{"title": "DaCapo: a modular deep learning framework for scalable 3D image segmentation", "response": "NOT_ENOUGH_RELATED", "timestamp": "2024-08-19T13:45:06.522423"}
{"title": "Adaptive Learning for Quantum Linear Regression", "authors": "Costantino Carugno, Maurizio Ferrari Dacrema, Paolo Cremonesi", "abstract": "The recent availability of quantum annealers as cloud-based services has\nenabled new ways to handle machine learning problems, and several relevant\nalgorithms have been adapted to run on these devices. In a recent work, linear\nregression was formulated as a quadratic binary optimization problem that can\nbe solved via quantum annealing. Although this approach promises a\ncomputational time advantage for large datasets, the quality of the solution is\nlimited by the necessary use of a precision vector, used to approximate the\nreal-numbered regression coefficients in the quantum formulation. In this work,\nwe focus on the practical challenge of improving the precision vector encoding:\ninstead of setting an array of generic values equal for all coefficients, we\nallow each one to be expressed by its specific precision, which is tuned with a\nsimple adaptive algorithm. This approach is evaluated on synthetic datasets of\nincreasing size, and linear regression is solved using the D-Wave Advantage\nquantum annealer, as well as classical solvers. To the best of our knowledge,\nthis is the largest dataset ever evaluated for linear regression on a quantum\nannealer. The results show that our formulation is able to deliver improved\nsolution quality in all instances, and could better exploit the potential of\ncurrent quantum devices.", "arxiv_id": "2408.02833v1", "pdf_url": "http://arxiv.org/pdf/2408.02833v1", "abstract_url": "http://arxiv.org/abs/2408.02833v1", "primary_category": "quant-ph", "published_date": "2024-08-05", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Adaptive Learning for Quantum Linear Regression", "response": "RELEVANT", "timestamp": "2024-08-19T13:45:07.529591"}
{"title": "Setting the duration of online A/B experiments", "authors": "Harrison H. Li, Chaoyu Yu", "abstract": "In designing an online A/B experiment, it is crucial to select a sample size\nand duration that ensure the resulting confidence interval (CI) for the\ntreatment effect is the right width to detect an effect of meaningful magnitude\nwith sufficient statistical power without wasting resources. While the\nrelationship between sample size and CI width is well understood, the effect of\nexperiment duration on CI width remains less clear. This paper provides an\nanalytical formula for the width of a CI based on a ratio treatment effect\nestimator as a function of both sample size (N) and duration (T). The formula\nis derived from a mixed effects model with two variance components. One\ncomponent, referred to as the temporal variance, persists over time for\nexperiments where the same users are kept in the same experiment arm across\ndifferent days. The remaining error variance component, by contrast, decays to\nzero as T gets large. The formula we derive introduces a key parameter that we\ncall the user-specific temporal correlation (UTC), which quantifies the\nrelative sizes of the two variance components and can be estimated from\nhistorical experiments. Higher UTC indicates a slower decay in CI width over\ntime. On the other hand, when the UTC is 0 -- as for experiments where users\nshuffle in and out of the experiment across days -- the CI width decays at the\nstandard parametric 1/T rate. We also study how access to pre-period data for\nthe users in the experiment affects the CI width decay. We show our formula\nclosely explains CI widths on real A/B experiments at YouTube.", "arxiv_id": "2408.02830v1", "pdf_url": "http://arxiv.org/pdf/2408.02830v1", "abstract_url": "http://arxiv.org/abs/2408.02830v1", "primary_category": "stat.ME", "published_date": "2024-08-05", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Setting the duration of online A/B experiments", "response": "RELEVANT", "timestamp": "2024-08-19T13:45:08.402803"}
{"title": "Wave-RVFL: A Randomized Neural Network Based on Wave Loss Function", "authors": "M. Sajid, A. Quadir, M. Tanveer", "abstract": "The random vector functional link (RVFL) network is well-regarded for its\nstrong generalization capabilities in the field of machine learning. However,\nits inherent dependencies on the square loss function make it susceptible to\nnoise and outliers. Furthermore, the calculation of RVFL's unknown parameters\nnecessitates matrix inversion of the entire training sample, which constrains\nits scalability. To address these challenges, we propose the Wave-RVFL, an RVFL\nmodel incorporating the wave loss function. We formulate and solve the proposed\noptimization problem of the Wave-RVFL using the adaptive moment estimation\n(Adam) algorithm in a way that successfully eliminates the requirement for\nmatrix inversion and significantly enhances scalability. The Wave-RVFL exhibits\nrobustness against noise and outliers by preventing over-penalization of\ndeviations, thereby maintaining a balanced approach to managing noise and\noutliers. The proposed Wave-RVFL model is evaluated on multiple UCI datasets,\nboth with and without the addition of noise and outliers, across various\ndomains and sizes. Empirical results affirm the superior performance and\nrobustness of the Wave-RVFL compared to baseline models, establishing it as a\nhighly effective and scalable classification solution.", "arxiv_id": "2408.02824v1", "pdf_url": "http://arxiv.org/pdf/2408.02824v1", "abstract_url": "http://arxiv.org/abs/2408.02824v1", "primary_category": "cs.LG", "published_date": "2024-08-05", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Wave-RVFL: A Randomized Neural Network Based on Wave Loss Function", "response": "RELEVANT", "timestamp": "2024-08-19T13:45:09.129086"}
{"title": "Continuous Monitoring via Repeated Significance", "authors": "Eric Bax, Arundhyoti Sarkar, Alex Shtoff", "abstract": "Requiring statistical significance at multiple interim analyses to declare a\nstatistically significant result for an AB test allows less stringent\nrequirements for significance at each interim analysis. Repeated repeated\nsignificance competes well with methods built on assumptions about the test --\nassumptions that may be impossible to evaluate a priori and may require extra\ndata to evaluate empirically.\n  Instead, requiring repeated significance allows the data itself to prove\ndirectly that the required results are not due to chance alone. We explain how\nto apply tests with repeated significance to continuously monitor unbounded\ntests -- tests that do not have an a priori bound on running time or number of\nobservations. We show that it is impossible to maintain a constant requirement\nfor significance for unbounded tests, but that we can come arbitrarily close to\nthat goal.", "arxiv_id": "2408.02821v1", "pdf_url": "http://arxiv.org/pdf/2408.02821v1", "abstract_url": "http://arxiv.org/abs/2408.02821v1", "primary_category": "stat.ME", "published_date": "2024-08-05", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Continuous Monitoring via Repeated Significance", "response": "RELEVANT", "timestamp": "2024-08-19T13:45:09.846325"}
{"title": "Pre-trained Encoder Inference: Revealing Upstream Encoders In Downstream Machine Learning Services", "authors": "Shaopeng Fu, Xuexue Sun, Ke Qing, Tianhang Zheng, Di Wang", "abstract": "Though pre-trained encoders can be easily accessed online to build downstream\nmachine learning (ML) services quickly, various attacks have been designed to\ncompromise the security and privacy of these encoders. While most attacks\ntarget encoders on the upstream side, it remains unknown how an encoder could\nbe threatened when deployed in a downstream ML service. This paper unveils a\nnew vulnerability: the Pre-trained Encoder Inference (PEI) attack, which posts\nprivacy threats toward encoders hidden behind downstream ML services. By only\nproviding API accesses to a targeted downstream service and a set of candidate\nencoders, the PEI attack can infer which encoder is secretly used by the\ntargeted service based on candidate ones. We evaluate the attack performance of\nPEI against real-world encoders on three downstream tasks: image\nclassification, text classification, and text-to-image generation. Experiments\nshow that the PEI attack succeeds in revealing the hidden encoder in most cases\nand seldom makes mistakes even when the hidden encoder is not in the candidate\nset. We also conducted a case study on one of the most recent vision-language\nmodels, LLaVA, to illustrate that the PEI attack is useful in assisting other\nML attacks such as adversarial attacks. The code is available at\nhttps://github.com/fshp971/encoder-inference.", "arxiv_id": "2408.02814v1", "pdf_url": "http://arxiv.org/pdf/2408.02814v1", "abstract_url": "http://arxiv.org/abs/2408.02814v1", "primary_category": "cs.LG", "published_date": "2024-08-05", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Pre-trained Encoder Inference: Revealing Upstream Encoders In Downstream Machine Learning Services", "response": "RELEVANT", "timestamp": "2024-08-19T13:45:10.665371"}
{"title": "Mitigating Malicious Attacks in Federated Learning via Confidence-aware Defense", "authors": "Qilei Li, Ahmed M. Abdelmoniem", "abstract": "Federated Learning (FL) is an emerging distributed machine learning paradigm\nthat allows multiple clients to collaboratively train a global model without\nsharing private local data. However, FL systems are vulnerable to attacks from\nmalicious clients, who can degrade the global model performance through data\npoisoning and model poisoning. Existing defense methods typically focus on a\nsingle type of attack, such as Byzantine attacks or backdoor attacks, and are\noften ineffective against potential data poisoning attacks like label flipping\nand label shuffling. Additionally, these methods often lack accuracy and\nrobustness in detecting and handling malicious updates. To address these\nissues, we propose a novel method based on model confidence scores, which\nevaluates the uncertainty of client model updates to detect and defend against\nmalicious clients. Our approach is comprehensively effective for both model\npoisoning and data poisoning attacks and is capable of accurately identifying\nand mitigating potential malicious updates from being aggregated. Experimental\nresults demonstrate that our method significantly improves the robustness of FL\nsystems against various types of attacks, also achieving higher model accuracy\nand stability across various scenarios.", "arxiv_id": "2408.02813v1", "pdf_url": "http://arxiv.org/pdf/2408.02813v1", "abstract_url": "http://arxiv.org/abs/2408.02813v1", "primary_category": "cs.LG", "published_date": "2024-08-05", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Mitigating Malicious Attacks in Federated Learning via Confidence-aware Defense", "response": "RELEVANT", "timestamp": "2024-08-19T13:45:11.482430"}
{"title": "miniCTX: Neural Theorem Proving with (Long-)Contexts", "authors": "Jiewen Hu, Thomas Zhu, Sean Welleck", "abstract": "We introduce miniCTX, which tests a model's ability to prove formal\nmathematical theorems that depend on new definitions, lemmas, or other\ncontextual information that was not observed during training. miniCTX contains\ntheorems sourced from real Lean projects and textbooks, each associated with a\ncontext that can span tens of thousands of tokens. Models are tasked with\nproving a theorem given access to code from the theorem's repository, which\ncontains context that is helpful or needed for the proof. As a baseline for\nminiCTX, we introduce file-tuning, a simple recipe that trains a model to\ngenerate a proof step conditioned on the preceding file contents. File-tuning\nsubstantially outperforms the traditional neural theorem proving approach that\nfine-tunes on states alone. Additionally, our file-tuned model improves\nperformance on the standard miniF2F benchmark, achieving a pass rate of 33.61%,\nwhich is a new state-of-the-art for 1.3B parameter models. Alongside miniCTX,\nwe offer ntp-toolkit for automatically extracting and annotating theorem\nproving data, making it easy to add new projects into miniCTX to ensure that\ncontexts are not seen during training. miniCTX offers a challenging and\nrealistic perspective on evaluating neural theorem provers.", "arxiv_id": "2408.03350v1", "pdf_url": "http://arxiv.org/pdf/2408.03350v1", "abstract_url": "http://arxiv.org/abs/2408.03350v1", "primary_category": "cs.AI", "published_date": "2024-08-05", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "miniCTX: Neural Theorem Proving with (Long-)Contexts", "response": "RELEVANT", "timestamp": "2024-08-19T13:45:12.631684"}
{"title": "Toward Smart Scheduling in Tapis", "authors": "Joe Stubbs, Smruti Padhy, Richard Cardone", "abstract": "The Tapis framework provides APIs for automating job execution on remote\nresources, including HPC clusters and servers running in the cloud. Tapis can\nsimplify the interaction with remote cyberinfrastructure (CI), but the current\nservices require users to specify the exact configuration of a job to run,\nincluding the system, queue, node count, and maximum run time, among other\nattributes. Moreover, the remote resources must be defined and configured in\nTapis before a job can be submitted. In this paper, we present our efforts to\ndevelop an intelligent job scheduling capability in Tapis, where various\nattributes about a job configuration can be automatically determined for the\nuser, and computational resources can be dynamically provisioned by Tapis for\nspecific jobs. We develop an overall architecture for such a feature, which\nsuggests a set of core challenges to be solved. Then, we focus on one such\nspecific challenge: predicting queue times for a job on different HPC systems\nand queues, and we present two sets of results based on machine learning\nmethods. Our first set of results cast the problem as a regression, which can\nbe used to select the best system from a list of existing options. Our second\nset of results frames the problem as a classification, allowing us to compare\nthe use of an existing system with a dynamically provisioned resource.", "arxiv_id": "2408.03349v1", "pdf_url": "http://arxiv.org/pdf/2408.03349v1", "abstract_url": "http://arxiv.org/abs/2408.03349v1", "primary_category": "cs.PF", "published_date": "2024-08-05", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Toward Smart Scheduling in Tapis", "response": "RELEVANT", "timestamp": "2024-08-19T13:45:13.531818"}
{"title": "Deciphering Air Travel Disruptions: A Machine Learning Approach", "authors": "Aravinda Jatavallabha, Jacob Gerlach, Aadithya Naresh", "abstract": "This research investigates flight delay trends by examining factors such as\ndeparture time, airline, and airport. It employs regression machine learning\nmethods to predict the contributions of various sources to delays. Time-series\nmodels, including LSTM, Hybrid LSTM, and Bi-LSTM, are compared with baseline\nregression models such as Multiple Regression, Decision Tree Regression, Random\nForest Regression, and Neural Network. Despite considerable errors in the\nbaseline models, the study aims to identify influential features in delay\nprediction, potentially informing flight planning strategies. Unlike previous\nwork, this research focuses on regression tasks and explores the use of\ntime-series models for predicting flight delays. It offers insights into\naviation operations by independently analyzing each delay component (e.g.,\nsecurity, weather).", "arxiv_id": "2408.02802v1", "pdf_url": "http://arxiv.org/pdf/2408.02802v1", "abstract_url": "http://arxiv.org/abs/2408.02802v1", "primary_category": "cs.LG", "published_date": "2024-08-05", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Deciphering Air Travel Disruptions: A Machine Learning Approach", "response": "RELEVANT", "timestamp": "2024-08-19T13:45:14.351290"}
{"title": "Sparse Deep Learning Models with the $\\ell_1$ Regularization", "authors": "Lixin Shen, Rui Wang, Yuesheng Xu, Mingsong Yan", "abstract": "Sparse neural networks are highly desirable in deep learning in reducing its\ncomplexity. The goal of this paper is to study how choices of regularization\nparameters influence the sparsity level of learned neural networks. We first\nderive the $\\ell_1$-norm sparsity-promoting deep learning models including\nsingle and multiple regularization parameters models, from a statistical\nviewpoint. We then characterize the sparsity level of a regularized neural\nnetwork in terms of the choice of the regularization parameters. Based on the\ncharacterizations, we develop iterative algorithms for selecting regularization\nparameters so that the weight parameters of the resulting deep neural network\nenjoy prescribed sparsity levels. Numerical experiments are presented to\ndemonstrate the effectiveness of the proposed algorithms in choosing desirable\nregularization parameters and obtaining corresponding neural networks having\nboth of predetermined sparsity levels and satisfactory approximation accuracy.", "arxiv_id": "2408.02801v1", "pdf_url": "http://arxiv.org/pdf/2408.02801v1", "abstract_url": "http://arxiv.org/abs/2408.02801v1", "primary_category": "cs.LG", "published_date": "2024-08-05", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Sparse Deep Learning Models with the $\\ell_1$ Regularization", "response": "RELEVANT", "timestamp": "2024-08-19T13:45:15.068382"}
{"title": "Examining Gender and Power on Wikipedia Through Face and Politeness", "authors": "Adil Soubki, Shyne Choi, Owen Rambow", "abstract": "We propose a framework for analyzing discourse by combining two\ninterdependent concepts from sociolinguistic theory: face acts and politeness.\nWhile politeness has robust existing tools and data, face acts are less\nresourced. We introduce a new corpus created by annotating Wikipedia talk pages\nwith face acts and we use this to train a face act tagger. We then employ our\nframework to study how face and politeness interact with gender and power in\ndiscussions between Wikipedia editors. Among other findings, we observe that\nfemale Wikipedians are not only more polite, which is consistent with prior\nstudies, but that this difference corresponds with significantly more language\ndirected at humbling aspects of their own face. Interestingly, the distinction\nnearly vanishes once limiting to editors with administrative power.", "arxiv_id": "2408.02798v1", "pdf_url": "http://arxiv.org/pdf/2408.02798v1", "abstract_url": "http://arxiv.org/abs/2408.02798v1", "primary_category": "cs.CL", "published_date": "2024-08-05", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Examining Gender and Power on Wikipedia Through Face and Politeness", "response": "RELEVANT", "timestamp": "2024-08-19T13:45:15.785178"}
{"title": "Algorithm-Informed Graph Neural Networks for Leakage Detection and Localization in Water Distribution Networks", "authors": "Zepeng Zhang, Olga Fink", "abstract": "Detecting and localizing leakages is a significant challenge for the\nefficient and sustainable management of water distribution networks (WDN).\nLeveraging the inherent graph structure of WDNs, recent approaches have used\ngraph-based data-driven methods. However, these methods often learn shortcuts\nthat work well with in-distribution data but fail to generalize to\nout-of-distribution data. To address this limitation and inspired by the\nperfect generalization ability of classical algorithms, we propose an\nalgorithm-informed graph neural network (AIGNN). Recognizing that WDNs function\nas flow networks, incorporating max-flow information can be beneficial for\ninferring pressures. In the proposed framework, we first train AIGNN to emulate\nthe Ford-Fulkerson algorithm for solving max-flow problems. This algorithmic\nknowledge is then transferred to address the pressure estimation problem in\nWDNs. Two AIGNNs are deployed, one to reconstruct pressure based on the current\nmeasurements, and another to predict pressure based on previous measurements.\nLeakages are detected and localized by comparing the outputs of the\nreconstructor and the predictor. By pretraining AIGNNs to reason like\nalgorithms, they are expected to extract more task-relevant and generalizable\nfeatures. Experimental results demonstrate that the proposed algorithm-informed\napproach achieves superior results with better generalization ability compared\nto GNNs that do not incorporate algorithmic knowledge.", "arxiv_id": "2408.02797v1", "pdf_url": "http://arxiv.org/pdf/2408.02797v1", "abstract_url": "http://arxiv.org/abs/2408.02797v1", "primary_category": "cs.LG", "published_date": "2024-08-05", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Algorithm-Informed Graph Neural Networks for Leakage Detection and Localization in Water Distribution Networks", "response": "RELEVANT", "timestamp": "2024-08-19T13:45:16.809353"}
{"title": "4D-Var using Hessian approximation and backpropagation applied to automatically-differentiable numerical and machine learning models", "authors": "Kylen Solvik, Stephen G. Penny, Stephan Hoyer", "abstract": "Constraining a numerical weather prediction (NWP) model with observations via\n4D variational (4D-Var) data assimilation is often difficult to implement in\npractice due to the need to develop and maintain a software-based tangent\nlinear model and adjoint model. One of the most common 4D-Var algorithms uses\nan incremental update procedure, which has been shown to be an approximation of\nthe Gauss-Newton method. Here we demonstrate that when using a forecast model\nthat supports automatic differentiation, an efficient and in some cases more\naccurate alternative approximation of the Gauss-Newton method can be applied by\ncombining backpropagation of errors with Hessian approximation. This approach\ncan be used with either a conventional numerical model implemented within a\nsoftware framework that supports automatic differentiation, or a machine\nlearning (ML) based surrogate model. We test the new approach on a variety of\nLorenz-96 and quasi-geostrophic models. The results indicate potential for a\ndeeper integration of modeling, data assimilation, and new technologies in a\nnext-generation of operational forecast systems that leverage weather models\ndesigned to support automatic differentiation.", "arxiv_id": "2408.02767v1", "pdf_url": "http://arxiv.org/pdf/2408.02767v1", "abstract_url": "http://arxiv.org/abs/2408.02767v1", "primary_category": "cs.LG", "published_date": "2024-08-05", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "4D-Var using Hessian approximation and backpropagation applied to automatically-differentiable numerical and machine learning models", "response": "RELEVANT", "timestamp": "2024-08-19T13:45:17.564494"}
{"title": "ConDL: Detector-Free Dense Image Matching", "authors": "Monika Kwiatkowski, Simon Matern, Olaf Hellwich", "abstract": "In this work, we introduce a deep-learning framework designed for estimating\ndense image correspondences. Our fully convolutional model generates dense\nfeature maps for images, where each pixel is associated with a descriptor that\ncan be matched across multiple images. Unlike previous methods, our model is\ntrained on synthetic data that includes significant distortions, such as\nperspective changes, illumination variations, shadows, and specular highlights.\nUtilizing contrastive learning, our feature maps achieve greater invariance to\nthese distortions, enabling robust matching. Notably, our method eliminates the\nneed for a keypoint detector, setting it apart from many existing\nimage-matching techniques.", "arxiv_id": "2408.02766v1", "pdf_url": "http://arxiv.org/pdf/2408.02766v1", "abstract_url": "http://arxiv.org/abs/2408.02766v1", "primary_category": "cs.CV", "published_date": "2024-08-05", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "ConDL: Detector-Free Dense Image Matching", "response": "RELEVANT", "timestamp": "2024-08-19T13:45:18.568884"}
{"title": "Dimensionality Reduction and Nearest Neighbors for Improving Out-of-Distribution Detection in Medical Image Segmentation", "authors": "McKell Woodland, Nihil Patel, Austin Castelo, Mais Al Taie, Mohamed Eltaher, Joshua P. Yung, Tucker J. Netherton, Tiffany L. Calderone, Jessica I. Sanchez, Darrel W. Cleere, Ahmed Elsaiey, Nakul Gupta, David Victor, Laura Beretta, Ankit B. Patel Kristy K. Brock", "abstract": "Clinically deployed deep learning-based segmentation models are known to fail\non data outside of their training distributions. While clinicians review the\nsegmentations, these models tend to perform well in most instances, which could\nexacerbate automation bias. Therefore, detecting out-of-distribution images at\ninference is critical to warn the clinicians that the model likely failed. This\nwork applied the Mahalanobis distance (MD) post hoc to the bottleneck features\nof four Swin UNETR and nnU-net models that segmented the liver on T1-weighted\nmagnetic resonance imaging and computed tomography. By reducing the dimensions\nof the bottleneck features with either principal component analysis or uniform\nmanifold approximation and projection, images the models failed on were\ndetected with high performance and minimal computational load. In addition,\nthis work explored a non-parametric alternative to the MD, a k-th nearest\nneighbors distance (KNN). KNN drastically improved scalability and performance\nover MD when both were applied to raw and average-pooled bottleneck features.", "arxiv_id": "2408.02761v1", "pdf_url": "http://arxiv.org/pdf/2408.02761v1", "abstract_url": "http://arxiv.org/abs/2408.02761v1", "primary_category": "cs.CV", "published_date": "2024-08-05", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Dimensionality Reduction and Nearest Neighbors for Improving Out-of-Distribution Detection in Medical Image Segmentation", "response": "RELEVANT", "timestamp": "2024-08-19T13:45:19.311847"}
{"title": "Classification of Raw MEG/EEG Data with Detach-Rocket Ensemble: An Improved ROCKET Algorithm for Multivariate Time Series Analysis", "authors": "Adri\u00e0 Solana, Erik Frans\u00e9n, Gonzalo Uribarri", "abstract": "Multivariate Time Series Classification (MTSC) is a ubiquitous problem in\nscience and engineering, particularly in neuroscience, where most data\nacquisition modalities involve the simultaneous time-dependent recording of\nbrain activity in multiple brain regions. In recent years, Random Convolutional\nKernel models such as ROCKET and MiniRocket have emerged as highly effective\ntime series classification algorithms, capable of achieving state-of-the-art\naccuracy results with low computational load. Despite their success, these\ntypes of models face two major challenges when employed in neuroscience: 1)\nthey struggle to deal with high-dimensional data such as EEG and MEG, and 2)\nthey are difficult to interpret. In this work, we present a novel ROCKET-based\nalgorithm, named Detach-Rocket Ensemble, that is specifically designed to\naddress these two problems in MTSC. Our algorithm leverages pruning to provide\nan integrated estimation of channel importance, and ensembles to achieve better\naccuracy and provide a label probability. Using a synthetic multivariate time\nseries classification dataset in which we control the amount of information\ncarried by each of the channels, we first show that our algorithm is able to\ncorrectly recover the channel importance for classification. Then, using two\nreal-world datasets, a MEG dataset and an EEG dataset, we show that\nDetach-Rocket Ensemble is able to provide both interpretable channel relevance\nand competitive classification accuracy, even when applied directly to the raw\nbrain data, without the need for feature engineering.", "arxiv_id": "2408.02760v1", "pdf_url": "http://arxiv.org/pdf/2408.02760v1", "abstract_url": "http://arxiv.org/abs/2408.02760v1", "primary_category": "cs.LG", "published_date": "2024-08-05", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "Classification of Raw MEG/EEG Data with Detach-Rocket Ensemble: An Improved ROCKET Algorithm for Multivariate Time Series Analysis", "response": "RELEVANT", "timestamp": "2024-08-19T13:45:20.022546"}
{"title": "A Novel Hybrid Approach for Tornado Prediction in the United States: Kalman-Convolutional BiLSTM with Multi-Head Attention", "authors": "Jiawei Zhou", "abstract": "Tornadoes are among the most intense atmospheric vortex phenomena and pose\nsignificant challenges for detection and forecasting. Conventional methods,\nwhich heavily depend on ground-based observations and radar data, are limited\nby issues such as decreased accuracy over greater distances and a high rate of\nfalse positives. To address these challenges, this study utilizes the Seamless\nHybrid Scan Reflectivity (SHSR) dataset from the Multi-Radar Multi-Sensor\n(MRMS) system, which integrates data from multiple radar sources to enhance\naccuracy. A novel hybrid model, the Kalman-Convolutional BiLSTM with Multi-Head\nAttention, is introduced to improve dynamic state estimation and capture both\nspatial and temporal dependencies within the data. This model demonstrates\nsuperior performance in precision, recall, F1-Score, and accuracy compared to\nmethods such as K-Nearest Neighbors (KNN) and LightGBM. The results highlight\nthe considerable potential of advanced machine learning techniques to improve\ntornado prediction and reduce false alarm rates. Future research will focus on\nexpanding datasets, exploring innovative model architectures, and incorporating\nlarge language models (LLMs) to provide deeper insights. This research\nintroduces a novel model for tornado prediction, offering a robust framework\nfor enhancing forecasting accuracy and public safety.", "arxiv_id": "2408.02751v1", "pdf_url": "http://arxiv.org/pdf/2408.02751v1", "abstract_url": "http://arxiv.org/abs/2408.02751v1", "primary_category": "cs.LG", "published_date": "2024-08-05", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "A Novel Hybrid Approach for Tornado Prediction in the United States: Kalman-Convolutional BiLSTM with Multi-Head Attention", "response": "RELEVANT", "timestamp": "2024-08-19T13:45:20.802605"}
{"title": "KAN we improve on HEP classification tasks? Kolmogorov-Arnold Networks applied to an LHC physics example", "authors": "Johannes Erdmann, Florian Mausolf, Jan Lukas Sp\u00e4h", "abstract": "Recently, Kolmogorov-Arnold Networks (KANs) have been proposed as an\nalternative to multilayer perceptrons, suggesting advantages in performance and\ninterpretability. We study a typical binary event classification task in\nhigh-energy physics including high-level features and comment on the\nperformance and interpretability of KANs in this context. We find that the\nlearned activation functions of a one-layer KAN resemble the log-likelihood\nratio of the input features. In deeper KANs, the activations in the first KAN\nlayer differ from those in the one-layer KAN, which indicates that the deeper\nKANs learn more complex representations of the data. We study KANs with\ndifferent depths and widths and we compare them to multilayer perceptrons in\nterms of performance and number of trainable parameters. For the chosen\nclassification task, we do not find that KANs are more parameter efficient.\nHowever, small KANs may offer advantages in terms of interpretability that come\nat the cost of only a moderate loss in performance.", "arxiv_id": "2408.02743v1", "pdf_url": "http://arxiv.org/pdf/2408.02743v1", "abstract_url": "http://arxiv.org/abs/2408.02743v1", "primary_category": "hep-ph", "published_date": "2024-08-05", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "KAN we improve on HEP classification tasks? Kolmogorov-Arnold Networks applied to an LHC physics example", "response": "RELEVANT", "timestamp": "2024-08-19T13:45:21.486165"}
{"title": "On Using Quasirandom Sequences in Machine Learning for Model Weight Initialization", "authors": "Andriy Miranskyy, Adam Sorrenti, Viral Thakar", "abstract": "The effectiveness of training neural networks directly impacts computational\ncosts, resource allocation, and model development timelines in machine learning\napplications. An optimizer's ability to train the model adequately (in terms of\ntrained model performance) depends on the model's initial weights. Model weight\ninitialization schemes use pseudorandom number generators (PRNGs) as a source\nof randomness.\n  We investigate whether substituting PRNGs for low-discrepancy quasirandom\nnumber generators (QRNGs) -- namely Sobol' sequences -- as a source of\nrandomness for initializers can improve model performance. We examine\nMulti-Layer Perceptrons (MLP), Convolutional Neural Networks (CNN), Long\nShort-Term Memory (LSTM), and Transformer architectures trained on MNIST,\nCIFAR-10, and IMDB datasets using SGD and Adam optimizers. Our analysis uses\nten initialization schemes: Glorot, He, Lecun (both Uniform and Normal);\nOrthogonal, Random Normal, Truncated Normal, and Random Uniform. Models with\nweights set using PRNG- and QRNG-based initializers are compared pairwise for\neach combination of dataset, architecture, optimizer, and initialization\nscheme.\n  Our findings indicate that QRNG-based neural network initializers either\nreach a higher accuracy or achieve the same accuracy more quickly than\nPRNG-based initializers in 60% of the 120 experiments conducted. Thus, using\nQRNG-based initializers instead of PRNG-based initializers can speed up and\nimprove model training.", "arxiv_id": "2408.02654v1", "pdf_url": "http://arxiv.org/pdf/2408.02654v1", "abstract_url": "http://arxiv.org/abs/2408.02654v1", "primary_category": "cs.LG", "published_date": "2024-08-05", "votes": 0, "preferences": "LLM reasoning", "response": "RELEVANT"}
{"title": "On Using Quasirandom Sequences in Machine Learning for Model Weight Initialization", "response": "RELEVANT", "timestamp": "2024-08-19T13:45:22.303955"}
